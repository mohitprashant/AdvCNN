{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUQ5JcwuKxRE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn,functional\n",
    "from torch.autograd import Variable\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ht-G8QSHLWHa"
   },
   "outputs": [],
   "source": [
    "location=''\n",
    "\n",
    "train=pd.read_csv(location+'mnist_train.csv')[:200]\n",
    "X_train=torch.from_numpy(train.loc[:,train.columns != \"label\"].values/255)\n",
    "Y_train=torch.from_numpy(train.label.values).type(torch.LongTensor)\n",
    "\n",
    "test=pd.read_csv(location+'mnist_test.csv')\n",
    "X_test=torch.from_numpy(test.loc[:,train.columns != \"label\"].values/255)\n",
    "Y_test=torch.from_numpy(test.label.values).type(torch.LongTensor)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(X_train,Y_train)\n",
    "test = torch.utils.data.TensorDataset(X_test,Y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = 200, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7p3fADtELskd"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.c1=nn.Conv2d(in_channels=1, out_channels=8, stride=2, kernel_size=4, padding=1)\n",
    "        self.l1=nn.Linear(288, 10)\n",
    "        \n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.c1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "\n",
    "        x=x.view(x.size(0), -1)\n",
    "\n",
    "        x=self.l1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iOsusc7HLztj"
   },
   "outputs": [],
   "source": [
    "model=CNN()\n",
    "model=model.double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "id": "-BX5G3nqL2Gl",
    "outputId": "be1f764a-1546-449d-c397-6fb8b395221d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 2.296..  Test Loss: 2.317..  Test Accuracy: 0.118\n",
      "Epoch: 2/10..  Training Loss: 2.277..  Test Loss: 2.305..  Test Accuracy: 0.119\n",
      "Epoch: 3/10..  Training Loss: 2.262..  Test Loss: 2.294..  Test Accuracy: 0.144\n",
      "Epoch: 4/10..  Training Loss: 2.248..  Test Loss: 2.281..  Test Accuracy: 0.166\n",
      "Epoch: 5/10..  Training Loss: 2.233..  Test Loss: 2.270..  Test Accuracy: 0.191\n",
      "Epoch: 6/10..  Training Loss: 2.220..  Test Loss: 2.261..  Test Accuracy: 0.206\n",
      "Epoch: 7/10..  Training Loss: 2.205..  Test Loss: 2.249..  Test Accuracy: 0.238\n",
      "Epoch: 8/10..  Training Loss: 2.191..  Test Loss: 2.238..  Test Accuracy: 0.253\n",
      "Epoch: 9/10..  Training Loss: 2.176..  Test Loss: 2.226..  Test Accuracy: 0.279\n",
      "Epoch: 10/10..  Training Loss: 2.161..  Test Loss: 2.213..  Test Accuracy: 0.302\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "train_losses, test_losses, accuracy_graph = [], [], []\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images,labels in train_loader:\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(train)\n",
    "        loss = criterion(output,labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad(): #Turning off gradients to speed up\n",
    "            model.eval()\n",
    "            for images,labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(-1,1,28,28))\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "                log_ps = model(test)\n",
    "                test_loss += criterion(log_ps,labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim = 1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()        \n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "        accuracy_graph.append(accuracy/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "PeJpfcVXL4xd",
    "outputId": "882a540e-098c-4898-8b3d-3c023f47fc32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18moh\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sb.lineplot(train_losses, label='Training loss')\n",
    "sb.lineplot(test_losses, label='Validation loss')\n",
    "sb.lineplot(accuracy_graph, label='Accuracy')\n",
    "sb.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvDFhMVNRIw5"
   },
   "outputs": [],
   "source": [
    "class Adv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Adv, self).__init__()\n",
    "\n",
    "        self.c1=nn.Conv2d(in_channels=1, out_channels=8, stride=2, kernel_size=4, padding=1)\n",
    "        self.l1=nn.Linear(288+1, 512)\n",
    "        self.l2=nn.Linear(512, 784)\n",
    "\n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.c1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "\n",
    "        x=x.view(x.size(0), -1)\n",
    "        r=torch.randn(x.size(0), 1)\n",
    "        x=torch.cat((x,r), 1)\n",
    "\n",
    "        x=self.l1(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pAPNJLzc0GU"
   },
   "outputs": [],
   "source": [
    "#loss = number of activated neurons in final layer - difference between label and classification\n",
    "\n",
    "adv=Adv()\n",
    "adv=adv.double()\n",
    "\n",
    "cnn=CNN()\n",
    "cnn=cnn.double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optCNN = torch.optim.Adam(cnn.parameters(), lr=0.0001)\n",
    "\n",
    "optAdv = torch.optim.Adam(adv.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZ_AFkA-PNWL"
   },
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "train_losses2, test_losses2, accuracy_graph2 = [], [], []\n",
    "\n",
    "sample_images=[]\n",
    "sample_masked=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    mask_loss = 0\n",
    "\n",
    "    currentdropout = 0.95\n",
    "    \n",
    "    if(epoch>400):\n",
    "        currentdropout=0.75\n",
    "    else:\n",
    "        currentdropout = 0.95 - epoch*(0.15/400)\n",
    "\n",
    "    i=0\n",
    "\n",
    "    for images,labels in train_loader:\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        if(i==0):\n",
    "            sample_images.append(train.clone().detach().numpy())\n",
    "\n",
    "        optAdv.zero_grad()\n",
    "        optCNN.zero_grad()\n",
    "\n",
    "        mask = adv(train)\n",
    "        finaldrop = nn.Dropout(p=currentdropout)\n",
    "        mask = finaldrop(mask)\n",
    "\n",
    "        images = images + mask\n",
    "        images = torch.minimum(images, torch.ones(images.shape))\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "\n",
    "        if(i==0):\n",
    "            sample_masked.append(train.clone().detach().numpy())\n",
    "\n",
    "        output = cnn(train)\n",
    "\n",
    "        lossAdv = -torch.log(criterion(output, labels))\n",
    "        lossCNN = criterion(output, labels)\n",
    "        \n",
    "        # print(lossAdv)\n",
    "        # print(lossCNN)\n",
    "\n",
    "        if(i%3==0):\n",
    "            lossAdv.backward()\n",
    "            optAdv.step()\n",
    "        else:\n",
    "            lossCNN.backward()\n",
    "            optCNN.step()\n",
    "        \n",
    "        mask_loss += lossAdv.item()\n",
    "        running_loss += lossCNN.item()\n",
    "        i+=1\n",
    "\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad(): #Turning off gradients to speed up\n",
    "            cnn.eval()\n",
    "            for images,labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(-1,1,28,28))\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "                log_ps = cnn(test)\n",
    "                test_loss += criterion(log_ps,labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim = 1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        cnn.train()        \n",
    "        train_losses2.append(running_loss/len(train_loader))\n",
    "        test_losses2.append(test_loss/len(test_loader))\n",
    "        accuracy_graph2.append(accuracy/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Mask Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "qickz47TlpZN",
    "outputId": "6f441c94-4d28-4bb4-ff4c-e6959ae046ae"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses2, label='Training loss')\n",
    "plt.plot(test_losses2, label='Validation loss')\n",
    "plt.plot(accuracy_graph2, label='Accuracy')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "nrX-7B8sFJZN",
    "outputId": "0f6c7402-88d2-4773-8357-416513042433"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses2, label='AdvCNNTraining loss')\n",
    "plt.plot(test_losses2, label='AdvCNN Validation loss')\n",
    "plt.plot(accuracy_graph2, label='AdvCNN Accuracy')\n",
    "plt.plot(train_losses, label='CNN Training loss')\n",
    "plt.plot(test_losses, label='CNN Validation loss')\n",
    "plt.plot(accuracy_graph, label='CNN Accuracy')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "XPdtoneIL3J0",
    "outputId": "37ed5984-c0ff-4a95-d1c8-3b7a5ec5993f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display image next to mask\n",
    "\n",
    "epoch = 100\n",
    "image = 5\n",
    "\n",
    "f, axarr = plt.subplots(2)\n",
    "\n",
    "axarr[0].imshow(sample_images[epoch][image][0])\n",
    "axarr[1].imshow(sample_masked[epoch][image][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8tOh1p5L6tK",
    "outputId": "7f63ba69-1c2b-4029-e4fa-1fdb28c2234d"
   },
   "outputs": [],
   "source": [
    "3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3IqnF7iL7L3",
    "outputId": "7c87c8cb-a06c-4abe-e353-e96062df5713"
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dtcp28bLL7yD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST AdvCnn v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
