{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aUQ5JcwuKxRE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn,functional\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-iOdDy2LNNO",
    "outputId": "c749d771-0758-44d6-f44d-0fb13959c3b9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ht-G8QSHLWHa"
   },
   "outputs": [],
   "source": [
    "location=''\n",
    "\n",
    "train=pd.read_csv(location+'mnist_train.csv')[:200]\n",
    "X_train=torch.from_numpy(train.loc[:,train.columns != \"label\"].values/255)\n",
    "Y_train=torch.from_numpy(train.label.values).type(torch.LongTensor)\n",
    "\n",
    "test=pd.read_csv(location+'mnist_test.csv')\n",
    "X_test=torch.from_numpy(test.loc[:,train.columns != \"label\"].values/255)\n",
    "Y_test=torch.from_numpy(test.label.values).type(torch.LongTensor)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(X_train,Y_train)\n",
    "test = torch.utils.data.TensorDataset(X_test,Y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = 1, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7p3fADtELskd"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.c1=nn.Conv2d(in_channels=1, out_channels=8, stride=2, kernel_size=4, padding=1)\n",
    "        self.l1=nn.Linear(288, 10)\n",
    "        \n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.c1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "\n",
    "        x=x.view(x.size(0), -1)\n",
    "\n",
    "        x=self.l1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2J7KNnGKDlLZ"
   },
   "outputs": [],
   "source": [
    "class Adv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Adv, self).__init__()\n",
    "\n",
    "        self.c1=nn.Conv2d(in_channels=1, out_channels=8, stride=2, kernel_size=4, padding=1)\n",
    "        self.l1=nn.Linear(288+1, 512)\n",
    "        self.l2=nn.Linear(512, 784)\n",
    "\n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.c1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "\n",
    "        x=x.view(x.size(0), -1)\n",
    "        r=torch.randn(x.size(0), 1)\n",
    "        x=torch.cat((x,r), 1)\n",
    "\n",
    "        x=self.l1(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.l2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ipXgzKBkfDGQ"
   },
   "outputs": [],
   "source": [
    "class Adv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Adv2, self).__init__()\n",
    "\n",
    "        self.c1=nn.Conv2d(in_channels=1, out_channels=8, stride=2, kernel_size=4, padding=1)\n",
    "        self.l1=nn.Linear(288+1, 64)\n",
    "        self.l2=nn.Linear(64, 128)\n",
    "        self.l3=nn.Linear(128, 784)\n",
    "\n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.c1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "\n",
    "        x=x.view(x.size(0), -1)\n",
    "        r=torch.randn(x.size(0), 1)\n",
    "        x=torch.cat((x,r), 1)\n",
    "\n",
    "        x=self.l1(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.l2(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VdO1n1CFeRQA"
   },
   "outputs": [],
   "source": [
    "class Adv3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Adv3, self).__init__()\n",
    "\n",
    "        self.c1=nn.Conv2d(in_channels=1, out_channels=16, stride=2, kernel_size=3, padding=1)\n",
    "        self.c2=nn.Conv2d(in_channels=16, out_channels=32, stride=2, kernel_size=3, padding=1)\n",
    "        self.l1=nn.Linear(32, 64)\n",
    "        self.l2=nn.Linear(64, 128)\n",
    "        self.l3=nn.Linear(128, 784)\n",
    "\n",
    "        self.dropout=nn.Dropout(p=0.2)\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.relu=nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.final=nn.Tanh()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.c1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        x=self.c2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "\n",
    "        x=x.view(x.size(0), -1)\n",
    "\n",
    "        x=self.l1(x)\n",
    "        x=x+torch.randn(x.shape)\n",
    "        x=self.dropout(x)\n",
    "        \n",
    "        x=self.l2(x)\n",
    "        x=self.dropout(x)\n",
    "        \n",
    "        x=self.l3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kv-NmP6eDoVF"
   },
   "source": [
    "# Baseline CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iOsusc7HLztj"
   },
   "outputs": [],
   "source": [
    "basecnn=CNN()\n",
    "basecnn=basecnn.double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(basecnn.parameters(), lr=0.0001)\n",
    "\n",
    "train_losses_basecnn, test_losses_basecnn, accuracy_graph_basecnn = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BX5G3nqL2Gl",
    "outputId": "594df859-6908-45c2-e6c8-b53126b8b84c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1500..  Training Loss: 2.310..  Test Loss: 2.283..  Test Accuracy: 0.140\n",
      "Epoch: 2/1500..  Training Loss: 2.220..  Test Loss: 2.225..  Test Accuracy: 0.200\n",
      "Epoch: 3/1500..  Training Loss: 2.150..  Test Loss: 2.173..  Test Accuracy: 0.257\n",
      "Epoch: 4/1500..  Training Loss: 2.079..  Test Loss: 2.113..  Test Accuracy: 0.334\n",
      "Epoch: 5/1500..  Training Loss: 2.002..  Test Loss: 2.049..  Test Accuracy: 0.393\n",
      "Epoch: 6/1500..  Training Loss: 1.912..  Test Loss: 1.979..  Test Accuracy: 0.437\n",
      "Epoch: 7/1500..  Training Loss: 1.817..  Test Loss: 1.903..  Test Accuracy: 0.477\n",
      "Epoch: 8/1500..  Training Loss: 1.712..  Test Loss: 1.820..  Test Accuracy: 0.502\n",
      "Epoch: 9/1500..  Training Loss: 1.608..  Test Loss: 1.736..  Test Accuracy: 0.521\n",
      "Epoch: 10/1500..  Training Loss: 1.500..  Test Loss: 1.652..  Test Accuracy: 0.542\n",
      "Epoch: 11/1500..  Training Loss: 1.396..  Test Loss: 1.581..  Test Accuracy: 0.564\n",
      "Epoch: 12/1500..  Training Loss: 1.301..  Test Loss: 1.511..  Test Accuracy: 0.572\n",
      "Epoch: 13/1500..  Training Loss: 1.206..  Test Loss: 1.446..  Test Accuracy: 0.589\n",
      "Epoch: 14/1500..  Training Loss: 1.130..  Test Loss: 1.391..  Test Accuracy: 0.601\n",
      "Epoch: 15/1500..  Training Loss: 1.053..  Test Loss: 1.347..  Test Accuracy: 0.598\n",
      "Epoch: 16/1500..  Training Loss: 0.989..  Test Loss: 1.292..  Test Accuracy: 0.614\n",
      "Epoch: 17/1500..  Training Loss: 0.929..  Test Loss: 1.268..  Test Accuracy: 0.619\n",
      "Epoch: 18/1500..  Training Loss: 0.882..  Test Loss: 1.235..  Test Accuracy: 0.621\n",
      "Epoch: 19/1500..  Training Loss: 0.839..  Test Loss: 1.208..  Test Accuracy: 0.626\n",
      "Epoch: 20/1500..  Training Loss: 0.796..  Test Loss: 1.185..  Test Accuracy: 0.639\n",
      "Epoch: 21/1500..  Training Loss: 0.755..  Test Loss: 1.160..  Test Accuracy: 0.641\n",
      "Epoch: 22/1500..  Training Loss: 0.724..  Test Loss: 1.136..  Test Accuracy: 0.651\n",
      "Epoch: 23/1500..  Training Loss: 0.691..  Test Loss: 1.144..  Test Accuracy: 0.645\n",
      "Epoch: 24/1500..  Training Loss: 0.669..  Test Loss: 1.116..  Test Accuracy: 0.659\n",
      "Epoch: 25/1500..  Training Loss: 0.641..  Test Loss: 1.083..  Test Accuracy: 0.668\n",
      "Epoch: 26/1500..  Training Loss: 0.617..  Test Loss: 1.073..  Test Accuracy: 0.674\n",
      "Epoch: 27/1500..  Training Loss: 0.594..  Test Loss: 1.074..  Test Accuracy: 0.666\n",
      "Epoch: 28/1500..  Training Loss: 0.579..  Test Loss: 1.056..  Test Accuracy: 0.675\n",
      "Epoch: 29/1500..  Training Loss: 0.556..  Test Loss: 1.033..  Test Accuracy: 0.676\n",
      "Epoch: 30/1500..  Training Loss: 0.537..  Test Loss: 1.021..  Test Accuracy: 0.681\n",
      "Epoch: 31/1500..  Training Loss: 0.519..  Test Loss: 1.033..  Test Accuracy: 0.676\n",
      "Epoch: 32/1500..  Training Loss: 0.502..  Test Loss: 1.018..  Test Accuracy: 0.688\n",
      "Epoch: 33/1500..  Training Loss: 0.486..  Test Loss: 1.006..  Test Accuracy: 0.693\n",
      "Epoch: 34/1500..  Training Loss: 0.475..  Test Loss: 0.994..  Test Accuracy: 0.696\n",
      "Epoch: 35/1500..  Training Loss: 0.459..  Test Loss: 0.999..  Test Accuracy: 0.691\n",
      "Epoch: 36/1500..  Training Loss: 0.448..  Test Loss: 0.989..  Test Accuracy: 0.693\n",
      "Epoch: 37/1500..  Training Loss: 0.434..  Test Loss: 0.978..  Test Accuracy: 0.701\n",
      "Epoch: 38/1500..  Training Loss: 0.420..  Test Loss: 0.975..  Test Accuracy: 0.704\n",
      "Epoch: 39/1500..  Training Loss: 0.407..  Test Loss: 0.991..  Test Accuracy: 0.704\n",
      "Epoch: 40/1500..  Training Loss: 0.393..  Test Loss: 0.948..  Test Accuracy: 0.714\n",
      "Epoch: 41/1500..  Training Loss: 0.383..  Test Loss: 0.961..  Test Accuracy: 0.710\n",
      "Epoch: 42/1500..  Training Loss: 0.371..  Test Loss: 0.952..  Test Accuracy: 0.714\n",
      "Epoch: 43/1500..  Training Loss: 0.362..  Test Loss: 0.948..  Test Accuracy: 0.711\n",
      "Epoch: 44/1500..  Training Loss: 0.350..  Test Loss: 0.949..  Test Accuracy: 0.714\n",
      "Epoch: 45/1500..  Training Loss: 0.343..  Test Loss: 0.941..  Test Accuracy: 0.723\n",
      "Epoch: 46/1500..  Training Loss: 0.329..  Test Loss: 0.948..  Test Accuracy: 0.716\n",
      "Epoch: 47/1500..  Training Loss: 0.320..  Test Loss: 0.966..  Test Accuracy: 0.714\n",
      "Epoch: 48/1500..  Training Loss: 0.313..  Test Loss: 0.950..  Test Accuracy: 0.717\n",
      "Epoch: 49/1500..  Training Loss: 0.305..  Test Loss: 0.948..  Test Accuracy: 0.718\n",
      "Epoch: 50/1500..  Training Loss: 0.294..  Test Loss: 0.922..  Test Accuracy: 0.735\n",
      "Epoch: 51/1500..  Training Loss: 0.289..  Test Loss: 0.930..  Test Accuracy: 0.727\n",
      "Epoch: 52/1500..  Training Loss: 0.279..  Test Loss: 0.939..  Test Accuracy: 0.726\n",
      "Epoch: 53/1500..  Training Loss: 0.269..  Test Loss: 0.934..  Test Accuracy: 0.727\n",
      "Epoch: 54/1500..  Training Loss: 0.263..  Test Loss: 0.946..  Test Accuracy: 0.727\n",
      "Epoch: 55/1500..  Training Loss: 0.255..  Test Loss: 0.917..  Test Accuracy: 0.742\n",
      "Epoch: 56/1500..  Training Loss: 0.248..  Test Loss: 0.933..  Test Accuracy: 0.737\n",
      "Epoch: 57/1500..  Training Loss: 0.239..  Test Loss: 0.919..  Test Accuracy: 0.740\n",
      "Epoch: 58/1500..  Training Loss: 0.234..  Test Loss: 0.916..  Test Accuracy: 0.744\n",
      "Epoch: 59/1500..  Training Loss: 0.227..  Test Loss: 0.924..  Test Accuracy: 0.737\n",
      "Epoch: 60/1500..  Training Loss: 0.221..  Test Loss: 0.931..  Test Accuracy: 0.736\n",
      "Epoch: 61/1500..  Training Loss: 0.214..  Test Loss: 0.927..  Test Accuracy: 0.735\n",
      "Epoch: 62/1500..  Training Loss: 0.209..  Test Loss: 0.932..  Test Accuracy: 0.740\n",
      "Epoch: 63/1500..  Training Loss: 0.201..  Test Loss: 0.922..  Test Accuracy: 0.749\n",
      "Epoch: 64/1500..  Training Loss: 0.196..  Test Loss: 0.930..  Test Accuracy: 0.743\n",
      "Epoch: 65/1500..  Training Loss: 0.190..  Test Loss: 0.931..  Test Accuracy: 0.742\n",
      "Epoch: 66/1500..  Training Loss: 0.186..  Test Loss: 0.926..  Test Accuracy: 0.748\n",
      "Epoch: 67/1500..  Training Loss: 0.181..  Test Loss: 0.923..  Test Accuracy: 0.747\n",
      "Epoch: 68/1500..  Training Loss: 0.175..  Test Loss: 0.940..  Test Accuracy: 0.743\n",
      "Epoch: 69/1500..  Training Loss: 0.170..  Test Loss: 0.956..  Test Accuracy: 0.746\n",
      "Epoch: 70/1500..  Training Loss: 0.165..  Test Loss: 0.944..  Test Accuracy: 0.744\n",
      "Epoch: 71/1500..  Training Loss: 0.158..  Test Loss: 0.930..  Test Accuracy: 0.746\n",
      "Epoch: 72/1500..  Training Loss: 0.153..  Test Loss: 0.932..  Test Accuracy: 0.753\n",
      "Epoch: 73/1500..  Training Loss: 0.148..  Test Loss: 0.963..  Test Accuracy: 0.742\n",
      "Epoch: 74/1500..  Training Loss: 0.146..  Test Loss: 0.935..  Test Accuracy: 0.756\n",
      "Epoch: 75/1500..  Training Loss: 0.142..  Test Loss: 0.953..  Test Accuracy: 0.750\n",
      "Epoch: 76/1500..  Training Loss: 0.137..  Test Loss: 0.953..  Test Accuracy: 0.755\n",
      "Epoch: 77/1500..  Training Loss: 0.133..  Test Loss: 0.969..  Test Accuracy: 0.749\n",
      "Epoch: 78/1500..  Training Loss: 0.129..  Test Loss: 0.956..  Test Accuracy: 0.751\n",
      "Epoch: 79/1500..  Training Loss: 0.125..  Test Loss: 0.974..  Test Accuracy: 0.750\n",
      "Epoch: 80/1500..  Training Loss: 0.122..  Test Loss: 0.961..  Test Accuracy: 0.750\n",
      "Epoch: 81/1500..  Training Loss: 0.118..  Test Loss: 0.963..  Test Accuracy: 0.753\n",
      "Epoch: 82/1500..  Training Loss: 0.114..  Test Loss: 0.987..  Test Accuracy: 0.745\n",
      "Epoch: 83/1500..  Training Loss: 0.110..  Test Loss: 0.970..  Test Accuracy: 0.756\n",
      "Epoch: 84/1500..  Training Loss: 0.107..  Test Loss: 0.985..  Test Accuracy: 0.753\n",
      "Epoch: 85/1500..  Training Loss: 0.104..  Test Loss: 0.981..  Test Accuracy: 0.757\n",
      "Epoch: 86/1500..  Training Loss: 0.101..  Test Loss: 0.992..  Test Accuracy: 0.752\n",
      "Epoch: 87/1500..  Training Loss: 0.098..  Test Loss: 1.033..  Test Accuracy: 0.747\n",
      "Epoch: 88/1500..  Training Loss: 0.096..  Test Loss: 1.000..  Test Accuracy: 0.753\n",
      "Epoch: 89/1500..  Training Loss: 0.090..  Test Loss: 0.986..  Test Accuracy: 0.760\n",
      "Epoch: 90/1500..  Training Loss: 0.089..  Test Loss: 1.003..  Test Accuracy: 0.757\n",
      "Epoch: 91/1500..  Training Loss: 0.085..  Test Loss: 1.021..  Test Accuracy: 0.750\n",
      "Epoch: 92/1500..  Training Loss: 0.083..  Test Loss: 1.014..  Test Accuracy: 0.752\n",
      "Epoch: 93/1500..  Training Loss: 0.080..  Test Loss: 1.049..  Test Accuracy: 0.748\n",
      "Epoch: 94/1500..  Training Loss: 0.077..  Test Loss: 1.021..  Test Accuracy: 0.752\n",
      "Epoch: 95/1500..  Training Loss: 0.075..  Test Loss: 1.035..  Test Accuracy: 0.751\n",
      "Epoch: 96/1500..  Training Loss: 0.073..  Test Loss: 1.032..  Test Accuracy: 0.754\n",
      "Epoch: 97/1500..  Training Loss: 0.070..  Test Loss: 1.044..  Test Accuracy: 0.750\n",
      "Epoch: 98/1500..  Training Loss: 0.069..  Test Loss: 1.057..  Test Accuracy: 0.750\n",
      "Epoch: 99/1500..  Training Loss: 0.068..  Test Loss: 1.052..  Test Accuracy: 0.751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/1500..  Training Loss: 0.064..  Test Loss: 1.055..  Test Accuracy: 0.754\n",
      "Epoch: 101/1500..  Training Loss: 0.063..  Test Loss: 1.087..  Test Accuracy: 0.750\n",
      "Epoch: 102/1500..  Training Loss: 0.062..  Test Loss: 1.056..  Test Accuracy: 0.755\n",
      "Epoch: 103/1500..  Training Loss: 0.058..  Test Loss: 1.071..  Test Accuracy: 0.755\n",
      "Epoch: 104/1500..  Training Loss: 0.057..  Test Loss: 1.085..  Test Accuracy: 0.754\n",
      "Epoch: 105/1500..  Training Loss: 0.055..  Test Loss: 1.101..  Test Accuracy: 0.752\n",
      "Epoch: 106/1500..  Training Loss: 0.053..  Test Loss: 1.072..  Test Accuracy: 0.756\n",
      "Epoch: 107/1500..  Training Loss: 0.051..  Test Loss: 1.081..  Test Accuracy: 0.756\n",
      "Epoch: 108/1500..  Training Loss: 0.050..  Test Loss: 1.087..  Test Accuracy: 0.755\n",
      "Epoch: 109/1500..  Training Loss: 0.049..  Test Loss: 1.093..  Test Accuracy: 0.751\n",
      "Epoch: 110/1500..  Training Loss: 0.046..  Test Loss: 1.100..  Test Accuracy: 0.759\n",
      "Epoch: 111/1500..  Training Loss: 0.046..  Test Loss: 1.146..  Test Accuracy: 0.747\n",
      "Epoch: 112/1500..  Training Loss: 0.045..  Test Loss: 1.105..  Test Accuracy: 0.758\n",
      "Epoch: 113/1500..  Training Loss: 0.042..  Test Loss: 1.135..  Test Accuracy: 0.746\n",
      "Epoch: 114/1500..  Training Loss: 0.042..  Test Loss: 1.138..  Test Accuracy: 0.755\n",
      "Epoch: 115/1500..  Training Loss: 0.039..  Test Loss: 1.176..  Test Accuracy: 0.748\n",
      "Epoch: 116/1500..  Training Loss: 0.038..  Test Loss: 1.156..  Test Accuracy: 0.752\n",
      "Epoch: 117/1500..  Training Loss: 0.038..  Test Loss: 1.163..  Test Accuracy: 0.753\n",
      "Epoch: 118/1500..  Training Loss: 0.036..  Test Loss: 1.172..  Test Accuracy: 0.750\n",
      "Epoch: 119/1500..  Training Loss: 0.034..  Test Loss: 1.158..  Test Accuracy: 0.749\n",
      "Epoch: 120/1500..  Training Loss: 0.034..  Test Loss: 1.175..  Test Accuracy: 0.749\n",
      "Epoch: 121/1500..  Training Loss: 0.032..  Test Loss: 1.198..  Test Accuracy: 0.746\n",
      "Epoch: 122/1500..  Training Loss: 0.033..  Test Loss: 1.194..  Test Accuracy: 0.749\n",
      "Epoch: 123/1500..  Training Loss: 0.031..  Test Loss: 1.201..  Test Accuracy: 0.749\n",
      "Epoch: 124/1500..  Training Loss: 0.028..  Test Loss: 1.224..  Test Accuracy: 0.745\n",
      "Epoch: 125/1500..  Training Loss: 0.029..  Test Loss: 1.201..  Test Accuracy: 0.756\n",
      "Epoch: 126/1500..  Training Loss: 0.027..  Test Loss: 1.228..  Test Accuracy: 0.751\n",
      "Epoch: 127/1500..  Training Loss: 0.027..  Test Loss: 1.248..  Test Accuracy: 0.748\n",
      "Epoch: 128/1500..  Training Loss: 0.026..  Test Loss: 1.217..  Test Accuracy: 0.756\n",
      "Epoch: 129/1500..  Training Loss: 0.025..  Test Loss: 1.240..  Test Accuracy: 0.747\n",
      "Epoch: 130/1500..  Training Loss: 0.024..  Test Loss: 1.250..  Test Accuracy: 0.746\n",
      "Epoch: 131/1500..  Training Loss: 0.024..  Test Loss: 1.262..  Test Accuracy: 0.747\n",
      "Epoch: 132/1500..  Training Loss: 0.023..  Test Loss: 1.241..  Test Accuracy: 0.752\n",
      "Epoch: 133/1500..  Training Loss: 0.022..  Test Loss: 1.235..  Test Accuracy: 0.754\n",
      "Epoch: 134/1500..  Training Loss: 0.021..  Test Loss: 1.263..  Test Accuracy: 0.752\n",
      "Epoch: 135/1500..  Training Loss: 0.021..  Test Loss: 1.284..  Test Accuracy: 0.750\n",
      "Epoch: 136/1500..  Training Loss: 0.020..  Test Loss: 1.287..  Test Accuracy: 0.748\n",
      "Epoch: 137/1500..  Training Loss: 0.019..  Test Loss: 1.283..  Test Accuracy: 0.750\n",
      "Epoch: 138/1500..  Training Loss: 0.018..  Test Loss: 1.285..  Test Accuracy: 0.750\n",
      "Epoch: 139/1500..  Training Loss: 0.018..  Test Loss: 1.293..  Test Accuracy: 0.754\n",
      "Epoch: 140/1500..  Training Loss: 0.017..  Test Loss: 1.322..  Test Accuracy: 0.749\n",
      "Epoch: 141/1500..  Training Loss: 0.017..  Test Loss: 1.315..  Test Accuracy: 0.752\n",
      "Epoch: 142/1500..  Training Loss: 0.016..  Test Loss: 1.322..  Test Accuracy: 0.749\n",
      "Epoch: 143/1500..  Training Loss: 0.016..  Test Loss: 1.327..  Test Accuracy: 0.750\n",
      "Epoch: 144/1500..  Training Loss: 0.015..  Test Loss: 1.350..  Test Accuracy: 0.749\n",
      "Epoch: 145/1500..  Training Loss: 0.014..  Test Loss: 1.362..  Test Accuracy: 0.746\n",
      "Epoch: 146/1500..  Training Loss: 0.014..  Test Loss: 1.345..  Test Accuracy: 0.751\n",
      "Epoch: 147/1500..  Training Loss: 0.013..  Test Loss: 1.368..  Test Accuracy: 0.751\n",
      "Epoch: 148/1500..  Training Loss: 0.013..  Test Loss: 1.376..  Test Accuracy: 0.751\n",
      "Epoch: 149/1500..  Training Loss: 0.013..  Test Loss: 1.394..  Test Accuracy: 0.748\n",
      "Epoch: 150/1500..  Training Loss: 0.013..  Test Loss: 1.365..  Test Accuracy: 0.751\n",
      "Epoch: 151/1500..  Training Loss: 0.012..  Test Loss: 1.382..  Test Accuracy: 0.751\n",
      "Epoch: 152/1500..  Training Loss: 0.012..  Test Loss: 1.376..  Test Accuracy: 0.751\n",
      "Epoch: 153/1500..  Training Loss: 0.011..  Test Loss: 1.434..  Test Accuracy: 0.746\n",
      "Epoch: 154/1500..  Training Loss: 0.011..  Test Loss: 1.395..  Test Accuracy: 0.751\n",
      "Epoch: 155/1500..  Training Loss: 0.011..  Test Loss: 1.408..  Test Accuracy: 0.751\n",
      "Epoch: 156/1500..  Training Loss: 0.010..  Test Loss: 1.410..  Test Accuracy: 0.751\n",
      "Epoch: 157/1500..  Training Loss: 0.010..  Test Loss: 1.429..  Test Accuracy: 0.748\n",
      "Epoch: 158/1500..  Training Loss: 0.009..  Test Loss: 1.447..  Test Accuracy: 0.747\n",
      "Epoch: 159/1500..  Training Loss: 0.009..  Test Loss: 1.433..  Test Accuracy: 0.749\n",
      "Epoch: 160/1500..  Training Loss: 0.009..  Test Loss: 1.455..  Test Accuracy: 0.746\n",
      "Epoch: 161/1500..  Training Loss: 0.008..  Test Loss: 1.439..  Test Accuracy: 0.754\n",
      "Epoch: 162/1500..  Training Loss: 0.008..  Test Loss: 1.481..  Test Accuracy: 0.750\n",
      "Epoch: 163/1500..  Training Loss: 0.008..  Test Loss: 1.478..  Test Accuracy: 0.748\n",
      "Epoch: 164/1500..  Training Loss: 0.008..  Test Loss: 1.490..  Test Accuracy: 0.745\n",
      "Epoch: 165/1500..  Training Loss: 0.008..  Test Loss: 1.508..  Test Accuracy: 0.748\n",
      "Epoch: 166/1500..  Training Loss: 0.007..  Test Loss: 1.502..  Test Accuracy: 0.747\n",
      "Epoch: 167/1500..  Training Loss: 0.007..  Test Loss: 1.535..  Test Accuracy: 0.743\n",
      "Epoch: 168/1500..  Training Loss: 0.007..  Test Loss: 1.534..  Test Accuracy: 0.743\n",
      "Epoch: 169/1500..  Training Loss: 0.007..  Test Loss: 1.536..  Test Accuracy: 0.748\n",
      "Epoch: 170/1500..  Training Loss: 0.006..  Test Loss: 1.542..  Test Accuracy: 0.748\n",
      "Epoch: 171/1500..  Training Loss: 0.006..  Test Loss: 1.548..  Test Accuracy: 0.746\n",
      "Epoch: 172/1500..  Training Loss: 0.006..  Test Loss: 1.541..  Test Accuracy: 0.750\n",
      "Epoch: 173/1500..  Training Loss: 0.005..  Test Loss: 1.543..  Test Accuracy: 0.749\n",
      "Epoch: 174/1500..  Training Loss: 0.005..  Test Loss: 1.587..  Test Accuracy: 0.744\n",
      "Epoch: 175/1500..  Training Loss: 0.006..  Test Loss: 1.576..  Test Accuracy: 0.746\n",
      "Epoch: 176/1500..  Training Loss: 0.005..  Test Loss: 1.581..  Test Accuracy: 0.748\n",
      "Epoch: 177/1500..  Training Loss: 0.005..  Test Loss: 1.575..  Test Accuracy: 0.751\n",
      "Epoch: 178/1500..  Training Loss: 0.005..  Test Loss: 1.576..  Test Accuracy: 0.747\n",
      "Epoch: 179/1500..  Training Loss: 0.005..  Test Loss: 1.626..  Test Accuracy: 0.746\n",
      "Epoch: 180/1500..  Training Loss: 0.004..  Test Loss: 1.633..  Test Accuracy: 0.743\n",
      "Epoch: 181/1500..  Training Loss: 0.004..  Test Loss: 1.621..  Test Accuracy: 0.743\n",
      "Epoch: 182/1500..  Training Loss: 0.004..  Test Loss: 1.634..  Test Accuracy: 0.746\n",
      "Epoch: 183/1500..  Training Loss: 0.004..  Test Loss: 1.651..  Test Accuracy: 0.745\n",
      "Epoch: 184/1500..  Training Loss: 0.004..  Test Loss: 1.653..  Test Accuracy: 0.745\n",
      "Epoch: 185/1500..  Training Loss: 0.004..  Test Loss: 1.697..  Test Accuracy: 0.744\n",
      "Epoch: 186/1500..  Training Loss: 0.003..  Test Loss: 1.655..  Test Accuracy: 0.745\n",
      "Epoch: 187/1500..  Training Loss: 0.004..  Test Loss: 1.673..  Test Accuracy: 0.747\n",
      "Epoch: 188/1500..  Training Loss: 0.003..  Test Loss: 1.653..  Test Accuracy: 0.751\n",
      "Epoch: 189/1500..  Training Loss: 0.003..  Test Loss: 1.721..  Test Accuracy: 0.745\n",
      "Epoch: 190/1500..  Training Loss: 0.003..  Test Loss: 1.696..  Test Accuracy: 0.749\n",
      "Epoch: 191/1500..  Training Loss: 0.003..  Test Loss: 1.682..  Test Accuracy: 0.750\n",
      "Epoch: 192/1500..  Training Loss: 0.003..  Test Loss: 1.685..  Test Accuracy: 0.750\n",
      "Epoch: 193/1500..  Training Loss: 0.003..  Test Loss: 1.694..  Test Accuracy: 0.750\n",
      "Epoch: 194/1500..  Training Loss: 0.003..  Test Loss: 1.737..  Test Accuracy: 0.747\n",
      "Epoch: 195/1500..  Training Loss: 0.003..  Test Loss: 1.742..  Test Accuracy: 0.749\n",
      "Epoch: 196/1500..  Training Loss: 0.002..  Test Loss: 1.755..  Test Accuracy: 0.746\n",
      "Epoch: 197/1500..  Training Loss: 0.002..  Test Loss: 1.748..  Test Accuracy: 0.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 198/1500..  Training Loss: 0.002..  Test Loss: 1.794..  Test Accuracy: 0.747\n",
      "Epoch: 199/1500..  Training Loss: 0.002..  Test Loss: 1.773..  Test Accuracy: 0.746\n",
      "Epoch: 200/1500..  Training Loss: 0.002..  Test Loss: 1.782..  Test Accuracy: 0.749\n",
      "Epoch: 201/1500..  Training Loss: 0.002..  Test Loss: 1.793..  Test Accuracy: 0.743\n",
      "Epoch: 202/1500..  Training Loss: 0.002..  Test Loss: 1.835..  Test Accuracy: 0.744\n",
      "Epoch: 203/1500..  Training Loss: 0.002..  Test Loss: 1.790..  Test Accuracy: 0.746\n",
      "Epoch: 204/1500..  Training Loss: 0.002..  Test Loss: 1.807..  Test Accuracy: 0.747\n",
      "Epoch: 205/1500..  Training Loss: 0.002..  Test Loss: 1.812..  Test Accuracy: 0.747\n",
      "Epoch: 206/1500..  Training Loss: 0.002..  Test Loss: 1.851..  Test Accuracy: 0.746\n",
      "Epoch: 207/1500..  Training Loss: 0.001..  Test Loss: 1.892..  Test Accuracy: 0.740\n",
      "Epoch: 208/1500..  Training Loss: 0.002..  Test Loss: 1.840..  Test Accuracy: 0.748\n",
      "Epoch: 209/1500..  Training Loss: 0.001..  Test Loss: 1.859..  Test Accuracy: 0.745\n",
      "Epoch: 210/1500..  Training Loss: 0.001..  Test Loss: 1.878..  Test Accuracy: 0.744\n",
      "Epoch: 211/1500..  Training Loss: 0.001..  Test Loss: 1.843..  Test Accuracy: 0.752\n",
      "Epoch: 212/1500..  Training Loss: 0.001..  Test Loss: 1.885..  Test Accuracy: 0.747\n",
      "Epoch: 213/1500..  Training Loss: 0.001..  Test Loss: 1.874..  Test Accuracy: 0.748\n",
      "Epoch: 214/1500..  Training Loss: 0.001..  Test Loss: 1.928..  Test Accuracy: 0.746\n",
      "Epoch: 215/1500..  Training Loss: 0.001..  Test Loss: 1.908..  Test Accuracy: 0.749\n",
      "Epoch: 216/1500..  Training Loss: 0.001..  Test Loss: 1.947..  Test Accuracy: 0.747\n",
      "Epoch: 217/1500..  Training Loss: 0.001..  Test Loss: 1.936..  Test Accuracy: 0.747\n",
      "Epoch: 218/1500..  Training Loss: 0.001..  Test Loss: 1.951..  Test Accuracy: 0.748\n",
      "Epoch: 219/1500..  Training Loss: 0.001..  Test Loss: 1.946..  Test Accuracy: 0.747\n",
      "Epoch: 220/1500..  Training Loss: 0.001..  Test Loss: 1.948..  Test Accuracy: 0.746\n",
      "Epoch: 221/1500..  Training Loss: 0.001..  Test Loss: 1.977..  Test Accuracy: 0.745\n",
      "Epoch: 222/1500..  Training Loss: 0.001..  Test Loss: 1.944..  Test Accuracy: 0.750\n",
      "Epoch: 223/1500..  Training Loss: 0.001..  Test Loss: 2.012..  Test Accuracy: 0.742\n",
      "Epoch: 224/1500..  Training Loss: 0.001..  Test Loss: 2.020..  Test Accuracy: 0.745\n",
      "Epoch: 225/1500..  Training Loss: 0.001..  Test Loss: 1.987..  Test Accuracy: 0.749\n",
      "Epoch: 226/1500..  Training Loss: 0.001..  Test Loss: 1.992..  Test Accuracy: 0.747\n",
      "Epoch: 227/1500..  Training Loss: 0.001..  Test Loss: 2.036..  Test Accuracy: 0.747\n",
      "Epoch: 228/1500..  Training Loss: 0.001..  Test Loss: 2.037..  Test Accuracy: 0.744\n",
      "Epoch: 229/1500..  Training Loss: 0.001..  Test Loss: 2.035..  Test Accuracy: 0.747\n",
      "Epoch: 230/1500..  Training Loss: 0.001..  Test Loss: 2.046..  Test Accuracy: 0.748\n",
      "Epoch: 231/1500..  Training Loss: 0.001..  Test Loss: 2.033..  Test Accuracy: 0.748\n",
      "Epoch: 232/1500..  Training Loss: 0.001..  Test Loss: 2.098..  Test Accuracy: 0.745\n",
      "Epoch: 233/1500..  Training Loss: 0.001..  Test Loss: 2.069..  Test Accuracy: 0.747\n",
      "Epoch: 234/1500..  Training Loss: 0.001..  Test Loss: 2.106..  Test Accuracy: 0.747\n",
      "Epoch: 235/1500..  Training Loss: 0.001..  Test Loss: 2.079..  Test Accuracy: 0.749\n",
      "Epoch: 236/1500..  Training Loss: 0.001..  Test Loss: 2.115..  Test Accuracy: 0.744\n",
      "Epoch: 237/1500..  Training Loss: 0.001..  Test Loss: 2.115..  Test Accuracy: 0.748\n",
      "Epoch: 238/1500..  Training Loss: 0.000..  Test Loss: 2.126..  Test Accuracy: 0.747\n",
      "Epoch: 239/1500..  Training Loss: 0.000..  Test Loss: 2.125..  Test Accuracy: 0.748\n",
      "Epoch: 240/1500..  Training Loss: 0.000..  Test Loss: 2.109..  Test Accuracy: 0.748\n",
      "Epoch: 241/1500..  Training Loss: 0.000..  Test Loss: 2.131..  Test Accuracy: 0.748\n",
      "Epoch: 242/1500..  Training Loss: 0.000..  Test Loss: 2.146..  Test Accuracy: 0.749\n",
      "Epoch: 243/1500..  Training Loss: 0.000..  Test Loss: 2.153..  Test Accuracy: 0.748\n",
      "Epoch: 244/1500..  Training Loss: 0.000..  Test Loss: 2.206..  Test Accuracy: 0.743\n",
      "Epoch: 245/1500..  Training Loss: 0.000..  Test Loss: 2.207..  Test Accuracy: 0.747\n",
      "Epoch: 246/1500..  Training Loss: 0.000..  Test Loss: 2.211..  Test Accuracy: 0.747\n",
      "Epoch: 247/1500..  Training Loss: 0.000..  Test Loss: 2.183..  Test Accuracy: 0.750\n",
      "Epoch: 248/1500..  Training Loss: 0.000..  Test Loss: 2.206..  Test Accuracy: 0.747\n",
      "Epoch: 249/1500..  Training Loss: 0.000..  Test Loss: 2.217..  Test Accuracy: 0.749\n",
      "Epoch: 250/1500..  Training Loss: 0.000..  Test Loss: 2.188..  Test Accuracy: 0.750\n",
      "Epoch: 251/1500..  Training Loss: 0.000..  Test Loss: 2.198..  Test Accuracy: 0.752\n",
      "Epoch: 252/1500..  Training Loss: 0.000..  Test Loss: 2.212..  Test Accuracy: 0.751\n",
      "Epoch: 253/1500..  Training Loss: 0.000..  Test Loss: 2.242..  Test Accuracy: 0.749\n",
      "Epoch: 254/1500..  Training Loss: 0.000..  Test Loss: 2.269..  Test Accuracy: 0.749\n",
      "Epoch: 255/1500..  Training Loss: 0.000..  Test Loss: 2.306..  Test Accuracy: 0.745\n",
      "Epoch: 256/1500..  Training Loss: 0.000..  Test Loss: 2.286..  Test Accuracy: 0.748\n",
      "Epoch: 257/1500..  Training Loss: 0.000..  Test Loss: 2.284..  Test Accuracy: 0.749\n",
      "Epoch: 258/1500..  Training Loss: 0.000..  Test Loss: 2.257..  Test Accuracy: 0.750\n",
      "Epoch: 259/1500..  Training Loss: 0.000..  Test Loss: 2.306..  Test Accuracy: 0.745\n",
      "Epoch: 260/1500..  Training Loss: 0.000..  Test Loss: 2.303..  Test Accuracy: 0.749\n",
      "Epoch: 261/1500..  Training Loss: 0.000..  Test Loss: 2.325..  Test Accuracy: 0.749\n",
      "Epoch: 262/1500..  Training Loss: 0.000..  Test Loss: 2.341..  Test Accuracy: 0.747\n",
      "Epoch: 263/1500..  Training Loss: 0.000..  Test Loss: 2.344..  Test Accuracy: 0.748\n",
      "Epoch: 264/1500..  Training Loss: 0.000..  Test Loss: 2.417..  Test Accuracy: 0.747\n",
      "Epoch: 265/1500..  Training Loss: 0.000..  Test Loss: 2.356..  Test Accuracy: 0.750\n",
      "Epoch: 266/1500..  Training Loss: 0.000..  Test Loss: 2.436..  Test Accuracy: 0.743\n",
      "Epoch: 267/1500..  Training Loss: 0.000..  Test Loss: 2.390..  Test Accuracy: 0.744\n",
      "Epoch: 268/1500..  Training Loss: 0.000..  Test Loss: 2.430..  Test Accuracy: 0.743\n",
      "Epoch: 269/1500..  Training Loss: 0.000..  Test Loss: 2.413..  Test Accuracy: 0.748\n",
      "Epoch: 270/1500..  Training Loss: 0.000..  Test Loss: 2.397..  Test Accuracy: 0.747\n",
      "Epoch: 271/1500..  Training Loss: 0.000..  Test Loss: 2.428..  Test Accuracy: 0.748\n",
      "Epoch: 272/1500..  Training Loss: 0.000..  Test Loss: 2.442..  Test Accuracy: 0.746\n",
      "Epoch: 273/1500..  Training Loss: 0.000..  Test Loss: 2.422..  Test Accuracy: 0.748\n",
      "Epoch: 274/1500..  Training Loss: 0.000..  Test Loss: 2.439..  Test Accuracy: 0.747\n",
      "Epoch: 275/1500..  Training Loss: 0.000..  Test Loss: 2.498..  Test Accuracy: 0.746\n",
      "Epoch: 276/1500..  Training Loss: 0.000..  Test Loss: 2.509..  Test Accuracy: 0.747\n",
      "Epoch: 277/1500..  Training Loss: 0.000..  Test Loss: 2.491..  Test Accuracy: 0.746\n",
      "Epoch: 278/1500..  Training Loss: 0.000..  Test Loss: 2.496..  Test Accuracy: 0.747\n",
      "Epoch: 279/1500..  Training Loss: 0.000..  Test Loss: 2.504..  Test Accuracy: 0.748\n",
      "Epoch: 280/1500..  Training Loss: 0.000..  Test Loss: 2.527..  Test Accuracy: 0.748\n",
      "Epoch: 281/1500..  Training Loss: 0.000..  Test Loss: 2.561..  Test Accuracy: 0.744\n",
      "Epoch: 282/1500..  Training Loss: 0.000..  Test Loss: 2.520..  Test Accuracy: 0.749\n",
      "Epoch: 283/1500..  Training Loss: 0.000..  Test Loss: 2.566..  Test Accuracy: 0.748\n",
      "Epoch: 284/1500..  Training Loss: 0.000..  Test Loss: 2.548..  Test Accuracy: 0.748\n",
      "Epoch: 285/1500..  Training Loss: 0.000..  Test Loss: 2.578..  Test Accuracy: 0.749\n",
      "Epoch: 286/1500..  Training Loss: 0.000..  Test Loss: 2.570..  Test Accuracy: 0.748\n",
      "Epoch: 287/1500..  Training Loss: 0.000..  Test Loss: 2.581..  Test Accuracy: 0.748\n",
      "Epoch: 288/1500..  Training Loss: 0.000..  Test Loss: 2.623..  Test Accuracy: 0.744\n",
      "Epoch: 289/1500..  Training Loss: 0.000..  Test Loss: 2.630..  Test Accuracy: 0.745\n",
      "Epoch: 290/1500..  Training Loss: 0.000..  Test Loss: 2.638..  Test Accuracy: 0.746\n",
      "Epoch: 291/1500..  Training Loss: 0.000..  Test Loss: 2.636..  Test Accuracy: 0.746\n",
      "Epoch: 292/1500..  Training Loss: 0.000..  Test Loss: 2.623..  Test Accuracy: 0.747\n",
      "Epoch: 293/1500..  Training Loss: 0.000..  Test Loss: 2.655..  Test Accuracy: 0.748\n",
      "Epoch: 294/1500..  Training Loss: 0.000..  Test Loss: 2.667..  Test Accuracy: 0.747\n",
      "Epoch: 295/1500..  Training Loss: 0.000..  Test Loss: 2.709..  Test Accuracy: 0.744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 296/1500..  Training Loss: 0.000..  Test Loss: 2.726..  Test Accuracy: 0.744\n",
      "Epoch: 297/1500..  Training Loss: 0.000..  Test Loss: 2.676..  Test Accuracy: 0.747\n",
      "Epoch: 298/1500..  Training Loss: 0.000..  Test Loss: 2.701..  Test Accuracy: 0.746\n",
      "Epoch: 299/1500..  Training Loss: 0.000..  Test Loss: 2.688..  Test Accuracy: 0.749\n",
      "Epoch: 300/1500..  Training Loss: 0.000..  Test Loss: 2.758..  Test Accuracy: 0.744\n",
      "Epoch: 301/1500..  Training Loss: 0.000..  Test Loss: 2.763..  Test Accuracy: 0.745\n",
      "Epoch: 302/1500..  Training Loss: 0.000..  Test Loss: 2.743..  Test Accuracy: 0.747\n",
      "Epoch: 303/1500..  Training Loss: 0.000..  Test Loss: 2.740..  Test Accuracy: 0.747\n",
      "Epoch: 304/1500..  Training Loss: 0.000..  Test Loss: 2.779..  Test Accuracy: 0.744\n",
      "Epoch: 305/1500..  Training Loss: 0.000..  Test Loss: 2.790..  Test Accuracy: 0.747\n",
      "Epoch: 306/1500..  Training Loss: 0.000..  Test Loss: 2.807..  Test Accuracy: 0.744\n",
      "Epoch: 307/1500..  Training Loss: 0.000..  Test Loss: 2.832..  Test Accuracy: 0.745\n",
      "Epoch: 308/1500..  Training Loss: 0.000..  Test Loss: 2.814..  Test Accuracy: 0.746\n",
      "Epoch: 309/1500..  Training Loss: 0.000..  Test Loss: 2.857..  Test Accuracy: 0.744\n",
      "Epoch: 310/1500..  Training Loss: 0.000..  Test Loss: 2.825..  Test Accuracy: 0.744\n",
      "Epoch: 311/1500..  Training Loss: 0.000..  Test Loss: 2.849..  Test Accuracy: 0.745\n",
      "Epoch: 312/1500..  Training Loss: 0.000..  Test Loss: 2.828..  Test Accuracy: 0.747\n",
      "Epoch: 313/1500..  Training Loss: 0.000..  Test Loss: 2.835..  Test Accuracy: 0.747\n",
      "Epoch: 314/1500..  Training Loss: 0.000..  Test Loss: 2.893..  Test Accuracy: 0.745\n",
      "Epoch: 315/1500..  Training Loss: 0.000..  Test Loss: 2.914..  Test Accuracy: 0.745\n",
      "Epoch: 316/1500..  Training Loss: 0.000..  Test Loss: 2.872..  Test Accuracy: 0.747\n",
      "Epoch: 317/1500..  Training Loss: 0.000..  Test Loss: 2.890..  Test Accuracy: 0.745\n",
      "Epoch: 318/1500..  Training Loss: 0.000..  Test Loss: 2.930..  Test Accuracy: 0.746\n",
      "Epoch: 319/1500..  Training Loss: 0.000..  Test Loss: 2.938..  Test Accuracy: 0.746\n",
      "Epoch: 320/1500..  Training Loss: 0.000..  Test Loss: 2.946..  Test Accuracy: 0.746\n",
      "Epoch: 321/1500..  Training Loss: 0.000..  Test Loss: 2.905..  Test Accuracy: 0.748\n",
      "Epoch: 322/1500..  Training Loss: 0.000..  Test Loss: 2.974..  Test Accuracy: 0.745\n",
      "Epoch: 323/1500..  Training Loss: 0.000..  Test Loss: 2.972..  Test Accuracy: 0.744\n",
      "Epoch: 324/1500..  Training Loss: 0.000..  Test Loss: 2.965..  Test Accuracy: 0.747\n",
      "Epoch: 325/1500..  Training Loss: 0.000..  Test Loss: 2.997..  Test Accuracy: 0.747\n",
      "Epoch: 326/1500..  Training Loss: 0.000..  Test Loss: 2.996..  Test Accuracy: 0.747\n",
      "Epoch: 327/1500..  Training Loss: 0.000..  Test Loss: 2.983..  Test Accuracy: 0.748\n",
      "Epoch: 328/1500..  Training Loss: 0.000..  Test Loss: 2.996..  Test Accuracy: 0.747\n",
      "Epoch: 329/1500..  Training Loss: 0.000..  Test Loss: 3.005..  Test Accuracy: 0.747\n",
      "Epoch: 330/1500..  Training Loss: 0.000..  Test Loss: 3.002..  Test Accuracy: 0.748\n",
      "Epoch: 331/1500..  Training Loss: 0.000..  Test Loss: 3.051..  Test Accuracy: 0.746\n",
      "Epoch: 332/1500..  Training Loss: 0.000..  Test Loss: 3.082..  Test Accuracy: 0.743\n",
      "Epoch: 333/1500..  Training Loss: 0.000..  Test Loss: 3.058..  Test Accuracy: 0.748\n",
      "Epoch: 334/1500..  Training Loss: 0.000..  Test Loss: 3.067..  Test Accuracy: 0.746\n",
      "Epoch: 335/1500..  Training Loss: 0.000..  Test Loss: 3.076..  Test Accuracy: 0.746\n",
      "Epoch: 336/1500..  Training Loss: 0.000..  Test Loss: 3.113..  Test Accuracy: 0.744\n",
      "Epoch: 337/1500..  Training Loss: 0.000..  Test Loss: 3.063..  Test Accuracy: 0.747\n",
      "Epoch: 338/1500..  Training Loss: 0.000..  Test Loss: 3.119..  Test Accuracy: 0.747\n",
      "Epoch: 339/1500..  Training Loss: 0.000..  Test Loss: 3.123..  Test Accuracy: 0.747\n",
      "Epoch: 340/1500..  Training Loss: 0.000..  Test Loss: 3.116..  Test Accuracy: 0.747\n",
      "Epoch: 341/1500..  Training Loss: 0.000..  Test Loss: 3.170..  Test Accuracy: 0.745\n",
      "Epoch: 342/1500..  Training Loss: 0.000..  Test Loss: 3.103..  Test Accuracy: 0.749\n",
      "Epoch: 343/1500..  Training Loss: 0.000..  Test Loss: 3.167..  Test Accuracy: 0.745\n",
      "Epoch: 344/1500..  Training Loss: 0.000..  Test Loss: 3.183..  Test Accuracy: 0.745\n",
      "Epoch: 345/1500..  Training Loss: 0.000..  Test Loss: 3.151..  Test Accuracy: 0.748\n",
      "Epoch: 346/1500..  Training Loss: 0.000..  Test Loss: 3.183..  Test Accuracy: 0.745\n",
      "Epoch: 347/1500..  Training Loss: 0.000..  Test Loss: 3.206..  Test Accuracy: 0.744\n",
      "Epoch: 348/1500..  Training Loss: 0.000..  Test Loss: 3.216..  Test Accuracy: 0.747\n",
      "Epoch: 349/1500..  Training Loss: 0.000..  Test Loss: 3.216..  Test Accuracy: 0.747\n",
      "Epoch: 350/1500..  Training Loss: 0.000..  Test Loss: 3.289..  Test Accuracy: 0.741\n",
      "Epoch: 351/1500..  Training Loss: 0.000..  Test Loss: 3.262..  Test Accuracy: 0.743\n",
      "Epoch: 352/1500..  Training Loss: 0.000..  Test Loss: 3.247..  Test Accuracy: 0.745\n",
      "Epoch: 353/1500..  Training Loss: 0.000..  Test Loss: 3.277..  Test Accuracy: 0.745\n",
      "Epoch: 354/1500..  Training Loss: 0.000..  Test Loss: 3.238..  Test Accuracy: 0.746\n",
      "Epoch: 355/1500..  Training Loss: 0.000..  Test Loss: 3.233..  Test Accuracy: 0.749\n",
      "Epoch: 356/1500..  Training Loss: 0.000..  Test Loss: 3.270..  Test Accuracy: 0.746\n",
      "Epoch: 357/1500..  Training Loss: 0.000..  Test Loss: 3.330..  Test Accuracy: 0.744\n",
      "Epoch: 358/1500..  Training Loss: 0.000..  Test Loss: 3.291..  Test Accuracy: 0.746\n",
      "Epoch: 359/1500..  Training Loss: 0.000..  Test Loss: 3.310..  Test Accuracy: 0.746\n",
      "Epoch: 360/1500..  Training Loss: 0.000..  Test Loss: 3.354..  Test Accuracy: 0.745\n",
      "Epoch: 361/1500..  Training Loss: 0.000..  Test Loss: 3.351..  Test Accuracy: 0.747\n",
      "Epoch: 362/1500..  Training Loss: 0.000..  Test Loss: 3.354..  Test Accuracy: 0.746\n",
      "Epoch: 363/1500..  Training Loss: 0.000..  Test Loss: 3.360..  Test Accuracy: 0.747\n",
      "Epoch: 364/1500..  Training Loss: 0.000..  Test Loss: 3.356..  Test Accuracy: 0.748\n",
      "Epoch: 365/1500..  Training Loss: 0.000..  Test Loss: 3.409..  Test Accuracy: 0.744\n",
      "Epoch: 366/1500..  Training Loss: 0.000..  Test Loss: 3.388..  Test Accuracy: 0.747\n",
      "Epoch: 367/1500..  Training Loss: 0.000..  Test Loss: 3.389..  Test Accuracy: 0.747\n",
      "Epoch: 368/1500..  Training Loss: 0.000..  Test Loss: 3.368..  Test Accuracy: 0.748\n",
      "Epoch: 369/1500..  Training Loss: 0.000..  Test Loss: 3.455..  Test Accuracy: 0.746\n",
      "Epoch: 370/1500..  Training Loss: 0.000..  Test Loss: 3.476..  Test Accuracy: 0.744\n",
      "Epoch: 371/1500..  Training Loss: 0.000..  Test Loss: 3.460..  Test Accuracy: 0.744\n",
      "Epoch: 372/1500..  Training Loss: 0.000..  Test Loss: 3.437..  Test Accuracy: 0.746\n",
      "Epoch: 373/1500..  Training Loss: 0.000..  Test Loss: 3.425..  Test Accuracy: 0.747\n",
      "Epoch: 374/1500..  Training Loss: 0.000..  Test Loss: 3.476..  Test Accuracy: 0.746\n",
      "Epoch: 375/1500..  Training Loss: 0.000..  Test Loss: 3.495..  Test Accuracy: 0.744\n",
      "Epoch: 376/1500..  Training Loss: 0.000..  Test Loss: 3.481..  Test Accuracy: 0.746\n",
      "Epoch: 377/1500..  Training Loss: 0.000..  Test Loss: 3.520..  Test Accuracy: 0.746\n",
      "Epoch: 378/1500..  Training Loss: 0.000..  Test Loss: 3.541..  Test Accuracy: 0.746\n",
      "Epoch: 379/1500..  Training Loss: 0.000..  Test Loss: 3.528..  Test Accuracy: 0.746\n",
      "Epoch: 380/1500..  Training Loss: 0.000..  Test Loss: 3.533..  Test Accuracy: 0.747\n",
      "Epoch: 381/1500..  Training Loss: 0.000..  Test Loss: 3.537..  Test Accuracy: 0.747\n",
      "Epoch: 382/1500..  Training Loss: 0.000..  Test Loss: 3.561..  Test Accuracy: 0.747\n",
      "Epoch: 383/1500..  Training Loss: 0.000..  Test Loss: 3.539..  Test Accuracy: 0.747\n",
      "Epoch: 384/1500..  Training Loss: 0.000..  Test Loss: 3.582..  Test Accuracy: 0.746\n",
      "Epoch: 385/1500..  Training Loss: 0.000..  Test Loss: 3.585..  Test Accuracy: 0.744\n",
      "Epoch: 386/1500..  Training Loss: 0.000..  Test Loss: 3.644..  Test Accuracy: 0.745\n",
      "Epoch: 387/1500..  Training Loss: 0.000..  Test Loss: 3.658..  Test Accuracy: 0.742\n",
      "Epoch: 388/1500..  Training Loss: 0.000..  Test Loss: 3.671..  Test Accuracy: 0.745\n",
      "Epoch: 389/1500..  Training Loss: 0.000..  Test Loss: 3.605..  Test Accuracy: 0.747\n",
      "Epoch: 390/1500..  Training Loss: 0.000..  Test Loss: 3.647..  Test Accuracy: 0.744\n",
      "Epoch: 391/1500..  Training Loss: 0.000..  Test Loss: 3.667..  Test Accuracy: 0.746\n",
      "Epoch: 392/1500..  Training Loss: 0.000..  Test Loss: 3.653..  Test Accuracy: 0.745\n",
      "Epoch: 393/1500..  Training Loss: 0.000..  Test Loss: 3.686..  Test Accuracy: 0.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 394/1500..  Training Loss: 0.000..  Test Loss: 3.712..  Test Accuracy: 0.744\n",
      "Epoch: 395/1500..  Training Loss: 0.000..  Test Loss: 3.700..  Test Accuracy: 0.744\n",
      "Epoch: 396/1500..  Training Loss: 0.000..  Test Loss: 3.673..  Test Accuracy: 0.746\n",
      "Epoch: 397/1500..  Training Loss: 0.000..  Test Loss: 3.691..  Test Accuracy: 0.746\n",
      "Epoch: 398/1500..  Training Loss: 0.000..  Test Loss: 3.710..  Test Accuracy: 0.747\n",
      "Epoch: 399/1500..  Training Loss: 0.000..  Test Loss: 3.704..  Test Accuracy: 0.746\n",
      "Epoch: 400/1500..  Training Loss: 0.000..  Test Loss: 3.727..  Test Accuracy: 0.746\n",
      "Epoch: 401/1500..  Training Loss: 0.000..  Test Loss: 3.719..  Test Accuracy: 0.745\n",
      "Epoch: 402/1500..  Training Loss: 0.000..  Test Loss: 3.781..  Test Accuracy: 0.744\n",
      "Epoch: 403/1500..  Training Loss: 0.000..  Test Loss: 3.761..  Test Accuracy: 0.745\n",
      "Epoch: 404/1500..  Training Loss: 0.000..  Test Loss: 3.770..  Test Accuracy: 0.746\n",
      "Epoch: 405/1500..  Training Loss: 0.000..  Test Loss: 3.811..  Test Accuracy: 0.746\n",
      "Epoch: 406/1500..  Training Loss: 0.000..  Test Loss: 3.806..  Test Accuracy: 0.746\n",
      "Epoch: 407/1500..  Training Loss: 0.000..  Test Loss: 3.794..  Test Accuracy: 0.747\n",
      "Epoch: 408/1500..  Training Loss: 0.000..  Test Loss: 3.830..  Test Accuracy: 0.743\n",
      "Epoch: 409/1500..  Training Loss: 0.000..  Test Loss: 3.790..  Test Accuracy: 0.747\n",
      "Epoch: 410/1500..  Training Loss: 0.000..  Test Loss: 3.876..  Test Accuracy: 0.744\n",
      "Epoch: 411/1500..  Training Loss: 0.000..  Test Loss: 3.863..  Test Accuracy: 0.745\n",
      "Epoch: 412/1500..  Training Loss: 0.000..  Test Loss: 3.865..  Test Accuracy: 0.746\n",
      "Epoch: 413/1500..  Training Loss: 0.000..  Test Loss: 3.834..  Test Accuracy: 0.747\n",
      "Epoch: 414/1500..  Training Loss: 0.000..  Test Loss: 3.898..  Test Accuracy: 0.745\n",
      "Epoch: 415/1500..  Training Loss: 0.000..  Test Loss: 3.869..  Test Accuracy: 0.746\n",
      "Epoch: 416/1500..  Training Loss: 0.000..  Test Loss: 3.909..  Test Accuracy: 0.747\n",
      "Epoch: 417/1500..  Training Loss: 0.000..  Test Loss: 3.947..  Test Accuracy: 0.744\n",
      "Epoch: 418/1500..  Training Loss: 0.000..  Test Loss: 3.962..  Test Accuracy: 0.744\n",
      "Epoch: 419/1500..  Training Loss: 0.000..  Test Loss: 3.938..  Test Accuracy: 0.747\n",
      "Epoch: 420/1500..  Training Loss: 0.000..  Test Loss: 3.944..  Test Accuracy: 0.745\n",
      "Epoch: 421/1500..  Training Loss: 0.000..  Test Loss: 3.971..  Test Accuracy: 0.744\n",
      "Epoch: 422/1500..  Training Loss: 0.000..  Test Loss: 3.958..  Test Accuracy: 0.745\n",
      "Epoch: 423/1500..  Training Loss: 0.000..  Test Loss: 3.964..  Test Accuracy: 0.745\n",
      "Epoch: 424/1500..  Training Loss: 0.000..  Test Loss: 3.970..  Test Accuracy: 0.745\n",
      "Epoch: 425/1500..  Training Loss: 0.000..  Test Loss: 3.980..  Test Accuracy: 0.746\n",
      "Epoch: 426/1500..  Training Loss: 0.000..  Test Loss: 4.042..  Test Accuracy: 0.743\n",
      "Epoch: 427/1500..  Training Loss: 0.000..  Test Loss: 3.994..  Test Accuracy: 0.745\n",
      "Epoch: 428/1500..  Training Loss: 0.000..  Test Loss: 4.056..  Test Accuracy: 0.742\n",
      "Epoch: 429/1500..  Training Loss: 0.000..  Test Loss: 4.064..  Test Accuracy: 0.743\n",
      "Epoch: 430/1500..  Training Loss: 0.000..  Test Loss: 4.075..  Test Accuracy: 0.742\n",
      "Epoch: 431/1500..  Training Loss: 0.000..  Test Loss: 4.024..  Test Accuracy: 0.747\n",
      "Epoch: 432/1500..  Training Loss: 0.000..  Test Loss: 4.038..  Test Accuracy: 0.746\n",
      "Epoch: 433/1500..  Training Loss: 0.000..  Test Loss: 4.061..  Test Accuracy: 0.744\n",
      "Epoch: 434/1500..  Training Loss: 0.000..  Test Loss: 4.103..  Test Accuracy: 0.745\n",
      "Epoch: 435/1500..  Training Loss: 0.000..  Test Loss: 4.110..  Test Accuracy: 0.745\n",
      "Epoch: 436/1500..  Training Loss: 0.000..  Test Loss: 4.143..  Test Accuracy: 0.743\n",
      "Epoch: 437/1500..  Training Loss: 0.000..  Test Loss: 4.131..  Test Accuracy: 0.745\n",
      "Epoch: 438/1500..  Training Loss: 0.000..  Test Loss: 4.150..  Test Accuracy: 0.744\n",
      "Epoch: 439/1500..  Training Loss: 0.000..  Test Loss: 4.118..  Test Accuracy: 0.745\n",
      "Epoch: 440/1500..  Training Loss: 0.000..  Test Loss: 4.120..  Test Accuracy: 0.745\n",
      "Epoch: 441/1500..  Training Loss: 0.000..  Test Loss: 4.210..  Test Accuracy: 0.743\n",
      "Epoch: 442/1500..  Training Loss: 0.000..  Test Loss: 4.170..  Test Accuracy: 0.743\n",
      "Epoch: 443/1500..  Training Loss: 0.000..  Test Loss: 4.131..  Test Accuracy: 0.747\n",
      "Epoch: 444/1500..  Training Loss: 0.000..  Test Loss: 4.158..  Test Accuracy: 0.746\n",
      "Epoch: 445/1500..  Training Loss: 0.000..  Test Loss: 4.214..  Test Accuracy: 0.743\n",
      "Epoch: 446/1500..  Training Loss: 0.000..  Test Loss: 4.157..  Test Accuracy: 0.747\n",
      "Epoch: 447/1500..  Training Loss: 0.000..  Test Loss: 4.243..  Test Accuracy: 0.744\n",
      "Epoch: 448/1500..  Training Loss: 0.000..  Test Loss: 4.215..  Test Accuracy: 0.745\n",
      "Epoch: 449/1500..  Training Loss: 0.000..  Test Loss: 4.290..  Test Accuracy: 0.742\n",
      "Epoch: 450/1500..  Training Loss: 0.000..  Test Loss: 4.280..  Test Accuracy: 0.742\n",
      "Epoch: 451/1500..  Training Loss: 0.000..  Test Loss: 4.220..  Test Accuracy: 0.746\n",
      "Epoch: 452/1500..  Training Loss: 0.000..  Test Loss: 4.246..  Test Accuracy: 0.745\n",
      "Epoch: 453/1500..  Training Loss: 0.000..  Test Loss: 4.267..  Test Accuracy: 0.744\n",
      "Epoch: 454/1500..  Training Loss: 0.000..  Test Loss: 4.238..  Test Accuracy: 0.745\n",
      "Epoch: 455/1500..  Training Loss: 0.000..  Test Loss: 4.258..  Test Accuracy: 0.746\n",
      "Epoch: 456/1500..  Training Loss: 0.000..  Test Loss: 4.285..  Test Accuracy: 0.745\n",
      "Epoch: 457/1500..  Training Loss: 0.000..  Test Loss: 4.321..  Test Accuracy: 0.745\n",
      "Epoch: 458/1500..  Training Loss: 0.000..  Test Loss: 4.283..  Test Accuracy: 0.744\n",
      "Epoch: 459/1500..  Training Loss: 0.000..  Test Loss: 4.309..  Test Accuracy: 0.744\n",
      "Epoch: 460/1500..  Training Loss: 0.000..  Test Loss: 4.366..  Test Accuracy: 0.742\n",
      "Epoch: 461/1500..  Training Loss: 0.000..  Test Loss: 4.327..  Test Accuracy: 0.744\n",
      "Epoch: 462/1500..  Training Loss: 0.000..  Test Loss: 4.350..  Test Accuracy: 0.746\n",
      "Epoch: 463/1500..  Training Loss: 0.000..  Test Loss: 4.342..  Test Accuracy: 0.744\n",
      "Epoch: 464/1500..  Training Loss: 0.000..  Test Loss: 4.332..  Test Accuracy: 0.746\n",
      "Epoch: 465/1500..  Training Loss: 0.000..  Test Loss: 4.345..  Test Accuracy: 0.745\n",
      "Epoch: 466/1500..  Training Loss: 0.000..  Test Loss: 4.384..  Test Accuracy: 0.743\n",
      "Epoch: 467/1500..  Training Loss: 0.000..  Test Loss: 4.352..  Test Accuracy: 0.746\n",
      "Epoch: 468/1500..  Training Loss: 0.000..  Test Loss: 4.383..  Test Accuracy: 0.744\n",
      "Epoch: 469/1500..  Training Loss: 0.000..  Test Loss: 4.406..  Test Accuracy: 0.742\n",
      "Epoch: 470/1500..  Training Loss: 0.000..  Test Loss: 4.446..  Test Accuracy: 0.744\n",
      "Epoch: 471/1500..  Training Loss: 0.000..  Test Loss: 4.426..  Test Accuracy: 0.744\n",
      "Epoch: 472/1500..  Training Loss: 0.000..  Test Loss: 4.400..  Test Accuracy: 0.747\n",
      "Epoch: 473/1500..  Training Loss: 0.000..  Test Loss: 4.414..  Test Accuracy: 0.745\n",
      "Epoch: 474/1500..  Training Loss: 0.000..  Test Loss: 4.487..  Test Accuracy: 0.741\n",
      "Epoch: 475/1500..  Training Loss: 0.000..  Test Loss: 4.454..  Test Accuracy: 0.743\n",
      "Epoch: 476/1500..  Training Loss: 0.000..  Test Loss: 4.486..  Test Accuracy: 0.743\n",
      "Epoch: 477/1500..  Training Loss: 0.000..  Test Loss: 4.455..  Test Accuracy: 0.745\n",
      "Epoch: 478/1500..  Training Loss: 0.000..  Test Loss: 4.476..  Test Accuracy: 0.744\n",
      "Epoch: 479/1500..  Training Loss: 0.000..  Test Loss: 4.458..  Test Accuracy: 0.744\n",
      "Epoch: 480/1500..  Training Loss: 0.000..  Test Loss: 4.446..  Test Accuracy: 0.745\n",
      "Epoch: 481/1500..  Training Loss: 0.000..  Test Loss: 4.505..  Test Accuracy: 0.743\n",
      "Epoch: 482/1500..  Training Loss: 0.000..  Test Loss: 4.503..  Test Accuracy: 0.743\n",
      "Epoch: 483/1500..  Training Loss: 0.000..  Test Loss: 4.533..  Test Accuracy: 0.742\n",
      "Epoch: 484/1500..  Training Loss: 0.000..  Test Loss: 4.515..  Test Accuracy: 0.744\n",
      "Epoch: 485/1500..  Training Loss: 0.000..  Test Loss: 4.524..  Test Accuracy: 0.745\n",
      "Epoch: 486/1500..  Training Loss: 0.000..  Test Loss: 4.542..  Test Accuracy: 0.743\n",
      "Epoch: 487/1500..  Training Loss: 0.000..  Test Loss: 4.542..  Test Accuracy: 0.743\n",
      "Epoch: 488/1500..  Training Loss: 0.000..  Test Loss: 4.547..  Test Accuracy: 0.744\n",
      "Epoch: 489/1500..  Training Loss: 0.000..  Test Loss: 4.543..  Test Accuracy: 0.745\n",
      "Epoch: 490/1500..  Training Loss: 0.000..  Test Loss: 4.554..  Test Accuracy: 0.743\n",
      "Epoch: 491/1500..  Training Loss: 0.000..  Test Loss: 4.570..  Test Accuracy: 0.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 492/1500..  Training Loss: 0.000..  Test Loss: 4.552..  Test Accuracy: 0.745\n",
      "Epoch: 493/1500..  Training Loss: 0.000..  Test Loss: 4.529..  Test Accuracy: 0.747\n",
      "Epoch: 494/1500..  Training Loss: 0.000..  Test Loss: 4.551..  Test Accuracy: 0.744\n",
      "Epoch: 495/1500..  Training Loss: 0.000..  Test Loss: 4.577..  Test Accuracy: 0.744\n",
      "Epoch: 496/1500..  Training Loss: 0.000..  Test Loss: 4.602..  Test Accuracy: 0.743\n",
      "Epoch: 497/1500..  Training Loss: 0.000..  Test Loss: 4.573..  Test Accuracy: 0.746\n",
      "Epoch: 498/1500..  Training Loss: 0.000..  Test Loss: 4.580..  Test Accuracy: 0.745\n",
      "Epoch: 499/1500..  Training Loss: 0.000..  Test Loss: 4.596..  Test Accuracy: 0.744\n",
      "Epoch: 500/1500..  Training Loss: 0.000..  Test Loss: 4.593..  Test Accuracy: 0.744\n",
      "Epoch: 501/1500..  Training Loss: 0.000..  Test Loss: 4.592..  Test Accuracy: 0.746\n",
      "Epoch: 502/1500..  Training Loss: 0.000..  Test Loss: 4.591..  Test Accuracy: 0.745\n",
      "Epoch: 503/1500..  Training Loss: 0.000..  Test Loss: 4.632..  Test Accuracy: 0.744\n",
      "Epoch: 504/1500..  Training Loss: 0.000..  Test Loss: 4.668..  Test Accuracy: 0.742\n",
      "Epoch: 505/1500..  Training Loss: 0.000..  Test Loss: 4.608..  Test Accuracy: 0.746\n",
      "Epoch: 506/1500..  Training Loss: 0.000..  Test Loss: 4.645..  Test Accuracy: 0.744\n",
      "Epoch: 507/1500..  Training Loss: 0.000..  Test Loss: 4.646..  Test Accuracy: 0.744\n",
      "Epoch: 508/1500..  Training Loss: 0.000..  Test Loss: 4.664..  Test Accuracy: 0.744\n",
      "Epoch: 509/1500..  Training Loss: 0.000..  Test Loss: 4.635..  Test Accuracy: 0.745\n",
      "Epoch: 510/1500..  Training Loss: 0.000..  Test Loss: 4.668..  Test Accuracy: 0.743\n",
      "Epoch: 511/1500..  Training Loss: 0.000..  Test Loss: 4.670..  Test Accuracy: 0.744\n",
      "Epoch: 512/1500..  Training Loss: 0.000..  Test Loss: 4.653..  Test Accuracy: 0.745\n",
      "Epoch: 513/1500..  Training Loss: 0.000..  Test Loss: 4.676..  Test Accuracy: 0.745\n",
      "Epoch: 514/1500..  Training Loss: 0.000..  Test Loss: 4.694..  Test Accuracy: 0.744\n",
      "Epoch: 515/1500..  Training Loss: 0.000..  Test Loss: 4.680..  Test Accuracy: 0.744\n",
      "Epoch: 516/1500..  Training Loss: 0.000..  Test Loss: 4.675..  Test Accuracy: 0.744\n",
      "Epoch: 517/1500..  Training Loss: 0.000..  Test Loss: 4.711..  Test Accuracy: 0.743\n",
      "Epoch: 518/1500..  Training Loss: 0.000..  Test Loss: 4.683..  Test Accuracy: 0.746\n",
      "Epoch: 519/1500..  Training Loss: 0.000..  Test Loss: 4.687..  Test Accuracy: 0.745\n",
      "Epoch: 520/1500..  Training Loss: 0.000..  Test Loss: 4.711..  Test Accuracy: 0.744\n",
      "Epoch: 521/1500..  Training Loss: 0.000..  Test Loss: 4.683..  Test Accuracy: 0.744\n",
      "Epoch: 522/1500..  Training Loss: 0.000..  Test Loss: 4.679..  Test Accuracy: 0.745\n",
      "Epoch: 523/1500..  Training Loss: 0.000..  Test Loss: 4.693..  Test Accuracy: 0.745\n",
      "Epoch: 524/1500..  Training Loss: 0.000..  Test Loss: 4.733..  Test Accuracy: 0.743\n",
      "Epoch: 525/1500..  Training Loss: 0.000..  Test Loss: 4.693..  Test Accuracy: 0.745\n",
      "Epoch: 526/1500..  Training Loss: 0.000..  Test Loss: 4.733..  Test Accuracy: 0.743\n",
      "Epoch: 527/1500..  Training Loss: 0.000..  Test Loss: 4.716..  Test Accuracy: 0.744\n",
      "Epoch: 528/1500..  Training Loss: 0.000..  Test Loss: 4.757..  Test Accuracy: 0.742\n",
      "Epoch: 529/1500..  Training Loss: 0.000..  Test Loss: 4.726..  Test Accuracy: 0.744\n",
      "Epoch: 530/1500..  Training Loss: 0.000..  Test Loss: 4.748..  Test Accuracy: 0.743\n",
      "Epoch: 531/1500..  Training Loss: 0.000..  Test Loss: 4.764..  Test Accuracy: 0.743\n",
      "Epoch: 532/1500..  Training Loss: 0.000..  Test Loss: 4.771..  Test Accuracy: 0.743\n",
      "Epoch: 533/1500..  Training Loss: 0.000..  Test Loss: 4.744..  Test Accuracy: 0.745\n",
      "Epoch: 534/1500..  Training Loss: 0.000..  Test Loss: 4.760..  Test Accuracy: 0.744\n",
      "Epoch: 535/1500..  Training Loss: 0.000..  Test Loss: 4.753..  Test Accuracy: 0.744\n",
      "Epoch: 536/1500..  Training Loss: 0.000..  Test Loss: 4.758..  Test Accuracy: 0.744\n",
      "Epoch: 537/1500..  Training Loss: 0.000..  Test Loss: 4.758..  Test Accuracy: 0.744\n",
      "Epoch: 538/1500..  Training Loss: 0.000..  Test Loss: 4.732..  Test Accuracy: 0.746\n",
      "Epoch: 539/1500..  Training Loss: 0.000..  Test Loss: 4.745..  Test Accuracy: 0.745\n",
      "Epoch: 540/1500..  Training Loss: 0.000..  Test Loss: 4.764..  Test Accuracy: 0.744\n",
      "Epoch: 541/1500..  Training Loss: 0.000..  Test Loss: 4.747..  Test Accuracy: 0.744\n",
      "Epoch: 542/1500..  Training Loss: 0.000..  Test Loss: 4.790..  Test Accuracy: 0.744\n",
      "Epoch: 543/1500..  Training Loss: 0.000..  Test Loss: 4.763..  Test Accuracy: 0.746\n",
      "Epoch: 544/1500..  Training Loss: 0.000..  Test Loss: 4.754..  Test Accuracy: 0.746\n",
      "Epoch: 545/1500..  Training Loss: 0.000..  Test Loss: 4.768..  Test Accuracy: 0.745\n",
      "Epoch: 546/1500..  Training Loss: 0.000..  Test Loss: 4.770..  Test Accuracy: 0.745\n",
      "Epoch: 547/1500..  Training Loss: 0.000..  Test Loss: 4.777..  Test Accuracy: 0.744\n",
      "Epoch: 548/1500..  Training Loss: 0.000..  Test Loss: 4.791..  Test Accuracy: 0.745\n",
      "Epoch: 549/1500..  Training Loss: 0.000..  Test Loss: 4.811..  Test Accuracy: 0.743\n",
      "Epoch: 550/1500..  Training Loss: 0.000..  Test Loss: 4.784..  Test Accuracy: 0.746\n",
      "Epoch: 551/1500..  Training Loss: 0.000..  Test Loss: 4.795..  Test Accuracy: 0.744\n",
      "Epoch: 552/1500..  Training Loss: 0.000..  Test Loss: 4.819..  Test Accuracy: 0.743\n",
      "Epoch: 553/1500..  Training Loss: 0.000..  Test Loss: 4.818..  Test Accuracy: 0.744\n",
      "Epoch: 554/1500..  Training Loss: 0.000..  Test Loss: 4.776..  Test Accuracy: 0.746\n",
      "Epoch: 555/1500..  Training Loss: 0.000..  Test Loss: 4.782..  Test Accuracy: 0.746\n",
      "Epoch: 556/1500..  Training Loss: 0.000..  Test Loss: 4.791..  Test Accuracy: 0.744\n",
      "Epoch: 557/1500..  Training Loss: 0.000..  Test Loss: 4.820..  Test Accuracy: 0.744\n",
      "Epoch: 558/1500..  Training Loss: 0.000..  Test Loss: 4.820..  Test Accuracy: 0.744\n",
      "Epoch: 559/1500..  Training Loss: 0.000..  Test Loss: 4.832..  Test Accuracy: 0.743\n",
      "Epoch: 560/1500..  Training Loss: 0.000..  Test Loss: 4.798..  Test Accuracy: 0.746\n",
      "Epoch: 561/1500..  Training Loss: 0.000..  Test Loss: 4.801..  Test Accuracy: 0.746\n",
      "Epoch: 562/1500..  Training Loss: 0.000..  Test Loss: 4.819..  Test Accuracy: 0.745\n",
      "Epoch: 563/1500..  Training Loss: 0.000..  Test Loss: 4.812..  Test Accuracy: 0.745\n",
      "Epoch: 564/1500..  Training Loss: 0.000..  Test Loss: 4.824..  Test Accuracy: 0.745\n",
      "Epoch: 565/1500..  Training Loss: 0.000..  Test Loss: 4.816..  Test Accuracy: 0.745\n",
      "Epoch: 566/1500..  Training Loss: 0.000..  Test Loss: 4.812..  Test Accuracy: 0.746\n",
      "Epoch: 567/1500..  Training Loss: 0.000..  Test Loss: 4.820..  Test Accuracy: 0.745\n",
      "Epoch: 568/1500..  Training Loss: 0.000..  Test Loss: 4.824..  Test Accuracy: 0.745\n",
      "Epoch: 569/1500..  Training Loss: 0.000..  Test Loss: 4.847..  Test Accuracy: 0.744\n",
      "Epoch: 570/1500..  Training Loss: 0.000..  Test Loss: 4.839..  Test Accuracy: 0.744\n",
      "Epoch: 571/1500..  Training Loss: 0.000..  Test Loss: 4.826..  Test Accuracy: 0.745\n",
      "Epoch: 572/1500..  Training Loss: 0.000..  Test Loss: 4.841..  Test Accuracy: 0.744\n",
      "Epoch: 573/1500..  Training Loss: 0.000..  Test Loss: 4.838..  Test Accuracy: 0.744\n",
      "Epoch: 574/1500..  Training Loss: 0.000..  Test Loss: 4.846..  Test Accuracy: 0.745\n",
      "Epoch: 575/1500..  Training Loss: 0.000..  Test Loss: 4.841..  Test Accuracy: 0.745\n",
      "Epoch: 576/1500..  Training Loss: 0.000..  Test Loss: 4.859..  Test Accuracy: 0.744\n",
      "Epoch: 577/1500..  Training Loss: 0.000..  Test Loss: 4.847..  Test Accuracy: 0.745\n",
      "Epoch: 578/1500..  Training Loss: 0.000..  Test Loss: 4.858..  Test Accuracy: 0.744\n",
      "Epoch: 579/1500..  Training Loss: 0.000..  Test Loss: 4.848..  Test Accuracy: 0.745\n",
      "Epoch: 580/1500..  Training Loss: 0.000..  Test Loss: 4.859..  Test Accuracy: 0.745\n",
      "Epoch: 581/1500..  Training Loss: 0.000..  Test Loss: 4.863..  Test Accuracy: 0.744\n",
      "Epoch: 582/1500..  Training Loss: 0.000..  Test Loss: 4.851..  Test Accuracy: 0.746\n",
      "Epoch: 583/1500..  Training Loss: 0.000..  Test Loss: 4.863..  Test Accuracy: 0.745\n",
      "Epoch: 584/1500..  Training Loss: 0.000..  Test Loss: 4.858..  Test Accuracy: 0.745\n",
      "Epoch: 585/1500..  Training Loss: 0.000..  Test Loss: 4.853..  Test Accuracy: 0.746\n",
      "Epoch: 586/1500..  Training Loss: 0.000..  Test Loss: 4.854..  Test Accuracy: 0.745\n",
      "Epoch: 587/1500..  Training Loss: 0.000..  Test Loss: 4.865..  Test Accuracy: 0.745\n",
      "Epoch: 588/1500..  Training Loss: 0.000..  Test Loss: 4.860..  Test Accuracy: 0.746\n",
      "Epoch: 589/1500..  Training Loss: 0.000..  Test Loss: 4.877..  Test Accuracy: 0.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 590/1500..  Training Loss: 0.000..  Test Loss: 4.865..  Test Accuracy: 0.745\n",
      "Epoch: 591/1500..  Training Loss: 0.000..  Test Loss: 4.889..  Test Accuracy: 0.744\n",
      "Epoch: 592/1500..  Training Loss: 0.000..  Test Loss: 4.881..  Test Accuracy: 0.744\n",
      "Epoch: 593/1500..  Training Loss: 0.000..  Test Loss: 4.861..  Test Accuracy: 0.745\n",
      "Epoch: 594/1500..  Training Loss: 0.000..  Test Loss: 4.879..  Test Accuracy: 0.745\n",
      "Epoch: 595/1500..  Training Loss: 0.000..  Test Loss: 4.883..  Test Accuracy: 0.744\n",
      "Epoch: 596/1500..  Training Loss: 0.000..  Test Loss: 4.870..  Test Accuracy: 0.745\n",
      "Epoch: 597/1500..  Training Loss: 0.000..  Test Loss: 4.881..  Test Accuracy: 0.744\n",
      "Epoch: 598/1500..  Training Loss: 0.000..  Test Loss: 4.866..  Test Accuracy: 0.745\n",
      "Epoch: 599/1500..  Training Loss: 0.000..  Test Loss: 4.887..  Test Accuracy: 0.745\n",
      "Epoch: 600/1500..  Training Loss: 0.000..  Test Loss: 4.900..  Test Accuracy: 0.744\n",
      "Epoch: 601/1500..  Training Loss: 0.000..  Test Loss: 4.880..  Test Accuracy: 0.745\n",
      "Epoch: 602/1500..  Training Loss: 0.000..  Test Loss: 4.886..  Test Accuracy: 0.745\n",
      "Epoch: 603/1500..  Training Loss: 0.000..  Test Loss: 4.889..  Test Accuracy: 0.744\n",
      "Epoch: 604/1500..  Training Loss: 0.000..  Test Loss: 4.884..  Test Accuracy: 0.746\n",
      "Epoch: 605/1500..  Training Loss: 0.000..  Test Loss: 4.887..  Test Accuracy: 0.745\n",
      "Epoch: 606/1500..  Training Loss: 0.000..  Test Loss: 4.892..  Test Accuracy: 0.745\n",
      "Epoch: 607/1500..  Training Loss: 0.000..  Test Loss: 4.902..  Test Accuracy: 0.744\n",
      "Epoch: 608/1500..  Training Loss: 0.000..  Test Loss: 4.884..  Test Accuracy: 0.746\n",
      "Epoch: 609/1500..  Training Loss: 0.000..  Test Loss: 4.899..  Test Accuracy: 0.745\n",
      "Epoch: 610/1500..  Training Loss: 0.000..  Test Loss: 4.893..  Test Accuracy: 0.745\n",
      "Epoch: 611/1500..  Training Loss: 0.000..  Test Loss: 4.898..  Test Accuracy: 0.745\n",
      "Epoch: 612/1500..  Training Loss: 0.000..  Test Loss: 4.892..  Test Accuracy: 0.746\n",
      "Epoch: 613/1500..  Training Loss: 0.000..  Test Loss: 4.895..  Test Accuracy: 0.746\n",
      "Epoch: 614/1500..  Training Loss: 0.000..  Test Loss: 4.893..  Test Accuracy: 0.746\n",
      "Epoch: 615/1500..  Training Loss: 0.000..  Test Loss: 4.902..  Test Accuracy: 0.745\n",
      "Epoch: 616/1500..  Training Loss: 0.000..  Test Loss: 4.899..  Test Accuracy: 0.746\n",
      "Epoch: 617/1500..  Training Loss: 0.000..  Test Loss: 4.909..  Test Accuracy: 0.744\n",
      "Epoch: 618/1500..  Training Loss: 0.000..  Test Loss: 4.909..  Test Accuracy: 0.745\n",
      "Epoch: 619/1500..  Training Loss: 0.000..  Test Loss: 4.911..  Test Accuracy: 0.745\n",
      "Epoch: 620/1500..  Training Loss: 0.000..  Test Loss: 4.902..  Test Accuracy: 0.745\n",
      "Epoch: 621/1500..  Training Loss: 0.000..  Test Loss: 4.907..  Test Accuracy: 0.745\n",
      "Epoch: 622/1500..  Training Loss: 0.000..  Test Loss: 4.909..  Test Accuracy: 0.746\n",
      "Epoch: 623/1500..  Training Loss: 0.000..  Test Loss: 4.913..  Test Accuracy: 0.745\n",
      "Epoch: 624/1500..  Training Loss: 0.000..  Test Loss: 4.915..  Test Accuracy: 0.745\n",
      "Epoch: 625/1500..  Training Loss: 0.000..  Test Loss: 4.907..  Test Accuracy: 0.746\n",
      "Epoch: 626/1500..  Training Loss: 0.000..  Test Loss: 4.910..  Test Accuracy: 0.745\n",
      "Epoch: 627/1500..  Training Loss: 0.000..  Test Loss: 4.909..  Test Accuracy: 0.745\n",
      "Epoch: 628/1500..  Training Loss: 0.000..  Test Loss: 4.917..  Test Accuracy: 0.745\n",
      "Epoch: 629/1500..  Training Loss: 0.000..  Test Loss: 4.914..  Test Accuracy: 0.745\n",
      "Epoch: 630/1500..  Training Loss: 0.000..  Test Loss: 4.923..  Test Accuracy: 0.744\n",
      "Epoch: 631/1500..  Training Loss: 0.000..  Test Loss: 4.923..  Test Accuracy: 0.745\n",
      "Epoch: 632/1500..  Training Loss: 0.000..  Test Loss: 4.919..  Test Accuracy: 0.745\n",
      "Epoch: 633/1500..  Training Loss: 0.000..  Test Loss: 4.927..  Test Accuracy: 0.745\n",
      "Epoch: 634/1500..  Training Loss: 0.000..  Test Loss: 4.922..  Test Accuracy: 0.746\n",
      "Epoch: 635/1500..  Training Loss: 0.000..  Test Loss: 4.927..  Test Accuracy: 0.745\n",
      "Epoch: 636/1500..  Training Loss: 0.000..  Test Loss: 4.926..  Test Accuracy: 0.745\n",
      "Epoch: 637/1500..  Training Loss: 0.000..  Test Loss: 4.930..  Test Accuracy: 0.745\n",
      "Epoch: 638/1500..  Training Loss: 0.000..  Test Loss: 4.936..  Test Accuracy: 0.745\n",
      "Epoch: 639/1500..  Training Loss: 0.000..  Test Loss: 4.929..  Test Accuracy: 0.746\n",
      "Epoch: 640/1500..  Training Loss: 0.000..  Test Loss: 4.921..  Test Accuracy: 0.746\n",
      "Epoch: 641/1500..  Training Loss: 0.000..  Test Loss: 4.941..  Test Accuracy: 0.745\n",
      "Epoch: 642/1500..  Training Loss: 0.000..  Test Loss: 4.935..  Test Accuracy: 0.745\n",
      "Epoch: 643/1500..  Training Loss: 0.000..  Test Loss: 4.933..  Test Accuracy: 0.745\n",
      "Epoch: 644/1500..  Training Loss: 0.000..  Test Loss: 4.932..  Test Accuracy: 0.745\n",
      "Epoch: 645/1500..  Training Loss: 0.000..  Test Loss: 4.935..  Test Accuracy: 0.745\n",
      "Epoch: 646/1500..  Training Loss: 0.000..  Test Loss: 4.928..  Test Accuracy: 0.746\n",
      "Epoch: 647/1500..  Training Loss: 0.000..  Test Loss: 4.941..  Test Accuracy: 0.745\n",
      "Epoch: 648/1500..  Training Loss: 0.000..  Test Loss: 4.934..  Test Accuracy: 0.746\n",
      "Epoch: 649/1500..  Training Loss: 0.000..  Test Loss: 4.934..  Test Accuracy: 0.746\n",
      "Epoch: 650/1500..  Training Loss: 0.000..  Test Loss: 4.933..  Test Accuracy: 0.746\n",
      "Epoch: 651/1500..  Training Loss: 0.000..  Test Loss: 4.943..  Test Accuracy: 0.746\n",
      "Epoch: 652/1500..  Training Loss: 0.000..  Test Loss: 4.939..  Test Accuracy: 0.746\n",
      "Epoch: 653/1500..  Training Loss: 0.000..  Test Loss: 4.940..  Test Accuracy: 0.746\n",
      "Epoch: 654/1500..  Training Loss: 0.000..  Test Loss: 4.948..  Test Accuracy: 0.745\n",
      "Epoch: 655/1500..  Training Loss: 0.000..  Test Loss: 4.943..  Test Accuracy: 0.745\n",
      "Epoch: 656/1500..  Training Loss: 0.000..  Test Loss: 4.943..  Test Accuracy: 0.746\n",
      "Epoch: 657/1500..  Training Loss: 0.000..  Test Loss: 4.946..  Test Accuracy: 0.746\n",
      "Epoch: 658/1500..  Training Loss: 0.000..  Test Loss: 4.944..  Test Accuracy: 0.746\n",
      "Epoch: 659/1500..  Training Loss: 0.000..  Test Loss: 4.943..  Test Accuracy: 0.746\n",
      "Epoch: 660/1500..  Training Loss: 0.000..  Test Loss: 4.954..  Test Accuracy: 0.745\n",
      "Epoch: 661/1500..  Training Loss: 0.000..  Test Loss: 4.947..  Test Accuracy: 0.745\n",
      "Epoch: 662/1500..  Training Loss: 0.000..  Test Loss: 4.952..  Test Accuracy: 0.746\n",
      "Epoch: 663/1500..  Training Loss: 0.000..  Test Loss: 4.957..  Test Accuracy: 0.745\n",
      "Epoch: 664/1500..  Training Loss: 0.000..  Test Loss: 4.956..  Test Accuracy: 0.746\n",
      "Epoch: 665/1500..  Training Loss: 0.000..  Test Loss: 4.955..  Test Accuracy: 0.745\n",
      "Epoch: 666/1500..  Training Loss: 0.000..  Test Loss: 4.954..  Test Accuracy: 0.745\n",
      "Epoch: 667/1500..  Training Loss: 0.000..  Test Loss: 4.959..  Test Accuracy: 0.745\n",
      "Epoch: 668/1500..  Training Loss: 0.000..  Test Loss: 4.951..  Test Accuracy: 0.746\n",
      "Epoch: 669/1500..  Training Loss: 0.000..  Test Loss: 4.957..  Test Accuracy: 0.745\n",
      "Epoch: 670/1500..  Training Loss: 0.000..  Test Loss: 4.960..  Test Accuracy: 0.745\n",
      "Epoch: 671/1500..  Training Loss: 0.000..  Test Loss: 4.958..  Test Accuracy: 0.746\n",
      "Epoch: 672/1500..  Training Loss: 0.000..  Test Loss: 4.963..  Test Accuracy: 0.745\n",
      "Epoch: 673/1500..  Training Loss: 0.000..  Test Loss: 4.963..  Test Accuracy: 0.745\n",
      "Epoch: 674/1500..  Training Loss: 0.000..  Test Loss: 4.960..  Test Accuracy: 0.746\n",
      "Epoch: 675/1500..  Training Loss: 0.000..  Test Loss: 4.962..  Test Accuracy: 0.746\n",
      "Epoch: 676/1500..  Training Loss: 0.000..  Test Loss: 4.967..  Test Accuracy: 0.746\n",
      "Epoch: 677/1500..  Training Loss: 0.000..  Test Loss: 4.967..  Test Accuracy: 0.745\n",
      "Epoch: 678/1500..  Training Loss: 0.000..  Test Loss: 4.962..  Test Accuracy: 0.746\n",
      "Epoch: 679/1500..  Training Loss: 0.000..  Test Loss: 4.963..  Test Accuracy: 0.746\n",
      "Epoch: 680/1500..  Training Loss: 0.000..  Test Loss: 4.974..  Test Accuracy: 0.745\n",
      "Epoch: 681/1500..  Training Loss: 0.000..  Test Loss: 4.970..  Test Accuracy: 0.746\n",
      "Epoch: 682/1500..  Training Loss: 0.000..  Test Loss: 4.964..  Test Accuracy: 0.746\n",
      "Epoch: 683/1500..  Training Loss: 0.000..  Test Loss: 4.968..  Test Accuracy: 0.746\n",
      "Epoch: 684/1500..  Training Loss: 0.000..  Test Loss: 4.966..  Test Accuracy: 0.746\n",
      "Epoch: 685/1500..  Training Loss: 0.000..  Test Loss: 4.974..  Test Accuracy: 0.745\n",
      "Epoch: 686/1500..  Training Loss: 0.000..  Test Loss: 4.967..  Test Accuracy: 0.746\n",
      "Epoch: 687/1500..  Training Loss: 0.000..  Test Loss: 4.966..  Test Accuracy: 0.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 688/1500..  Training Loss: 0.000..  Test Loss: 4.967..  Test Accuracy: 0.746\n",
      "Epoch: 689/1500..  Training Loss: 0.000..  Test Loss: 4.974..  Test Accuracy: 0.746\n",
      "Epoch: 690/1500..  Training Loss: 0.000..  Test Loss: 4.979..  Test Accuracy: 0.745\n",
      "Epoch: 691/1500..  Training Loss: 0.000..  Test Loss: 4.976..  Test Accuracy: 0.746\n",
      "Epoch: 692/1500..  Training Loss: 0.000..  Test Loss: 4.972..  Test Accuracy: 0.745\n",
      "Epoch: 693/1500..  Training Loss: 0.000..  Test Loss: 4.971..  Test Accuracy: 0.746\n",
      "Epoch: 694/1500..  Training Loss: 0.000..  Test Loss: 4.972..  Test Accuracy: 0.746\n",
      "Epoch: 695/1500..  Training Loss: 0.000..  Test Loss: 4.975..  Test Accuracy: 0.745\n",
      "Epoch: 696/1500..  Training Loss: 0.000..  Test Loss: 4.975..  Test Accuracy: 0.746\n",
      "Epoch: 697/1500..  Training Loss: 0.000..  Test Loss: 4.975..  Test Accuracy: 0.745\n",
      "Epoch: 698/1500..  Training Loss: 0.000..  Test Loss: 4.976..  Test Accuracy: 0.745\n",
      "Epoch: 699/1500..  Training Loss: 0.000..  Test Loss: 4.974..  Test Accuracy: 0.746\n",
      "Epoch: 700/1500..  Training Loss: 0.000..  Test Loss: 4.982..  Test Accuracy: 0.745\n",
      "Epoch: 701/1500..  Training Loss: 0.000..  Test Loss: 4.983..  Test Accuracy: 0.745\n",
      "Epoch: 702/1500..  Training Loss: 0.000..  Test Loss: 4.982..  Test Accuracy: 0.746\n",
      "Epoch: 703/1500..  Training Loss: 0.000..  Test Loss: 4.983..  Test Accuracy: 0.745\n",
      "Epoch: 704/1500..  Training Loss: 0.000..  Test Loss: 4.981..  Test Accuracy: 0.746\n",
      "Epoch: 705/1500..  Training Loss: 0.000..  Test Loss: 4.983..  Test Accuracy: 0.746\n",
      "Epoch: 706/1500..  Training Loss: 0.000..  Test Loss: 4.980..  Test Accuracy: 0.745\n",
      "Epoch: 707/1500..  Training Loss: 0.000..  Test Loss: 4.983..  Test Accuracy: 0.745\n",
      "Epoch: 708/1500..  Training Loss: 0.000..  Test Loss: 4.981..  Test Accuracy: 0.746\n",
      "Epoch: 709/1500..  Training Loss: 0.000..  Test Loss: 4.980..  Test Accuracy: 0.746\n",
      "Epoch: 710/1500..  Training Loss: 0.000..  Test Loss: 4.986..  Test Accuracy: 0.746\n",
      "Epoch: 711/1500..  Training Loss: 0.000..  Test Loss: 4.986..  Test Accuracy: 0.746\n",
      "Epoch: 712/1500..  Training Loss: 0.000..  Test Loss: 4.982..  Test Accuracy: 0.745\n",
      "Epoch: 713/1500..  Training Loss: 0.000..  Test Loss: 4.981..  Test Accuracy: 0.746\n",
      "Epoch: 714/1500..  Training Loss: 0.000..  Test Loss: 4.982..  Test Accuracy: 0.746\n",
      "Epoch: 715/1500..  Training Loss: 0.000..  Test Loss: 4.981..  Test Accuracy: 0.746\n",
      "Epoch: 716/1500..  Training Loss: 0.000..  Test Loss: 4.989..  Test Accuracy: 0.746\n",
      "Epoch: 717/1500..  Training Loss: 0.000..  Test Loss: 4.988..  Test Accuracy: 0.746\n",
      "Epoch: 718/1500..  Training Loss: 0.000..  Test Loss: 4.984..  Test Accuracy: 0.746\n",
      "Epoch: 719/1500..  Training Loss: 0.000..  Test Loss: 4.988..  Test Accuracy: 0.746\n",
      "Epoch: 720/1500..  Training Loss: 0.000..  Test Loss: 4.988..  Test Accuracy: 0.746\n",
      "Epoch: 721/1500..  Training Loss: 0.000..  Test Loss: 4.988..  Test Accuracy: 0.746\n",
      "Epoch: 722/1500..  Training Loss: 0.000..  Test Loss: 4.992..  Test Accuracy: 0.746\n",
      "Epoch: 723/1500..  Training Loss: 0.000..  Test Loss: 4.992..  Test Accuracy: 0.746\n",
      "Epoch: 724/1500..  Training Loss: 0.000..  Test Loss: 4.995..  Test Accuracy: 0.746\n",
      "Epoch: 725/1500..  Training Loss: 0.000..  Test Loss: 5.002..  Test Accuracy: 0.745\n",
      "Epoch: 726/1500..  Training Loss: 0.000..  Test Loss: 4.998..  Test Accuracy: 0.746\n",
      "Epoch: 727/1500..  Training Loss: 0.000..  Test Loss: 4.998..  Test Accuracy: 0.746\n",
      "Epoch: 728/1500..  Training Loss: 0.000..  Test Loss: 4.993..  Test Accuracy: 0.746\n",
      "Epoch: 729/1500..  Training Loss: 0.000..  Test Loss: 4.996..  Test Accuracy: 0.746\n",
      "Epoch: 730/1500..  Training Loss: 0.000..  Test Loss: 4.996..  Test Accuracy: 0.746\n",
      "Epoch: 731/1500..  Training Loss: 0.000..  Test Loss: 4.996..  Test Accuracy: 0.746\n",
      "Epoch: 732/1500..  Training Loss: 0.000..  Test Loss: 4.995..  Test Accuracy: 0.746\n",
      "Epoch: 733/1500..  Training Loss: 0.000..  Test Loss: 4.999..  Test Accuracy: 0.746\n",
      "Epoch: 734/1500..  Training Loss: 0.000..  Test Loss: 5.000..  Test Accuracy: 0.746\n",
      "Epoch: 735/1500..  Training Loss: 0.000..  Test Loss: 5.001..  Test Accuracy: 0.746\n",
      "Epoch: 736/1500..  Training Loss: 0.000..  Test Loss: 5.002..  Test Accuracy: 0.746\n",
      "Epoch: 737/1500..  Training Loss: 0.000..  Test Loss: 5.006..  Test Accuracy: 0.745\n",
      "Epoch: 738/1500..  Training Loss: 0.000..  Test Loss: 5.003..  Test Accuracy: 0.746\n",
      "Epoch: 739/1500..  Training Loss: 0.000..  Test Loss: 5.004..  Test Accuracy: 0.745\n",
      "Epoch: 740/1500..  Training Loss: 0.000..  Test Loss: 4.999..  Test Accuracy: 0.746\n",
      "Epoch: 741/1500..  Training Loss: 0.000..  Test Loss: 5.002..  Test Accuracy: 0.746\n",
      "Epoch: 742/1500..  Training Loss: 0.000..  Test Loss: 5.002..  Test Accuracy: 0.746\n",
      "Epoch: 743/1500..  Training Loss: 0.000..  Test Loss: 5.004..  Test Accuracy: 0.746\n",
      "Epoch: 744/1500..  Training Loss: 0.000..  Test Loss: 5.006..  Test Accuracy: 0.745\n",
      "Epoch: 745/1500..  Training Loss: 0.000..  Test Loss: 5.006..  Test Accuracy: 0.746\n",
      "Epoch: 746/1500..  Training Loss: 0.000..  Test Loss: 5.007..  Test Accuracy: 0.746\n",
      "Epoch: 747/1500..  Training Loss: 0.000..  Test Loss: 5.003..  Test Accuracy: 0.746\n",
      "Epoch: 748/1500..  Training Loss: 0.000..  Test Loss: 5.006..  Test Accuracy: 0.745\n",
      "Epoch: 749/1500..  Training Loss: 0.000..  Test Loss: 5.005..  Test Accuracy: 0.746\n",
      "Epoch: 750/1500..  Training Loss: 0.000..  Test Loss: 5.008..  Test Accuracy: 0.746\n",
      "Epoch: 751/1500..  Training Loss: 0.000..  Test Loss: 5.003..  Test Accuracy: 0.746\n",
      "Epoch: 752/1500..  Training Loss: 0.000..  Test Loss: 5.007..  Test Accuracy: 0.746\n",
      "Epoch: 753/1500..  Training Loss: 0.000..  Test Loss: 5.013..  Test Accuracy: 0.745\n",
      "Epoch: 754/1500..  Training Loss: 0.000..  Test Loss: 5.016..  Test Accuracy: 0.745\n",
      "Epoch: 755/1500..  Training Loss: 0.000..  Test Loss: 5.007..  Test Accuracy: 0.746\n",
      "Epoch: 756/1500..  Training Loss: 0.000..  Test Loss: 5.009..  Test Accuracy: 0.746\n",
      "Epoch: 757/1500..  Training Loss: 0.000..  Test Loss: 5.010..  Test Accuracy: 0.745\n",
      "Epoch: 758/1500..  Training Loss: 0.000..  Test Loss: 5.013..  Test Accuracy: 0.745\n",
      "Epoch: 759/1500..  Training Loss: 0.000..  Test Loss: 5.013..  Test Accuracy: 0.746\n",
      "Epoch: 760/1500..  Training Loss: 0.000..  Test Loss: 5.011..  Test Accuracy: 0.746\n",
      "Epoch: 761/1500..  Training Loss: 0.000..  Test Loss: 5.014..  Test Accuracy: 0.746\n",
      "Epoch: 762/1500..  Training Loss: 0.000..  Test Loss: 5.011..  Test Accuracy: 0.746\n",
      "Epoch: 763/1500..  Training Loss: 0.000..  Test Loss: 5.011..  Test Accuracy: 0.746\n",
      "Epoch: 764/1500..  Training Loss: 0.000..  Test Loss: 5.015..  Test Accuracy: 0.746\n",
      "Epoch: 765/1500..  Training Loss: 0.000..  Test Loss: 5.015..  Test Accuracy: 0.746\n",
      "Epoch: 766/1500..  Training Loss: 0.000..  Test Loss: 5.014..  Test Accuracy: 0.745\n",
      "Epoch: 767/1500..  Training Loss: 0.000..  Test Loss: 5.013..  Test Accuracy: 0.745\n",
      "Epoch: 768/1500..  Training Loss: 0.000..  Test Loss: 5.018..  Test Accuracy: 0.745\n",
      "Epoch: 769/1500..  Training Loss: 0.000..  Test Loss: 5.018..  Test Accuracy: 0.746\n",
      "Epoch: 770/1500..  Training Loss: 0.000..  Test Loss: 5.014..  Test Accuracy: 0.746\n",
      "Epoch: 771/1500..  Training Loss: 0.000..  Test Loss: 5.017..  Test Accuracy: 0.746\n",
      "Epoch: 772/1500..  Training Loss: 0.000..  Test Loss: 5.017..  Test Accuracy: 0.746\n",
      "Epoch: 773/1500..  Training Loss: 0.000..  Test Loss: 5.018..  Test Accuracy: 0.746\n",
      "Epoch: 774/1500..  Training Loss: 0.000..  Test Loss: 5.019..  Test Accuracy: 0.746\n",
      "Epoch: 775/1500..  Training Loss: 0.000..  Test Loss: 5.023..  Test Accuracy: 0.746\n",
      "Epoch: 776/1500..  Training Loss: 0.000..  Test Loss: 5.028..  Test Accuracy: 0.745\n",
      "Epoch: 777/1500..  Training Loss: 0.000..  Test Loss: 5.023..  Test Accuracy: 0.746\n",
      "Epoch: 778/1500..  Training Loss: 0.000..  Test Loss: 5.027..  Test Accuracy: 0.745\n",
      "Epoch: 779/1500..  Training Loss: 0.000..  Test Loss: 5.024..  Test Accuracy: 0.746\n",
      "Epoch: 780/1500..  Training Loss: 0.000..  Test Loss: 5.024..  Test Accuracy: 0.746\n",
      "Epoch: 781/1500..  Training Loss: 0.000..  Test Loss: 5.025..  Test Accuracy: 0.745\n",
      "Epoch: 782/1500..  Training Loss: 0.000..  Test Loss: 5.026..  Test Accuracy: 0.746\n",
      "Epoch: 783/1500..  Training Loss: 0.000..  Test Loss: 5.023..  Test Accuracy: 0.746\n",
      "Epoch: 784/1500..  Training Loss: 0.000..  Test Loss: 5.022..  Test Accuracy: 0.745\n",
      "Epoch: 785/1500..  Training Loss: 0.000..  Test Loss: 5.022..  Test Accuracy: 0.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 786/1500..  Training Loss: 0.000..  Test Loss: 5.028..  Test Accuracy: 0.745\n",
      "Epoch: 787/1500..  Training Loss: 0.000..  Test Loss: 5.026..  Test Accuracy: 0.746\n",
      "Epoch: 788/1500..  Training Loss: 0.000..  Test Loss: 5.031..  Test Accuracy: 0.745\n",
      "Epoch: 789/1500..  Training Loss: 0.000..  Test Loss: 5.033..  Test Accuracy: 0.745\n",
      "Epoch: 790/1500..  Training Loss: 0.000..  Test Loss: 5.029..  Test Accuracy: 0.745\n",
      "Epoch: 791/1500..  Training Loss: 0.000..  Test Loss: 5.029..  Test Accuracy: 0.745\n",
      "Epoch: 792/1500..  Training Loss: 0.000..  Test Loss: 5.029..  Test Accuracy: 0.745\n",
      "Epoch: 793/1500..  Training Loss: 0.000..  Test Loss: 5.030..  Test Accuracy: 0.746\n",
      "Epoch: 794/1500..  Training Loss: 0.000..  Test Loss: 5.027..  Test Accuracy: 0.746\n",
      "Epoch: 795/1500..  Training Loss: 0.000..  Test Loss: 5.032..  Test Accuracy: 0.745\n",
      "Epoch: 796/1500..  Training Loss: 0.000..  Test Loss: 5.028..  Test Accuracy: 0.746\n",
      "Epoch: 797/1500..  Training Loss: 0.000..  Test Loss: 5.029..  Test Accuracy: 0.746\n",
      "Epoch: 798/1500..  Training Loss: 0.000..  Test Loss: 5.031..  Test Accuracy: 0.745\n",
      "Epoch: 799/1500..  Training Loss: 0.000..  Test Loss: 5.034..  Test Accuracy: 0.745\n",
      "Epoch: 800/1500..  Training Loss: 0.000..  Test Loss: 5.035..  Test Accuracy: 0.745\n",
      "Epoch: 801/1500..  Training Loss: 0.000..  Test Loss: 5.032..  Test Accuracy: 0.746\n",
      "Epoch: 802/1500..  Training Loss: 0.000..  Test Loss: 5.033..  Test Accuracy: 0.746\n",
      "Epoch: 803/1500..  Training Loss: 0.000..  Test Loss: 5.034..  Test Accuracy: 0.746\n",
      "Epoch: 804/1500..  Training Loss: 0.000..  Test Loss: 5.036..  Test Accuracy: 0.746\n",
      "Epoch: 805/1500..  Training Loss: 0.000..  Test Loss: 5.037..  Test Accuracy: 0.746\n",
      "Epoch: 806/1500..  Training Loss: 0.000..  Test Loss: 5.038..  Test Accuracy: 0.745\n",
      "Epoch: 807/1500..  Training Loss: 0.000..  Test Loss: 5.037..  Test Accuracy: 0.746\n",
      "Epoch: 808/1500..  Training Loss: 0.000..  Test Loss: 5.036..  Test Accuracy: 0.746\n",
      "Epoch: 809/1500..  Training Loss: 0.000..  Test Loss: 5.036..  Test Accuracy: 0.746\n",
      "Epoch: 810/1500..  Training Loss: 0.000..  Test Loss: 5.035..  Test Accuracy: 0.746\n",
      "Epoch: 811/1500..  Training Loss: 0.000..  Test Loss: 5.036..  Test Accuracy: 0.746\n",
      "Epoch: 812/1500..  Training Loss: 0.000..  Test Loss: 5.039..  Test Accuracy: 0.745\n",
      "Epoch: 813/1500..  Training Loss: 0.000..  Test Loss: 5.039..  Test Accuracy: 0.746\n",
      "Epoch: 814/1500..  Training Loss: 0.000..  Test Loss: 5.038..  Test Accuracy: 0.746\n",
      "Epoch: 815/1500..  Training Loss: 0.000..  Test Loss: 5.038..  Test Accuracy: 0.746\n",
      "Epoch: 816/1500..  Training Loss: 0.000..  Test Loss: 5.039..  Test Accuracy: 0.746\n",
      "Epoch: 817/1500..  Training Loss: 0.000..  Test Loss: 5.038..  Test Accuracy: 0.746\n",
      "Epoch: 818/1500..  Training Loss: 0.000..  Test Loss: 5.039..  Test Accuracy: 0.746\n",
      "Epoch: 819/1500..  Training Loss: 0.000..  Test Loss: 5.039..  Test Accuracy: 0.746\n",
      "Epoch: 820/1500..  Training Loss: 0.000..  Test Loss: 5.043..  Test Accuracy: 0.746\n",
      "Epoch: 821/1500..  Training Loss: 0.000..  Test Loss: 5.039..  Test Accuracy: 0.746\n",
      "Epoch: 822/1500..  Training Loss: 0.000..  Test Loss: 5.041..  Test Accuracy: 0.746\n",
      "Epoch: 823/1500..  Training Loss: 0.000..  Test Loss: 5.042..  Test Accuracy: 0.745\n",
      "Epoch: 824/1500..  Training Loss: 0.000..  Test Loss: 5.042..  Test Accuracy: 0.746\n",
      "Epoch: 825/1500..  Training Loss: 0.000..  Test Loss: 5.042..  Test Accuracy: 0.746\n",
      "Epoch: 826/1500..  Training Loss: 0.000..  Test Loss: 5.042..  Test Accuracy: 0.746\n",
      "Epoch: 827/1500..  Training Loss: 0.000..  Test Loss: 5.043..  Test Accuracy: 0.746\n",
      "Epoch: 828/1500..  Training Loss: 0.000..  Test Loss: 5.041..  Test Accuracy: 0.746\n",
      "Epoch: 829/1500..  Training Loss: 0.000..  Test Loss: 5.042..  Test Accuracy: 0.746\n",
      "Epoch: 830/1500..  Training Loss: 0.000..  Test Loss: 5.041..  Test Accuracy: 0.746\n",
      "Epoch: 831/1500..  Training Loss: 0.000..  Test Loss: 5.045..  Test Accuracy: 0.746\n",
      "Epoch: 832/1500..  Training Loss: 0.000..  Test Loss: 5.047..  Test Accuracy: 0.746\n",
      "Epoch: 833/1500..  Training Loss: 0.000..  Test Loss: 5.048..  Test Accuracy: 0.745\n",
      "Epoch: 834/1500..  Training Loss: 0.000..  Test Loss: 5.047..  Test Accuracy: 0.746\n",
      "Epoch: 835/1500..  Training Loss: 0.000..  Test Loss: 5.048..  Test Accuracy: 0.746\n",
      "Epoch: 836/1500..  Training Loss: 0.000..  Test Loss: 5.045..  Test Accuracy: 0.746\n",
      "Epoch: 837/1500..  Training Loss: 0.000..  Test Loss: 5.046..  Test Accuracy: 0.746\n",
      "Epoch: 838/1500..  Training Loss: 0.000..  Test Loss: 5.048..  Test Accuracy: 0.746\n",
      "Epoch: 839/1500..  Training Loss: 0.000..  Test Loss: 5.050..  Test Accuracy: 0.746\n",
      "Epoch: 840/1500..  Training Loss: 0.000..  Test Loss: 5.052..  Test Accuracy: 0.746\n",
      "Epoch: 841/1500..  Training Loss: 0.000..  Test Loss: 5.052..  Test Accuracy: 0.746\n",
      "Epoch: 842/1500..  Training Loss: 0.000..  Test Loss: 5.048..  Test Accuracy: 0.746\n",
      "Epoch: 843/1500..  Training Loss: 0.000..  Test Loss: 5.049..  Test Accuracy: 0.746\n",
      "Epoch: 844/1500..  Training Loss: 0.000..  Test Loss: 5.050..  Test Accuracy: 0.746\n",
      "Epoch: 845/1500..  Training Loss: 0.000..  Test Loss: 5.047..  Test Accuracy: 0.746\n",
      "Epoch: 846/1500..  Training Loss: 0.000..  Test Loss: 5.051..  Test Accuracy: 0.746\n",
      "Epoch: 847/1500..  Training Loss: 0.000..  Test Loss: 5.050..  Test Accuracy: 0.746\n",
      "Epoch: 848/1500..  Training Loss: 0.000..  Test Loss: 5.053..  Test Accuracy: 0.746\n",
      "Epoch: 849/1500..  Training Loss: 0.000..  Test Loss: 5.050..  Test Accuracy: 0.746\n",
      "Epoch: 850/1500..  Training Loss: 0.000..  Test Loss: 5.054..  Test Accuracy: 0.746\n",
      "Epoch: 851/1500..  Training Loss: 0.000..  Test Loss: 5.056..  Test Accuracy: 0.746\n",
      "Epoch: 852/1500..  Training Loss: 0.000..  Test Loss: 5.050..  Test Accuracy: 0.746\n",
      "Epoch: 853/1500..  Training Loss: 0.000..  Test Loss: 5.053..  Test Accuracy: 0.746\n",
      "Epoch: 854/1500..  Training Loss: 0.000..  Test Loss: 5.051..  Test Accuracy: 0.746\n",
      "Epoch: 855/1500..  Training Loss: 0.000..  Test Loss: 5.052..  Test Accuracy: 0.746\n",
      "Epoch: 856/1500..  Training Loss: 0.000..  Test Loss: 5.054..  Test Accuracy: 0.746\n",
      "Epoch: 857/1500..  Training Loss: 0.000..  Test Loss: 5.057..  Test Accuracy: 0.746\n",
      "Epoch: 858/1500..  Training Loss: 0.000..  Test Loss: 5.055..  Test Accuracy: 0.746\n",
      "Epoch: 859/1500..  Training Loss: 0.000..  Test Loss: 5.055..  Test Accuracy: 0.746\n",
      "Epoch: 860/1500..  Training Loss: 0.000..  Test Loss: 5.056..  Test Accuracy: 0.746\n",
      "Epoch: 861/1500..  Training Loss: 0.000..  Test Loss: 5.057..  Test Accuracy: 0.746\n",
      "Epoch: 862/1500..  Training Loss: 0.000..  Test Loss: 5.058..  Test Accuracy: 0.746\n",
      "Epoch: 863/1500..  Training Loss: 0.000..  Test Loss: 5.057..  Test Accuracy: 0.746\n",
      "Epoch: 864/1500..  Training Loss: 0.000..  Test Loss: 5.059..  Test Accuracy: 0.746\n",
      "Epoch: 865/1500..  Training Loss: 0.000..  Test Loss: 5.061..  Test Accuracy: 0.746\n",
      "Epoch: 866/1500..  Training Loss: 0.000..  Test Loss: 5.061..  Test Accuracy: 0.746\n",
      "Epoch: 867/1500..  Training Loss: 0.000..  Test Loss: 5.060..  Test Accuracy: 0.746\n",
      "Epoch: 868/1500..  Training Loss: 0.000..  Test Loss: 5.060..  Test Accuracy: 0.746\n",
      "Epoch: 869/1500..  Training Loss: 0.000..  Test Loss: 5.061..  Test Accuracy: 0.746\n",
      "Epoch: 870/1500..  Training Loss: 0.000..  Test Loss: 5.063..  Test Accuracy: 0.746\n",
      "Epoch: 871/1500..  Training Loss: 0.000..  Test Loss: 5.060..  Test Accuracy: 0.746\n",
      "Epoch: 872/1500..  Training Loss: 0.000..  Test Loss: 5.059..  Test Accuracy: 0.746\n",
      "Epoch: 873/1500..  Training Loss: 0.000..  Test Loss: 5.059..  Test Accuracy: 0.746\n",
      "Epoch: 874/1500..  Training Loss: 0.000..  Test Loss: 5.060..  Test Accuracy: 0.746\n",
      "Epoch: 875/1500..  Training Loss: 0.000..  Test Loss: 5.063..  Test Accuracy: 0.746\n",
      "Epoch: 876/1500..  Training Loss: 0.000..  Test Loss: 5.061..  Test Accuracy: 0.746\n",
      "Epoch: 877/1500..  Training Loss: 0.000..  Test Loss: 5.061..  Test Accuracy: 0.746\n",
      "Epoch: 878/1500..  Training Loss: 0.000..  Test Loss: 5.062..  Test Accuracy: 0.746\n",
      "Epoch: 879/1500..  Training Loss: 0.000..  Test Loss: 5.063..  Test Accuracy: 0.746\n",
      "Epoch: 880/1500..  Training Loss: 0.000..  Test Loss: 5.063..  Test Accuracy: 0.746\n",
      "Epoch: 881/1500..  Training Loss: 0.000..  Test Loss: 5.063..  Test Accuracy: 0.746\n",
      "Epoch: 882/1500..  Training Loss: 0.000..  Test Loss: 5.062..  Test Accuracy: 0.746\n",
      "Epoch: 883/1500..  Training Loss: 0.000..  Test Loss: 5.063..  Test Accuracy: 0.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 884/1500..  Training Loss: 0.000..  Test Loss: 5.066..  Test Accuracy: 0.746\n",
      "Epoch: 885/1500..  Training Loss: 0.000..  Test Loss: 5.064..  Test Accuracy: 0.746\n",
      "Epoch: 886/1500..  Training Loss: 0.000..  Test Loss: 5.065..  Test Accuracy: 0.746\n",
      "Epoch: 887/1500..  Training Loss: 0.000..  Test Loss: 5.065..  Test Accuracy: 0.746\n",
      "Epoch: 888/1500..  Training Loss: 0.000..  Test Loss: 5.065..  Test Accuracy: 0.746\n",
      "Epoch: 889/1500..  Training Loss: 0.000..  Test Loss: 5.065..  Test Accuracy: 0.746\n",
      "Epoch: 890/1500..  Training Loss: 0.000..  Test Loss: 5.064..  Test Accuracy: 0.746\n",
      "Epoch: 891/1500..  Training Loss: 0.000..  Test Loss: 5.067..  Test Accuracy: 0.746\n",
      "Epoch: 892/1500..  Training Loss: 0.000..  Test Loss: 5.066..  Test Accuracy: 0.746\n",
      "Epoch: 893/1500..  Training Loss: 0.000..  Test Loss: 5.065..  Test Accuracy: 0.746\n",
      "Epoch: 894/1500..  Training Loss: 0.000..  Test Loss: 5.066..  Test Accuracy: 0.746\n",
      "Epoch: 895/1500..  Training Loss: 0.000..  Test Loss: 5.065..  Test Accuracy: 0.746\n",
      "Epoch: 896/1500..  Training Loss: 0.000..  Test Loss: 5.065..  Test Accuracy: 0.747\n",
      "Epoch: 897/1500..  Training Loss: 0.000..  Test Loss: 5.068..  Test Accuracy: 0.746\n",
      "Epoch: 898/1500..  Training Loss: 0.000..  Test Loss: 5.069..  Test Accuracy: 0.746\n",
      "Epoch: 899/1500..  Training Loss: 0.000..  Test Loss: 5.069..  Test Accuracy: 0.746\n",
      "Epoch: 900/1500..  Training Loss: 0.000..  Test Loss: 5.070..  Test Accuracy: 0.746\n",
      "Epoch: 901/1500..  Training Loss: 0.000..  Test Loss: 5.069..  Test Accuracy: 0.746\n",
      "Epoch: 902/1500..  Training Loss: 0.000..  Test Loss: 5.070..  Test Accuracy: 0.746\n",
      "Epoch: 903/1500..  Training Loss: 0.000..  Test Loss: 5.068..  Test Accuracy: 0.746\n",
      "Epoch: 904/1500..  Training Loss: 0.000..  Test Loss: 5.067..  Test Accuracy: 0.746\n",
      "Epoch: 905/1500..  Training Loss: 0.000..  Test Loss: 5.069..  Test Accuracy: 0.746\n",
      "Epoch: 906/1500..  Training Loss: 0.000..  Test Loss: 5.069..  Test Accuracy: 0.746\n",
      "Epoch: 907/1500..  Training Loss: 0.000..  Test Loss: 5.069..  Test Accuracy: 0.746\n",
      "Epoch: 908/1500..  Training Loss: 0.000..  Test Loss: 5.072..  Test Accuracy: 0.746\n",
      "Epoch: 909/1500..  Training Loss: 0.000..  Test Loss: 5.071..  Test Accuracy: 0.746\n",
      "Epoch: 910/1500..  Training Loss: 0.000..  Test Loss: 5.071..  Test Accuracy: 0.747\n",
      "Epoch: 911/1500..  Training Loss: 0.000..  Test Loss: 5.071..  Test Accuracy: 0.747\n",
      "Epoch: 912/1500..  Training Loss: 0.000..  Test Loss: 5.071..  Test Accuracy: 0.746\n",
      "Epoch: 913/1500..  Training Loss: 0.000..  Test Loss: 5.072..  Test Accuracy: 0.746\n",
      "Epoch: 914/1500..  Training Loss: 0.000..  Test Loss: 5.072..  Test Accuracy: 0.746\n",
      "Epoch: 915/1500..  Training Loss: 0.000..  Test Loss: 5.073..  Test Accuracy: 0.747\n",
      "Epoch: 916/1500..  Training Loss: 0.000..  Test Loss: 5.075..  Test Accuracy: 0.746\n",
      "Epoch: 917/1500..  Training Loss: 0.000..  Test Loss: 5.073..  Test Accuracy: 0.746\n",
      "Epoch: 918/1500..  Training Loss: 0.000..  Test Loss: 5.075..  Test Accuracy: 0.746\n",
      "Epoch: 919/1500..  Training Loss: 0.000..  Test Loss: 5.075..  Test Accuracy: 0.746\n",
      "Epoch: 920/1500..  Training Loss: 0.000..  Test Loss: 5.077..  Test Accuracy: 0.746\n",
      "Epoch: 921/1500..  Training Loss: 0.000..  Test Loss: 5.076..  Test Accuracy: 0.746\n",
      "Epoch: 922/1500..  Training Loss: 0.000..  Test Loss: 5.077..  Test Accuracy: 0.746\n",
      "Epoch: 923/1500..  Training Loss: 0.000..  Test Loss: 5.076..  Test Accuracy: 0.746\n",
      "Epoch: 924/1500..  Training Loss: 0.000..  Test Loss: 5.076..  Test Accuracy: 0.746\n",
      "Epoch: 925/1500..  Training Loss: 0.000..  Test Loss: 5.077..  Test Accuracy: 0.746\n",
      "Epoch: 926/1500..  Training Loss: 0.000..  Test Loss: 5.078..  Test Accuracy: 0.746\n",
      "Epoch: 927/1500..  Training Loss: 0.000..  Test Loss: 5.081..  Test Accuracy: 0.746\n",
      "Epoch: 928/1500..  Training Loss: 0.000..  Test Loss: 5.078..  Test Accuracy: 0.746\n",
      "Epoch: 929/1500..  Training Loss: 0.000..  Test Loss: 5.078..  Test Accuracy: 0.746\n",
      "Epoch: 930/1500..  Training Loss: 0.000..  Test Loss: 5.080..  Test Accuracy: 0.746\n",
      "Epoch: 931/1500..  Training Loss: 0.000..  Test Loss: 5.079..  Test Accuracy: 0.747\n",
      "Epoch: 932/1500..  Training Loss: 0.000..  Test Loss: 5.078..  Test Accuracy: 0.747\n",
      "Epoch: 933/1500..  Training Loss: 0.000..  Test Loss: 5.078..  Test Accuracy: 0.746\n",
      "Epoch: 934/1500..  Training Loss: 0.000..  Test Loss: 5.079..  Test Accuracy: 0.746\n",
      "Epoch: 935/1500..  Training Loss: 0.000..  Test Loss: 5.082..  Test Accuracy: 0.747\n",
      "Epoch: 936/1500..  Training Loss: 0.000..  Test Loss: 5.080..  Test Accuracy: 0.746\n",
      "Epoch: 937/1500..  Training Loss: 0.000..  Test Loss: 5.079..  Test Accuracy: 0.746\n",
      "Epoch: 938/1500..  Training Loss: 0.000..  Test Loss: 5.081..  Test Accuracy: 0.746\n",
      "Epoch: 939/1500..  Training Loss: 0.000..  Test Loss: 5.082..  Test Accuracy: 0.746\n",
      "Epoch: 940/1500..  Training Loss: 0.000..  Test Loss: 5.080..  Test Accuracy: 0.747\n",
      "Epoch: 941/1500..  Training Loss: 0.000..  Test Loss: 5.081..  Test Accuracy: 0.747\n",
      "Epoch: 942/1500..  Training Loss: 0.000..  Test Loss: 5.083..  Test Accuracy: 0.746\n",
      "Epoch: 943/1500..  Training Loss: 0.000..  Test Loss: 5.084..  Test Accuracy: 0.747\n",
      "Epoch: 944/1500..  Training Loss: 0.000..  Test Loss: 5.084..  Test Accuracy: 0.747\n",
      "Epoch: 945/1500..  Training Loss: 0.000..  Test Loss: 5.084..  Test Accuracy: 0.746\n",
      "Epoch: 946/1500..  Training Loss: 0.000..  Test Loss: 5.085..  Test Accuracy: 0.746\n",
      "Epoch: 947/1500..  Training Loss: 0.000..  Test Loss: 5.085..  Test Accuracy: 0.747\n",
      "Epoch: 948/1500..  Training Loss: 0.000..  Test Loss: 5.084..  Test Accuracy: 0.746\n",
      "Epoch: 949/1500..  Training Loss: 0.000..  Test Loss: 5.086..  Test Accuracy: 0.746\n",
      "Epoch: 950/1500..  Training Loss: 0.000..  Test Loss: 5.084..  Test Accuracy: 0.747\n",
      "Epoch: 951/1500..  Training Loss: 0.000..  Test Loss: 5.087..  Test Accuracy: 0.747\n",
      "Epoch: 952/1500..  Training Loss: 0.000..  Test Loss: 5.082..  Test Accuracy: 0.747\n",
      "Epoch: 953/1500..  Training Loss: 0.000..  Test Loss: 5.084..  Test Accuracy: 0.746\n",
      "Epoch: 954/1500..  Training Loss: 0.000..  Test Loss: 5.084..  Test Accuracy: 0.747\n",
      "Epoch: 955/1500..  Training Loss: 0.000..  Test Loss: 5.085..  Test Accuracy: 0.746\n",
      "Epoch: 956/1500..  Training Loss: 0.000..  Test Loss: 5.084..  Test Accuracy: 0.746\n",
      "Epoch: 957/1500..  Training Loss: 0.000..  Test Loss: 5.086..  Test Accuracy: 0.747\n",
      "Epoch: 958/1500..  Training Loss: 0.000..  Test Loss: 5.087..  Test Accuracy: 0.747\n",
      "Epoch: 959/1500..  Training Loss: 0.000..  Test Loss: 5.086..  Test Accuracy: 0.747\n",
      "Epoch: 960/1500..  Training Loss: 0.000..  Test Loss: 5.087..  Test Accuracy: 0.746\n",
      "Epoch: 961/1500..  Training Loss: 0.000..  Test Loss: 5.087..  Test Accuracy: 0.746\n",
      "Epoch: 962/1500..  Training Loss: 0.000..  Test Loss: 5.087..  Test Accuracy: 0.747\n",
      "Epoch: 963/1500..  Training Loss: 0.000..  Test Loss: 5.089..  Test Accuracy: 0.746\n",
      "Epoch: 964/1500..  Training Loss: 0.000..  Test Loss: 5.089..  Test Accuracy: 0.747\n",
      "Epoch: 965/1500..  Training Loss: 0.000..  Test Loss: 5.088..  Test Accuracy: 0.747\n",
      "Epoch: 966/1500..  Training Loss: 0.000..  Test Loss: 5.087..  Test Accuracy: 0.746\n",
      "Epoch: 967/1500..  Training Loss: 0.000..  Test Loss: 5.089..  Test Accuracy: 0.746\n",
      "Epoch: 968/1500..  Training Loss: 0.000..  Test Loss: 5.087..  Test Accuracy: 0.747\n",
      "Epoch: 969/1500..  Training Loss: 0.000..  Test Loss: 5.088..  Test Accuracy: 0.747\n",
      "Epoch: 970/1500..  Training Loss: 0.000..  Test Loss: 5.089..  Test Accuracy: 0.747\n",
      "Epoch: 971/1500..  Training Loss: 0.000..  Test Loss: 5.089..  Test Accuracy: 0.747\n",
      "Epoch: 972/1500..  Training Loss: 0.000..  Test Loss: 5.090..  Test Accuracy: 0.747\n",
      "Epoch: 973/1500..  Training Loss: 0.000..  Test Loss: 5.091..  Test Accuracy: 0.747\n",
      "Epoch: 974/1500..  Training Loss: 0.000..  Test Loss: 5.090..  Test Accuracy: 0.747\n",
      "Epoch: 975/1500..  Training Loss: 0.000..  Test Loss: 5.092..  Test Accuracy: 0.747\n",
      "Epoch: 976/1500..  Training Loss: 0.000..  Test Loss: 5.092..  Test Accuracy: 0.747\n",
      "Epoch: 977/1500..  Training Loss: 0.000..  Test Loss: 5.092..  Test Accuracy: 0.747\n",
      "Epoch: 978/1500..  Training Loss: 0.000..  Test Loss: 5.089..  Test Accuracy: 0.747\n",
      "Epoch: 979/1500..  Training Loss: 0.000..  Test Loss: 5.092..  Test Accuracy: 0.747\n",
      "Epoch: 980/1500..  Training Loss: 0.000..  Test Loss: 5.092..  Test Accuracy: 0.747\n",
      "Epoch: 981/1500..  Training Loss: 0.000..  Test Loss: 5.093..  Test Accuracy: 0.747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 982/1500..  Training Loss: 0.000..  Test Loss: 5.092..  Test Accuracy: 0.747\n",
      "Epoch: 983/1500..  Training Loss: 0.000..  Test Loss: 5.092..  Test Accuracy: 0.747\n",
      "Epoch: 984/1500..  Training Loss: 0.000..  Test Loss: 5.094..  Test Accuracy: 0.746\n",
      "Epoch: 985/1500..  Training Loss: 0.000..  Test Loss: 5.094..  Test Accuracy: 0.747\n",
      "Epoch: 986/1500..  Training Loss: 0.000..  Test Loss: 5.094..  Test Accuracy: 0.747\n",
      "Epoch: 987/1500..  Training Loss: 0.000..  Test Loss: 5.094..  Test Accuracy: 0.747\n",
      "Epoch: 988/1500..  Training Loss: 0.000..  Test Loss: 5.095..  Test Accuracy: 0.747\n",
      "Epoch: 989/1500..  Training Loss: 0.000..  Test Loss: 5.093..  Test Accuracy: 0.747\n",
      "Epoch: 990/1500..  Training Loss: 0.000..  Test Loss: 5.096..  Test Accuracy: 0.747\n",
      "Epoch: 991/1500..  Training Loss: 0.000..  Test Loss: 5.096..  Test Accuracy: 0.747\n",
      "Epoch: 992/1500..  Training Loss: 0.000..  Test Loss: 5.096..  Test Accuracy: 0.747\n",
      "Epoch: 993/1500..  Training Loss: 0.000..  Test Loss: 5.096..  Test Accuracy: 0.747\n",
      "Epoch: 994/1500..  Training Loss: 0.000..  Test Loss: 5.094..  Test Accuracy: 0.747\n",
      "Epoch: 995/1500..  Training Loss: 0.000..  Test Loss: 5.098..  Test Accuracy: 0.747\n",
      "Epoch: 996/1500..  Training Loss: 0.000..  Test Loss: 5.095..  Test Accuracy: 0.747\n",
      "Epoch: 997/1500..  Training Loss: 0.000..  Test Loss: 5.099..  Test Accuracy: 0.747\n",
      "Epoch: 998/1500..  Training Loss: 0.000..  Test Loss: 5.099..  Test Accuracy: 0.747\n",
      "Epoch: 999/1500..  Training Loss: 0.000..  Test Loss: 5.099..  Test Accuracy: 0.747\n",
      "Epoch: 1000/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.746\n",
      "Epoch: 1001/1500..  Training Loss: 0.000..  Test Loss: 5.099..  Test Accuracy: 0.746\n",
      "Epoch: 1002/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1003/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1004/1500..  Training Loss: 0.000..  Test Loss: 5.099..  Test Accuracy: 0.747\n",
      "Epoch: 1005/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1006/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1007/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1008/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1009/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1010/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1011/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1012/1500..  Training Loss: 0.000..  Test Loss: 5.101..  Test Accuracy: 0.747\n",
      "Epoch: 1013/1500..  Training Loss: 0.000..  Test Loss: 5.101..  Test Accuracy: 0.747\n",
      "Epoch: 1014/1500..  Training Loss: 0.000..  Test Loss: 5.100..  Test Accuracy: 0.747\n",
      "Epoch: 1015/1500..  Training Loss: 0.000..  Test Loss: 5.102..  Test Accuracy: 0.747\n",
      "Epoch: 1016/1500..  Training Loss: 0.000..  Test Loss: 5.102..  Test Accuracy: 0.747\n",
      "Epoch: 1017/1500..  Training Loss: 0.000..  Test Loss: 5.102..  Test Accuracy: 0.747\n",
      "Epoch: 1018/1500..  Training Loss: 0.000..  Test Loss: 5.103..  Test Accuracy: 0.747\n",
      "Epoch: 1019/1500..  Training Loss: 0.000..  Test Loss: 5.103..  Test Accuracy: 0.747\n",
      "Epoch: 1020/1500..  Training Loss: 0.000..  Test Loss: 5.103..  Test Accuracy: 0.747\n",
      "Epoch: 1021/1500..  Training Loss: 0.000..  Test Loss: 5.102..  Test Accuracy: 0.747\n",
      "Epoch: 1022/1500..  Training Loss: 0.000..  Test Loss: 5.104..  Test Accuracy: 0.747\n",
      "Epoch: 1023/1500..  Training Loss: 0.000..  Test Loss: 5.104..  Test Accuracy: 0.746\n",
      "Epoch: 1024/1500..  Training Loss: 0.000..  Test Loss: 5.107..  Test Accuracy: 0.747\n",
      "Epoch: 1025/1500..  Training Loss: 0.000..  Test Loss: 5.103..  Test Accuracy: 0.747\n",
      "Epoch: 1026/1500..  Training Loss: 0.000..  Test Loss: 5.105..  Test Accuracy: 0.747\n",
      "Epoch: 1027/1500..  Training Loss: 0.000..  Test Loss: 5.105..  Test Accuracy: 0.747\n",
      "Epoch: 1028/1500..  Training Loss: 0.000..  Test Loss: 5.107..  Test Accuracy: 0.747\n",
      "Epoch: 1029/1500..  Training Loss: 0.000..  Test Loss: 5.104..  Test Accuracy: 0.747\n",
      "Epoch: 1030/1500..  Training Loss: 0.000..  Test Loss: 5.106..  Test Accuracy: 0.747\n",
      "Epoch: 1031/1500..  Training Loss: 0.000..  Test Loss: 5.106..  Test Accuracy: 0.747\n",
      "Epoch: 1032/1500..  Training Loss: 0.000..  Test Loss: 5.103..  Test Accuracy: 0.747\n",
      "Epoch: 1033/1500..  Training Loss: 0.000..  Test Loss: 5.105..  Test Accuracy: 0.747\n",
      "Epoch: 1034/1500..  Training Loss: 0.000..  Test Loss: 5.106..  Test Accuracy: 0.747\n",
      "Epoch: 1035/1500..  Training Loss: 0.000..  Test Loss: 5.107..  Test Accuracy: 0.747\n",
      "Epoch: 1036/1500..  Training Loss: 0.000..  Test Loss: 5.107..  Test Accuracy: 0.747\n",
      "Epoch: 1037/1500..  Training Loss: 0.000..  Test Loss: 5.105..  Test Accuracy: 0.747\n",
      "Epoch: 1038/1500..  Training Loss: 0.000..  Test Loss: 5.106..  Test Accuracy: 0.747\n",
      "Epoch: 1039/1500..  Training Loss: 0.000..  Test Loss: 5.109..  Test Accuracy: 0.747\n",
      "Epoch: 1040/1500..  Training Loss: 0.000..  Test Loss: 5.106..  Test Accuracy: 0.747\n",
      "Epoch: 1041/1500..  Training Loss: 0.000..  Test Loss: 5.107..  Test Accuracy: 0.747\n",
      "Epoch: 1042/1500..  Training Loss: 0.000..  Test Loss: 5.106..  Test Accuracy: 0.747\n",
      "Epoch: 1043/1500..  Training Loss: 0.000..  Test Loss: 5.107..  Test Accuracy: 0.747\n",
      "Epoch: 1044/1500..  Training Loss: 0.000..  Test Loss: 5.108..  Test Accuracy: 0.747\n",
      "Epoch: 1045/1500..  Training Loss: 0.000..  Test Loss: 5.108..  Test Accuracy: 0.747\n",
      "Epoch: 1046/1500..  Training Loss: 0.000..  Test Loss: 5.107..  Test Accuracy: 0.747\n",
      "Epoch: 1047/1500..  Training Loss: 0.000..  Test Loss: 5.108..  Test Accuracy: 0.747\n",
      "Epoch: 1048/1500..  Training Loss: 0.000..  Test Loss: 5.108..  Test Accuracy: 0.747\n",
      "Epoch: 1049/1500..  Training Loss: 0.000..  Test Loss: 5.108..  Test Accuracy: 0.747\n",
      "Epoch: 1050/1500..  Training Loss: 0.000..  Test Loss: 5.109..  Test Accuracy: 0.747\n",
      "Epoch: 1051/1500..  Training Loss: 0.000..  Test Loss: 5.109..  Test Accuracy: 0.747\n",
      "Epoch: 1052/1500..  Training Loss: 0.000..  Test Loss: 5.109..  Test Accuracy: 0.747\n",
      "Epoch: 1053/1500..  Training Loss: 0.000..  Test Loss: 5.111..  Test Accuracy: 0.746\n",
      "Epoch: 1054/1500..  Training Loss: 0.000..  Test Loss: 5.111..  Test Accuracy: 0.747\n",
      "Epoch: 1055/1500..  Training Loss: 0.000..  Test Loss: 5.112..  Test Accuracy: 0.747\n",
      "Epoch: 1056/1500..  Training Loss: 0.000..  Test Loss: 5.111..  Test Accuracy: 0.747\n",
      "Epoch: 1057/1500..  Training Loss: 0.000..  Test Loss: 5.113..  Test Accuracy: 0.747\n",
      "Epoch: 1058/1500..  Training Loss: 0.000..  Test Loss: 5.113..  Test Accuracy: 0.747\n",
      "Epoch: 1059/1500..  Training Loss: 0.000..  Test Loss: 5.111..  Test Accuracy: 0.747\n",
      "Epoch: 1060/1500..  Training Loss: 0.000..  Test Loss: 5.111..  Test Accuracy: 0.747\n",
      "Epoch: 1061/1500..  Training Loss: 0.000..  Test Loss: 5.112..  Test Accuracy: 0.747\n",
      "Epoch: 1062/1500..  Training Loss: 0.000..  Test Loss: 5.113..  Test Accuracy: 0.747\n",
      "Epoch: 1063/1500..  Training Loss: 0.000..  Test Loss: 5.112..  Test Accuracy: 0.747\n",
      "Epoch: 1064/1500..  Training Loss: 0.000..  Test Loss: 5.115..  Test Accuracy: 0.747\n",
      "Epoch: 1065/1500..  Training Loss: 0.000..  Test Loss: 5.112..  Test Accuracy: 0.747\n",
      "Epoch: 1066/1500..  Training Loss: 0.000..  Test Loss: 5.111..  Test Accuracy: 0.747\n",
      "Epoch: 1067/1500..  Training Loss: 0.000..  Test Loss: 5.112..  Test Accuracy: 0.747\n",
      "Epoch: 1068/1500..  Training Loss: 0.000..  Test Loss: 5.113..  Test Accuracy: 0.747\n",
      "Epoch: 1069/1500..  Training Loss: 0.000..  Test Loss: 5.112..  Test Accuracy: 0.747\n",
      "Epoch: 1070/1500..  Training Loss: 0.000..  Test Loss: 5.112..  Test Accuracy: 0.747\n",
      "Epoch: 1071/1500..  Training Loss: 0.000..  Test Loss: 5.113..  Test Accuracy: 0.747\n",
      "Epoch: 1072/1500..  Training Loss: 0.000..  Test Loss: 5.115..  Test Accuracy: 0.747\n",
      "Epoch: 1073/1500..  Training Loss: 0.000..  Test Loss: 5.114..  Test Accuracy: 0.747\n",
      "Epoch: 1074/1500..  Training Loss: 0.000..  Test Loss: 5.115..  Test Accuracy: 0.747\n",
      "Epoch: 1075/1500..  Training Loss: 0.000..  Test Loss: 5.114..  Test Accuracy: 0.747\n",
      "Epoch: 1076/1500..  Training Loss: 0.000..  Test Loss: 5.115..  Test Accuracy: 0.747\n",
      "Epoch: 1077/1500..  Training Loss: 0.000..  Test Loss: 5.116..  Test Accuracy: 0.747\n",
      "Epoch: 1078/1500..  Training Loss: 0.000..  Test Loss: 5.116..  Test Accuracy: 0.747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1079/1500..  Training Loss: 0.000..  Test Loss: 5.116..  Test Accuracy: 0.747\n",
      "Epoch: 1080/1500..  Training Loss: 0.000..  Test Loss: 5.115..  Test Accuracy: 0.747\n",
      "Epoch: 1081/1500..  Training Loss: 0.000..  Test Loss: 5.116..  Test Accuracy: 0.747\n",
      "Epoch: 1082/1500..  Training Loss: 0.000..  Test Loss: 5.117..  Test Accuracy: 0.747\n",
      "Epoch: 1083/1500..  Training Loss: 0.000..  Test Loss: 5.118..  Test Accuracy: 0.747\n",
      "Epoch: 1084/1500..  Training Loss: 0.000..  Test Loss: 5.117..  Test Accuracy: 0.747\n",
      "Epoch: 1085/1500..  Training Loss: 0.000..  Test Loss: 5.118..  Test Accuracy: 0.747\n",
      "Epoch: 1086/1500..  Training Loss: 0.000..  Test Loss: 5.117..  Test Accuracy: 0.747\n",
      "Epoch: 1087/1500..  Training Loss: 0.000..  Test Loss: 5.117..  Test Accuracy: 0.747\n",
      "Epoch: 1088/1500..  Training Loss: 0.000..  Test Loss: 5.118..  Test Accuracy: 0.747\n",
      "Epoch: 1089/1500..  Training Loss: 0.000..  Test Loss: 5.117..  Test Accuracy: 0.747\n",
      "Epoch: 1090/1500..  Training Loss: 0.000..  Test Loss: 5.117..  Test Accuracy: 0.747\n",
      "Epoch: 1091/1500..  Training Loss: 0.000..  Test Loss: 5.118..  Test Accuracy: 0.747\n",
      "Epoch: 1092/1500..  Training Loss: 0.000..  Test Loss: 5.118..  Test Accuracy: 0.747\n",
      "Epoch: 1093/1500..  Training Loss: 0.000..  Test Loss: 5.119..  Test Accuracy: 0.747\n",
      "Epoch: 1094/1500..  Training Loss: 0.000..  Test Loss: 5.118..  Test Accuracy: 0.747\n",
      "Epoch: 1095/1500..  Training Loss: 0.000..  Test Loss: 5.121..  Test Accuracy: 0.747\n",
      "Epoch: 1096/1500..  Training Loss: 0.000..  Test Loss: 5.119..  Test Accuracy: 0.747\n",
      "Epoch: 1097/1500..  Training Loss: 0.000..  Test Loss: 5.118..  Test Accuracy: 0.747\n",
      "Epoch: 1098/1500..  Training Loss: 0.000..  Test Loss: 5.121..  Test Accuracy: 0.747\n",
      "Epoch: 1099/1500..  Training Loss: 0.000..  Test Loss: 5.119..  Test Accuracy: 0.747\n",
      "Epoch: 1100/1500..  Training Loss: 0.000..  Test Loss: 5.119..  Test Accuracy: 0.747\n",
      "Epoch: 1101/1500..  Training Loss: 0.000..  Test Loss: 5.119..  Test Accuracy: 0.747\n",
      "Epoch: 1102/1500..  Training Loss: 0.000..  Test Loss: 5.118..  Test Accuracy: 0.747\n",
      "Epoch: 1103/1500..  Training Loss: 0.000..  Test Loss: 5.120..  Test Accuracy: 0.747\n",
      "Epoch: 1104/1500..  Training Loss: 0.000..  Test Loss: 5.120..  Test Accuracy: 0.747\n",
      "Epoch: 1105/1500..  Training Loss: 0.000..  Test Loss: 5.122..  Test Accuracy: 0.747\n",
      "Epoch: 1106/1500..  Training Loss: 0.000..  Test Loss: 5.122..  Test Accuracy: 0.747\n",
      "Epoch: 1107/1500..  Training Loss: 0.000..  Test Loss: 5.121..  Test Accuracy: 0.747\n",
      "Epoch: 1108/1500..  Training Loss: 0.000..  Test Loss: 5.120..  Test Accuracy: 0.747\n",
      "Epoch: 1109/1500..  Training Loss: 0.000..  Test Loss: 5.121..  Test Accuracy: 0.747\n",
      "Epoch: 1110/1500..  Training Loss: 0.000..  Test Loss: 5.122..  Test Accuracy: 0.747\n",
      "Epoch: 1111/1500..  Training Loss: 0.000..  Test Loss: 5.122..  Test Accuracy: 0.747\n",
      "Epoch: 1112/1500..  Training Loss: 0.000..  Test Loss: 5.123..  Test Accuracy: 0.746\n",
      "Epoch: 1113/1500..  Training Loss: 0.000..  Test Loss: 5.123..  Test Accuracy: 0.747\n",
      "Epoch: 1114/1500..  Training Loss: 0.000..  Test Loss: 5.123..  Test Accuracy: 0.747\n",
      "Epoch: 1115/1500..  Training Loss: 0.000..  Test Loss: 5.123..  Test Accuracy: 0.747\n",
      "Epoch: 1116/1500..  Training Loss: 0.000..  Test Loss: 5.123..  Test Accuracy: 0.747\n",
      "Epoch: 1117/1500..  Training Loss: 0.000..  Test Loss: 5.124..  Test Accuracy: 0.747\n",
      "Epoch: 1118/1500..  Training Loss: 0.000..  Test Loss: 5.124..  Test Accuracy: 0.747\n",
      "Epoch: 1119/1500..  Training Loss: 0.000..  Test Loss: 5.123..  Test Accuracy: 0.747\n",
      "Epoch: 1120/1500..  Training Loss: 0.000..  Test Loss: 5.123..  Test Accuracy: 0.747\n",
      "Epoch: 1121/1500..  Training Loss: 0.000..  Test Loss: 5.123..  Test Accuracy: 0.747\n",
      "Epoch: 1122/1500..  Training Loss: 0.000..  Test Loss: 5.124..  Test Accuracy: 0.747\n",
      "Epoch: 1123/1500..  Training Loss: 0.000..  Test Loss: 5.124..  Test Accuracy: 0.747\n",
      "Epoch: 1124/1500..  Training Loss: 0.000..  Test Loss: 5.125..  Test Accuracy: 0.747\n",
      "Epoch: 1125/1500..  Training Loss: 0.000..  Test Loss: 5.125..  Test Accuracy: 0.747\n",
      "Epoch: 1126/1500..  Training Loss: 0.000..  Test Loss: 5.127..  Test Accuracy: 0.747\n",
      "Epoch: 1127/1500..  Training Loss: 0.000..  Test Loss: 5.125..  Test Accuracy: 0.747\n",
      "Epoch: 1128/1500..  Training Loss: 0.000..  Test Loss: 5.125..  Test Accuracy: 0.747\n",
      "Epoch: 1129/1500..  Training Loss: 0.000..  Test Loss: 5.126..  Test Accuracy: 0.747\n",
      "Epoch: 1130/1500..  Training Loss: 0.000..  Test Loss: 5.126..  Test Accuracy: 0.747\n",
      "Epoch: 1131/1500..  Training Loss: 0.000..  Test Loss: 5.126..  Test Accuracy: 0.747\n",
      "Epoch: 1132/1500..  Training Loss: 0.000..  Test Loss: 5.127..  Test Accuracy: 0.747\n",
      "Epoch: 1133/1500..  Training Loss: 0.000..  Test Loss: 5.127..  Test Accuracy: 0.747\n",
      "Epoch: 1134/1500..  Training Loss: 0.000..  Test Loss: 5.128..  Test Accuracy: 0.747\n",
      "Epoch: 1135/1500..  Training Loss: 0.000..  Test Loss: 5.128..  Test Accuracy: 0.747\n",
      "Epoch: 1136/1500..  Training Loss: 0.000..  Test Loss: 5.128..  Test Accuracy: 0.747\n",
      "Epoch: 1137/1500..  Training Loss: 0.000..  Test Loss: 5.128..  Test Accuracy: 0.747\n",
      "Epoch: 1138/1500..  Training Loss: 0.000..  Test Loss: 5.129..  Test Accuracy: 0.747\n",
      "Epoch: 1139/1500..  Training Loss: 0.000..  Test Loss: 5.128..  Test Accuracy: 0.747\n",
      "Epoch: 1140/1500..  Training Loss: 0.000..  Test Loss: 5.127..  Test Accuracy: 0.747\n",
      "Epoch: 1141/1500..  Training Loss: 0.000..  Test Loss: 5.128..  Test Accuracy: 0.747\n",
      "Epoch: 1142/1500..  Training Loss: 0.000..  Test Loss: 5.129..  Test Accuracy: 0.747\n",
      "Epoch: 1143/1500..  Training Loss: 0.000..  Test Loss: 5.128..  Test Accuracy: 0.747\n",
      "Epoch: 1144/1500..  Training Loss: 0.000..  Test Loss: 5.129..  Test Accuracy: 0.747\n",
      "Epoch: 1145/1500..  Training Loss: 0.000..  Test Loss: 5.129..  Test Accuracy: 0.747\n",
      "Epoch: 1146/1500..  Training Loss: 0.000..  Test Loss: 5.130..  Test Accuracy: 0.747\n",
      "Epoch: 1147/1500..  Training Loss: 0.000..  Test Loss: 5.129..  Test Accuracy: 0.747\n",
      "Epoch: 1148/1500..  Training Loss: 0.000..  Test Loss: 5.130..  Test Accuracy: 0.747\n",
      "Epoch: 1149/1500..  Training Loss: 0.000..  Test Loss: 5.129..  Test Accuracy: 0.747\n",
      "Epoch: 1150/1500..  Training Loss: 0.000..  Test Loss: 5.130..  Test Accuracy: 0.747\n",
      "Epoch: 1151/1500..  Training Loss: 0.000..  Test Loss: 5.130..  Test Accuracy: 0.747\n",
      "Epoch: 1152/1500..  Training Loss: 0.000..  Test Loss: 5.130..  Test Accuracy: 0.747\n",
      "Epoch: 1153/1500..  Training Loss: 0.000..  Test Loss: 5.130..  Test Accuracy: 0.747\n",
      "Epoch: 1154/1500..  Training Loss: 0.000..  Test Loss: 5.131..  Test Accuracy: 0.747\n",
      "Epoch: 1155/1500..  Training Loss: 0.000..  Test Loss: 5.131..  Test Accuracy: 0.747\n",
      "Epoch: 1156/1500..  Training Loss: 0.000..  Test Loss: 5.132..  Test Accuracy: 0.747\n",
      "Epoch: 1157/1500..  Training Loss: 0.000..  Test Loss: 5.132..  Test Accuracy: 0.747\n",
      "Epoch: 1158/1500..  Training Loss: 0.000..  Test Loss: 5.132..  Test Accuracy: 0.747\n",
      "Epoch: 1159/1500..  Training Loss: 0.000..  Test Loss: 5.131..  Test Accuracy: 0.747\n",
      "Epoch: 1160/1500..  Training Loss: 0.000..  Test Loss: 5.132..  Test Accuracy: 0.747\n",
      "Epoch: 1161/1500..  Training Loss: 0.000..  Test Loss: 5.132..  Test Accuracy: 0.747\n",
      "Epoch: 1162/1500..  Training Loss: 0.000..  Test Loss: 5.132..  Test Accuracy: 0.747\n",
      "Epoch: 1163/1500..  Training Loss: 0.000..  Test Loss: 5.133..  Test Accuracy: 0.747\n",
      "Epoch: 1164/1500..  Training Loss: 0.000..  Test Loss: 5.133..  Test Accuracy: 0.747\n",
      "Epoch: 1165/1500..  Training Loss: 0.000..  Test Loss: 5.132..  Test Accuracy: 0.748\n",
      "Epoch: 1166/1500..  Training Loss: 0.000..  Test Loss: 5.132..  Test Accuracy: 0.748\n",
      "Epoch: 1167/1500..  Training Loss: 0.000..  Test Loss: 5.133..  Test Accuracy: 0.748\n",
      "Epoch: 1168/1500..  Training Loss: 0.000..  Test Loss: 5.133..  Test Accuracy: 0.747\n",
      "Epoch: 1169/1500..  Training Loss: 0.000..  Test Loss: 5.135..  Test Accuracy: 0.747\n",
      "Epoch: 1170/1500..  Training Loss: 0.000..  Test Loss: 5.134..  Test Accuracy: 0.747\n",
      "Epoch: 1171/1500..  Training Loss: 0.000..  Test Loss: 5.134..  Test Accuracy: 0.747\n",
      "Epoch: 1172/1500..  Training Loss: 0.000..  Test Loss: 5.135..  Test Accuracy: 0.747\n",
      "Epoch: 1173/1500..  Training Loss: 0.000..  Test Loss: 5.136..  Test Accuracy: 0.747\n",
      "Epoch: 1174/1500..  Training Loss: 0.000..  Test Loss: 5.134..  Test Accuracy: 0.747\n",
      "Epoch: 1175/1500..  Training Loss: 0.000..  Test Loss: 5.135..  Test Accuracy: 0.747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1176/1500..  Training Loss: 0.000..  Test Loss: 5.135..  Test Accuracy: 0.747\n",
      "Epoch: 1177/1500..  Training Loss: 0.000..  Test Loss: 5.134..  Test Accuracy: 0.747\n",
      "Epoch: 1178/1500..  Training Loss: 0.000..  Test Loss: 5.136..  Test Accuracy: 0.747\n",
      "Epoch: 1179/1500..  Training Loss: 0.000..  Test Loss: 5.136..  Test Accuracy: 0.747\n",
      "Epoch: 1180/1500..  Training Loss: 0.000..  Test Loss: 5.136..  Test Accuracy: 0.747\n",
      "Epoch: 1181/1500..  Training Loss: 0.000..  Test Loss: 5.136..  Test Accuracy: 0.747\n",
      "Epoch: 1182/1500..  Training Loss: 0.000..  Test Loss: 5.135..  Test Accuracy: 0.747\n",
      "Epoch: 1183/1500..  Training Loss: 0.000..  Test Loss: 5.136..  Test Accuracy: 0.747\n",
      "Epoch: 1184/1500..  Training Loss: 0.000..  Test Loss: 5.136..  Test Accuracy: 0.747\n",
      "Epoch: 1185/1500..  Training Loss: 0.000..  Test Loss: 5.136..  Test Accuracy: 0.747\n",
      "Epoch: 1186/1500..  Training Loss: 0.000..  Test Loss: 5.137..  Test Accuracy: 0.747\n",
      "Epoch: 1187/1500..  Training Loss: 0.000..  Test Loss: 5.136..  Test Accuracy: 0.747\n",
      "Epoch: 1188/1500..  Training Loss: 0.000..  Test Loss: 5.137..  Test Accuracy: 0.747\n",
      "Epoch: 1189/1500..  Training Loss: 0.000..  Test Loss: 5.137..  Test Accuracy: 0.748\n",
      "Epoch: 1190/1500..  Training Loss: 0.000..  Test Loss: 5.137..  Test Accuracy: 0.747\n",
      "Epoch: 1191/1500..  Training Loss: 0.000..  Test Loss: 5.138..  Test Accuracy: 0.747\n",
      "Epoch: 1192/1500..  Training Loss: 0.000..  Test Loss: 5.138..  Test Accuracy: 0.747\n",
      "Epoch: 1193/1500..  Training Loss: 0.000..  Test Loss: 5.138..  Test Accuracy: 0.747\n",
      "Epoch: 1194/1500..  Training Loss: 0.000..  Test Loss: 5.138..  Test Accuracy: 0.747\n",
      "Epoch: 1195/1500..  Training Loss: 0.000..  Test Loss: 5.138..  Test Accuracy: 0.747\n",
      "Epoch: 1196/1500..  Training Loss: 0.000..  Test Loss: 5.138..  Test Accuracy: 0.747\n",
      "Epoch: 1197/1500..  Training Loss: 0.000..  Test Loss: 5.138..  Test Accuracy: 0.747\n",
      "Epoch: 1198/1500..  Training Loss: 0.000..  Test Loss: 5.141..  Test Accuracy: 0.747\n",
      "Epoch: 1199/1500..  Training Loss: 0.000..  Test Loss: 5.138..  Test Accuracy: 0.747\n",
      "Epoch: 1200/1500..  Training Loss: 0.000..  Test Loss: 5.139..  Test Accuracy: 0.747\n",
      "Epoch: 1201/1500..  Training Loss: 0.000..  Test Loss: 5.138..  Test Accuracy: 0.747\n",
      "Epoch: 1202/1500..  Training Loss: 0.000..  Test Loss: 5.139..  Test Accuracy: 0.747\n",
      "Epoch: 1203/1500..  Training Loss: 0.000..  Test Loss: 5.139..  Test Accuracy: 0.747\n",
      "Epoch: 1204/1500..  Training Loss: 0.000..  Test Loss: 5.139..  Test Accuracy: 0.747\n",
      "Epoch: 1205/1500..  Training Loss: 0.000..  Test Loss: 5.139..  Test Accuracy: 0.747\n",
      "Epoch: 1206/1500..  Training Loss: 0.000..  Test Loss: 5.139..  Test Accuracy: 0.747\n",
      "Epoch: 1207/1500..  Training Loss: 0.000..  Test Loss: 5.140..  Test Accuracy: 0.747\n",
      "Epoch: 1208/1500..  Training Loss: 0.000..  Test Loss: 5.139..  Test Accuracy: 0.747\n",
      "Epoch: 1209/1500..  Training Loss: 0.000..  Test Loss: 5.140..  Test Accuracy: 0.747\n",
      "Epoch: 1210/1500..  Training Loss: 0.000..  Test Loss: 5.140..  Test Accuracy: 0.747\n",
      "Epoch: 1211/1500..  Training Loss: 0.000..  Test Loss: 5.140..  Test Accuracy: 0.747\n",
      "Epoch: 1212/1500..  Training Loss: 0.000..  Test Loss: 5.141..  Test Accuracy: 0.747\n",
      "Epoch: 1213/1500..  Training Loss: 0.000..  Test Loss: 5.141..  Test Accuracy: 0.748\n",
      "Epoch: 1214/1500..  Training Loss: 0.000..  Test Loss: 5.141..  Test Accuracy: 0.747\n",
      "Epoch: 1215/1500..  Training Loss: 0.000..  Test Loss: 5.142..  Test Accuracy: 0.747\n",
      "Epoch: 1216/1500..  Training Loss: 0.000..  Test Loss: 5.142..  Test Accuracy: 0.747\n",
      "Epoch: 1217/1500..  Training Loss: 0.000..  Test Loss: 5.142..  Test Accuracy: 0.747\n",
      "Epoch: 1218/1500..  Training Loss: 0.000..  Test Loss: 5.142..  Test Accuracy: 0.747\n",
      "Epoch: 1219/1500..  Training Loss: 0.000..  Test Loss: 5.143..  Test Accuracy: 0.747\n",
      "Epoch: 1220/1500..  Training Loss: 0.000..  Test Loss: 5.142..  Test Accuracy: 0.747\n",
      "Epoch: 1221/1500..  Training Loss: 0.000..  Test Loss: 5.143..  Test Accuracy: 0.747\n",
      "Epoch: 1222/1500..  Training Loss: 0.000..  Test Loss: 5.143..  Test Accuracy: 0.747\n",
      "Epoch: 1223/1500..  Training Loss: 0.000..  Test Loss: 5.144..  Test Accuracy: 0.747\n",
      "Epoch: 1224/1500..  Training Loss: 0.000..  Test Loss: 5.143..  Test Accuracy: 0.747\n",
      "Epoch: 1225/1500..  Training Loss: 0.000..  Test Loss: 5.143..  Test Accuracy: 0.747\n",
      "Epoch: 1226/1500..  Training Loss: 0.000..  Test Loss: 5.144..  Test Accuracy: 0.747\n",
      "Epoch: 1227/1500..  Training Loss: 0.000..  Test Loss: 5.144..  Test Accuracy: 0.747\n",
      "Epoch: 1228/1500..  Training Loss: 0.000..  Test Loss: 5.144..  Test Accuracy: 0.747\n",
      "Epoch: 1229/1500..  Training Loss: 0.000..  Test Loss: 5.144..  Test Accuracy: 0.747\n",
      "Epoch: 1230/1500..  Training Loss: 0.000..  Test Loss: 5.144..  Test Accuracy: 0.747\n",
      "Epoch: 1231/1500..  Training Loss: 0.000..  Test Loss: 5.146..  Test Accuracy: 0.747\n",
      "Epoch: 1232/1500..  Training Loss: 0.000..  Test Loss: 5.144..  Test Accuracy: 0.747\n",
      "Epoch: 1233/1500..  Training Loss: 0.000..  Test Loss: 5.145..  Test Accuracy: 0.747\n",
      "Epoch: 1234/1500..  Training Loss: 0.000..  Test Loss: 5.145..  Test Accuracy: 0.747\n",
      "Epoch: 1235/1500..  Training Loss: 0.000..  Test Loss: 5.146..  Test Accuracy: 0.747\n",
      "Epoch: 1236/1500..  Training Loss: 0.000..  Test Loss: 5.145..  Test Accuracy: 0.748\n",
      "Epoch: 1237/1500..  Training Loss: 0.000..  Test Loss: 5.145..  Test Accuracy: 0.748\n",
      "Epoch: 1238/1500..  Training Loss: 0.000..  Test Loss: 5.146..  Test Accuracy: 0.747\n",
      "Epoch: 1239/1500..  Training Loss: 0.000..  Test Loss: 5.146..  Test Accuracy: 0.747\n",
      "Epoch: 1240/1500..  Training Loss: 0.000..  Test Loss: 5.145..  Test Accuracy: 0.748\n",
      "Epoch: 1241/1500..  Training Loss: 0.000..  Test Loss: 5.146..  Test Accuracy: 0.747\n",
      "Epoch: 1242/1500..  Training Loss: 0.000..  Test Loss: 5.145..  Test Accuracy: 0.748\n",
      "Epoch: 1243/1500..  Training Loss: 0.000..  Test Loss: 5.148..  Test Accuracy: 0.747\n",
      "Epoch: 1244/1500..  Training Loss: 0.000..  Test Loss: 5.147..  Test Accuracy: 0.748\n",
      "Epoch: 1245/1500..  Training Loss: 0.000..  Test Loss: 5.148..  Test Accuracy: 0.747\n",
      "Epoch: 1246/1500..  Training Loss: 0.000..  Test Loss: 5.148..  Test Accuracy: 0.747\n",
      "Epoch: 1247/1500..  Training Loss: 0.000..  Test Loss: 5.147..  Test Accuracy: 0.747\n",
      "Epoch: 1248/1500..  Training Loss: 0.000..  Test Loss: 5.147..  Test Accuracy: 0.747\n",
      "Epoch: 1249/1500..  Training Loss: 0.000..  Test Loss: 5.147..  Test Accuracy: 0.748\n",
      "Epoch: 1250/1500..  Training Loss: 0.000..  Test Loss: 5.147..  Test Accuracy: 0.747\n",
      "Epoch: 1251/1500..  Training Loss: 0.000..  Test Loss: 5.146..  Test Accuracy: 0.748\n",
      "Epoch: 1252/1500..  Training Loss: 0.000..  Test Loss: 5.147..  Test Accuracy: 0.748\n",
      "Epoch: 1253/1500..  Training Loss: 0.000..  Test Loss: 5.148..  Test Accuracy: 0.748\n",
      "Epoch: 1254/1500..  Training Loss: 0.000..  Test Loss: 5.148..  Test Accuracy: 0.747\n",
      "Epoch: 1255/1500..  Training Loss: 0.000..  Test Loss: 5.148..  Test Accuracy: 0.747\n",
      "Epoch: 1256/1500..  Training Loss: 0.000..  Test Loss: 5.149..  Test Accuracy: 0.747\n",
      "Epoch: 1257/1500..  Training Loss: 0.000..  Test Loss: 5.149..  Test Accuracy: 0.747\n",
      "Epoch: 1258/1500..  Training Loss: 0.000..  Test Loss: 5.150..  Test Accuracy: 0.747\n",
      "Epoch: 1259/1500..  Training Loss: 0.000..  Test Loss: 5.150..  Test Accuracy: 0.747\n",
      "Epoch: 1260/1500..  Training Loss: 0.000..  Test Loss: 5.150..  Test Accuracy: 0.748\n",
      "Epoch: 1261/1500..  Training Loss: 0.000..  Test Loss: 5.149..  Test Accuracy: 0.748\n",
      "Epoch: 1262/1500..  Training Loss: 0.000..  Test Loss: 5.150..  Test Accuracy: 0.747\n",
      "Epoch: 1263/1500..  Training Loss: 0.000..  Test Loss: 5.150..  Test Accuracy: 0.748\n",
      "Epoch: 1264/1500..  Training Loss: 0.000..  Test Loss: 5.151..  Test Accuracy: 0.747\n",
      "Epoch: 1265/1500..  Training Loss: 0.000..  Test Loss: 5.150..  Test Accuracy: 0.747\n",
      "Epoch: 1266/1500..  Training Loss: 0.000..  Test Loss: 5.150..  Test Accuracy: 0.748\n",
      "Epoch: 1267/1500..  Training Loss: 0.000..  Test Loss: 5.151..  Test Accuracy: 0.748\n",
      "Epoch: 1268/1500..  Training Loss: 0.000..  Test Loss: 5.151..  Test Accuracy: 0.748\n",
      "Epoch: 1269/1500..  Training Loss: 0.000..  Test Loss: 5.151..  Test Accuracy: 0.747\n",
      "Epoch: 1270/1500..  Training Loss: 0.000..  Test Loss: 5.152..  Test Accuracy: 0.747\n",
      "Epoch: 1271/1500..  Training Loss: 0.000..  Test Loss: 5.151..  Test Accuracy: 0.748\n",
      "Epoch: 1272/1500..  Training Loss: 0.000..  Test Loss: 5.152..  Test Accuracy: 0.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1273/1500..  Training Loss: 0.000..  Test Loss: 5.151..  Test Accuracy: 0.748\n",
      "Epoch: 1274/1500..  Training Loss: 0.000..  Test Loss: 5.153..  Test Accuracy: 0.747\n",
      "Epoch: 1275/1500..  Training Loss: 0.000..  Test Loss: 5.151..  Test Accuracy: 0.748\n",
      "Epoch: 1276/1500..  Training Loss: 0.000..  Test Loss: 5.152..  Test Accuracy: 0.748\n",
      "Epoch: 1277/1500..  Training Loss: 0.000..  Test Loss: 5.152..  Test Accuracy: 0.748\n",
      "Epoch: 1278/1500..  Training Loss: 0.000..  Test Loss: 5.152..  Test Accuracy: 0.748\n",
      "Epoch: 1279/1500..  Training Loss: 0.000..  Test Loss: 5.152..  Test Accuracy: 0.747\n",
      "Epoch: 1280/1500..  Training Loss: 0.000..  Test Loss: 5.152..  Test Accuracy: 0.747\n",
      "Epoch: 1281/1500..  Training Loss: 0.000..  Test Loss: 5.153..  Test Accuracy: 0.747\n",
      "Epoch: 1282/1500..  Training Loss: 0.000..  Test Loss: 5.153..  Test Accuracy: 0.748\n",
      "Epoch: 1283/1500..  Training Loss: 0.000..  Test Loss: 5.153..  Test Accuracy: 0.747\n",
      "Epoch: 1284/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.747\n",
      "Epoch: 1285/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.747\n",
      "Epoch: 1286/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.748\n",
      "Epoch: 1287/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.748\n",
      "Epoch: 1288/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.747\n",
      "Epoch: 1289/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.747\n",
      "Epoch: 1290/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.747\n",
      "Epoch: 1291/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.747\n",
      "Epoch: 1292/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.747\n",
      "Epoch: 1293/1500..  Training Loss: 0.000..  Test Loss: 5.155..  Test Accuracy: 0.748\n",
      "Epoch: 1294/1500..  Training Loss: 0.000..  Test Loss: 5.155..  Test Accuracy: 0.748\n",
      "Epoch: 1295/1500..  Training Loss: 0.000..  Test Loss: 5.155..  Test Accuracy: 0.748\n",
      "Epoch: 1296/1500..  Training Loss: 0.000..  Test Loss: 5.154..  Test Accuracy: 0.748\n",
      "Epoch: 1297/1500..  Training Loss: 0.000..  Test Loss: 5.155..  Test Accuracy: 0.747\n",
      "Epoch: 1298/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.747\n",
      "Epoch: 1299/1500..  Training Loss: 0.000..  Test Loss: 5.157..  Test Accuracy: 0.747\n",
      "Epoch: 1300/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.748\n",
      "Epoch: 1301/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.748\n",
      "Epoch: 1302/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.748\n",
      "Epoch: 1303/1500..  Training Loss: 0.000..  Test Loss: 5.155..  Test Accuracy: 0.748\n",
      "Epoch: 1304/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.747\n",
      "Epoch: 1305/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.747\n",
      "Epoch: 1306/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.747\n",
      "Epoch: 1307/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.748\n",
      "Epoch: 1308/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.748\n",
      "Epoch: 1309/1500..  Training Loss: 0.000..  Test Loss: 5.156..  Test Accuracy: 0.748\n",
      "Epoch: 1310/1500..  Training Loss: 0.000..  Test Loss: 5.157..  Test Accuracy: 0.748\n",
      "Epoch: 1311/1500..  Training Loss: 0.000..  Test Loss: 5.157..  Test Accuracy: 0.748\n",
      "Epoch: 1312/1500..  Training Loss: 0.000..  Test Loss: 5.157..  Test Accuracy: 0.748\n",
      "Epoch: 1313/1500..  Training Loss: 0.000..  Test Loss: 5.158..  Test Accuracy: 0.748\n",
      "Epoch: 1314/1500..  Training Loss: 0.000..  Test Loss: 5.157..  Test Accuracy: 0.748\n",
      "Epoch: 1315/1500..  Training Loss: 0.000..  Test Loss: 5.158..  Test Accuracy: 0.748\n",
      "Epoch: 1316/1500..  Training Loss: 0.000..  Test Loss: 5.157..  Test Accuracy: 0.748\n",
      "Epoch: 1317/1500..  Training Loss: 0.000..  Test Loss: 5.158..  Test Accuracy: 0.748\n",
      "Epoch: 1318/1500..  Training Loss: 0.000..  Test Loss: 5.158..  Test Accuracy: 0.748\n",
      "Epoch: 1319/1500..  Training Loss: 0.000..  Test Loss: 5.158..  Test Accuracy: 0.748\n",
      "Epoch: 1320/1500..  Training Loss: 0.000..  Test Loss: 5.159..  Test Accuracy: 0.748\n",
      "Epoch: 1321/1500..  Training Loss: 0.000..  Test Loss: 5.158..  Test Accuracy: 0.748\n",
      "Epoch: 1322/1500..  Training Loss: 0.000..  Test Loss: 5.159..  Test Accuracy: 0.748\n",
      "Epoch: 1323/1500..  Training Loss: 0.000..  Test Loss: 5.159..  Test Accuracy: 0.748\n",
      "Epoch: 1324/1500..  Training Loss: 0.000..  Test Loss: 5.158..  Test Accuracy: 0.748\n",
      "Epoch: 1325/1500..  Training Loss: 0.000..  Test Loss: 5.158..  Test Accuracy: 0.748\n",
      "Epoch: 1326/1500..  Training Loss: 0.000..  Test Loss: 5.160..  Test Accuracy: 0.748\n",
      "Epoch: 1327/1500..  Training Loss: 0.000..  Test Loss: 5.160..  Test Accuracy: 0.748\n",
      "Epoch: 1328/1500..  Training Loss: 0.000..  Test Loss: 5.160..  Test Accuracy: 0.748\n",
      "Epoch: 1329/1500..  Training Loss: 0.000..  Test Loss: 5.160..  Test Accuracy: 0.748\n",
      "Epoch: 1330/1500..  Training Loss: 0.000..  Test Loss: 5.160..  Test Accuracy: 0.748\n",
      "Epoch: 1331/1500..  Training Loss: 0.000..  Test Loss: 5.161..  Test Accuracy: 0.748\n",
      "Epoch: 1332/1500..  Training Loss: 0.000..  Test Loss: 5.161..  Test Accuracy: 0.748\n",
      "Epoch: 1333/1500..  Training Loss: 0.000..  Test Loss: 5.161..  Test Accuracy: 0.748\n",
      "Epoch: 1334/1500..  Training Loss: 0.000..  Test Loss: 5.160..  Test Accuracy: 0.748\n",
      "Epoch: 1335/1500..  Training Loss: 0.000..  Test Loss: 5.161..  Test Accuracy: 0.748\n",
      "Epoch: 1336/1500..  Training Loss: 0.000..  Test Loss: 5.161..  Test Accuracy: 0.748\n",
      "Epoch: 1337/1500..  Training Loss: 0.000..  Test Loss: 5.161..  Test Accuracy: 0.748\n",
      "Epoch: 1338/1500..  Training Loss: 0.000..  Test Loss: 5.161..  Test Accuracy: 0.748\n",
      "Epoch: 1339/1500..  Training Loss: 0.000..  Test Loss: 5.161..  Test Accuracy: 0.748\n",
      "Epoch: 1340/1500..  Training Loss: 0.000..  Test Loss: 5.162..  Test Accuracy: 0.748\n",
      "Epoch: 1341/1500..  Training Loss: 0.000..  Test Loss: 5.161..  Test Accuracy: 0.748\n",
      "Epoch: 1342/1500..  Training Loss: 0.000..  Test Loss: 5.162..  Test Accuracy: 0.748\n",
      "Epoch: 1343/1500..  Training Loss: 0.000..  Test Loss: 5.163..  Test Accuracy: 0.748\n",
      "Epoch: 1344/1500..  Training Loss: 0.000..  Test Loss: 5.162..  Test Accuracy: 0.748\n",
      "Epoch: 1345/1500..  Training Loss: 0.000..  Test Loss: 5.162..  Test Accuracy: 0.748\n",
      "Epoch: 1346/1500..  Training Loss: 0.000..  Test Loss: 5.163..  Test Accuracy: 0.748\n",
      "Epoch: 1347/1500..  Training Loss: 0.000..  Test Loss: 5.162..  Test Accuracy: 0.748\n",
      "Epoch: 1348/1500..  Training Loss: 0.000..  Test Loss: 5.164..  Test Accuracy: 0.748\n",
      "Epoch: 1349/1500..  Training Loss: 0.000..  Test Loss: 5.164..  Test Accuracy: 0.748\n",
      "Epoch: 1350/1500..  Training Loss: 0.000..  Test Loss: 5.163..  Test Accuracy: 0.748\n",
      "Epoch: 1351/1500..  Training Loss: 0.000..  Test Loss: 5.164..  Test Accuracy: 0.748\n",
      "Epoch: 1352/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1353/1500..  Training Loss: 0.000..  Test Loss: 5.163..  Test Accuracy: 0.748\n",
      "Epoch: 1354/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1355/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1356/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.747\n",
      "Epoch: 1357/1500..  Training Loss: 0.000..  Test Loss: 5.164..  Test Accuracy: 0.748\n",
      "Epoch: 1358/1500..  Training Loss: 0.000..  Test Loss: 5.164..  Test Accuracy: 0.748\n",
      "Epoch: 1359/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1360/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1361/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1362/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1363/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1364/1500..  Training Loss: 0.000..  Test Loss: 5.166..  Test Accuracy: 0.748\n",
      "Epoch: 1365/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1366/1500..  Training Loss: 0.000..  Test Loss: 5.167..  Test Accuracy: 0.748\n",
      "Epoch: 1367/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1368/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1369/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1370/1500..  Training Loss: 0.000..  Test Loss: 5.166..  Test Accuracy: 0.748\n",
      "Epoch: 1371/1500..  Training Loss: 0.000..  Test Loss: 5.165..  Test Accuracy: 0.748\n",
      "Epoch: 1372/1500..  Training Loss: 0.000..  Test Loss: 5.166..  Test Accuracy: 0.748\n",
      "Epoch: 1373/1500..  Training Loss: 0.000..  Test Loss: 5.166..  Test Accuracy: 0.748\n",
      "Epoch: 1374/1500..  Training Loss: 0.000..  Test Loss: 5.166..  Test Accuracy: 0.748\n",
      "Epoch: 1375/1500..  Training Loss: 0.000..  Test Loss: 5.167..  Test Accuracy: 0.748\n",
      "Epoch: 1376/1500..  Training Loss: 0.000..  Test Loss: 5.167..  Test Accuracy: 0.748\n",
      "Epoch: 1377/1500..  Training Loss: 0.000..  Test Loss: 5.167..  Test Accuracy: 0.748\n",
      "Epoch: 1378/1500..  Training Loss: 0.000..  Test Loss: 5.167..  Test Accuracy: 0.748\n",
      "Epoch: 1379/1500..  Training Loss: 0.000..  Test Loss: 5.167..  Test Accuracy: 0.748\n",
      "Epoch: 1380/1500..  Training Loss: 0.000..  Test Loss: 5.168..  Test Accuracy: 0.748\n",
      "Epoch: 1381/1500..  Training Loss: 0.000..  Test Loss: 5.168..  Test Accuracy: 0.748\n",
      "Epoch: 1382/1500..  Training Loss: 0.000..  Test Loss: 5.168..  Test Accuracy: 0.748\n",
      "Epoch: 1383/1500..  Training Loss: 0.000..  Test Loss: 5.167..  Test Accuracy: 0.748\n",
      "Epoch: 1384/1500..  Training Loss: 0.000..  Test Loss: 5.167..  Test Accuracy: 0.748\n",
      "Epoch: 1385/1500..  Training Loss: 0.000..  Test Loss: 5.167..  Test Accuracy: 0.748\n",
      "Epoch: 1386/1500..  Training Loss: 0.000..  Test Loss: 5.168..  Test Accuracy: 0.748\n",
      "Epoch: 1387/1500..  Training Loss: 0.000..  Test Loss: 5.169..  Test Accuracy: 0.748\n",
      "Epoch: 1388/1500..  Training Loss: 0.000..  Test Loss: 5.168..  Test Accuracy: 0.748\n",
      "Epoch: 1389/1500..  Training Loss: 0.000..  Test Loss: 5.169..  Test Accuracy: 0.748\n",
      "Epoch: 1390/1500..  Training Loss: 0.000..  Test Loss: 5.169..  Test Accuracy: 0.748\n",
      "Epoch: 1391/1500..  Training Loss: 0.000..  Test Loss: 5.169..  Test Accuracy: 0.748\n",
      "Epoch: 1392/1500..  Training Loss: 0.000..  Test Loss: 5.169..  Test Accuracy: 0.748\n",
      "Epoch: 1393/1500..  Training Loss: 0.000..  Test Loss: 5.170..  Test Accuracy: 0.748\n",
      "Epoch: 1394/1500..  Training Loss: 0.000..  Test Loss: 5.169..  Test Accuracy: 0.748\n",
      "Epoch: 1395/1500..  Training Loss: 0.000..  Test Loss: 5.169..  Test Accuracy: 0.748\n",
      "Epoch: 1396/1500..  Training Loss: 0.000..  Test Loss: 5.169..  Test Accuracy: 0.748\n",
      "Epoch: 1397/1500..  Training Loss: 0.000..  Test Loss: 5.169..  Test Accuracy: 0.748\n",
      "Epoch: 1398/1500..  Training Loss: 0.000..  Test Loss: 5.170..  Test Accuracy: 0.748\n",
      "Epoch: 1399/1500..  Training Loss: 0.000..  Test Loss: 5.170..  Test Accuracy: 0.748\n",
      "Epoch: 1400/1500..  Training Loss: 0.000..  Test Loss: 5.171..  Test Accuracy: 0.748\n",
      "Epoch: 1401/1500..  Training Loss: 0.000..  Test Loss: 5.170..  Test Accuracy: 0.748\n",
      "Epoch: 1402/1500..  Training Loss: 0.000..  Test Loss: 5.170..  Test Accuracy: 0.748\n",
      "Epoch: 1403/1500..  Training Loss: 0.000..  Test Loss: 5.171..  Test Accuracy: 0.748\n",
      "Epoch: 1404/1500..  Training Loss: 0.000..  Test Loss: 5.170..  Test Accuracy: 0.748\n",
      "Epoch: 1405/1500..  Training Loss: 0.000..  Test Loss: 5.170..  Test Accuracy: 0.748\n",
      "Epoch: 1406/1500..  Training Loss: 0.000..  Test Loss: 5.171..  Test Accuracy: 0.748\n",
      "Epoch: 1407/1500..  Training Loss: 0.000..  Test Loss: 5.171..  Test Accuracy: 0.748\n",
      "Epoch: 1408/1500..  Training Loss: 0.000..  Test Loss: 5.171..  Test Accuracy: 0.748\n",
      "Epoch: 1409/1500..  Training Loss: 0.000..  Test Loss: 5.171..  Test Accuracy: 0.748\n",
      "Epoch: 1410/1500..  Training Loss: 0.000..  Test Loss: 5.171..  Test Accuracy: 0.748\n",
      "Epoch: 1411/1500..  Training Loss: 0.000..  Test Loss: 5.171..  Test Accuracy: 0.748\n",
      "Epoch: 1412/1500..  Training Loss: 0.000..  Test Loss: 5.172..  Test Accuracy: 0.748\n",
      "Epoch: 1413/1500..  Training Loss: 0.000..  Test Loss: 5.172..  Test Accuracy: 0.748\n",
      "Epoch: 1414/1500..  Training Loss: 0.000..  Test Loss: 5.172..  Test Accuracy: 0.748\n",
      "Epoch: 1415/1500..  Training Loss: 0.000..  Test Loss: 5.172..  Test Accuracy: 0.748\n",
      "Epoch: 1416/1500..  Training Loss: 0.000..  Test Loss: 5.172..  Test Accuracy: 0.748\n",
      "Epoch: 1417/1500..  Training Loss: 0.000..  Test Loss: 5.171..  Test Accuracy: 0.748\n",
      "Epoch: 1418/1500..  Training Loss: 0.000..  Test Loss: 5.172..  Test Accuracy: 0.748\n",
      "Epoch: 1419/1500..  Training Loss: 0.000..  Test Loss: 5.172..  Test Accuracy: 0.748\n",
      "Epoch: 1420/1500..  Training Loss: 0.000..  Test Loss: 5.172..  Test Accuracy: 0.748\n",
      "Epoch: 1421/1500..  Training Loss: 0.000..  Test Loss: 5.173..  Test Accuracy: 0.748\n",
      "Epoch: 1422/1500..  Training Loss: 0.000..  Test Loss: 5.173..  Test Accuracy: 0.748\n",
      "Epoch: 1423/1500..  Training Loss: 0.000..  Test Loss: 5.173..  Test Accuracy: 0.748\n",
      "Epoch: 1424/1500..  Training Loss: 0.000..  Test Loss: 5.173..  Test Accuracy: 0.748\n",
      "Epoch: 1425/1500..  Training Loss: 0.000..  Test Loss: 5.172..  Test Accuracy: 0.748\n",
      "Epoch: 1426/1500..  Training Loss: 0.000..  Test Loss: 5.173..  Test Accuracy: 0.748\n",
      "Epoch: 1427/1500..  Training Loss: 0.000..  Test Loss: 5.174..  Test Accuracy: 0.748\n",
      "Epoch: 1428/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1429/1500..  Training Loss: 0.000..  Test Loss: 5.174..  Test Accuracy: 0.748\n",
      "Epoch: 1430/1500..  Training Loss: 0.000..  Test Loss: 5.174..  Test Accuracy: 0.748\n",
      "Epoch: 1431/1500..  Training Loss: 0.000..  Test Loss: 5.174..  Test Accuracy: 0.748\n",
      "Epoch: 1432/1500..  Training Loss: 0.000..  Test Loss: 5.174..  Test Accuracy: 0.748\n",
      "Epoch: 1433/1500..  Training Loss: 0.000..  Test Loss: 5.174..  Test Accuracy: 0.748\n",
      "Epoch: 1434/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1435/1500..  Training Loss: 0.000..  Test Loss: 5.174..  Test Accuracy: 0.748\n",
      "Epoch: 1436/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1437/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1438/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1439/1500..  Training Loss: 0.000..  Test Loss: 5.174..  Test Accuracy: 0.748\n",
      "Epoch: 1440/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1441/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1442/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1443/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1444/1500..  Training Loss: 0.000..  Test Loss: 5.176..  Test Accuracy: 0.748\n",
      "Epoch: 1445/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1446/1500..  Training Loss: 0.000..  Test Loss: 5.176..  Test Accuracy: 0.748\n",
      "Epoch: 1447/1500..  Training Loss: 0.000..  Test Loss: 5.176..  Test Accuracy: 0.748\n",
      "Epoch: 1448/1500..  Training Loss: 0.000..  Test Loss: 5.176..  Test Accuracy: 0.748\n",
      "Epoch: 1449/1500..  Training Loss: 0.000..  Test Loss: 5.176..  Test Accuracy: 0.748\n",
      "Epoch: 1450/1500..  Training Loss: 0.000..  Test Loss: 5.175..  Test Accuracy: 0.748\n",
      "Epoch: 1451/1500..  Training Loss: 0.000..  Test Loss: 5.176..  Test Accuracy: 0.748\n",
      "Epoch: 1452/1500..  Training Loss: 0.000..  Test Loss: 5.177..  Test Accuracy: 0.748\n",
      "Epoch: 1453/1500..  Training Loss: 0.000..  Test Loss: 5.177..  Test Accuracy: 0.748\n",
      "Epoch: 1454/1500..  Training Loss: 0.000..  Test Loss: 5.177..  Test Accuracy: 0.748\n",
      "Epoch: 1455/1500..  Training Loss: 0.000..  Test Loss: 5.178..  Test Accuracy: 0.748\n",
      "Epoch: 1456/1500..  Training Loss: 0.000..  Test Loss: 5.178..  Test Accuracy: 0.748\n",
      "Epoch: 1457/1500..  Training Loss: 0.000..  Test Loss: 5.178..  Test Accuracy: 0.748\n",
      "Epoch: 1458/1500..  Training Loss: 0.000..  Test Loss: 5.178..  Test Accuracy: 0.748\n",
      "Epoch: 1459/1500..  Training Loss: 0.000..  Test Loss: 5.179..  Test Accuracy: 0.748\n",
      "Epoch: 1460/1500..  Training Loss: 0.000..  Test Loss: 5.178..  Test Accuracy: 0.748\n",
      "Epoch: 1461/1500..  Training Loss: 0.000..  Test Loss: 5.178..  Test Accuracy: 0.748\n",
      "Epoch: 1462/1500..  Training Loss: 0.000..  Test Loss: 5.177..  Test Accuracy: 0.748\n",
      "Epoch: 1463/1500..  Training Loss: 0.000..  Test Loss: 5.178..  Test Accuracy: 0.748\n",
      "Epoch: 1464/1500..  Training Loss: 0.000..  Test Loss: 5.178..  Test Accuracy: 0.748\n",
      "Epoch: 1465/1500..  Training Loss: 0.000..  Test Loss: 5.178..  Test Accuracy: 0.748\n",
      "Epoch: 1466/1500..  Training Loss: 0.000..  Test Loss: 5.179..  Test Accuracy: 0.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1467/1500..  Training Loss: 0.000..  Test Loss: 5.179..  Test Accuracy: 0.748\n",
      "Epoch: 1468/1500..  Training Loss: 0.000..  Test Loss: 5.179..  Test Accuracy: 0.748\n",
      "Epoch: 1469/1500..  Training Loss: 0.000..  Test Loss: 5.179..  Test Accuracy: 0.748\n",
      "Epoch: 1470/1500..  Training Loss: 0.000..  Test Loss: 5.179..  Test Accuracy: 0.748\n",
      "Epoch: 1471/1500..  Training Loss: 0.000..  Test Loss: 5.180..  Test Accuracy: 0.748\n",
      "Epoch: 1472/1500..  Training Loss: 0.000..  Test Loss: 5.180..  Test Accuracy: 0.748\n",
      "Epoch: 1473/1500..  Training Loss: 0.000..  Test Loss: 5.179..  Test Accuracy: 0.748\n",
      "Epoch: 1474/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1475/1500..  Training Loss: 0.000..  Test Loss: 5.180..  Test Accuracy: 0.748\n",
      "Epoch: 1476/1500..  Training Loss: 0.000..  Test Loss: 5.180..  Test Accuracy: 0.748\n",
      "Epoch: 1477/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1478/1500..  Training Loss: 0.000..  Test Loss: 5.180..  Test Accuracy: 0.748\n",
      "Epoch: 1479/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1480/1500..  Training Loss: 0.000..  Test Loss: 5.180..  Test Accuracy: 0.748\n",
      "Epoch: 1481/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1482/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1483/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1484/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1485/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1486/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1487/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1488/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1489/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1490/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1491/1500..  Training Loss: 0.000..  Test Loss: 5.181..  Test Accuracy: 0.748\n",
      "Epoch: 1492/1500..  Training Loss: 0.000..  Test Loss: 5.183..  Test Accuracy: 0.748\n",
      "Epoch: 1493/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1494/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1495/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1496/1500..  Training Loss: 0.000..  Test Loss: 5.183..  Test Accuracy: 0.748\n",
      "Epoch: 1497/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1498/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1499/1500..  Training Loss: 0.000..  Test Loss: 5.182..  Test Accuracy: 0.748\n",
      "Epoch: 1500/1500..  Training Loss: 0.000..  Test Loss: 5.183..  Test Accuracy: 0.748\n"
     ]
    }
   ],
   "source": [
    "epochs = 1500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "\n",
    "    for images,labels in train_loader:\n",
    "\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = basecnn(train)\n",
    "        loss = criterion(output,labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad(): #Turning off gradients to speed up\n",
    "            basecnn.eval()\n",
    "            for images,labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(-1,1,28,28))\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "                log_ps = basecnn(test)\n",
    "                test_loss += criterion(log_ps,labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim = 1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "        basecnn.train()        \n",
    "        train_losses_basecnn.append(running_loss/len(train_loader))\n",
    "        test_losses_basecnn.append(test_loss/len(test_loader))\n",
    "        accuracy_graph_basecnn.append(accuracy/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "PeJpfcVXL4xd",
    "outputId": "7fa8c205-2625-495d-957e-6922fc47fbab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x202c141a280>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses_basecnn, label='Training loss')\n",
    "plt.plot(test_losses_basecnn, label='Validation loss')\n",
    "plt.plot(accuracy_graph_basecnn, label='Accuracy')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgU6-GfkDuBb"
   },
   "source": [
    "# Gaussian Mask Input CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3pAPNJLzc0GU"
   },
   "outputs": [],
   "source": [
    "gcnn=CNN()\n",
    "gcnn=gcnn.double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gcnn.parameters(), lr=0.0001)\n",
    "\n",
    "train_losses_gcnn, test_losses_gcnn, accuracy_graph_gcnn = [], [], []\n",
    "\n",
    "sample_images_gcnn=[]\n",
    "sample_masked_gcnn=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZ_AFkA-PNWL",
    "outputId": "6a25cd76-4a51-483f-8e3b-963594f27a3c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4000..  Training Loss: 2.317..  Test Loss: 2.278..  Test Accuracy: 0.112\n",
      "Epoch: 2/4000..  Training Loss: 2.268..  Test Loss: 2.260..  Test Accuracy: 0.195\n",
      "Epoch: 3/4000..  Training Loss: 2.245..  Test Loss: 2.243..  Test Accuracy: 0.268\n",
      "Epoch: 4/4000..  Training Loss: 2.222..  Test Loss: 2.224..  Test Accuracy: 0.312\n",
      "Epoch: 5/4000..  Training Loss: 2.200..  Test Loss: 2.202..  Test Accuracy: 0.340\n",
      "Epoch: 6/4000..  Training Loss: 2.173..  Test Loss: 2.178..  Test Accuracy: 0.382\n",
      "Epoch: 7/4000..  Training Loss: 2.147..  Test Loss: 2.149..  Test Accuracy: 0.432\n",
      "Epoch: 8/4000..  Training Loss: 2.118..  Test Loss: 2.114..  Test Accuracy: 0.459\n",
      "Epoch: 9/4000..  Training Loss: 2.075..  Test Loss: 2.082..  Test Accuracy: 0.459\n",
      "Epoch: 10/4000..  Training Loss: 2.039..  Test Loss: 2.043..  Test Accuracy: 0.482\n",
      "Epoch: 11/4000..  Training Loss: 1.994..  Test Loss: 1.999..  Test Accuracy: 0.496\n",
      "Epoch: 12/4000..  Training Loss: 1.947..  Test Loss: 1.956..  Test Accuracy: 0.514\n",
      "Epoch: 13/4000..  Training Loss: 1.894..  Test Loss: 1.912..  Test Accuracy: 0.498\n",
      "Epoch: 14/4000..  Training Loss: 1.838..  Test Loss: 1.860..  Test Accuracy: 0.540\n",
      "Epoch: 15/4000..  Training Loss: 1.779..  Test Loss: 1.814..  Test Accuracy: 0.533\n",
      "Epoch: 16/4000..  Training Loss: 1.734..  Test Loss: 1.761..  Test Accuracy: 0.566\n",
      "Epoch: 17/4000..  Training Loss: 1.651..  Test Loss: 1.711..  Test Accuracy: 0.560\n",
      "Epoch: 18/4000..  Training Loss: 1.600..  Test Loss: 1.660..  Test Accuracy: 0.579\n",
      "Epoch: 19/4000..  Training Loss: 1.553..  Test Loss: 1.609..  Test Accuracy: 0.596\n",
      "Epoch: 20/4000..  Training Loss: 1.475..  Test Loss: 1.567..  Test Accuracy: 0.576\n",
      "Epoch: 21/4000..  Training Loss: 1.418..  Test Loss: 1.522..  Test Accuracy: 0.582\n",
      "Epoch: 22/4000..  Training Loss: 1.365..  Test Loss: 1.475..  Test Accuracy: 0.614\n",
      "Epoch: 23/4000..  Training Loss: 1.319..  Test Loss: 1.442..  Test Accuracy: 0.597\n",
      "Epoch: 24/4000..  Training Loss: 1.273..  Test Loss: 1.399..  Test Accuracy: 0.604\n",
      "Epoch: 25/4000..  Training Loss: 1.205..  Test Loss: 1.360..  Test Accuracy: 0.619\n",
      "Epoch: 26/4000..  Training Loss: 1.162..  Test Loss: 1.331..  Test Accuracy: 0.610\n",
      "Epoch: 27/4000..  Training Loss: 1.137..  Test Loss: 1.317..  Test Accuracy: 0.608\n",
      "Epoch: 28/4000..  Training Loss: 1.094..  Test Loss: 1.270..  Test Accuracy: 0.624\n",
      "Epoch: 29/4000..  Training Loss: 1.058..  Test Loss: 1.255..  Test Accuracy: 0.622\n",
      "Epoch: 30/4000..  Training Loss: 1.021..  Test Loss: 1.242..  Test Accuracy: 0.612\n",
      "Epoch: 31/4000..  Training Loss: 1.004..  Test Loss: 1.216..  Test Accuracy: 0.617\n",
      "Epoch: 32/4000..  Training Loss: 0.957..  Test Loss: 1.186..  Test Accuracy: 0.629\n",
      "Epoch: 33/4000..  Training Loss: 0.931..  Test Loss: 1.176..  Test Accuracy: 0.621\n",
      "Epoch: 34/4000..  Training Loss: 0.884..  Test Loss: 1.156..  Test Accuracy: 0.627\n",
      "Epoch: 35/4000..  Training Loss: 0.881..  Test Loss: 1.151..  Test Accuracy: 0.619\n",
      "Epoch: 36/4000..  Training Loss: 0.855..  Test Loss: 1.141..  Test Accuracy: 0.626\n",
      "Epoch: 37/4000..  Training Loss: 0.827..  Test Loss: 1.130..  Test Accuracy: 0.623\n",
      "Epoch: 38/4000..  Training Loss: 0.802..  Test Loss: 1.117..  Test Accuracy: 0.626\n",
      "Epoch: 39/4000..  Training Loss: 0.790..  Test Loss: 1.101..  Test Accuracy: 0.629\n",
      "Epoch: 40/4000..  Training Loss: 0.773..  Test Loss: 1.095..  Test Accuracy: 0.628\n",
      "Epoch: 41/4000..  Training Loss: 0.746..  Test Loss: 1.095..  Test Accuracy: 0.626\n",
      "Epoch: 42/4000..  Training Loss: 0.736..  Test Loss: 1.063..  Test Accuracy: 0.639\n",
      "Epoch: 43/4000..  Training Loss: 0.707..  Test Loss: 1.065..  Test Accuracy: 0.637\n",
      "Epoch: 44/4000..  Training Loss: 0.696..  Test Loss: 1.056..  Test Accuracy: 0.641\n",
      "Epoch: 45/4000..  Training Loss: 0.714..  Test Loss: 1.055..  Test Accuracy: 0.638\n",
      "Epoch: 46/4000..  Training Loss: 0.683..  Test Loss: 1.037..  Test Accuracy: 0.649\n",
      "Epoch: 47/4000..  Training Loss: 0.665..  Test Loss: 1.042..  Test Accuracy: 0.644\n",
      "Epoch: 48/4000..  Training Loss: 0.658..  Test Loss: 1.036..  Test Accuracy: 0.642\n",
      "Epoch: 49/4000..  Training Loss: 0.640..  Test Loss: 1.041..  Test Accuracy: 0.633\n",
      "Epoch: 50/4000..  Training Loss: 0.636..  Test Loss: 1.011..  Test Accuracy: 0.652\n",
      "Epoch: 51/4000..  Training Loss: 0.613..  Test Loss: 1.018..  Test Accuracy: 0.652\n",
      "Epoch: 52/4000..  Training Loss: 0.608..  Test Loss: 0.982..  Test Accuracy: 0.666\n",
      "Epoch: 53/4000..  Training Loss: 0.607..  Test Loss: 0.986..  Test Accuracy: 0.660\n",
      "Epoch: 54/4000..  Training Loss: 0.593..  Test Loss: 1.011..  Test Accuracy: 0.650\n",
      "Epoch: 55/4000..  Training Loss: 0.576..  Test Loss: 0.986..  Test Accuracy: 0.657\n",
      "Epoch: 56/4000..  Training Loss: 0.561..  Test Loss: 1.009..  Test Accuracy: 0.644\n",
      "Epoch: 57/4000..  Training Loss: 0.565..  Test Loss: 0.971..  Test Accuracy: 0.662\n",
      "Epoch: 58/4000..  Training Loss: 0.553..  Test Loss: 0.962..  Test Accuracy: 0.668\n",
      "Epoch: 59/4000..  Training Loss: 0.549..  Test Loss: 0.978..  Test Accuracy: 0.658\n",
      "Epoch: 60/4000..  Training Loss: 0.538..  Test Loss: 0.962..  Test Accuracy: 0.665\n",
      "Epoch: 61/4000..  Training Loss: 0.537..  Test Loss: 0.952..  Test Accuracy: 0.667\n",
      "Epoch: 62/4000..  Training Loss: 0.539..  Test Loss: 0.943..  Test Accuracy: 0.677\n",
      "Epoch: 63/4000..  Training Loss: 0.518..  Test Loss: 0.936..  Test Accuracy: 0.679\n",
      "Epoch: 64/4000..  Training Loss: 0.513..  Test Loss: 0.953..  Test Accuracy: 0.667\n",
      "Epoch: 65/4000..  Training Loss: 0.493..  Test Loss: 0.946..  Test Accuracy: 0.673\n",
      "Epoch: 66/4000..  Training Loss: 0.494..  Test Loss: 0.982..  Test Accuracy: 0.655\n",
      "Epoch: 67/4000..  Training Loss: 0.480..  Test Loss: 0.935..  Test Accuracy: 0.673\n",
      "Epoch: 68/4000..  Training Loss: 0.465..  Test Loss: 0.942..  Test Accuracy: 0.673\n",
      "Epoch: 69/4000..  Training Loss: 0.448..  Test Loss: 0.922..  Test Accuracy: 0.678\n",
      "Epoch: 70/4000..  Training Loss: 0.468..  Test Loss: 0.936..  Test Accuracy: 0.671\n",
      "Epoch: 71/4000..  Training Loss: 0.446..  Test Loss: 0.935..  Test Accuracy: 0.672\n",
      "Epoch: 72/4000..  Training Loss: 0.438..  Test Loss: 0.934..  Test Accuracy: 0.672\n",
      "Epoch: 73/4000..  Training Loss: 0.448..  Test Loss: 0.938..  Test Accuracy: 0.671\n",
      "Epoch: 74/4000..  Training Loss: 0.414..  Test Loss: 0.910..  Test Accuracy: 0.681\n",
      "Epoch: 75/4000..  Training Loss: 0.431..  Test Loss: 0.934..  Test Accuracy: 0.673\n",
      "Epoch: 76/4000..  Training Loss: 0.431..  Test Loss: 0.924..  Test Accuracy: 0.676\n",
      "Epoch: 77/4000..  Training Loss: 0.411..  Test Loss: 0.922..  Test Accuracy: 0.681\n",
      "Epoch: 78/4000..  Training Loss: 0.412..  Test Loss: 0.907..  Test Accuracy: 0.681\n",
      "Epoch: 79/4000..  Training Loss: 0.422..  Test Loss: 0.877..  Test Accuracy: 0.695\n",
      "Epoch: 80/4000..  Training Loss: 0.406..  Test Loss: 0.917..  Test Accuracy: 0.681\n",
      "Epoch: 81/4000..  Training Loss: 0.402..  Test Loss: 0.893..  Test Accuracy: 0.691\n",
      "Epoch: 82/4000..  Training Loss: 0.410..  Test Loss: 0.881..  Test Accuracy: 0.694\n",
      "Epoch: 83/4000..  Training Loss: 0.401..  Test Loss: 0.942..  Test Accuracy: 0.667\n",
      "Epoch: 84/4000..  Training Loss: 0.379..  Test Loss: 0.906..  Test Accuracy: 0.684\n",
      "Epoch: 85/4000..  Training Loss: 0.393..  Test Loss: 0.893..  Test Accuracy: 0.692\n",
      "Epoch: 86/4000..  Training Loss: 0.376..  Test Loss: 0.907..  Test Accuracy: 0.686\n",
      "Epoch: 87/4000..  Training Loss: 0.373..  Test Loss: 0.886..  Test Accuracy: 0.694\n",
      "Epoch: 88/4000..  Training Loss: 0.369..  Test Loss: 0.901..  Test Accuracy: 0.686\n",
      "Epoch: 89/4000..  Training Loss: 0.373..  Test Loss: 0.906..  Test Accuracy: 0.685\n",
      "Epoch: 90/4000..  Training Loss: 0.360..  Test Loss: 0.894..  Test Accuracy: 0.689\n",
      "Epoch: 91/4000..  Training Loss: 0.345..  Test Loss: 0.880..  Test Accuracy: 0.700\n",
      "Epoch: 92/4000..  Training Loss: 0.348..  Test Loss: 0.882..  Test Accuracy: 0.697\n",
      "Epoch: 93/4000..  Training Loss: 0.359..  Test Loss: 0.856..  Test Accuracy: 0.713\n",
      "Epoch: 94/4000..  Training Loss: 0.329..  Test Loss: 0.868..  Test Accuracy: 0.706\n",
      "Epoch: 95/4000..  Training Loss: 0.330..  Test Loss: 0.871..  Test Accuracy: 0.704\n",
      "Epoch: 96/4000..  Training Loss: 0.353..  Test Loss: 0.885..  Test Accuracy: 0.699\n",
      "Epoch: 97/4000..  Training Loss: 0.340..  Test Loss: 0.880..  Test Accuracy: 0.698\n",
      "Epoch: 98/4000..  Training Loss: 0.308..  Test Loss: 0.882..  Test Accuracy: 0.698\n",
      "Epoch: 99/4000..  Training Loss: 0.308..  Test Loss: 0.886..  Test Accuracy: 0.694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/4000..  Training Loss: 0.339..  Test Loss: 0.857..  Test Accuracy: 0.709\n",
      "Epoch: 101/4000..  Training Loss: 0.327..  Test Loss: 0.848..  Test Accuracy: 0.715\n",
      "Epoch: 102/4000..  Training Loss: 0.312..  Test Loss: 0.865..  Test Accuracy: 0.707\n",
      "Epoch: 103/4000..  Training Loss: 0.302..  Test Loss: 0.846..  Test Accuracy: 0.716\n",
      "Epoch: 104/4000..  Training Loss: 0.294..  Test Loss: 0.836..  Test Accuracy: 0.718\n",
      "Epoch: 105/4000..  Training Loss: 0.300..  Test Loss: 0.868..  Test Accuracy: 0.711\n",
      "Epoch: 106/4000..  Training Loss: 0.286..  Test Loss: 0.864..  Test Accuracy: 0.708\n",
      "Epoch: 107/4000..  Training Loss: 0.293..  Test Loss: 0.870..  Test Accuracy: 0.708\n",
      "Epoch: 108/4000..  Training Loss: 0.289..  Test Loss: 0.876..  Test Accuracy: 0.710\n",
      "Epoch: 109/4000..  Training Loss: 0.264..  Test Loss: 0.843..  Test Accuracy: 0.720\n",
      "Epoch: 110/4000..  Training Loss: 0.255..  Test Loss: 0.848..  Test Accuracy: 0.719\n",
      "Epoch: 111/4000..  Training Loss: 0.289..  Test Loss: 0.886..  Test Accuracy: 0.701\n",
      "Epoch: 112/4000..  Training Loss: 0.298..  Test Loss: 0.851..  Test Accuracy: 0.721\n",
      "Epoch: 113/4000..  Training Loss: 0.285..  Test Loss: 0.845..  Test Accuracy: 0.723\n",
      "Epoch: 114/4000..  Training Loss: 0.268..  Test Loss: 0.867..  Test Accuracy: 0.714\n",
      "Epoch: 115/4000..  Training Loss: 0.277..  Test Loss: 0.879..  Test Accuracy: 0.706\n",
      "Epoch: 116/4000..  Training Loss: 0.243..  Test Loss: 0.869..  Test Accuracy: 0.712\n",
      "Epoch: 117/4000..  Training Loss: 0.267..  Test Loss: 0.880..  Test Accuracy: 0.705\n",
      "Epoch: 118/4000..  Training Loss: 0.258..  Test Loss: 0.835..  Test Accuracy: 0.727\n",
      "Epoch: 119/4000..  Training Loss: 0.261..  Test Loss: 0.856..  Test Accuracy: 0.719\n",
      "Epoch: 120/4000..  Training Loss: 0.244..  Test Loss: 0.846..  Test Accuracy: 0.725\n",
      "Epoch: 121/4000..  Training Loss: 0.246..  Test Loss: 0.825..  Test Accuracy: 0.731\n",
      "Epoch: 122/4000..  Training Loss: 0.252..  Test Loss: 0.853..  Test Accuracy: 0.721\n",
      "Epoch: 123/4000..  Training Loss: 0.225..  Test Loss: 0.850..  Test Accuracy: 0.723\n",
      "Epoch: 124/4000..  Training Loss: 0.245..  Test Loss: 0.839..  Test Accuracy: 0.730\n",
      "Epoch: 125/4000..  Training Loss: 0.254..  Test Loss: 0.867..  Test Accuracy: 0.721\n",
      "Epoch: 126/4000..  Training Loss: 0.253..  Test Loss: 0.846..  Test Accuracy: 0.725\n",
      "Epoch: 127/4000..  Training Loss: 0.230..  Test Loss: 0.830..  Test Accuracy: 0.731\n",
      "Epoch: 128/4000..  Training Loss: 0.234..  Test Loss: 0.854..  Test Accuracy: 0.725\n",
      "Epoch: 129/4000..  Training Loss: 0.221..  Test Loss: 0.851..  Test Accuracy: 0.730\n",
      "Epoch: 130/4000..  Training Loss: 0.230..  Test Loss: 0.848..  Test Accuracy: 0.725\n",
      "Epoch: 131/4000..  Training Loss: 0.208..  Test Loss: 0.812..  Test Accuracy: 0.741\n",
      "Epoch: 132/4000..  Training Loss: 0.238..  Test Loss: 0.876..  Test Accuracy: 0.719\n",
      "Epoch: 133/4000..  Training Loss: 0.221..  Test Loss: 0.874..  Test Accuracy: 0.721\n",
      "Epoch: 134/4000..  Training Loss: 0.224..  Test Loss: 0.814..  Test Accuracy: 0.741\n",
      "Epoch: 135/4000..  Training Loss: 0.223..  Test Loss: 0.832..  Test Accuracy: 0.733\n",
      "Epoch: 136/4000..  Training Loss: 0.214..  Test Loss: 0.798..  Test Accuracy: 0.747\n",
      "Epoch: 137/4000..  Training Loss: 0.236..  Test Loss: 0.812..  Test Accuracy: 0.743\n",
      "Epoch: 138/4000..  Training Loss: 0.207..  Test Loss: 0.866..  Test Accuracy: 0.724\n",
      "Epoch: 139/4000..  Training Loss: 0.228..  Test Loss: 0.832..  Test Accuracy: 0.736\n",
      "Epoch: 140/4000..  Training Loss: 0.206..  Test Loss: 0.850..  Test Accuracy: 0.731\n",
      "Epoch: 141/4000..  Training Loss: 0.227..  Test Loss: 0.834..  Test Accuracy: 0.739\n",
      "Epoch: 142/4000..  Training Loss: 0.189..  Test Loss: 0.833..  Test Accuracy: 0.740\n",
      "Epoch: 143/4000..  Training Loss: 0.209..  Test Loss: 0.846..  Test Accuracy: 0.735\n",
      "Epoch: 144/4000..  Training Loss: 0.204..  Test Loss: 0.825..  Test Accuracy: 0.738\n",
      "Epoch: 145/4000..  Training Loss: 0.218..  Test Loss: 0.834..  Test Accuracy: 0.738\n",
      "Epoch: 146/4000..  Training Loss: 0.215..  Test Loss: 0.818..  Test Accuracy: 0.742\n",
      "Epoch: 147/4000..  Training Loss: 0.191..  Test Loss: 0.839..  Test Accuracy: 0.737\n",
      "Epoch: 148/4000..  Training Loss: 0.199..  Test Loss: 0.850..  Test Accuracy: 0.735\n",
      "Epoch: 149/4000..  Training Loss: 0.200..  Test Loss: 0.840..  Test Accuracy: 0.737\n",
      "Epoch: 150/4000..  Training Loss: 0.200..  Test Loss: 0.836..  Test Accuracy: 0.739\n",
      "Epoch: 151/4000..  Training Loss: 0.173..  Test Loss: 0.852..  Test Accuracy: 0.739\n",
      "Epoch: 152/4000..  Training Loss: 0.189..  Test Loss: 0.841..  Test Accuracy: 0.742\n",
      "Epoch: 153/4000..  Training Loss: 0.176..  Test Loss: 0.840..  Test Accuracy: 0.745\n",
      "Epoch: 154/4000..  Training Loss: 0.199..  Test Loss: 0.830..  Test Accuracy: 0.741\n",
      "Epoch: 155/4000..  Training Loss: 0.190..  Test Loss: 0.843..  Test Accuracy: 0.742\n",
      "Epoch: 156/4000..  Training Loss: 0.186..  Test Loss: 0.862..  Test Accuracy: 0.735\n",
      "Epoch: 157/4000..  Training Loss: 0.188..  Test Loss: 0.812..  Test Accuracy: 0.751\n",
      "Epoch: 158/4000..  Training Loss: 0.176..  Test Loss: 0.860..  Test Accuracy: 0.738\n",
      "Epoch: 159/4000..  Training Loss: 0.190..  Test Loss: 0.835..  Test Accuracy: 0.741\n",
      "Epoch: 160/4000..  Training Loss: 0.187..  Test Loss: 0.861..  Test Accuracy: 0.735\n",
      "Epoch: 161/4000..  Training Loss: 0.185..  Test Loss: 0.865..  Test Accuracy: 0.739\n",
      "Epoch: 162/4000..  Training Loss: 0.192..  Test Loss: 0.835..  Test Accuracy: 0.744\n",
      "Epoch: 163/4000..  Training Loss: 0.166..  Test Loss: 0.806..  Test Accuracy: 0.757\n",
      "Epoch: 164/4000..  Training Loss: 0.177..  Test Loss: 0.801..  Test Accuracy: 0.757\n",
      "Epoch: 165/4000..  Training Loss: 0.163..  Test Loss: 0.825..  Test Accuracy: 0.751\n",
      "Epoch: 166/4000..  Training Loss: 0.183..  Test Loss: 0.850..  Test Accuracy: 0.743\n",
      "Epoch: 167/4000..  Training Loss: 0.180..  Test Loss: 0.843..  Test Accuracy: 0.745\n",
      "Epoch: 168/4000..  Training Loss: 0.180..  Test Loss: 0.859..  Test Accuracy: 0.740\n",
      "Epoch: 169/4000..  Training Loss: 0.190..  Test Loss: 0.835..  Test Accuracy: 0.750\n",
      "Epoch: 170/4000..  Training Loss: 0.151..  Test Loss: 0.828..  Test Accuracy: 0.750\n",
      "Epoch: 171/4000..  Training Loss: 0.157..  Test Loss: 0.838..  Test Accuracy: 0.750\n",
      "Epoch: 172/4000..  Training Loss: 0.162..  Test Loss: 0.829..  Test Accuracy: 0.753\n",
      "Epoch: 173/4000..  Training Loss: 0.155..  Test Loss: 0.814..  Test Accuracy: 0.757\n",
      "Epoch: 174/4000..  Training Loss: 0.147..  Test Loss: 0.825..  Test Accuracy: 0.753\n",
      "Epoch: 175/4000..  Training Loss: 0.173..  Test Loss: 0.849..  Test Accuracy: 0.744\n",
      "Epoch: 176/4000..  Training Loss: 0.153..  Test Loss: 0.818..  Test Accuracy: 0.755\n",
      "Epoch: 177/4000..  Training Loss: 0.138..  Test Loss: 0.846..  Test Accuracy: 0.749\n",
      "Epoch: 178/4000..  Training Loss: 0.159..  Test Loss: 0.861..  Test Accuracy: 0.747\n",
      "Epoch: 179/4000..  Training Loss: 0.161..  Test Loss: 0.877..  Test Accuracy: 0.744\n",
      "Epoch: 180/4000..  Training Loss: 0.152..  Test Loss: 0.851..  Test Accuracy: 0.749\n",
      "Epoch: 181/4000..  Training Loss: 0.168..  Test Loss: 0.838..  Test Accuracy: 0.752\n",
      "Epoch: 182/4000..  Training Loss: 0.153..  Test Loss: 0.859..  Test Accuracy: 0.746\n",
      "Epoch: 183/4000..  Training Loss: 0.144..  Test Loss: 0.875..  Test Accuracy: 0.744\n",
      "Epoch: 184/4000..  Training Loss: 0.134..  Test Loss: 0.826..  Test Accuracy: 0.756\n",
      "Epoch: 185/4000..  Training Loss: 0.124..  Test Loss: 0.825..  Test Accuracy: 0.754\n",
      "Epoch: 186/4000..  Training Loss: 0.166..  Test Loss: 0.872..  Test Accuracy: 0.745\n",
      "Epoch: 187/4000..  Training Loss: 0.151..  Test Loss: 0.823..  Test Accuracy: 0.759\n",
      "Epoch: 188/4000..  Training Loss: 0.179..  Test Loss: 0.839..  Test Accuracy: 0.756\n",
      "Epoch: 189/4000..  Training Loss: 0.128..  Test Loss: 0.860..  Test Accuracy: 0.750\n",
      "Epoch: 190/4000..  Training Loss: 0.131..  Test Loss: 0.827..  Test Accuracy: 0.762\n",
      "Epoch: 191/4000..  Training Loss: 0.142..  Test Loss: 0.844..  Test Accuracy: 0.755\n",
      "Epoch: 192/4000..  Training Loss: 0.157..  Test Loss: 0.838..  Test Accuracy: 0.761\n",
      "Epoch: 193/4000..  Training Loss: 0.155..  Test Loss: 0.848..  Test Accuracy: 0.755\n",
      "Epoch: 194/4000..  Training Loss: 0.156..  Test Loss: 0.830..  Test Accuracy: 0.762\n",
      "Epoch: 195/4000..  Training Loss: 0.152..  Test Loss: 0.837..  Test Accuracy: 0.759\n",
      "Epoch: 196/4000..  Training Loss: 0.157..  Test Loss: 0.896..  Test Accuracy: 0.742\n",
      "Epoch: 197/4000..  Training Loss: 0.127..  Test Loss: 0.845..  Test Accuracy: 0.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 198/4000..  Training Loss: 0.122..  Test Loss: 0.819..  Test Accuracy: 0.764\n",
      "Epoch: 199/4000..  Training Loss: 0.143..  Test Loss: 0.794..  Test Accuracy: 0.771\n",
      "Epoch: 200/4000..  Training Loss: 0.161..  Test Loss: 0.803..  Test Accuracy: 0.772\n",
      "Epoch: 201/4000..  Training Loss: 0.141..  Test Loss: 0.822..  Test Accuracy: 0.758\n",
      "Epoch: 202/4000..  Training Loss: 0.142..  Test Loss: 0.849..  Test Accuracy: 0.756\n",
      "Epoch: 203/4000..  Training Loss: 0.143..  Test Loss: 0.853..  Test Accuracy: 0.759\n",
      "Epoch: 204/4000..  Training Loss: 0.144..  Test Loss: 0.852..  Test Accuracy: 0.755\n",
      "Epoch: 205/4000..  Training Loss: 0.107..  Test Loss: 0.813..  Test Accuracy: 0.766\n",
      "Epoch: 206/4000..  Training Loss: 0.129..  Test Loss: 0.852..  Test Accuracy: 0.762\n",
      "Epoch: 207/4000..  Training Loss: 0.142..  Test Loss: 0.836..  Test Accuracy: 0.767\n",
      "Epoch: 208/4000..  Training Loss: 0.123..  Test Loss: 0.813..  Test Accuracy: 0.766\n",
      "Epoch: 209/4000..  Training Loss: 0.125..  Test Loss: 0.826..  Test Accuracy: 0.765\n",
      "Epoch: 210/4000..  Training Loss: 0.142..  Test Loss: 0.853..  Test Accuracy: 0.759\n",
      "Epoch: 211/4000..  Training Loss: 0.120..  Test Loss: 0.869..  Test Accuracy: 0.753\n",
      "Epoch: 212/4000..  Training Loss: 0.140..  Test Loss: 0.837..  Test Accuracy: 0.764\n",
      "Epoch: 213/4000..  Training Loss: 0.112..  Test Loss: 0.840..  Test Accuracy: 0.763\n",
      "Epoch: 214/4000..  Training Loss: 0.122..  Test Loss: 0.840..  Test Accuracy: 0.760\n",
      "Epoch: 215/4000..  Training Loss: 0.120..  Test Loss: 0.829..  Test Accuracy: 0.765\n",
      "Epoch: 216/4000..  Training Loss: 0.131..  Test Loss: 0.829..  Test Accuracy: 0.766\n",
      "Epoch: 217/4000..  Training Loss: 0.134..  Test Loss: 0.832..  Test Accuracy: 0.765\n",
      "Epoch: 218/4000..  Training Loss: 0.128..  Test Loss: 0.847..  Test Accuracy: 0.762\n",
      "Epoch: 219/4000..  Training Loss: 0.121..  Test Loss: 0.818..  Test Accuracy: 0.771\n",
      "Epoch: 220/4000..  Training Loss: 0.128..  Test Loss: 0.811..  Test Accuracy: 0.767\n",
      "Epoch: 221/4000..  Training Loss: 0.115..  Test Loss: 0.857..  Test Accuracy: 0.764\n",
      "Epoch: 222/4000..  Training Loss: 0.134..  Test Loss: 0.893..  Test Accuracy: 0.752\n",
      "Epoch: 223/4000..  Training Loss: 0.125..  Test Loss: 0.881..  Test Accuracy: 0.753\n",
      "Epoch: 224/4000..  Training Loss: 0.116..  Test Loss: 0.867..  Test Accuracy: 0.760\n",
      "Epoch: 225/4000..  Training Loss: 0.114..  Test Loss: 0.864..  Test Accuracy: 0.766\n",
      "Epoch: 226/4000..  Training Loss: 0.127..  Test Loss: 0.856..  Test Accuracy: 0.761\n",
      "Epoch: 227/4000..  Training Loss: 0.095..  Test Loss: 0.890..  Test Accuracy: 0.754\n",
      "Epoch: 228/4000..  Training Loss: 0.105..  Test Loss: 0.806..  Test Accuracy: 0.776\n",
      "Epoch: 229/4000..  Training Loss: 0.119..  Test Loss: 0.877..  Test Accuracy: 0.762\n",
      "Epoch: 230/4000..  Training Loss: 0.111..  Test Loss: 0.817..  Test Accuracy: 0.771\n",
      "Epoch: 231/4000..  Training Loss: 0.118..  Test Loss: 0.863..  Test Accuracy: 0.762\n",
      "Epoch: 232/4000..  Training Loss: 0.102..  Test Loss: 0.872..  Test Accuracy: 0.757\n",
      "Epoch: 233/4000..  Training Loss: 0.114..  Test Loss: 0.851..  Test Accuracy: 0.766\n",
      "Epoch: 234/4000..  Training Loss: 0.098..  Test Loss: 0.842..  Test Accuracy: 0.769\n",
      "Epoch: 235/4000..  Training Loss: 0.100..  Test Loss: 0.858..  Test Accuracy: 0.764\n",
      "Epoch: 236/4000..  Training Loss: 0.119..  Test Loss: 0.895..  Test Accuracy: 0.753\n",
      "Epoch: 237/4000..  Training Loss: 0.105..  Test Loss: 0.848..  Test Accuracy: 0.770\n",
      "Epoch: 238/4000..  Training Loss: 0.101..  Test Loss: 0.889..  Test Accuracy: 0.758\n",
      "Epoch: 239/4000..  Training Loss: 0.107..  Test Loss: 0.857..  Test Accuracy: 0.766\n",
      "Epoch: 240/4000..  Training Loss: 0.116..  Test Loss: 0.909..  Test Accuracy: 0.756\n",
      "Epoch: 241/4000..  Training Loss: 0.116..  Test Loss: 0.857..  Test Accuracy: 0.768\n",
      "Epoch: 242/4000..  Training Loss: 0.107..  Test Loss: 0.859..  Test Accuracy: 0.765\n",
      "Epoch: 243/4000..  Training Loss: 0.086..  Test Loss: 0.868..  Test Accuracy: 0.767\n",
      "Epoch: 244/4000..  Training Loss: 0.116..  Test Loss: 0.828..  Test Accuracy: 0.772\n",
      "Epoch: 245/4000..  Training Loss: 0.096..  Test Loss: 0.849..  Test Accuracy: 0.766\n",
      "Epoch: 246/4000..  Training Loss: 0.103..  Test Loss: 0.905..  Test Accuracy: 0.762\n",
      "Epoch: 247/4000..  Training Loss: 0.110..  Test Loss: 0.866..  Test Accuracy: 0.766\n",
      "Epoch: 248/4000..  Training Loss: 0.106..  Test Loss: 0.814..  Test Accuracy: 0.779\n",
      "Epoch: 249/4000..  Training Loss: 0.094..  Test Loss: 0.803..  Test Accuracy: 0.781\n",
      "Epoch: 250/4000..  Training Loss: 0.096..  Test Loss: 0.831..  Test Accuracy: 0.776\n",
      "Epoch: 251/4000..  Training Loss: 0.104..  Test Loss: 0.873..  Test Accuracy: 0.770\n",
      "Epoch: 252/4000..  Training Loss: 0.119..  Test Loss: 0.856..  Test Accuracy: 0.769\n",
      "Epoch: 253/4000..  Training Loss: 0.089..  Test Loss: 0.884..  Test Accuracy: 0.767\n",
      "Epoch: 254/4000..  Training Loss: 0.106..  Test Loss: 0.867..  Test Accuracy: 0.769\n",
      "Epoch: 255/4000..  Training Loss: 0.078..  Test Loss: 0.841..  Test Accuracy: 0.772\n",
      "Epoch: 256/4000..  Training Loss: 0.124..  Test Loss: 0.882..  Test Accuracy: 0.767\n",
      "Epoch: 257/4000..  Training Loss: 0.122..  Test Loss: 0.876..  Test Accuracy: 0.768\n",
      "Epoch: 258/4000..  Training Loss: 0.116..  Test Loss: 0.842..  Test Accuracy: 0.774\n",
      "Epoch: 259/4000..  Training Loss: 0.079..  Test Loss: 0.868..  Test Accuracy: 0.771\n",
      "Epoch: 260/4000..  Training Loss: 0.106..  Test Loss: 0.933..  Test Accuracy: 0.756\n",
      "Epoch: 261/4000..  Training Loss: 0.094..  Test Loss: 0.901..  Test Accuracy: 0.761\n",
      "Epoch: 262/4000..  Training Loss: 0.090..  Test Loss: 0.849..  Test Accuracy: 0.775\n",
      "Epoch: 263/4000..  Training Loss: 0.097..  Test Loss: 0.880..  Test Accuracy: 0.771\n",
      "Epoch: 264/4000..  Training Loss: 0.108..  Test Loss: 0.878..  Test Accuracy: 0.771\n",
      "Epoch: 265/4000..  Training Loss: 0.076..  Test Loss: 0.837..  Test Accuracy: 0.778\n",
      "Epoch: 266/4000..  Training Loss: 0.095..  Test Loss: 0.843..  Test Accuracy: 0.779\n",
      "Epoch: 267/4000..  Training Loss: 0.113..  Test Loss: 0.844..  Test Accuracy: 0.776\n",
      "Epoch: 268/4000..  Training Loss: 0.074..  Test Loss: 0.849..  Test Accuracy: 0.776\n",
      "Epoch: 269/4000..  Training Loss: 0.114..  Test Loss: 0.866..  Test Accuracy: 0.775\n",
      "Epoch: 270/4000..  Training Loss: 0.107..  Test Loss: 0.886..  Test Accuracy: 0.769\n",
      "Epoch: 271/4000..  Training Loss: 0.111..  Test Loss: 0.893..  Test Accuracy: 0.765\n",
      "Epoch: 272/4000..  Training Loss: 0.104..  Test Loss: 0.858..  Test Accuracy: 0.773\n",
      "Epoch: 273/4000..  Training Loss: 0.090..  Test Loss: 0.826..  Test Accuracy: 0.781\n",
      "Epoch: 274/4000..  Training Loss: 0.082..  Test Loss: 0.843..  Test Accuracy: 0.776\n",
      "Epoch: 275/4000..  Training Loss: 0.106..  Test Loss: 0.884..  Test Accuracy: 0.768\n",
      "Epoch: 276/4000..  Training Loss: 0.089..  Test Loss: 0.894..  Test Accuracy: 0.768\n",
      "Epoch: 277/4000..  Training Loss: 0.115..  Test Loss: 0.851..  Test Accuracy: 0.780\n",
      "Epoch: 278/4000..  Training Loss: 0.133..  Test Loss: 0.873..  Test Accuracy: 0.776\n",
      "Epoch: 279/4000..  Training Loss: 0.085..  Test Loss: 0.901..  Test Accuracy: 0.769\n",
      "Epoch: 280/4000..  Training Loss: 0.089..  Test Loss: 0.863..  Test Accuracy: 0.774\n",
      "Epoch: 281/4000..  Training Loss: 0.092..  Test Loss: 0.904..  Test Accuracy: 0.766\n",
      "Epoch: 282/4000..  Training Loss: 0.087..  Test Loss: 0.854..  Test Accuracy: 0.775\n",
      "Epoch: 283/4000..  Training Loss: 0.098..  Test Loss: 0.874..  Test Accuracy: 0.776\n",
      "Epoch: 284/4000..  Training Loss: 0.084..  Test Loss: 0.846..  Test Accuracy: 0.780\n",
      "Epoch: 285/4000..  Training Loss: 0.097..  Test Loss: 0.863..  Test Accuracy: 0.777\n",
      "Epoch: 286/4000..  Training Loss: 0.084..  Test Loss: 0.897..  Test Accuracy: 0.773\n",
      "Epoch: 287/4000..  Training Loss: 0.091..  Test Loss: 0.870..  Test Accuracy: 0.775\n",
      "Epoch: 288/4000..  Training Loss: 0.065..  Test Loss: 0.927..  Test Accuracy: 0.769\n",
      "Epoch: 289/4000..  Training Loss: 0.082..  Test Loss: 0.884..  Test Accuracy: 0.776\n",
      "Epoch: 290/4000..  Training Loss: 0.085..  Test Loss: 0.877..  Test Accuracy: 0.777\n",
      "Epoch: 291/4000..  Training Loss: 0.096..  Test Loss: 0.870..  Test Accuracy: 0.779\n",
      "Epoch: 292/4000..  Training Loss: 0.079..  Test Loss: 0.856..  Test Accuracy: 0.785\n",
      "Epoch: 293/4000..  Training Loss: 0.086..  Test Loss: 0.895..  Test Accuracy: 0.774\n",
      "Epoch: 294/4000..  Training Loss: 0.081..  Test Loss: 0.920..  Test Accuracy: 0.769\n",
      "Epoch: 295/4000..  Training Loss: 0.091..  Test Loss: 0.951..  Test Accuracy: 0.762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 296/4000..  Training Loss: 0.089..  Test Loss: 0.867..  Test Accuracy: 0.780\n",
      "Epoch: 297/4000..  Training Loss: 0.093..  Test Loss: 0.921..  Test Accuracy: 0.766\n",
      "Epoch: 298/4000..  Training Loss: 0.092..  Test Loss: 0.924..  Test Accuracy: 0.767\n",
      "Epoch: 299/4000..  Training Loss: 0.087..  Test Loss: 0.875..  Test Accuracy: 0.780\n",
      "Epoch: 300/4000..  Training Loss: 0.109..  Test Loss: 0.933..  Test Accuracy: 0.773\n",
      "Epoch: 301/4000..  Training Loss: 0.077..  Test Loss: 0.866..  Test Accuracy: 0.783\n",
      "Epoch: 302/4000..  Training Loss: 0.084..  Test Loss: 0.907..  Test Accuracy: 0.773\n",
      "Epoch: 303/4000..  Training Loss: 0.078..  Test Loss: 0.865..  Test Accuracy: 0.779\n",
      "Epoch: 304/4000..  Training Loss: 0.096..  Test Loss: 0.902..  Test Accuracy: 0.776\n",
      "Epoch: 305/4000..  Training Loss: 0.087..  Test Loss: 0.932..  Test Accuracy: 0.770\n",
      "Epoch: 306/4000..  Training Loss: 0.067..  Test Loss: 0.887..  Test Accuracy: 0.777\n",
      "Epoch: 307/4000..  Training Loss: 0.090..  Test Loss: 0.894..  Test Accuracy: 0.774\n",
      "Epoch: 308/4000..  Training Loss: 0.084..  Test Loss: 0.860..  Test Accuracy: 0.780\n",
      "Epoch: 309/4000..  Training Loss: 0.077..  Test Loss: 0.899..  Test Accuracy: 0.772\n",
      "Epoch: 310/4000..  Training Loss: 0.103..  Test Loss: 0.904..  Test Accuracy: 0.777\n",
      "Epoch: 311/4000..  Training Loss: 0.104..  Test Loss: 0.874..  Test Accuracy: 0.780\n",
      "Epoch: 312/4000..  Training Loss: 0.092..  Test Loss: 0.835..  Test Accuracy: 0.789\n",
      "Epoch: 313/4000..  Training Loss: 0.069..  Test Loss: 0.887..  Test Accuracy: 0.780\n",
      "Epoch: 314/4000..  Training Loss: 0.091..  Test Loss: 0.939..  Test Accuracy: 0.772\n",
      "Epoch: 315/4000..  Training Loss: 0.076..  Test Loss: 0.857..  Test Accuracy: 0.784\n",
      "Epoch: 316/4000..  Training Loss: 0.081..  Test Loss: 0.921..  Test Accuracy: 0.775\n",
      "Epoch: 317/4000..  Training Loss: 0.083..  Test Loss: 0.861..  Test Accuracy: 0.785\n",
      "Epoch: 318/4000..  Training Loss: 0.093..  Test Loss: 0.885..  Test Accuracy: 0.779\n",
      "Epoch: 319/4000..  Training Loss: 0.101..  Test Loss: 0.890..  Test Accuracy: 0.777\n",
      "Epoch: 320/4000..  Training Loss: 0.093..  Test Loss: 0.917..  Test Accuracy: 0.776\n",
      "Epoch: 321/4000..  Training Loss: 0.078..  Test Loss: 0.901..  Test Accuracy: 0.776\n",
      "Epoch: 322/4000..  Training Loss: 0.059..  Test Loss: 0.915..  Test Accuracy: 0.776\n",
      "Epoch: 323/4000..  Training Loss: 0.077..  Test Loss: 0.931..  Test Accuracy: 0.772\n",
      "Epoch: 324/4000..  Training Loss: 0.070..  Test Loss: 0.903..  Test Accuracy: 0.778\n",
      "Epoch: 325/4000..  Training Loss: 0.065..  Test Loss: 0.917..  Test Accuracy: 0.771\n",
      "Epoch: 326/4000..  Training Loss: 0.063..  Test Loss: 0.897..  Test Accuracy: 0.779\n",
      "Epoch: 327/4000..  Training Loss: 0.089..  Test Loss: 0.951..  Test Accuracy: 0.770\n",
      "Epoch: 328/4000..  Training Loss: 0.081..  Test Loss: 0.905..  Test Accuracy: 0.779\n",
      "Epoch: 329/4000..  Training Loss: 0.084..  Test Loss: 0.930..  Test Accuracy: 0.772\n",
      "Epoch: 330/4000..  Training Loss: 0.075..  Test Loss: 0.918..  Test Accuracy: 0.772\n",
      "Epoch: 331/4000..  Training Loss: 0.059..  Test Loss: 0.909..  Test Accuracy: 0.778\n",
      "Epoch: 332/4000..  Training Loss: 0.086..  Test Loss: 0.914..  Test Accuracy: 0.777\n",
      "Epoch: 333/4000..  Training Loss: 0.073..  Test Loss: 0.896..  Test Accuracy: 0.782\n",
      "Epoch: 334/4000..  Training Loss: 0.077..  Test Loss: 0.880..  Test Accuracy: 0.784\n",
      "Epoch: 335/4000..  Training Loss: 0.093..  Test Loss: 0.864..  Test Accuracy: 0.786\n",
      "Epoch: 336/4000..  Training Loss: 0.083..  Test Loss: 0.876..  Test Accuracy: 0.781\n",
      "Epoch: 337/4000..  Training Loss: 0.104..  Test Loss: 0.888..  Test Accuracy: 0.784\n",
      "Epoch: 338/4000..  Training Loss: 0.086..  Test Loss: 0.909..  Test Accuracy: 0.776\n",
      "Epoch: 339/4000..  Training Loss: 0.063..  Test Loss: 0.957..  Test Accuracy: 0.767\n",
      "Epoch: 340/4000..  Training Loss: 0.074..  Test Loss: 0.890..  Test Accuracy: 0.781\n",
      "Epoch: 341/4000..  Training Loss: 0.080..  Test Loss: 0.920..  Test Accuracy: 0.780\n",
      "Epoch: 342/4000..  Training Loss: 0.087..  Test Loss: 0.965..  Test Accuracy: 0.771\n",
      "Epoch: 343/4000..  Training Loss: 0.084..  Test Loss: 0.937..  Test Accuracy: 0.775\n",
      "Epoch: 344/4000..  Training Loss: 0.094..  Test Loss: 0.951..  Test Accuracy: 0.769\n",
      "Epoch: 345/4000..  Training Loss: 0.075..  Test Loss: 0.986..  Test Accuracy: 0.767\n",
      "Epoch: 346/4000..  Training Loss: 0.062..  Test Loss: 0.940..  Test Accuracy: 0.772\n",
      "Epoch: 347/4000..  Training Loss: 0.083..  Test Loss: 0.891..  Test Accuracy: 0.786\n",
      "Epoch: 348/4000..  Training Loss: 0.077..  Test Loss: 0.934..  Test Accuracy: 0.778\n",
      "Epoch: 349/4000..  Training Loss: 0.065..  Test Loss: 0.881..  Test Accuracy: 0.785\n",
      "Epoch: 350/4000..  Training Loss: 0.068..  Test Loss: 0.906..  Test Accuracy: 0.781\n",
      "Epoch: 351/4000..  Training Loss: 0.082..  Test Loss: 0.933..  Test Accuracy: 0.774\n",
      "Epoch: 352/4000..  Training Loss: 0.079..  Test Loss: 0.919..  Test Accuracy: 0.783\n",
      "Epoch: 353/4000..  Training Loss: 0.061..  Test Loss: 0.869..  Test Accuracy: 0.789\n",
      "Epoch: 354/4000..  Training Loss: 0.066..  Test Loss: 0.912..  Test Accuracy: 0.779\n",
      "Epoch: 355/4000..  Training Loss: 0.100..  Test Loss: 0.907..  Test Accuracy: 0.783\n",
      "Epoch: 356/4000..  Training Loss: 0.092..  Test Loss: 0.851..  Test Accuracy: 0.793\n",
      "Epoch: 357/4000..  Training Loss: 0.082..  Test Loss: 0.943..  Test Accuracy: 0.775\n",
      "Epoch: 358/4000..  Training Loss: 0.077..  Test Loss: 0.879..  Test Accuracy: 0.788\n",
      "Epoch: 359/4000..  Training Loss: 0.051..  Test Loss: 0.897..  Test Accuracy: 0.784\n",
      "Epoch: 360/4000..  Training Loss: 0.055..  Test Loss: 0.924..  Test Accuracy: 0.780\n",
      "Epoch: 361/4000..  Training Loss: 0.094..  Test Loss: 0.899..  Test Accuracy: 0.787\n",
      "Epoch: 362/4000..  Training Loss: 0.072..  Test Loss: 0.963..  Test Accuracy: 0.777\n",
      "Epoch: 363/4000..  Training Loss: 0.073..  Test Loss: 0.956..  Test Accuracy: 0.775\n",
      "Epoch: 364/4000..  Training Loss: 0.073..  Test Loss: 0.931..  Test Accuracy: 0.781\n",
      "Epoch: 365/4000..  Training Loss: 0.082..  Test Loss: 0.936..  Test Accuracy: 0.782\n",
      "Epoch: 366/4000..  Training Loss: 0.060..  Test Loss: 0.938..  Test Accuracy: 0.776\n",
      "Epoch: 367/4000..  Training Loss: 0.078..  Test Loss: 0.882..  Test Accuracy: 0.786\n",
      "Epoch: 368/4000..  Training Loss: 0.077..  Test Loss: 0.919..  Test Accuracy: 0.779\n",
      "Epoch: 369/4000..  Training Loss: 0.072..  Test Loss: 0.936..  Test Accuracy: 0.779\n",
      "Epoch: 370/4000..  Training Loss: 0.080..  Test Loss: 0.900..  Test Accuracy: 0.786\n",
      "Epoch: 371/4000..  Training Loss: 0.064..  Test Loss: 0.908..  Test Accuracy: 0.782\n",
      "Epoch: 372/4000..  Training Loss: 0.070..  Test Loss: 0.906..  Test Accuracy: 0.785\n",
      "Epoch: 373/4000..  Training Loss: 0.079..  Test Loss: 0.919..  Test Accuracy: 0.782\n",
      "Epoch: 374/4000..  Training Loss: 0.072..  Test Loss: 0.925..  Test Accuracy: 0.780\n",
      "Epoch: 375/4000..  Training Loss: 0.057..  Test Loss: 0.944..  Test Accuracy: 0.777\n",
      "Epoch: 376/4000..  Training Loss: 0.067..  Test Loss: 0.922..  Test Accuracy: 0.781\n",
      "Epoch: 377/4000..  Training Loss: 0.069..  Test Loss: 0.950..  Test Accuracy: 0.781\n",
      "Epoch: 378/4000..  Training Loss: 0.095..  Test Loss: 0.969..  Test Accuracy: 0.777\n",
      "Epoch: 379/4000..  Training Loss: 0.078..  Test Loss: 0.911..  Test Accuracy: 0.785\n",
      "Epoch: 380/4000..  Training Loss: 0.074..  Test Loss: 0.909..  Test Accuracy: 0.785\n",
      "Epoch: 381/4000..  Training Loss: 0.072..  Test Loss: 0.969..  Test Accuracy: 0.778\n",
      "Epoch: 382/4000..  Training Loss: 0.070..  Test Loss: 0.945..  Test Accuracy: 0.781\n",
      "Epoch: 383/4000..  Training Loss: 0.068..  Test Loss: 0.943..  Test Accuracy: 0.780\n",
      "Epoch: 384/4000..  Training Loss: 0.088..  Test Loss: 0.912..  Test Accuracy: 0.784\n",
      "Epoch: 385/4000..  Training Loss: 0.053..  Test Loss: 0.915..  Test Accuracy: 0.788\n",
      "Epoch: 386/4000..  Training Loss: 0.082..  Test Loss: 0.866..  Test Accuracy: 0.791\n",
      "Epoch: 387/4000..  Training Loss: 0.098..  Test Loss: 0.924..  Test Accuracy: 0.785\n",
      "Epoch: 388/4000..  Training Loss: 0.084..  Test Loss: 0.918..  Test Accuracy: 0.785\n",
      "Epoch: 389/4000..  Training Loss: 0.064..  Test Loss: 0.938..  Test Accuracy: 0.782\n",
      "Epoch: 390/4000..  Training Loss: 0.081..  Test Loss: 0.927..  Test Accuracy: 0.780\n",
      "Epoch: 391/4000..  Training Loss: 0.075..  Test Loss: 0.880..  Test Accuracy: 0.792\n",
      "Epoch: 392/4000..  Training Loss: 0.085..  Test Loss: 0.982..  Test Accuracy: 0.773\n",
      "Epoch: 393/4000..  Training Loss: 0.072..  Test Loss: 0.947..  Test Accuracy: 0.781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 394/4000..  Training Loss: 0.059..  Test Loss: 0.952..  Test Accuracy: 0.781\n",
      "Epoch: 395/4000..  Training Loss: 0.086..  Test Loss: 1.012..  Test Accuracy: 0.773\n",
      "Epoch: 396/4000..  Training Loss: 0.085..  Test Loss: 0.989..  Test Accuracy: 0.778\n",
      "Epoch: 397/4000..  Training Loss: 0.079..  Test Loss: 0.933..  Test Accuracy: 0.783\n",
      "Epoch: 398/4000..  Training Loss: 0.069..  Test Loss: 0.929..  Test Accuracy: 0.786\n",
      "Epoch: 399/4000..  Training Loss: 0.079..  Test Loss: 0.955..  Test Accuracy: 0.782\n",
      "Epoch: 400/4000..  Training Loss: 0.061..  Test Loss: 1.002..  Test Accuracy: 0.775\n",
      "Epoch: 401/4000..  Training Loss: 0.082..  Test Loss: 0.919..  Test Accuracy: 0.786\n",
      "Epoch: 402/4000..  Training Loss: 0.107..  Test Loss: 0.957..  Test Accuracy: 0.777\n",
      "Epoch: 403/4000..  Training Loss: 0.089..  Test Loss: 1.007..  Test Accuracy: 0.770\n",
      "Epoch: 404/4000..  Training Loss: 0.103..  Test Loss: 1.024..  Test Accuracy: 0.768\n",
      "Epoch: 405/4000..  Training Loss: 0.105..  Test Loss: 1.004..  Test Accuracy: 0.774\n",
      "Epoch: 406/4000..  Training Loss: 0.101..  Test Loss: 1.005..  Test Accuracy: 0.774\n",
      "Epoch: 407/4000..  Training Loss: 0.086..  Test Loss: 1.031..  Test Accuracy: 0.770\n",
      "Epoch: 408/4000..  Training Loss: 0.111..  Test Loss: 0.996..  Test Accuracy: 0.774\n",
      "Epoch: 409/4000..  Training Loss: 0.081..  Test Loss: 1.004..  Test Accuracy: 0.774\n",
      "Epoch: 410/4000..  Training Loss: 0.085..  Test Loss: 0.967..  Test Accuracy: 0.775\n",
      "Epoch: 411/4000..  Training Loss: 0.080..  Test Loss: 1.012..  Test Accuracy: 0.773\n",
      "Epoch: 412/4000..  Training Loss: 0.146..  Test Loss: 0.977..  Test Accuracy: 0.778\n",
      "Epoch: 413/4000..  Training Loss: 0.086..  Test Loss: 0.962..  Test Accuracy: 0.777\n",
      "Epoch: 414/4000..  Training Loss: 0.078..  Test Loss: 0.987..  Test Accuracy: 0.778\n",
      "Epoch: 415/4000..  Training Loss: 0.080..  Test Loss: 1.013..  Test Accuracy: 0.776\n",
      "Epoch: 416/4000..  Training Loss: 0.095..  Test Loss: 1.003..  Test Accuracy: 0.774\n",
      "Epoch: 417/4000..  Training Loss: 0.079..  Test Loss: 1.048..  Test Accuracy: 0.769\n",
      "Epoch: 418/4000..  Training Loss: 0.079..  Test Loss: 1.052..  Test Accuracy: 0.768\n",
      "Epoch: 419/4000..  Training Loss: 0.107..  Test Loss: 0.971..  Test Accuracy: 0.778\n",
      "Epoch: 420/4000..  Training Loss: 0.103..  Test Loss: 1.022..  Test Accuracy: 0.771\n",
      "Epoch: 421/4000..  Training Loss: 0.092..  Test Loss: 0.984..  Test Accuracy: 0.779\n",
      "Epoch: 422/4000..  Training Loss: 0.086..  Test Loss: 0.988..  Test Accuracy: 0.779\n",
      "Epoch: 423/4000..  Training Loss: 0.086..  Test Loss: 1.012..  Test Accuracy: 0.773\n",
      "Epoch: 424/4000..  Training Loss: 0.077..  Test Loss: 0.999..  Test Accuracy: 0.776\n",
      "Epoch: 425/4000..  Training Loss: 0.109..  Test Loss: 0.984..  Test Accuracy: 0.780\n",
      "Epoch: 426/4000..  Training Loss: 0.093..  Test Loss: 0.992..  Test Accuracy: 0.778\n",
      "Epoch: 427/4000..  Training Loss: 0.132..  Test Loss: 0.974..  Test Accuracy: 0.778\n",
      "Epoch: 428/4000..  Training Loss: 0.095..  Test Loss: 0.957..  Test Accuracy: 0.783\n",
      "Epoch: 429/4000..  Training Loss: 0.084..  Test Loss: 0.963..  Test Accuracy: 0.782\n",
      "Epoch: 430/4000..  Training Loss: 0.078..  Test Loss: 1.020..  Test Accuracy: 0.776\n",
      "Epoch: 431/4000..  Training Loss: 0.108..  Test Loss: 1.051..  Test Accuracy: 0.771\n",
      "Epoch: 432/4000..  Training Loss: 0.098..  Test Loss: 0.976..  Test Accuracy: 0.780\n",
      "Epoch: 433/4000..  Training Loss: 0.109..  Test Loss: 0.967..  Test Accuracy: 0.783\n",
      "Epoch: 434/4000..  Training Loss: 0.069..  Test Loss: 0.995..  Test Accuracy: 0.778\n",
      "Epoch: 435/4000..  Training Loss: 0.099..  Test Loss: 1.029..  Test Accuracy: 0.774\n",
      "Epoch: 436/4000..  Training Loss: 0.079..  Test Loss: 0.990..  Test Accuracy: 0.780\n",
      "Epoch: 437/4000..  Training Loss: 0.090..  Test Loss: 0.962..  Test Accuracy: 0.785\n",
      "Epoch: 438/4000..  Training Loss: 0.101..  Test Loss: 1.083..  Test Accuracy: 0.764\n",
      "Epoch: 439/4000..  Training Loss: 0.078..  Test Loss: 1.014..  Test Accuracy: 0.776\n",
      "Epoch: 440/4000..  Training Loss: 0.084..  Test Loss: 0.954..  Test Accuracy: 0.785\n",
      "Epoch: 441/4000..  Training Loss: 0.080..  Test Loss: 0.997..  Test Accuracy: 0.779\n",
      "Epoch: 442/4000..  Training Loss: 0.077..  Test Loss: 1.042..  Test Accuracy: 0.772\n",
      "Epoch: 443/4000..  Training Loss: 0.086..  Test Loss: 1.011..  Test Accuracy: 0.778\n",
      "Epoch: 444/4000..  Training Loss: 0.099..  Test Loss: 1.041..  Test Accuracy: 0.773\n",
      "Epoch: 445/4000..  Training Loss: 0.090..  Test Loss: 1.046..  Test Accuracy: 0.772\n",
      "Epoch: 446/4000..  Training Loss: 0.090..  Test Loss: 1.015..  Test Accuracy: 0.777\n",
      "Epoch: 447/4000..  Training Loss: 0.083..  Test Loss: 1.035..  Test Accuracy: 0.775\n",
      "Epoch: 448/4000..  Training Loss: 0.075..  Test Loss: 0.989..  Test Accuracy: 0.781\n",
      "Epoch: 449/4000..  Training Loss: 0.068..  Test Loss: 0.983..  Test Accuracy: 0.781\n",
      "Epoch: 450/4000..  Training Loss: 0.079..  Test Loss: 0.972..  Test Accuracy: 0.783\n",
      "Epoch: 451/4000..  Training Loss: 0.090..  Test Loss: 1.056..  Test Accuracy: 0.770\n",
      "Epoch: 452/4000..  Training Loss: 0.094..  Test Loss: 0.995..  Test Accuracy: 0.782\n",
      "Epoch: 453/4000..  Training Loss: 0.075..  Test Loss: 1.026..  Test Accuracy: 0.776\n",
      "Epoch: 454/4000..  Training Loss: 0.084..  Test Loss: 0.990..  Test Accuracy: 0.782\n",
      "Epoch: 455/4000..  Training Loss: 0.083..  Test Loss: 1.006..  Test Accuracy: 0.782\n",
      "Epoch: 456/4000..  Training Loss: 0.078..  Test Loss: 1.008..  Test Accuracy: 0.779\n",
      "Epoch: 457/4000..  Training Loss: 0.093..  Test Loss: 1.060..  Test Accuracy: 0.772\n",
      "Epoch: 458/4000..  Training Loss: 0.098..  Test Loss: 1.019..  Test Accuracy: 0.778\n",
      "Epoch: 459/4000..  Training Loss: 0.094..  Test Loss: 1.044..  Test Accuracy: 0.773\n",
      "Epoch: 460/4000..  Training Loss: 0.085..  Test Loss: 1.002..  Test Accuracy: 0.781\n",
      "Epoch: 461/4000..  Training Loss: 0.125..  Test Loss: 0.962..  Test Accuracy: 0.786\n",
      "Epoch: 462/4000..  Training Loss: 0.061..  Test Loss: 1.001..  Test Accuracy: 0.782\n",
      "Epoch: 463/4000..  Training Loss: 0.085..  Test Loss: 0.984..  Test Accuracy: 0.781\n",
      "Epoch: 464/4000..  Training Loss: 0.085..  Test Loss: 1.068..  Test Accuracy: 0.771\n",
      "Epoch: 465/4000..  Training Loss: 0.083..  Test Loss: 0.996..  Test Accuracy: 0.780\n",
      "Epoch: 466/4000..  Training Loss: 0.102..  Test Loss: 1.038..  Test Accuracy: 0.777\n",
      "Epoch: 467/4000..  Training Loss: 0.088..  Test Loss: 1.054..  Test Accuracy: 0.774\n",
      "Epoch: 468/4000..  Training Loss: 0.086..  Test Loss: 1.052..  Test Accuracy: 0.774\n",
      "Epoch: 469/4000..  Training Loss: 0.077..  Test Loss: 0.997..  Test Accuracy: 0.780\n",
      "Epoch: 470/4000..  Training Loss: 0.074..  Test Loss: 1.021..  Test Accuracy: 0.779\n",
      "Epoch: 471/4000..  Training Loss: 0.069..  Test Loss: 1.068..  Test Accuracy: 0.773\n",
      "Epoch: 472/4000..  Training Loss: 0.076..  Test Loss: 0.995..  Test Accuracy: 0.783\n",
      "Epoch: 473/4000..  Training Loss: 0.079..  Test Loss: 0.995..  Test Accuracy: 0.785\n",
      "Epoch: 474/4000..  Training Loss: 0.080..  Test Loss: 0.989..  Test Accuracy: 0.786\n",
      "Epoch: 475/4000..  Training Loss: 0.108..  Test Loss: 1.061..  Test Accuracy: 0.770\n",
      "Epoch: 476/4000..  Training Loss: 0.077..  Test Loss: 1.003..  Test Accuracy: 0.782\n",
      "Epoch: 477/4000..  Training Loss: 0.062..  Test Loss: 1.002..  Test Accuracy: 0.782\n",
      "Epoch: 478/4000..  Training Loss: 0.071..  Test Loss: 0.956..  Test Accuracy: 0.791\n",
      "Epoch: 479/4000..  Training Loss: 0.107..  Test Loss: 0.988..  Test Accuracy: 0.783\n",
      "Epoch: 480/4000..  Training Loss: 0.098..  Test Loss: 0.982..  Test Accuracy: 0.782\n",
      "Epoch: 481/4000..  Training Loss: 0.075..  Test Loss: 1.014..  Test Accuracy: 0.780\n",
      "Epoch: 482/4000..  Training Loss: 0.064..  Test Loss: 1.009..  Test Accuracy: 0.780\n",
      "Epoch: 483/4000..  Training Loss: 0.068..  Test Loss: 0.980..  Test Accuracy: 0.785\n",
      "Epoch: 484/4000..  Training Loss: 0.085..  Test Loss: 1.009..  Test Accuracy: 0.779\n",
      "Epoch: 485/4000..  Training Loss: 0.091..  Test Loss: 0.985..  Test Accuracy: 0.787\n",
      "Epoch: 486/4000..  Training Loss: 0.071..  Test Loss: 0.988..  Test Accuracy: 0.784\n",
      "Epoch: 487/4000..  Training Loss: 0.107..  Test Loss: 1.020..  Test Accuracy: 0.779\n",
      "Epoch: 488/4000..  Training Loss: 0.083..  Test Loss: 1.026..  Test Accuracy: 0.779\n",
      "Epoch: 489/4000..  Training Loss: 0.100..  Test Loss: 1.041..  Test Accuracy: 0.773\n",
      "Epoch: 490/4000..  Training Loss: 0.084..  Test Loss: 0.969..  Test Accuracy: 0.786\n",
      "Epoch: 491/4000..  Training Loss: 0.063..  Test Loss: 1.016..  Test Accuracy: 0.779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 492/4000..  Training Loss: 0.073..  Test Loss: 1.004..  Test Accuracy: 0.778\n",
      "Epoch: 493/4000..  Training Loss: 0.084..  Test Loss: 0.947..  Test Accuracy: 0.792\n",
      "Epoch: 494/4000..  Training Loss: 0.062..  Test Loss: 1.045..  Test Accuracy: 0.775\n",
      "Epoch: 495/4000..  Training Loss: 0.049..  Test Loss: 0.999..  Test Accuracy: 0.781\n",
      "Epoch: 496/4000..  Training Loss: 0.079..  Test Loss: 1.003..  Test Accuracy: 0.780\n",
      "Epoch: 497/4000..  Training Loss: 0.094..  Test Loss: 0.992..  Test Accuracy: 0.783\n",
      "Epoch: 498/4000..  Training Loss: 0.088..  Test Loss: 0.982..  Test Accuracy: 0.784\n",
      "Epoch: 499/4000..  Training Loss: 0.058..  Test Loss: 0.986..  Test Accuracy: 0.786\n",
      "Epoch: 500/4000..  Training Loss: 0.068..  Test Loss: 0.990..  Test Accuracy: 0.783\n",
      "Epoch: 501/4000..  Training Loss: 0.095..  Test Loss: 1.000..  Test Accuracy: 0.779\n",
      "Epoch: 502/4000..  Training Loss: 0.085..  Test Loss: 0.972..  Test Accuracy: 0.783\n",
      "Epoch: 503/4000..  Training Loss: 0.072..  Test Loss: 1.035..  Test Accuracy: 0.779\n",
      "Epoch: 504/4000..  Training Loss: 0.061..  Test Loss: 1.037..  Test Accuracy: 0.775\n",
      "Epoch: 505/4000..  Training Loss: 0.082..  Test Loss: 0.982..  Test Accuracy: 0.785\n",
      "Epoch: 506/4000..  Training Loss: 0.085..  Test Loss: 0.964..  Test Accuracy: 0.787\n",
      "Epoch: 507/4000..  Training Loss: 0.063..  Test Loss: 0.978..  Test Accuracy: 0.787\n",
      "Epoch: 508/4000..  Training Loss: 0.077..  Test Loss: 0.932..  Test Accuracy: 0.789\n",
      "Epoch: 509/4000..  Training Loss: 0.083..  Test Loss: 0.935..  Test Accuracy: 0.793\n",
      "Epoch: 510/4000..  Training Loss: 0.073..  Test Loss: 1.112..  Test Accuracy: 0.767\n",
      "Epoch: 511/4000..  Training Loss: 0.075..  Test Loss: 0.939..  Test Accuracy: 0.792\n",
      "Epoch: 512/4000..  Training Loss: 0.076..  Test Loss: 0.960..  Test Accuracy: 0.793\n",
      "Epoch: 513/4000..  Training Loss: 0.062..  Test Loss: 0.995..  Test Accuracy: 0.783\n",
      "Epoch: 514/4000..  Training Loss: 0.072..  Test Loss: 1.021..  Test Accuracy: 0.784\n",
      "Epoch: 515/4000..  Training Loss: 0.109..  Test Loss: 0.941..  Test Accuracy: 0.792\n",
      "Epoch: 516/4000..  Training Loss: 0.054..  Test Loss: 1.004..  Test Accuracy: 0.786\n",
      "Epoch: 517/4000..  Training Loss: 0.110..  Test Loss: 0.955..  Test Accuracy: 0.787\n",
      "Epoch: 518/4000..  Training Loss: 0.053..  Test Loss: 0.958..  Test Accuracy: 0.793\n",
      "Epoch: 519/4000..  Training Loss: 0.072..  Test Loss: 0.987..  Test Accuracy: 0.787\n",
      "Epoch: 520/4000..  Training Loss: 0.087..  Test Loss: 0.971..  Test Accuracy: 0.784\n",
      "Epoch: 521/4000..  Training Loss: 0.053..  Test Loss: 1.006..  Test Accuracy: 0.783\n",
      "Epoch: 522/4000..  Training Loss: 0.069..  Test Loss: 0.908..  Test Accuracy: 0.798\n",
      "Epoch: 523/4000..  Training Loss: 0.067..  Test Loss: 0.997..  Test Accuracy: 0.785\n",
      "Epoch: 524/4000..  Training Loss: 0.075..  Test Loss: 0.972..  Test Accuracy: 0.789\n",
      "Epoch: 525/4000..  Training Loss: 0.090..  Test Loss: 0.969..  Test Accuracy: 0.790\n",
      "Epoch: 526/4000..  Training Loss: 0.066..  Test Loss: 0.963..  Test Accuracy: 0.792\n",
      "Epoch: 527/4000..  Training Loss: 0.051..  Test Loss: 0.993..  Test Accuracy: 0.786\n",
      "Epoch: 528/4000..  Training Loss: 0.079..  Test Loss: 1.010..  Test Accuracy: 0.784\n",
      "Epoch: 529/4000..  Training Loss: 0.067..  Test Loss: 0.968..  Test Accuracy: 0.787\n",
      "Epoch: 530/4000..  Training Loss: 0.079..  Test Loss: 0.933..  Test Accuracy: 0.793\n",
      "Epoch: 531/4000..  Training Loss: 0.068..  Test Loss: 0.997..  Test Accuracy: 0.783\n",
      "Epoch: 532/4000..  Training Loss: 0.073..  Test Loss: 0.940..  Test Accuracy: 0.793\n",
      "Epoch: 533/4000..  Training Loss: 0.074..  Test Loss: 1.010..  Test Accuracy: 0.785\n",
      "Epoch: 534/4000..  Training Loss: 0.068..  Test Loss: 0.986..  Test Accuracy: 0.787\n",
      "Epoch: 535/4000..  Training Loss: 0.077..  Test Loss: 1.001..  Test Accuracy: 0.787\n",
      "Epoch: 536/4000..  Training Loss: 0.073..  Test Loss: 1.012..  Test Accuracy: 0.784\n",
      "Epoch: 537/4000..  Training Loss: 0.054..  Test Loss: 0.999..  Test Accuracy: 0.787\n",
      "Epoch: 538/4000..  Training Loss: 0.071..  Test Loss: 0.973..  Test Accuracy: 0.791\n",
      "Epoch: 539/4000..  Training Loss: 0.086..  Test Loss: 1.053..  Test Accuracy: 0.780\n",
      "Epoch: 540/4000..  Training Loss: 0.076..  Test Loss: 0.977..  Test Accuracy: 0.789\n",
      "Epoch: 541/4000..  Training Loss: 0.070..  Test Loss: 1.037..  Test Accuracy: 0.780\n",
      "Epoch: 542/4000..  Training Loss: 0.068..  Test Loss: 0.991..  Test Accuracy: 0.788\n",
      "Epoch: 543/4000..  Training Loss: 0.071..  Test Loss: 1.005..  Test Accuracy: 0.779\n",
      "Epoch: 544/4000..  Training Loss: 0.073..  Test Loss: 0.959..  Test Accuracy: 0.793\n",
      "Epoch: 545/4000..  Training Loss: 0.074..  Test Loss: 1.011..  Test Accuracy: 0.784\n",
      "Epoch: 546/4000..  Training Loss: 0.081..  Test Loss: 0.972..  Test Accuracy: 0.790\n",
      "Epoch: 547/4000..  Training Loss: 0.049..  Test Loss: 0.937..  Test Accuracy: 0.793\n",
      "Epoch: 548/4000..  Training Loss: 0.079..  Test Loss: 0.986..  Test Accuracy: 0.786\n",
      "Epoch: 549/4000..  Training Loss: 0.088..  Test Loss: 1.006..  Test Accuracy: 0.787\n",
      "Epoch: 550/4000..  Training Loss: 0.062..  Test Loss: 0.991..  Test Accuracy: 0.789\n",
      "Epoch: 551/4000..  Training Loss: 0.053..  Test Loss: 0.964..  Test Accuracy: 0.797\n",
      "Epoch: 552/4000..  Training Loss: 0.112..  Test Loss: 0.978..  Test Accuracy: 0.790\n",
      "Epoch: 553/4000..  Training Loss: 0.067..  Test Loss: 0.956..  Test Accuracy: 0.793\n",
      "Epoch: 554/4000..  Training Loss: 0.081..  Test Loss: 0.953..  Test Accuracy: 0.794\n",
      "Epoch: 555/4000..  Training Loss: 0.077..  Test Loss: 0.951..  Test Accuracy: 0.792\n",
      "Epoch: 556/4000..  Training Loss: 0.066..  Test Loss: 0.978..  Test Accuracy: 0.793\n",
      "Epoch: 557/4000..  Training Loss: 0.066..  Test Loss: 1.044..  Test Accuracy: 0.781\n",
      "Epoch: 558/4000..  Training Loss: 0.086..  Test Loss: 0.916..  Test Accuracy: 0.800\n",
      "Epoch: 559/4000..  Training Loss: 0.084..  Test Loss: 0.950..  Test Accuracy: 0.796\n",
      "Epoch: 560/4000..  Training Loss: 0.037..  Test Loss: 1.015..  Test Accuracy: 0.784\n",
      "Epoch: 561/4000..  Training Loss: 0.056..  Test Loss: 1.031..  Test Accuracy: 0.785\n",
      "Epoch: 562/4000..  Training Loss: 0.063..  Test Loss: 1.017..  Test Accuracy: 0.783\n",
      "Epoch: 563/4000..  Training Loss: 0.072..  Test Loss: 0.982..  Test Accuracy: 0.790\n",
      "Epoch: 564/4000..  Training Loss: 0.087..  Test Loss: 1.024..  Test Accuracy: 0.781\n",
      "Epoch: 565/4000..  Training Loss: 0.071..  Test Loss: 1.052..  Test Accuracy: 0.782\n",
      "Epoch: 566/4000..  Training Loss: 0.047..  Test Loss: 0.994..  Test Accuracy: 0.791\n",
      "Epoch: 567/4000..  Training Loss: 0.063..  Test Loss: 0.986..  Test Accuracy: 0.790\n",
      "Epoch: 568/4000..  Training Loss: 0.080..  Test Loss: 1.017..  Test Accuracy: 0.785\n",
      "Epoch: 569/4000..  Training Loss: 0.059..  Test Loss: 0.979..  Test Accuracy: 0.793\n",
      "Epoch: 570/4000..  Training Loss: 0.062..  Test Loss: 0.984..  Test Accuracy: 0.792\n",
      "Epoch: 571/4000..  Training Loss: 0.052..  Test Loss: 0.978..  Test Accuracy: 0.792\n",
      "Epoch: 572/4000..  Training Loss: 0.076..  Test Loss: 0.959..  Test Accuracy: 0.796\n",
      "Epoch: 573/4000..  Training Loss: 0.107..  Test Loss: 0.951..  Test Accuracy: 0.796\n",
      "Epoch: 574/4000..  Training Loss: 0.103..  Test Loss: 0.977..  Test Accuracy: 0.792\n",
      "Epoch: 575/4000..  Training Loss: 0.072..  Test Loss: 0.940..  Test Accuracy: 0.796\n",
      "Epoch: 576/4000..  Training Loss: 0.064..  Test Loss: 0.982..  Test Accuracy: 0.788\n",
      "Epoch: 577/4000..  Training Loss: 0.039..  Test Loss: 0.978..  Test Accuracy: 0.789\n",
      "Epoch: 578/4000..  Training Loss: 0.077..  Test Loss: 0.984..  Test Accuracy: 0.788\n",
      "Epoch: 579/4000..  Training Loss: 0.073..  Test Loss: 0.981..  Test Accuracy: 0.793\n",
      "Epoch: 580/4000..  Training Loss: 0.065..  Test Loss: 0.947..  Test Accuracy: 0.797\n",
      "Epoch: 581/4000..  Training Loss: 0.065..  Test Loss: 0.924..  Test Accuracy: 0.799\n",
      "Epoch: 582/4000..  Training Loss: 0.062..  Test Loss: 1.003..  Test Accuracy: 0.790\n",
      "Epoch: 583/4000..  Training Loss: 0.058..  Test Loss: 1.046..  Test Accuracy: 0.780\n",
      "Epoch: 584/4000..  Training Loss: 0.076..  Test Loss: 1.022..  Test Accuracy: 0.786\n",
      "Epoch: 585/4000..  Training Loss: 0.069..  Test Loss: 0.967..  Test Accuracy: 0.794\n",
      "Epoch: 586/4000..  Training Loss: 0.085..  Test Loss: 1.013..  Test Accuracy: 0.785\n",
      "Epoch: 587/4000..  Training Loss: 0.056..  Test Loss: 0.945..  Test Accuracy: 0.796\n",
      "Epoch: 588/4000..  Training Loss: 0.077..  Test Loss: 0.982..  Test Accuracy: 0.793\n",
      "Epoch: 589/4000..  Training Loss: 0.060..  Test Loss: 1.034..  Test Accuracy: 0.786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 590/4000..  Training Loss: 0.077..  Test Loss: 0.934..  Test Accuracy: 0.798\n",
      "Epoch: 591/4000..  Training Loss: 0.053..  Test Loss: 0.942..  Test Accuracy: 0.799\n",
      "Epoch: 592/4000..  Training Loss: 0.059..  Test Loss: 0.958..  Test Accuracy: 0.794\n",
      "Epoch: 593/4000..  Training Loss: 0.069..  Test Loss: 0.922..  Test Accuracy: 0.799\n",
      "Epoch: 594/4000..  Training Loss: 0.084..  Test Loss: 0.974..  Test Accuracy: 0.793\n",
      "Epoch: 595/4000..  Training Loss: 0.070..  Test Loss: 0.976..  Test Accuracy: 0.794\n",
      "Epoch: 596/4000..  Training Loss: 0.032..  Test Loss: 0.960..  Test Accuracy: 0.797\n",
      "Epoch: 597/4000..  Training Loss: 0.052..  Test Loss: 0.953..  Test Accuracy: 0.797\n",
      "Epoch: 598/4000..  Training Loss: 0.077..  Test Loss: 0.991..  Test Accuracy: 0.790\n",
      "Epoch: 599/4000..  Training Loss: 0.084..  Test Loss: 0.944..  Test Accuracy: 0.799\n",
      "Epoch: 600/4000..  Training Loss: 0.074..  Test Loss: 0.988..  Test Accuracy: 0.790\n",
      "Epoch: 601/4000..  Training Loss: 0.059..  Test Loss: 0.958..  Test Accuracy: 0.797\n",
      "Epoch: 602/4000..  Training Loss: 0.045..  Test Loss: 0.945..  Test Accuracy: 0.799\n",
      "Epoch: 603/4000..  Training Loss: 0.067..  Test Loss: 0.937..  Test Accuracy: 0.798\n",
      "Epoch: 604/4000..  Training Loss: 0.068..  Test Loss: 0.983..  Test Accuracy: 0.794\n",
      "Epoch: 605/4000..  Training Loss: 0.067..  Test Loss: 0.974..  Test Accuracy: 0.794\n",
      "Epoch: 606/4000..  Training Loss: 0.077..  Test Loss: 0.958..  Test Accuracy: 0.796\n",
      "Epoch: 607/4000..  Training Loss: 0.042..  Test Loss: 0.996..  Test Accuracy: 0.792\n",
      "Epoch: 608/4000..  Training Loss: 0.068..  Test Loss: 0.991..  Test Accuracy: 0.793\n",
      "Epoch: 609/4000..  Training Loss: 0.054..  Test Loss: 1.011..  Test Accuracy: 0.790\n",
      "Epoch: 610/4000..  Training Loss: 0.059..  Test Loss: 0.977..  Test Accuracy: 0.793\n",
      "Epoch: 611/4000..  Training Loss: 0.080..  Test Loss: 0.951..  Test Accuracy: 0.796\n",
      "Epoch: 612/4000..  Training Loss: 0.107..  Test Loss: 0.908..  Test Accuracy: 0.803\n",
      "Epoch: 613/4000..  Training Loss: 0.054..  Test Loss: 1.021..  Test Accuracy: 0.789\n",
      "Epoch: 614/4000..  Training Loss: 0.070..  Test Loss: 0.960..  Test Accuracy: 0.797\n",
      "Epoch: 615/4000..  Training Loss: 0.081..  Test Loss: 0.971..  Test Accuracy: 0.795\n",
      "Epoch: 616/4000..  Training Loss: 0.082..  Test Loss: 0.989..  Test Accuracy: 0.794\n",
      "Epoch: 617/4000..  Training Loss: 0.059..  Test Loss: 0.977..  Test Accuracy: 0.796\n",
      "Epoch: 618/4000..  Training Loss: 0.060..  Test Loss: 1.000..  Test Accuracy: 0.793\n",
      "Epoch: 619/4000..  Training Loss: 0.043..  Test Loss: 0.974..  Test Accuracy: 0.797\n",
      "Epoch: 620/4000..  Training Loss: 0.035..  Test Loss: 0.956..  Test Accuracy: 0.799\n",
      "Epoch: 621/4000..  Training Loss: 0.055..  Test Loss: 0.894..  Test Accuracy: 0.806\n",
      "Epoch: 622/4000..  Training Loss: 0.055..  Test Loss: 0.986..  Test Accuracy: 0.792\n",
      "Epoch: 623/4000..  Training Loss: 0.089..  Test Loss: 0.984..  Test Accuracy: 0.795\n",
      "Epoch: 624/4000..  Training Loss: 0.081..  Test Loss: 0.959..  Test Accuracy: 0.796\n",
      "Epoch: 625/4000..  Training Loss: 0.053..  Test Loss: 0.998..  Test Accuracy: 0.791\n",
      "Epoch: 626/4000..  Training Loss: 0.092..  Test Loss: 1.071..  Test Accuracy: 0.783\n",
      "Epoch: 627/4000..  Training Loss: 0.028..  Test Loss: 0.993..  Test Accuracy: 0.794\n",
      "Epoch: 628/4000..  Training Loss: 0.036..  Test Loss: 1.009..  Test Accuracy: 0.791\n",
      "Epoch: 629/4000..  Training Loss: 0.044..  Test Loss: 0.980..  Test Accuracy: 0.797\n",
      "Epoch: 630/4000..  Training Loss: 0.064..  Test Loss: 0.944..  Test Accuracy: 0.800\n",
      "Epoch: 631/4000..  Training Loss: 0.057..  Test Loss: 1.037..  Test Accuracy: 0.789\n",
      "Epoch: 632/4000..  Training Loss: 0.046..  Test Loss: 1.058..  Test Accuracy: 0.782\n",
      "Epoch: 633/4000..  Training Loss: 0.062..  Test Loss: 1.027..  Test Accuracy: 0.785\n",
      "Epoch: 634/4000..  Training Loss: 0.060..  Test Loss: 0.963..  Test Accuracy: 0.798\n",
      "Epoch: 635/4000..  Training Loss: 0.046..  Test Loss: 1.019..  Test Accuracy: 0.791\n",
      "Epoch: 636/4000..  Training Loss: 0.048..  Test Loss: 0.960..  Test Accuracy: 0.796\n",
      "Epoch: 637/4000..  Training Loss: 0.062..  Test Loss: 0.976..  Test Accuracy: 0.796\n",
      "Epoch: 638/4000..  Training Loss: 0.059..  Test Loss: 0.981..  Test Accuracy: 0.796\n",
      "Epoch: 639/4000..  Training Loss: 0.057..  Test Loss: 0.958..  Test Accuracy: 0.798\n",
      "Epoch: 640/4000..  Training Loss: 0.039..  Test Loss: 1.001..  Test Accuracy: 0.793\n",
      "Epoch: 641/4000..  Training Loss: 0.049..  Test Loss: 0.959..  Test Accuracy: 0.799\n",
      "Epoch: 642/4000..  Training Loss: 0.032..  Test Loss: 0.948..  Test Accuracy: 0.801\n",
      "Epoch: 643/4000..  Training Loss: 0.048..  Test Loss: 0.963..  Test Accuracy: 0.799\n",
      "Epoch: 644/4000..  Training Loss: 0.051..  Test Loss: 0.958..  Test Accuracy: 0.800\n",
      "Epoch: 645/4000..  Training Loss: 0.072..  Test Loss: 1.013..  Test Accuracy: 0.793\n",
      "Epoch: 646/4000..  Training Loss: 0.051..  Test Loss: 1.014..  Test Accuracy: 0.793\n",
      "Epoch: 647/4000..  Training Loss: 0.040..  Test Loss: 0.990..  Test Accuracy: 0.798\n",
      "Epoch: 648/4000..  Training Loss: 0.069..  Test Loss: 0.946..  Test Accuracy: 0.802\n",
      "Epoch: 649/4000..  Training Loss: 0.052..  Test Loss: 0.994..  Test Accuracy: 0.794\n",
      "Epoch: 650/4000..  Training Loss: 0.052..  Test Loss: 0.951..  Test Accuracy: 0.800\n",
      "Epoch: 651/4000..  Training Loss: 0.057..  Test Loss: 0.893..  Test Accuracy: 0.808\n",
      "Epoch: 652/4000..  Training Loss: 0.054..  Test Loss: 0.972..  Test Accuracy: 0.798\n",
      "Epoch: 653/4000..  Training Loss: 0.065..  Test Loss: 0.975..  Test Accuracy: 0.796\n",
      "Epoch: 654/4000..  Training Loss: 0.108..  Test Loss: 1.026..  Test Accuracy: 0.789\n",
      "Epoch: 655/4000..  Training Loss: 0.054..  Test Loss: 1.005..  Test Accuracy: 0.792\n",
      "Epoch: 656/4000..  Training Loss: 0.033..  Test Loss: 0.964..  Test Accuracy: 0.799\n",
      "Epoch: 657/4000..  Training Loss: 0.065..  Test Loss: 0.954..  Test Accuracy: 0.799\n",
      "Epoch: 658/4000..  Training Loss: 0.043..  Test Loss: 0.976..  Test Accuracy: 0.797\n",
      "Epoch: 659/4000..  Training Loss: 0.051..  Test Loss: 0.986..  Test Accuracy: 0.796\n",
      "Epoch: 660/4000..  Training Loss: 0.048..  Test Loss: 0.948..  Test Accuracy: 0.800\n",
      "Epoch: 661/4000..  Training Loss: 0.044..  Test Loss: 1.011..  Test Accuracy: 0.792\n",
      "Epoch: 662/4000..  Training Loss: 0.056..  Test Loss: 0.975..  Test Accuracy: 0.798\n",
      "Epoch: 663/4000..  Training Loss: 0.084..  Test Loss: 0.935..  Test Accuracy: 0.804\n",
      "Epoch: 664/4000..  Training Loss: 0.074..  Test Loss: 1.016..  Test Accuracy: 0.790\n",
      "Epoch: 665/4000..  Training Loss: 0.053..  Test Loss: 1.005..  Test Accuracy: 0.794\n",
      "Epoch: 666/4000..  Training Loss: 0.045..  Test Loss: 0.966..  Test Accuracy: 0.799\n",
      "Epoch: 667/4000..  Training Loss: 0.057..  Test Loss: 0.971..  Test Accuracy: 0.801\n",
      "Epoch: 668/4000..  Training Loss: 0.040..  Test Loss: 0.968..  Test Accuracy: 0.795\n",
      "Epoch: 669/4000..  Training Loss: 0.064..  Test Loss: 0.982..  Test Accuracy: 0.799\n",
      "Epoch: 670/4000..  Training Loss: 0.059..  Test Loss: 0.940..  Test Accuracy: 0.802\n",
      "Epoch: 671/4000..  Training Loss: 0.066..  Test Loss: 0.976..  Test Accuracy: 0.797\n",
      "Epoch: 672/4000..  Training Loss: 0.069..  Test Loss: 0.947..  Test Accuracy: 0.801\n",
      "Epoch: 673/4000..  Training Loss: 0.084..  Test Loss: 1.002..  Test Accuracy: 0.793\n",
      "Epoch: 674/4000..  Training Loss: 0.050..  Test Loss: 1.009..  Test Accuracy: 0.793\n",
      "Epoch: 675/4000..  Training Loss: 0.060..  Test Loss: 0.967..  Test Accuracy: 0.801\n",
      "Epoch: 676/4000..  Training Loss: 0.071..  Test Loss: 1.014..  Test Accuracy: 0.796\n",
      "Epoch: 677/4000..  Training Loss: 0.033..  Test Loss: 0.974..  Test Accuracy: 0.800\n",
      "Epoch: 678/4000..  Training Loss: 0.049..  Test Loss: 0.964..  Test Accuracy: 0.800\n",
      "Epoch: 679/4000..  Training Loss: 0.056..  Test Loss: 1.004..  Test Accuracy: 0.795\n",
      "Epoch: 680/4000..  Training Loss: 0.041..  Test Loss: 0.952..  Test Accuracy: 0.803\n",
      "Epoch: 681/4000..  Training Loss: 0.060..  Test Loss: 0.978..  Test Accuracy: 0.799\n",
      "Epoch: 682/4000..  Training Loss: 0.059..  Test Loss: 0.958..  Test Accuracy: 0.799\n",
      "Epoch: 683/4000..  Training Loss: 0.044..  Test Loss: 0.988..  Test Accuracy: 0.798\n",
      "Epoch: 684/4000..  Training Loss: 0.060..  Test Loss: 0.979..  Test Accuracy: 0.799\n",
      "Epoch: 685/4000..  Training Loss: 0.031..  Test Loss: 0.954..  Test Accuracy: 0.800\n",
      "Epoch: 686/4000..  Training Loss: 0.039..  Test Loss: 0.917..  Test Accuracy: 0.807\n",
      "Epoch: 687/4000..  Training Loss: 0.067..  Test Loss: 0.962..  Test Accuracy: 0.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 688/4000..  Training Loss: 0.040..  Test Loss: 0.934..  Test Accuracy: 0.802\n",
      "Epoch: 689/4000..  Training Loss: 0.054..  Test Loss: 0.939..  Test Accuracy: 0.803\n",
      "Epoch: 690/4000..  Training Loss: 0.040..  Test Loss: 0.911..  Test Accuracy: 0.805\n",
      "Epoch: 691/4000..  Training Loss: 0.042..  Test Loss: 0.966..  Test Accuracy: 0.800\n",
      "Epoch: 692/4000..  Training Loss: 0.083..  Test Loss: 0.971..  Test Accuracy: 0.794\n",
      "Epoch: 693/4000..  Training Loss: 0.047..  Test Loss: 0.918..  Test Accuracy: 0.807\n",
      "Epoch: 694/4000..  Training Loss: 0.047..  Test Loss: 0.949..  Test Accuracy: 0.804\n",
      "Epoch: 695/4000..  Training Loss: 0.055..  Test Loss: 0.965..  Test Accuracy: 0.800\n",
      "Epoch: 696/4000..  Training Loss: 0.036..  Test Loss: 0.991..  Test Accuracy: 0.798\n",
      "Epoch: 697/4000..  Training Loss: 0.039..  Test Loss: 1.004..  Test Accuracy: 0.796\n",
      "Epoch: 698/4000..  Training Loss: 0.049..  Test Loss: 1.020..  Test Accuracy: 0.793\n",
      "Epoch: 699/4000..  Training Loss: 0.047..  Test Loss: 0.974..  Test Accuracy: 0.802\n",
      "Epoch: 700/4000..  Training Loss: 0.043..  Test Loss: 1.011..  Test Accuracy: 0.793\n",
      "Epoch: 701/4000..  Training Loss: 0.042..  Test Loss: 0.995..  Test Accuracy: 0.796\n",
      "Epoch: 702/4000..  Training Loss: 0.055..  Test Loss: 0.989..  Test Accuracy: 0.795\n",
      "Epoch: 703/4000..  Training Loss: 0.046..  Test Loss: 0.976..  Test Accuracy: 0.803\n",
      "Epoch: 704/4000..  Training Loss: 0.042..  Test Loss: 1.049..  Test Accuracy: 0.792\n",
      "Epoch: 705/4000..  Training Loss: 0.061..  Test Loss: 0.972..  Test Accuracy: 0.799\n",
      "Epoch: 706/4000..  Training Loss: 0.060..  Test Loss: 0.996..  Test Accuracy: 0.792\n",
      "Epoch: 707/4000..  Training Loss: 0.063..  Test Loss: 0.979..  Test Accuracy: 0.802\n",
      "Epoch: 708/4000..  Training Loss: 0.062..  Test Loss: 0.972..  Test Accuracy: 0.801\n",
      "Epoch: 709/4000..  Training Loss: 0.067..  Test Loss: 0.969..  Test Accuracy: 0.801\n",
      "Epoch: 710/4000..  Training Loss: 0.061..  Test Loss: 1.007..  Test Accuracy: 0.791\n",
      "Epoch: 711/4000..  Training Loss: 0.046..  Test Loss: 0.994..  Test Accuracy: 0.798\n",
      "Epoch: 712/4000..  Training Loss: 0.033..  Test Loss: 1.011..  Test Accuracy: 0.798\n",
      "Epoch: 713/4000..  Training Loss: 0.029..  Test Loss: 1.014..  Test Accuracy: 0.796\n",
      "Epoch: 714/4000..  Training Loss: 0.042..  Test Loss: 0.957..  Test Accuracy: 0.804\n",
      "Epoch: 715/4000..  Training Loss: 0.044..  Test Loss: 0.955..  Test Accuracy: 0.805\n",
      "Epoch: 716/4000..  Training Loss: 0.047..  Test Loss: 1.003..  Test Accuracy: 0.795\n",
      "Epoch: 717/4000..  Training Loss: 0.072..  Test Loss: 0.969..  Test Accuracy: 0.799\n",
      "Epoch: 718/4000..  Training Loss: 0.069..  Test Loss: 0.967..  Test Accuracy: 0.802\n",
      "Epoch: 719/4000..  Training Loss: 0.026..  Test Loss: 0.954..  Test Accuracy: 0.804\n",
      "Epoch: 720/4000..  Training Loss: 0.046..  Test Loss: 0.985..  Test Accuracy: 0.800\n",
      "Epoch: 721/4000..  Training Loss: 0.041..  Test Loss: 0.950..  Test Accuracy: 0.803\n",
      "Epoch: 722/4000..  Training Loss: 0.061..  Test Loss: 1.055..  Test Accuracy: 0.787\n",
      "Epoch: 723/4000..  Training Loss: 0.066..  Test Loss: 1.004..  Test Accuracy: 0.797\n",
      "Epoch: 724/4000..  Training Loss: 0.056..  Test Loss: 0.943..  Test Accuracy: 0.805\n",
      "Epoch: 725/4000..  Training Loss: 0.037..  Test Loss: 0.991..  Test Accuracy: 0.800\n",
      "Epoch: 726/4000..  Training Loss: 0.057..  Test Loss: 1.056..  Test Accuracy: 0.788\n",
      "Epoch: 727/4000..  Training Loss: 0.059..  Test Loss: 1.051..  Test Accuracy: 0.792\n",
      "Epoch: 728/4000..  Training Loss: 0.041..  Test Loss: 0.996..  Test Accuracy: 0.799\n",
      "Epoch: 729/4000..  Training Loss: 0.048..  Test Loss: 0.983..  Test Accuracy: 0.799\n",
      "Epoch: 730/4000..  Training Loss: 0.044..  Test Loss: 1.026..  Test Accuracy: 0.795\n",
      "Epoch: 731/4000..  Training Loss: 0.052..  Test Loss: 0.997..  Test Accuracy: 0.798\n",
      "Epoch: 732/4000..  Training Loss: 0.061..  Test Loss: 0.977..  Test Accuracy: 0.801\n",
      "Epoch: 733/4000..  Training Loss: 0.039..  Test Loss: 0.981..  Test Accuracy: 0.800\n",
      "Epoch: 734/4000..  Training Loss: 0.064..  Test Loss: 0.946..  Test Accuracy: 0.806\n",
      "Epoch: 735/4000..  Training Loss: 0.049..  Test Loss: 0.991..  Test Accuracy: 0.799\n",
      "Epoch: 736/4000..  Training Loss: 0.063..  Test Loss: 0.949..  Test Accuracy: 0.808\n",
      "Epoch: 737/4000..  Training Loss: 0.035..  Test Loss: 0.971..  Test Accuracy: 0.804\n",
      "Epoch: 738/4000..  Training Loss: 0.046..  Test Loss: 0.986..  Test Accuracy: 0.800\n",
      "Epoch: 739/4000..  Training Loss: 0.048..  Test Loss: 0.983..  Test Accuracy: 0.803\n",
      "Epoch: 740/4000..  Training Loss: 0.032..  Test Loss: 0.984..  Test Accuracy: 0.803\n",
      "Epoch: 741/4000..  Training Loss: 0.067..  Test Loss: 0.923..  Test Accuracy: 0.806\n",
      "Epoch: 742/4000..  Training Loss: 0.045..  Test Loss: 0.977..  Test Accuracy: 0.802\n",
      "Epoch: 743/4000..  Training Loss: 0.032..  Test Loss: 1.005..  Test Accuracy: 0.798\n",
      "Epoch: 744/4000..  Training Loss: 0.041..  Test Loss: 0.995..  Test Accuracy: 0.798\n",
      "Epoch: 745/4000..  Training Loss: 0.074..  Test Loss: 1.042..  Test Accuracy: 0.794\n",
      "Epoch: 746/4000..  Training Loss: 0.043..  Test Loss: 0.957..  Test Accuracy: 0.805\n",
      "Epoch: 747/4000..  Training Loss: 0.094..  Test Loss: 0.985..  Test Accuracy: 0.800\n",
      "Epoch: 748/4000..  Training Loss: 0.051..  Test Loss: 0.969..  Test Accuracy: 0.803\n",
      "Epoch: 749/4000..  Training Loss: 0.045..  Test Loss: 1.005..  Test Accuracy: 0.799\n",
      "Epoch: 750/4000..  Training Loss: 0.055..  Test Loss: 0.977..  Test Accuracy: 0.801\n",
      "Epoch: 751/4000..  Training Loss: 0.046..  Test Loss: 0.951..  Test Accuracy: 0.804\n",
      "Epoch: 752/4000..  Training Loss: 0.058..  Test Loss: 0.924..  Test Accuracy: 0.807\n",
      "Epoch: 753/4000..  Training Loss: 0.046..  Test Loss: 0.982..  Test Accuracy: 0.801\n",
      "Epoch: 754/4000..  Training Loss: 0.040..  Test Loss: 0.966..  Test Accuracy: 0.804\n",
      "Epoch: 755/4000..  Training Loss: 0.041..  Test Loss: 1.078..  Test Accuracy: 0.789\n",
      "Epoch: 756/4000..  Training Loss: 0.063..  Test Loss: 0.987..  Test Accuracy: 0.800\n",
      "Epoch: 757/4000..  Training Loss: 0.043..  Test Loss: 0.995..  Test Accuracy: 0.798\n",
      "Epoch: 758/4000..  Training Loss: 0.059..  Test Loss: 0.951..  Test Accuracy: 0.805\n",
      "Epoch: 759/4000..  Training Loss: 0.033..  Test Loss: 0.975..  Test Accuracy: 0.803\n",
      "Epoch: 760/4000..  Training Loss: 0.068..  Test Loss: 1.036..  Test Accuracy: 0.794\n",
      "Epoch: 761/4000..  Training Loss: 0.029..  Test Loss: 1.017..  Test Accuracy: 0.800\n",
      "Epoch: 762/4000..  Training Loss: 0.036..  Test Loss: 0.991..  Test Accuracy: 0.801\n",
      "Epoch: 763/4000..  Training Loss: 0.034..  Test Loss: 1.016..  Test Accuracy: 0.798\n",
      "Epoch: 764/4000..  Training Loss: 0.066..  Test Loss: 0.961..  Test Accuracy: 0.803\n",
      "Epoch: 765/4000..  Training Loss: 0.031..  Test Loss: 0.950..  Test Accuracy: 0.806\n",
      "Epoch: 766/4000..  Training Loss: 0.037..  Test Loss: 0.969..  Test Accuracy: 0.804\n",
      "Epoch: 767/4000..  Training Loss: 0.044..  Test Loss: 1.000..  Test Accuracy: 0.801\n",
      "Epoch: 768/4000..  Training Loss: 0.017..  Test Loss: 0.990..  Test Accuracy: 0.802\n",
      "Epoch: 769/4000..  Training Loss: 0.040..  Test Loss: 1.026..  Test Accuracy: 0.796\n",
      "Epoch: 770/4000..  Training Loss: 0.050..  Test Loss: 0.968..  Test Accuracy: 0.804\n",
      "Epoch: 771/4000..  Training Loss: 0.040..  Test Loss: 0.964..  Test Accuracy: 0.803\n",
      "Epoch: 772/4000..  Training Loss: 0.046..  Test Loss: 1.014..  Test Accuracy: 0.798\n",
      "Epoch: 773/4000..  Training Loss: 0.058..  Test Loss: 0.942..  Test Accuracy: 0.807\n",
      "Epoch: 774/4000..  Training Loss: 0.036..  Test Loss: 0.967..  Test Accuracy: 0.806\n",
      "Epoch: 775/4000..  Training Loss: 0.052..  Test Loss: 0.997..  Test Accuracy: 0.802\n",
      "Epoch: 776/4000..  Training Loss: 0.045..  Test Loss: 0.997..  Test Accuracy: 0.802\n",
      "Epoch: 777/4000..  Training Loss: 0.045..  Test Loss: 1.008..  Test Accuracy: 0.801\n",
      "Epoch: 778/4000..  Training Loss: 0.057..  Test Loss: 1.017..  Test Accuracy: 0.798\n",
      "Epoch: 779/4000..  Training Loss: 0.066..  Test Loss: 0.968..  Test Accuracy: 0.804\n",
      "Epoch: 780/4000..  Training Loss: 0.083..  Test Loss: 0.994..  Test Accuracy: 0.803\n",
      "Epoch: 781/4000..  Training Loss: 0.046..  Test Loss: 1.008..  Test Accuracy: 0.796\n",
      "Epoch: 782/4000..  Training Loss: 0.042..  Test Loss: 0.997..  Test Accuracy: 0.800\n",
      "Epoch: 783/4000..  Training Loss: 0.060..  Test Loss: 0.978..  Test Accuracy: 0.802\n",
      "Epoch: 784/4000..  Training Loss: 0.026..  Test Loss: 0.931..  Test Accuracy: 0.810\n",
      "Epoch: 785/4000..  Training Loss: 0.019..  Test Loss: 0.975..  Test Accuracy: 0.805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 786/4000..  Training Loss: 0.028..  Test Loss: 0.972..  Test Accuracy: 0.805\n",
      "Epoch: 787/4000..  Training Loss: 0.061..  Test Loss: 0.952..  Test Accuracy: 0.810\n",
      "Epoch: 788/4000..  Training Loss: 0.042..  Test Loss: 0.988..  Test Accuracy: 0.804\n",
      "Epoch: 789/4000..  Training Loss: 0.032..  Test Loss: 0.964..  Test Accuracy: 0.807\n",
      "Epoch: 790/4000..  Training Loss: 0.023..  Test Loss: 0.969..  Test Accuracy: 0.806\n",
      "Epoch: 791/4000..  Training Loss: 0.053..  Test Loss: 1.000..  Test Accuracy: 0.799\n",
      "Epoch: 792/4000..  Training Loss: 0.041..  Test Loss: 0.964..  Test Accuracy: 0.804\n",
      "Epoch: 793/4000..  Training Loss: 0.030..  Test Loss: 1.014..  Test Accuracy: 0.799\n",
      "Epoch: 794/4000..  Training Loss: 0.044..  Test Loss: 0.959..  Test Accuracy: 0.806\n",
      "Epoch: 795/4000..  Training Loss: 0.039..  Test Loss: 1.046..  Test Accuracy: 0.796\n",
      "Epoch: 796/4000..  Training Loss: 0.048..  Test Loss: 1.010..  Test Accuracy: 0.801\n",
      "Epoch: 797/4000..  Training Loss: 0.040..  Test Loss: 0.970..  Test Accuracy: 0.804\n",
      "Epoch: 798/4000..  Training Loss: 0.037..  Test Loss: 0.989..  Test Accuracy: 0.803\n",
      "Epoch: 799/4000..  Training Loss: 0.058..  Test Loss: 0.978..  Test Accuracy: 0.804\n",
      "Epoch: 800/4000..  Training Loss: 0.044..  Test Loss: 0.994..  Test Accuracy: 0.798\n",
      "Epoch: 801/4000..  Training Loss: 0.036..  Test Loss: 0.963..  Test Accuracy: 0.806\n",
      "Epoch: 802/4000..  Training Loss: 0.020..  Test Loss: 0.967..  Test Accuracy: 0.805\n",
      "Epoch: 803/4000..  Training Loss: 0.061..  Test Loss: 0.965..  Test Accuracy: 0.806\n",
      "Epoch: 804/4000..  Training Loss: 0.055..  Test Loss: 0.997..  Test Accuracy: 0.800\n",
      "Epoch: 805/4000..  Training Loss: 0.045..  Test Loss: 0.935..  Test Accuracy: 0.811\n",
      "Epoch: 806/4000..  Training Loss: 0.049..  Test Loss: 1.004..  Test Accuracy: 0.800\n",
      "Epoch: 807/4000..  Training Loss: 0.046..  Test Loss: 0.999..  Test Accuracy: 0.798\n",
      "Epoch: 808/4000..  Training Loss: 0.037..  Test Loss: 0.988..  Test Accuracy: 0.801\n",
      "Epoch: 809/4000..  Training Loss: 0.070..  Test Loss: 0.988..  Test Accuracy: 0.799\n",
      "Epoch: 810/4000..  Training Loss: 0.046..  Test Loss: 0.995..  Test Accuracy: 0.801\n",
      "Epoch: 811/4000..  Training Loss: 0.040..  Test Loss: 0.936..  Test Accuracy: 0.808\n",
      "Epoch: 812/4000..  Training Loss: 0.031..  Test Loss: 0.949..  Test Accuracy: 0.809\n",
      "Epoch: 813/4000..  Training Loss: 0.082..  Test Loss: 1.033..  Test Accuracy: 0.795\n",
      "Epoch: 814/4000..  Training Loss: 0.059..  Test Loss: 0.923..  Test Accuracy: 0.816\n",
      "Epoch: 815/4000..  Training Loss: 0.039..  Test Loss: 0.952..  Test Accuracy: 0.809\n",
      "Epoch: 816/4000..  Training Loss: 0.041..  Test Loss: 0.981..  Test Accuracy: 0.805\n",
      "Epoch: 817/4000..  Training Loss: 0.044..  Test Loss: 0.996..  Test Accuracy: 0.801\n",
      "Epoch: 818/4000..  Training Loss: 0.025..  Test Loss: 1.007..  Test Accuracy: 0.800\n",
      "Epoch: 819/4000..  Training Loss: 0.033..  Test Loss: 0.964..  Test Accuracy: 0.806\n",
      "Epoch: 820/4000..  Training Loss: 0.058..  Test Loss: 0.965..  Test Accuracy: 0.806\n",
      "Epoch: 821/4000..  Training Loss: 0.038..  Test Loss: 0.961..  Test Accuracy: 0.808\n",
      "Epoch: 822/4000..  Training Loss: 0.079..  Test Loss: 0.956..  Test Accuracy: 0.808\n",
      "Epoch: 823/4000..  Training Loss: 0.035..  Test Loss: 0.968..  Test Accuracy: 0.806\n",
      "Epoch: 824/4000..  Training Loss: 0.031..  Test Loss: 1.060..  Test Accuracy: 0.795\n",
      "Epoch: 825/4000..  Training Loss: 0.073..  Test Loss: 1.014..  Test Accuracy: 0.802\n",
      "Epoch: 826/4000..  Training Loss: 0.065..  Test Loss: 0.969..  Test Accuracy: 0.805\n",
      "Epoch: 827/4000..  Training Loss: 0.045..  Test Loss: 0.966..  Test Accuracy: 0.809\n",
      "Epoch: 828/4000..  Training Loss: 0.039..  Test Loss: 0.967..  Test Accuracy: 0.805\n",
      "Epoch: 829/4000..  Training Loss: 0.048..  Test Loss: 0.957..  Test Accuracy: 0.805\n",
      "Epoch: 830/4000..  Training Loss: 0.031..  Test Loss: 0.944..  Test Accuracy: 0.806\n",
      "Epoch: 831/4000..  Training Loss: 0.017..  Test Loss: 0.950..  Test Accuracy: 0.808\n",
      "Epoch: 832/4000..  Training Loss: 0.036..  Test Loss: 0.962..  Test Accuracy: 0.809\n",
      "Epoch: 833/4000..  Training Loss: 0.040..  Test Loss: 0.960..  Test Accuracy: 0.810\n",
      "Epoch: 834/4000..  Training Loss: 0.032..  Test Loss: 0.971..  Test Accuracy: 0.806\n",
      "Epoch: 835/4000..  Training Loss: 0.060..  Test Loss: 0.990..  Test Accuracy: 0.802\n",
      "Epoch: 836/4000..  Training Loss: 0.070..  Test Loss: 0.942..  Test Accuracy: 0.807\n",
      "Epoch: 837/4000..  Training Loss: 0.046..  Test Loss: 0.970..  Test Accuracy: 0.808\n",
      "Epoch: 838/4000..  Training Loss: 0.043..  Test Loss: 1.024..  Test Accuracy: 0.798\n",
      "Epoch: 839/4000..  Training Loss: 0.042..  Test Loss: 0.986..  Test Accuracy: 0.807\n",
      "Epoch: 840/4000..  Training Loss: 0.036..  Test Loss: 0.907..  Test Accuracy: 0.815\n",
      "Epoch: 841/4000..  Training Loss: 0.038..  Test Loss: 0.947..  Test Accuracy: 0.811\n",
      "Epoch: 842/4000..  Training Loss: 0.080..  Test Loss: 0.929..  Test Accuracy: 0.813\n",
      "Epoch: 843/4000..  Training Loss: 0.056..  Test Loss: 0.943..  Test Accuracy: 0.811\n",
      "Epoch: 844/4000..  Training Loss: 0.062..  Test Loss: 1.002..  Test Accuracy: 0.798\n",
      "Epoch: 845/4000..  Training Loss: 0.050..  Test Loss: 0.997..  Test Accuracy: 0.803\n",
      "Epoch: 846/4000..  Training Loss: 0.023..  Test Loss: 0.988..  Test Accuracy: 0.805\n",
      "Epoch: 847/4000..  Training Loss: 0.026..  Test Loss: 0.996..  Test Accuracy: 0.804\n",
      "Epoch: 848/4000..  Training Loss: 0.046..  Test Loss: 1.009..  Test Accuracy: 0.802\n",
      "Epoch: 849/4000..  Training Loss: 0.032..  Test Loss: 0.999..  Test Accuracy: 0.805\n",
      "Epoch: 850/4000..  Training Loss: 0.044..  Test Loss: 1.044..  Test Accuracy: 0.798\n",
      "Epoch: 851/4000..  Training Loss: 0.049..  Test Loss: 1.023..  Test Accuracy: 0.798\n",
      "Epoch: 852/4000..  Training Loss: 0.042..  Test Loss: 0.972..  Test Accuracy: 0.807\n",
      "Epoch: 853/4000..  Training Loss: 0.036..  Test Loss: 1.012..  Test Accuracy: 0.800\n",
      "Epoch: 854/4000..  Training Loss: 0.049..  Test Loss: 0.971..  Test Accuracy: 0.805\n",
      "Epoch: 855/4000..  Training Loss: 0.018..  Test Loss: 0.979..  Test Accuracy: 0.807\n",
      "Epoch: 856/4000..  Training Loss: 0.056..  Test Loss: 0.961..  Test Accuracy: 0.809\n",
      "Epoch: 857/4000..  Training Loss: 0.044..  Test Loss: 0.960..  Test Accuracy: 0.809\n",
      "Epoch: 858/4000..  Training Loss: 0.027..  Test Loss: 0.981..  Test Accuracy: 0.809\n",
      "Epoch: 859/4000..  Training Loss: 0.029..  Test Loss: 0.964..  Test Accuracy: 0.805\n",
      "Epoch: 860/4000..  Training Loss: 0.065..  Test Loss: 0.925..  Test Accuracy: 0.814\n",
      "Epoch: 861/4000..  Training Loss: 0.022..  Test Loss: 0.970..  Test Accuracy: 0.809\n",
      "Epoch: 862/4000..  Training Loss: 0.037..  Test Loss: 0.987..  Test Accuracy: 0.804\n",
      "Epoch: 863/4000..  Training Loss: 0.021..  Test Loss: 0.965..  Test Accuracy: 0.809\n",
      "Epoch: 864/4000..  Training Loss: 0.026..  Test Loss: 1.004..  Test Accuracy: 0.803\n",
      "Epoch: 865/4000..  Training Loss: 0.031..  Test Loss: 0.966..  Test Accuracy: 0.812\n",
      "Epoch: 866/4000..  Training Loss: 0.032..  Test Loss: 0.963..  Test Accuracy: 0.807\n",
      "Epoch: 867/4000..  Training Loss: 0.053..  Test Loss: 0.932..  Test Accuracy: 0.816\n",
      "Epoch: 868/4000..  Training Loss: 0.053..  Test Loss: 1.040..  Test Accuracy: 0.802\n",
      "Epoch: 869/4000..  Training Loss: 0.038..  Test Loss: 1.024..  Test Accuracy: 0.801\n",
      "Epoch: 870/4000..  Training Loss: 0.050..  Test Loss: 0.957..  Test Accuracy: 0.811\n",
      "Epoch: 871/4000..  Training Loss: 0.060..  Test Loss: 1.036..  Test Accuracy: 0.792\n",
      "Epoch: 872/4000..  Training Loss: 0.034..  Test Loss: 0.939..  Test Accuracy: 0.811\n",
      "Epoch: 873/4000..  Training Loss: 0.044..  Test Loss: 0.939..  Test Accuracy: 0.812\n",
      "Epoch: 874/4000..  Training Loss: 0.034..  Test Loss: 0.994..  Test Accuracy: 0.807\n",
      "Epoch: 875/4000..  Training Loss: 0.051..  Test Loss: 0.966..  Test Accuracy: 0.806\n",
      "Epoch: 876/4000..  Training Loss: 0.043..  Test Loss: 0.979..  Test Accuracy: 0.806\n",
      "Epoch: 877/4000..  Training Loss: 0.056..  Test Loss: 0.964..  Test Accuracy: 0.807\n",
      "Epoch: 878/4000..  Training Loss: 0.026..  Test Loss: 0.989..  Test Accuracy: 0.804\n",
      "Epoch: 879/4000..  Training Loss: 0.062..  Test Loss: 0.945..  Test Accuracy: 0.811\n",
      "Epoch: 880/4000..  Training Loss: 0.025..  Test Loss: 1.010..  Test Accuracy: 0.801\n",
      "Epoch: 881/4000..  Training Loss: 0.034..  Test Loss: 1.028..  Test Accuracy: 0.798\n",
      "Epoch: 882/4000..  Training Loss: 0.065..  Test Loss: 0.996..  Test Accuracy: 0.800\n",
      "Epoch: 883/4000..  Training Loss: 0.030..  Test Loss: 1.009..  Test Accuracy: 0.803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 884/4000..  Training Loss: 0.030..  Test Loss: 0.961..  Test Accuracy: 0.810\n",
      "Epoch: 885/4000..  Training Loss: 0.027..  Test Loss: 0.956..  Test Accuracy: 0.812\n",
      "Epoch: 886/4000..  Training Loss: 0.040..  Test Loss: 0.913..  Test Accuracy: 0.815\n",
      "Epoch: 887/4000..  Training Loss: 0.029..  Test Loss: 0.934..  Test Accuracy: 0.814\n",
      "Epoch: 888/4000..  Training Loss: 0.037..  Test Loss: 0.968..  Test Accuracy: 0.808\n",
      "Epoch: 889/4000..  Training Loss: 0.049..  Test Loss: 0.924..  Test Accuracy: 0.814\n",
      "Epoch: 890/4000..  Training Loss: 0.040..  Test Loss: 0.986..  Test Accuracy: 0.808\n",
      "Epoch: 891/4000..  Training Loss: 0.025..  Test Loss: 0.924..  Test Accuracy: 0.816\n",
      "Epoch: 892/4000..  Training Loss: 0.056..  Test Loss: 0.987..  Test Accuracy: 0.806\n",
      "Epoch: 893/4000..  Training Loss: 0.058..  Test Loss: 0.904..  Test Accuracy: 0.816\n",
      "Epoch: 894/4000..  Training Loss: 0.029..  Test Loss: 0.926..  Test Accuracy: 0.815\n",
      "Epoch: 895/4000..  Training Loss: 0.019..  Test Loss: 0.944..  Test Accuracy: 0.812\n",
      "Epoch: 896/4000..  Training Loss: 0.026..  Test Loss: 0.923..  Test Accuracy: 0.814\n",
      "Epoch: 897/4000..  Training Loss: 0.041..  Test Loss: 0.932..  Test Accuracy: 0.814\n",
      "Epoch: 898/4000..  Training Loss: 0.057..  Test Loss: 0.981..  Test Accuracy: 0.807\n",
      "Epoch: 899/4000..  Training Loss: 0.033..  Test Loss: 1.010..  Test Accuracy: 0.805\n",
      "Epoch: 900/4000..  Training Loss: 0.035..  Test Loss: 0.987..  Test Accuracy: 0.809\n",
      "Epoch: 901/4000..  Training Loss: 0.059..  Test Loss: 0.975..  Test Accuracy: 0.808\n",
      "Epoch: 902/4000..  Training Loss: 0.065..  Test Loss: 0.945..  Test Accuracy: 0.813\n",
      "Epoch: 903/4000..  Training Loss: 0.033..  Test Loss: 1.009..  Test Accuracy: 0.805\n",
      "Epoch: 904/4000..  Training Loss: 0.053..  Test Loss: 0.981..  Test Accuracy: 0.809\n",
      "Epoch: 905/4000..  Training Loss: 0.032..  Test Loss: 0.965..  Test Accuracy: 0.810\n",
      "Epoch: 906/4000..  Training Loss: 0.038..  Test Loss: 0.994..  Test Accuracy: 0.805\n",
      "Epoch: 907/4000..  Training Loss: 0.033..  Test Loss: 0.911..  Test Accuracy: 0.816\n",
      "Epoch: 908/4000..  Training Loss: 0.023..  Test Loss: 0.946..  Test Accuracy: 0.812\n",
      "Epoch: 909/4000..  Training Loss: 0.055..  Test Loss: 0.972..  Test Accuracy: 0.808\n",
      "Epoch: 910/4000..  Training Loss: 0.043..  Test Loss: 0.986..  Test Accuracy: 0.806\n",
      "Epoch: 911/4000..  Training Loss: 0.024..  Test Loss: 1.003..  Test Accuracy: 0.807\n",
      "Epoch: 912/4000..  Training Loss: 0.017..  Test Loss: 0.986..  Test Accuracy: 0.809\n",
      "Epoch: 913/4000..  Training Loss: 0.039..  Test Loss: 1.012..  Test Accuracy: 0.805\n",
      "Epoch: 914/4000..  Training Loss: 0.049..  Test Loss: 1.004..  Test Accuracy: 0.805\n",
      "Epoch: 915/4000..  Training Loss: 0.028..  Test Loss: 1.011..  Test Accuracy: 0.808\n",
      "Epoch: 916/4000..  Training Loss: 0.027..  Test Loss: 0.967..  Test Accuracy: 0.811\n",
      "Epoch: 917/4000..  Training Loss: 0.035..  Test Loss: 0.973..  Test Accuracy: 0.810\n",
      "Epoch: 918/4000..  Training Loss: 0.056..  Test Loss: 1.073..  Test Accuracy: 0.796\n",
      "Epoch: 919/4000..  Training Loss: 0.047..  Test Loss: 0.953..  Test Accuracy: 0.810\n",
      "Epoch: 920/4000..  Training Loss: 0.032..  Test Loss: 0.909..  Test Accuracy: 0.819\n",
      "Epoch: 921/4000..  Training Loss: 0.041..  Test Loss: 0.974..  Test Accuracy: 0.807\n",
      "Epoch: 922/4000..  Training Loss: 0.031..  Test Loss: 0.973..  Test Accuracy: 0.810\n",
      "Epoch: 923/4000..  Training Loss: 0.028..  Test Loss: 0.996..  Test Accuracy: 0.804\n",
      "Epoch: 924/4000..  Training Loss: 0.037..  Test Loss: 1.038..  Test Accuracy: 0.800\n",
      "Epoch: 925/4000..  Training Loss: 0.027..  Test Loss: 0.953..  Test Accuracy: 0.812\n",
      "Epoch: 926/4000..  Training Loss: 0.023..  Test Loss: 0.921..  Test Accuracy: 0.816\n",
      "Epoch: 927/4000..  Training Loss: 0.052..  Test Loss: 0.943..  Test Accuracy: 0.813\n",
      "Epoch: 928/4000..  Training Loss: 0.022..  Test Loss: 0.970..  Test Accuracy: 0.812\n",
      "Epoch: 929/4000..  Training Loss: 0.025..  Test Loss: 0.954..  Test Accuracy: 0.813\n",
      "Epoch: 930/4000..  Training Loss: 0.038..  Test Loss: 0.977..  Test Accuracy: 0.810\n",
      "Epoch: 931/4000..  Training Loss: 0.039..  Test Loss: 0.966..  Test Accuracy: 0.812\n",
      "Epoch: 932/4000..  Training Loss: 0.043..  Test Loss: 0.933..  Test Accuracy: 0.812\n",
      "Epoch: 933/4000..  Training Loss: 0.049..  Test Loss: 1.041..  Test Accuracy: 0.797\n",
      "Epoch: 934/4000..  Training Loss: 0.040..  Test Loss: 0.902..  Test Accuracy: 0.820\n",
      "Epoch: 935/4000..  Training Loss: 0.020..  Test Loss: 0.979..  Test Accuracy: 0.810\n",
      "Epoch: 936/4000..  Training Loss: 0.056..  Test Loss: 1.012..  Test Accuracy: 0.803\n",
      "Epoch: 937/4000..  Training Loss: 0.043..  Test Loss: 0.971..  Test Accuracy: 0.811\n",
      "Epoch: 938/4000..  Training Loss: 0.021..  Test Loss: 0.982..  Test Accuracy: 0.810\n",
      "Epoch: 939/4000..  Training Loss: 0.031..  Test Loss: 0.970..  Test Accuracy: 0.811\n",
      "Epoch: 940/4000..  Training Loss: 0.038..  Test Loss: 0.933..  Test Accuracy: 0.813\n",
      "Epoch: 941/4000..  Training Loss: 0.037..  Test Loss: 0.958..  Test Accuracy: 0.808\n",
      "Epoch: 942/4000..  Training Loss: 0.039..  Test Loss: 0.930..  Test Accuracy: 0.818\n",
      "Epoch: 943/4000..  Training Loss: 0.028..  Test Loss: 0.966..  Test Accuracy: 0.811\n",
      "Epoch: 944/4000..  Training Loss: 0.043..  Test Loss: 1.030..  Test Accuracy: 0.804\n",
      "Epoch: 945/4000..  Training Loss: 0.119..  Test Loss: 0.993..  Test Accuracy: 0.809\n",
      "Epoch: 946/4000..  Training Loss: 0.026..  Test Loss: 0.968..  Test Accuracy: 0.810\n",
      "Epoch: 947/4000..  Training Loss: 0.031..  Test Loss: 0.975..  Test Accuracy: 0.811\n",
      "Epoch: 948/4000..  Training Loss: 0.025..  Test Loss: 1.014..  Test Accuracy: 0.805\n",
      "Epoch: 949/4000..  Training Loss: 0.043..  Test Loss: 0.973..  Test Accuracy: 0.811\n",
      "Epoch: 950/4000..  Training Loss: 0.022..  Test Loss: 0.986..  Test Accuracy: 0.809\n",
      "Epoch: 951/4000..  Training Loss: 0.069..  Test Loss: 0.978..  Test Accuracy: 0.809\n",
      "Epoch: 952/4000..  Training Loss: 0.041..  Test Loss: 0.995..  Test Accuracy: 0.806\n",
      "Epoch: 953/4000..  Training Loss: 0.057..  Test Loss: 0.983..  Test Accuracy: 0.808\n",
      "Epoch: 954/4000..  Training Loss: 0.047..  Test Loss: 0.988..  Test Accuracy: 0.809\n",
      "Epoch: 955/4000..  Training Loss: 0.027..  Test Loss: 1.000..  Test Accuracy: 0.807\n",
      "Epoch: 956/4000..  Training Loss: 0.016..  Test Loss: 0.984..  Test Accuracy: 0.810\n",
      "Epoch: 957/4000..  Training Loss: 0.025..  Test Loss: 0.932..  Test Accuracy: 0.814\n",
      "Epoch: 958/4000..  Training Loss: 0.017..  Test Loss: 0.948..  Test Accuracy: 0.812\n",
      "Epoch: 959/4000..  Training Loss: 0.056..  Test Loss: 1.042..  Test Accuracy: 0.800\n",
      "Epoch: 960/4000..  Training Loss: 0.037..  Test Loss: 1.008..  Test Accuracy: 0.803\n",
      "Epoch: 961/4000..  Training Loss: 0.042..  Test Loss: 1.039..  Test Accuracy: 0.802\n",
      "Epoch: 962/4000..  Training Loss: 0.040..  Test Loss: 0.957..  Test Accuracy: 0.812\n",
      "Epoch: 963/4000..  Training Loss: 0.054..  Test Loss: 0.984..  Test Accuracy: 0.810\n",
      "Epoch: 964/4000..  Training Loss: 0.036..  Test Loss: 0.934..  Test Accuracy: 0.816\n",
      "Epoch: 965/4000..  Training Loss: 0.040..  Test Loss: 1.006..  Test Accuracy: 0.806\n",
      "Epoch: 966/4000..  Training Loss: 0.027..  Test Loss: 0.979..  Test Accuracy: 0.808\n",
      "Epoch: 967/4000..  Training Loss: 0.054..  Test Loss: 0.991..  Test Accuracy: 0.805\n",
      "Epoch: 968/4000..  Training Loss: 0.035..  Test Loss: 0.993..  Test Accuracy: 0.809\n",
      "Epoch: 969/4000..  Training Loss: 0.033..  Test Loss: 1.012..  Test Accuracy: 0.808\n",
      "Epoch: 970/4000..  Training Loss: 0.029..  Test Loss: 0.974..  Test Accuracy: 0.811\n",
      "Epoch: 971/4000..  Training Loss: 0.032..  Test Loss: 0.976..  Test Accuracy: 0.812\n",
      "Epoch: 972/4000..  Training Loss: 0.031..  Test Loss: 1.024..  Test Accuracy: 0.804\n",
      "Epoch: 973/4000..  Training Loss: 0.041..  Test Loss: 0.994..  Test Accuracy: 0.806\n",
      "Epoch: 974/4000..  Training Loss: 0.040..  Test Loss: 0.931..  Test Accuracy: 0.816\n",
      "Epoch: 975/4000..  Training Loss: 0.059..  Test Loss: 0.928..  Test Accuracy: 0.816\n",
      "Epoch: 976/4000..  Training Loss: 0.034..  Test Loss: 0.994..  Test Accuracy: 0.808\n",
      "Epoch: 977/4000..  Training Loss: 0.027..  Test Loss: 1.000..  Test Accuracy: 0.807\n",
      "Epoch: 978/4000..  Training Loss: 0.029..  Test Loss: 1.009..  Test Accuracy: 0.807\n",
      "Epoch: 979/4000..  Training Loss: 0.033..  Test Loss: 0.998..  Test Accuracy: 0.810\n",
      "Epoch: 980/4000..  Training Loss: 0.027..  Test Loss: 0.940..  Test Accuracy: 0.816\n",
      "Epoch: 981/4000..  Training Loss: 0.026..  Test Loss: 0.956..  Test Accuracy: 0.812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 982/4000..  Training Loss: 0.049..  Test Loss: 1.040..  Test Accuracy: 0.802\n",
      "Epoch: 983/4000..  Training Loss: 0.029..  Test Loss: 1.000..  Test Accuracy: 0.808\n",
      "Epoch: 984/4000..  Training Loss: 0.038..  Test Loss: 0.947..  Test Accuracy: 0.817\n",
      "Epoch: 985/4000..  Training Loss: 0.038..  Test Loss: 0.980..  Test Accuracy: 0.806\n",
      "Epoch: 986/4000..  Training Loss: 0.046..  Test Loss: 0.946..  Test Accuracy: 0.815\n",
      "Epoch: 987/4000..  Training Loss: 0.034..  Test Loss: 0.968..  Test Accuracy: 0.811\n",
      "Epoch: 988/4000..  Training Loss: 0.030..  Test Loss: 1.017..  Test Accuracy: 0.806\n",
      "Epoch: 989/4000..  Training Loss: 0.039..  Test Loss: 0.977..  Test Accuracy: 0.811\n",
      "Epoch: 990/4000..  Training Loss: 0.043..  Test Loss: 0.987..  Test Accuracy: 0.809\n",
      "Epoch: 991/4000..  Training Loss: 0.041..  Test Loss: 1.015..  Test Accuracy: 0.806\n",
      "Epoch: 992/4000..  Training Loss: 0.043..  Test Loss: 0.989..  Test Accuracy: 0.809\n",
      "Epoch: 993/4000..  Training Loss: 0.029..  Test Loss: 1.000..  Test Accuracy: 0.807\n",
      "Epoch: 994/4000..  Training Loss: 0.047..  Test Loss: 0.986..  Test Accuracy: 0.808\n",
      "Epoch: 995/4000..  Training Loss: 0.031..  Test Loss: 1.024..  Test Accuracy: 0.803\n",
      "Epoch: 996/4000..  Training Loss: 0.034..  Test Loss: 0.972..  Test Accuracy: 0.812\n",
      "Epoch: 997/4000..  Training Loss: 0.028..  Test Loss: 1.025..  Test Accuracy: 0.805\n",
      "Epoch: 998/4000..  Training Loss: 0.034..  Test Loss: 1.050..  Test Accuracy: 0.802\n",
      "Epoch: 999/4000..  Training Loss: 0.043..  Test Loss: 1.004..  Test Accuracy: 0.806\n",
      "Epoch: 1000/4000..  Training Loss: 0.046..  Test Loss: 1.072..  Test Accuracy: 0.793\n",
      "Epoch: 1001/4000..  Training Loss: 0.027..  Test Loss: 1.063..  Test Accuracy: 0.800\n",
      "Epoch: 1002/4000..  Training Loss: 0.055..  Test Loss: 1.041..  Test Accuracy: 0.803\n",
      "Epoch: 1003/4000..  Training Loss: 0.022..  Test Loss: 1.027..  Test Accuracy: 0.805\n",
      "Epoch: 1004/4000..  Training Loss: 0.024..  Test Loss: 1.085..  Test Accuracy: 0.797\n",
      "Epoch: 1005/4000..  Training Loss: 0.024..  Test Loss: 1.021..  Test Accuracy: 0.805\n",
      "Epoch: 1006/4000..  Training Loss: 0.020..  Test Loss: 1.032..  Test Accuracy: 0.805\n",
      "Epoch: 1007/4000..  Training Loss: 0.024..  Test Loss: 1.016..  Test Accuracy: 0.806\n",
      "Epoch: 1008/4000..  Training Loss: 0.031..  Test Loss: 1.029..  Test Accuracy: 0.804\n",
      "Epoch: 1009/4000..  Training Loss: 0.044..  Test Loss: 1.020..  Test Accuracy: 0.807\n",
      "Epoch: 1010/4000..  Training Loss: 0.015..  Test Loss: 1.003..  Test Accuracy: 0.808\n",
      "Epoch: 1011/4000..  Training Loss: 0.035..  Test Loss: 0.945..  Test Accuracy: 0.816\n",
      "Epoch: 1012/4000..  Training Loss: 0.042..  Test Loss: 0.987..  Test Accuracy: 0.811\n",
      "Epoch: 1013/4000..  Training Loss: 0.037..  Test Loss: 0.991..  Test Accuracy: 0.811\n",
      "Epoch: 1014/4000..  Training Loss: 0.019..  Test Loss: 1.006..  Test Accuracy: 0.808\n",
      "Epoch: 1015/4000..  Training Loss: 0.031..  Test Loss: 1.094..  Test Accuracy: 0.794\n",
      "Epoch: 1016/4000..  Training Loss: 0.016..  Test Loss: 1.031..  Test Accuracy: 0.805\n",
      "Epoch: 1017/4000..  Training Loss: 0.041..  Test Loss: 1.025..  Test Accuracy: 0.804\n",
      "Epoch: 1018/4000..  Training Loss: 0.074..  Test Loss: 1.029..  Test Accuracy: 0.806\n",
      "Epoch: 1019/4000..  Training Loss: 0.039..  Test Loss: 0.946..  Test Accuracy: 0.816\n",
      "Epoch: 1020/4000..  Training Loss: 0.028..  Test Loss: 1.046..  Test Accuracy: 0.806\n",
      "Epoch: 1021/4000..  Training Loss: 0.042..  Test Loss: 1.095..  Test Accuracy: 0.797\n",
      "Epoch: 1022/4000..  Training Loss: 0.038..  Test Loss: 1.075..  Test Accuracy: 0.798\n",
      "Epoch: 1023/4000..  Training Loss: 0.024..  Test Loss: 1.043..  Test Accuracy: 0.803\n",
      "Epoch: 1024/4000..  Training Loss: 0.038..  Test Loss: 1.141..  Test Accuracy: 0.790\n",
      "Epoch: 1025/4000..  Training Loss: 0.034..  Test Loss: 1.019..  Test Accuracy: 0.805\n",
      "Epoch: 1026/4000..  Training Loss: 0.063..  Test Loss: 0.957..  Test Accuracy: 0.814\n",
      "Epoch: 1027/4000..  Training Loss: 0.041..  Test Loss: 1.083..  Test Accuracy: 0.799\n",
      "Epoch: 1028/4000..  Training Loss: 0.060..  Test Loss: 1.084..  Test Accuracy: 0.797\n",
      "Epoch: 1029/4000..  Training Loss: 0.044..  Test Loss: 1.022..  Test Accuracy: 0.808\n",
      "Epoch: 1030/4000..  Training Loss: 0.039..  Test Loss: 0.986..  Test Accuracy: 0.812\n",
      "Epoch: 1031/4000..  Training Loss: 0.036..  Test Loss: 1.026..  Test Accuracy: 0.808\n",
      "Epoch: 1032/4000..  Training Loss: 0.038..  Test Loss: 0.989..  Test Accuracy: 0.812\n",
      "Epoch: 1033/4000..  Training Loss: 0.032..  Test Loss: 1.027..  Test Accuracy: 0.805\n",
      "Epoch: 1034/4000..  Training Loss: 0.019..  Test Loss: 1.027..  Test Accuracy: 0.807\n",
      "Epoch: 1035/4000..  Training Loss: 0.033..  Test Loss: 0.984..  Test Accuracy: 0.812\n",
      "Epoch: 1036/4000..  Training Loss: 0.023..  Test Loss: 1.014..  Test Accuracy: 0.806\n",
      "Epoch: 1037/4000..  Training Loss: 0.043..  Test Loss: 1.011..  Test Accuracy: 0.808\n",
      "Epoch: 1038/4000..  Training Loss: 0.027..  Test Loss: 1.019..  Test Accuracy: 0.808\n",
      "Epoch: 1039/4000..  Training Loss: 0.022..  Test Loss: 1.003..  Test Accuracy: 0.811\n",
      "Epoch: 1040/4000..  Training Loss: 0.035..  Test Loss: 1.060..  Test Accuracy: 0.803\n",
      "Epoch: 1041/4000..  Training Loss: 0.022..  Test Loss: 1.019..  Test Accuracy: 0.808\n",
      "Epoch: 1042/4000..  Training Loss: 0.035..  Test Loss: 1.022..  Test Accuracy: 0.808\n",
      "Epoch: 1043/4000..  Training Loss: 0.025..  Test Loss: 1.016..  Test Accuracy: 0.808\n",
      "Epoch: 1044/4000..  Training Loss: 0.019..  Test Loss: 1.024..  Test Accuracy: 0.806\n",
      "Epoch: 1045/4000..  Training Loss: 0.034..  Test Loss: 0.986..  Test Accuracy: 0.811\n",
      "Epoch: 1046/4000..  Training Loss: 0.028..  Test Loss: 1.006..  Test Accuracy: 0.806\n",
      "Epoch: 1047/4000..  Training Loss: 0.039..  Test Loss: 0.976..  Test Accuracy: 0.813\n",
      "Epoch: 1048/4000..  Training Loss: 0.041..  Test Loss: 1.070..  Test Accuracy: 0.801\n",
      "Epoch: 1049/4000..  Training Loss: 0.041..  Test Loss: 1.060..  Test Accuracy: 0.798\n",
      "Epoch: 1050/4000..  Training Loss: 0.035..  Test Loss: 1.006..  Test Accuracy: 0.809\n",
      "Epoch: 1051/4000..  Training Loss: 0.032..  Test Loss: 1.012..  Test Accuracy: 0.808\n",
      "Epoch: 1052/4000..  Training Loss: 0.036..  Test Loss: 1.090..  Test Accuracy: 0.798\n",
      "Epoch: 1053/4000..  Training Loss: 0.059..  Test Loss: 0.978..  Test Accuracy: 0.814\n",
      "Epoch: 1054/4000..  Training Loss: 0.019..  Test Loss: 1.023..  Test Accuracy: 0.806\n",
      "Epoch: 1055/4000..  Training Loss: 0.043..  Test Loss: 0.994..  Test Accuracy: 0.810\n",
      "Epoch: 1056/4000..  Training Loss: 0.041..  Test Loss: 0.943..  Test Accuracy: 0.815\n",
      "Epoch: 1057/4000..  Training Loss: 0.037..  Test Loss: 0.991..  Test Accuracy: 0.808\n",
      "Epoch: 1058/4000..  Training Loss: 0.012..  Test Loss: 0.982..  Test Accuracy: 0.812\n",
      "Epoch: 1059/4000..  Training Loss: 0.018..  Test Loss: 1.076..  Test Accuracy: 0.799\n",
      "Epoch: 1060/4000..  Training Loss: 0.026..  Test Loss: 1.016..  Test Accuracy: 0.809\n",
      "Epoch: 1061/4000..  Training Loss: 0.027..  Test Loss: 1.014..  Test Accuracy: 0.809\n",
      "Epoch: 1062/4000..  Training Loss: 0.038..  Test Loss: 1.004..  Test Accuracy: 0.811\n",
      "Epoch: 1063/4000..  Training Loss: 0.023..  Test Loss: 0.997..  Test Accuracy: 0.811\n",
      "Epoch: 1064/4000..  Training Loss: 0.047..  Test Loss: 1.052..  Test Accuracy: 0.802\n",
      "Epoch: 1065/4000..  Training Loss: 0.019..  Test Loss: 0.971..  Test Accuracy: 0.812\n",
      "Epoch: 1066/4000..  Training Loss: 0.019..  Test Loss: 1.049..  Test Accuracy: 0.805\n",
      "Epoch: 1067/4000..  Training Loss: 0.034..  Test Loss: 1.052..  Test Accuracy: 0.804\n",
      "Epoch: 1068/4000..  Training Loss: 0.027..  Test Loss: 1.017..  Test Accuracy: 0.807\n",
      "Epoch: 1069/4000..  Training Loss: 0.047..  Test Loss: 0.977..  Test Accuracy: 0.811\n",
      "Epoch: 1070/4000..  Training Loss: 0.027..  Test Loss: 1.037..  Test Accuracy: 0.802\n",
      "Epoch: 1071/4000..  Training Loss: 0.017..  Test Loss: 1.010..  Test Accuracy: 0.809\n",
      "Epoch: 1072/4000..  Training Loss: 0.041..  Test Loss: 0.975..  Test Accuracy: 0.811\n",
      "Epoch: 1073/4000..  Training Loss: 0.067..  Test Loss: 1.013..  Test Accuracy: 0.810\n",
      "Epoch: 1074/4000..  Training Loss: 0.051..  Test Loss: 1.060..  Test Accuracy: 0.802\n",
      "Epoch: 1075/4000..  Training Loss: 0.030..  Test Loss: 1.115..  Test Accuracy: 0.797\n",
      "Epoch: 1076/4000..  Training Loss: 0.038..  Test Loss: 1.039..  Test Accuracy: 0.807\n",
      "Epoch: 1077/4000..  Training Loss: 0.024..  Test Loss: 1.006..  Test Accuracy: 0.811\n",
      "Epoch: 1078/4000..  Training Loss: 0.035..  Test Loss: 0.982..  Test Accuracy: 0.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1079/4000..  Training Loss: 0.017..  Test Loss: 0.976..  Test Accuracy: 0.813\n",
      "Epoch: 1080/4000..  Training Loss: 0.014..  Test Loss: 0.980..  Test Accuracy: 0.813\n",
      "Epoch: 1081/4000..  Training Loss: 0.032..  Test Loss: 1.038..  Test Accuracy: 0.803\n",
      "Epoch: 1082/4000..  Training Loss: 0.033..  Test Loss: 1.040..  Test Accuracy: 0.808\n",
      "Epoch: 1083/4000..  Training Loss: 0.032..  Test Loss: 1.076..  Test Accuracy: 0.801\n",
      "Epoch: 1084/4000..  Training Loss: 0.032..  Test Loss: 1.033..  Test Accuracy: 0.806\n",
      "Epoch: 1085/4000..  Training Loss: 0.039..  Test Loss: 1.032..  Test Accuracy: 0.807\n",
      "Epoch: 1086/4000..  Training Loss: 0.029..  Test Loss: 1.033..  Test Accuracy: 0.803\n",
      "Epoch: 1087/4000..  Training Loss: 0.036..  Test Loss: 0.975..  Test Accuracy: 0.812\n",
      "Epoch: 1088/4000..  Training Loss: 0.022..  Test Loss: 0.998..  Test Accuracy: 0.811\n",
      "Epoch: 1089/4000..  Training Loss: 0.021..  Test Loss: 0.951..  Test Accuracy: 0.816\n",
      "Epoch: 1090/4000..  Training Loss: 0.019..  Test Loss: 1.013..  Test Accuracy: 0.809\n",
      "Epoch: 1091/4000..  Training Loss: 0.045..  Test Loss: 1.000..  Test Accuracy: 0.811\n",
      "Epoch: 1092/4000..  Training Loss: 0.031..  Test Loss: 0.971..  Test Accuracy: 0.811\n",
      "Epoch: 1093/4000..  Training Loss: 0.025..  Test Loss: 0.942..  Test Accuracy: 0.818\n",
      "Epoch: 1094/4000..  Training Loss: 0.038..  Test Loss: 1.028..  Test Accuracy: 0.808\n",
      "Epoch: 1095/4000..  Training Loss: 0.032..  Test Loss: 1.008..  Test Accuracy: 0.808\n",
      "Epoch: 1096/4000..  Training Loss: 0.025..  Test Loss: 0.988..  Test Accuracy: 0.813\n",
      "Epoch: 1097/4000..  Training Loss: 0.032..  Test Loss: 1.010..  Test Accuracy: 0.807\n",
      "Epoch: 1098/4000..  Training Loss: 0.031..  Test Loss: 1.068..  Test Accuracy: 0.802\n",
      "Epoch: 1099/4000..  Training Loss: 0.051..  Test Loss: 0.977..  Test Accuracy: 0.812\n",
      "Epoch: 1100/4000..  Training Loss: 0.032..  Test Loss: 0.987..  Test Accuracy: 0.814\n",
      "Epoch: 1101/4000..  Training Loss: 0.050..  Test Loss: 0.931..  Test Accuracy: 0.820\n",
      "Epoch: 1102/4000..  Training Loss: 0.029..  Test Loss: 0.935..  Test Accuracy: 0.820\n",
      "Epoch: 1103/4000..  Training Loss: 0.042..  Test Loss: 0.996..  Test Accuracy: 0.812\n",
      "Epoch: 1104/4000..  Training Loss: 0.040..  Test Loss: 1.022..  Test Accuracy: 0.810\n",
      "Epoch: 1105/4000..  Training Loss: 0.029..  Test Loss: 1.029..  Test Accuracy: 0.809\n",
      "Epoch: 1106/4000..  Training Loss: 0.037..  Test Loss: 1.017..  Test Accuracy: 0.808\n",
      "Epoch: 1107/4000..  Training Loss: 0.029..  Test Loss: 0.998..  Test Accuracy: 0.813\n",
      "Epoch: 1108/4000..  Training Loss: 0.016..  Test Loss: 0.980..  Test Accuracy: 0.815\n",
      "Epoch: 1109/4000..  Training Loss: 0.025..  Test Loss: 0.983..  Test Accuracy: 0.813\n",
      "Epoch: 1110/4000..  Training Loss: 0.032..  Test Loss: 1.025..  Test Accuracy: 0.807\n",
      "Epoch: 1111/4000..  Training Loss: 0.022..  Test Loss: 1.027..  Test Accuracy: 0.807\n",
      "Epoch: 1112/4000..  Training Loss: 0.027..  Test Loss: 1.054..  Test Accuracy: 0.802\n",
      "Epoch: 1113/4000..  Training Loss: 0.033..  Test Loss: 1.013..  Test Accuracy: 0.810\n",
      "Epoch: 1114/4000..  Training Loss: 0.038..  Test Loss: 1.029..  Test Accuracy: 0.806\n",
      "Epoch: 1115/4000..  Training Loss: 0.040..  Test Loss: 1.062..  Test Accuracy: 0.799\n",
      "Epoch: 1116/4000..  Training Loss: 0.022..  Test Loss: 1.033..  Test Accuracy: 0.806\n",
      "Epoch: 1117/4000..  Training Loss: 0.016..  Test Loss: 0.996..  Test Accuracy: 0.812\n",
      "Epoch: 1118/4000..  Training Loss: 0.014..  Test Loss: 1.002..  Test Accuracy: 0.810\n",
      "Epoch: 1119/4000..  Training Loss: 0.027..  Test Loss: 0.999..  Test Accuracy: 0.813\n",
      "Epoch: 1120/4000..  Training Loss: 0.020..  Test Loss: 1.062..  Test Accuracy: 0.802\n",
      "Epoch: 1121/4000..  Training Loss: 0.040..  Test Loss: 1.066..  Test Accuracy: 0.797\n",
      "Epoch: 1122/4000..  Training Loss: 0.042..  Test Loss: 1.057..  Test Accuracy: 0.806\n",
      "Epoch: 1123/4000..  Training Loss: 0.033..  Test Loss: 1.004..  Test Accuracy: 0.812\n",
      "Epoch: 1124/4000..  Training Loss: 0.021..  Test Loss: 0.941..  Test Accuracy: 0.821\n",
      "Epoch: 1125/4000..  Training Loss: 0.022..  Test Loss: 1.005..  Test Accuracy: 0.813\n",
      "Epoch: 1126/4000..  Training Loss: 0.053..  Test Loss: 1.050..  Test Accuracy: 0.807\n",
      "Epoch: 1127/4000..  Training Loss: 0.040..  Test Loss: 1.037..  Test Accuracy: 0.809\n",
      "Epoch: 1128/4000..  Training Loss: 0.024..  Test Loss: 1.076..  Test Accuracy: 0.802\n",
      "Epoch: 1129/4000..  Training Loss: 0.030..  Test Loss: 1.030..  Test Accuracy: 0.809\n",
      "Epoch: 1130/4000..  Training Loss: 0.035..  Test Loss: 0.974..  Test Accuracy: 0.815\n",
      "Epoch: 1131/4000..  Training Loss: 0.024..  Test Loss: 1.019..  Test Accuracy: 0.811\n",
      "Epoch: 1132/4000..  Training Loss: 0.034..  Test Loss: 0.952..  Test Accuracy: 0.819\n",
      "Epoch: 1133/4000..  Training Loss: 0.014..  Test Loss: 0.987..  Test Accuracy: 0.813\n",
      "Epoch: 1134/4000..  Training Loss: 0.028..  Test Loss: 1.100..  Test Accuracy: 0.799\n",
      "Epoch: 1135/4000..  Training Loss: 0.030..  Test Loss: 0.964..  Test Accuracy: 0.819\n",
      "Epoch: 1136/4000..  Training Loss: 0.033..  Test Loss: 1.007..  Test Accuracy: 0.812\n",
      "Epoch: 1137/4000..  Training Loss: 0.032..  Test Loss: 1.000..  Test Accuracy: 0.812\n",
      "Epoch: 1138/4000..  Training Loss: 0.033..  Test Loss: 1.076..  Test Accuracy: 0.802\n",
      "Epoch: 1139/4000..  Training Loss: 0.051..  Test Loss: 0.996..  Test Accuracy: 0.811\n",
      "Epoch: 1140/4000..  Training Loss: 0.040..  Test Loss: 0.966..  Test Accuracy: 0.819\n",
      "Epoch: 1141/4000..  Training Loss: 0.028..  Test Loss: 0.993..  Test Accuracy: 0.814\n",
      "Epoch: 1142/4000..  Training Loss: 0.025..  Test Loss: 0.986..  Test Accuracy: 0.815\n",
      "Epoch: 1143/4000..  Training Loss: 0.026..  Test Loss: 0.980..  Test Accuracy: 0.816\n",
      "Epoch: 1144/4000..  Training Loss: 0.018..  Test Loss: 1.028..  Test Accuracy: 0.810\n",
      "Epoch: 1145/4000..  Training Loss: 0.021..  Test Loss: 0.965..  Test Accuracy: 0.816\n",
      "Epoch: 1146/4000..  Training Loss: 0.018..  Test Loss: 0.999..  Test Accuracy: 0.813\n",
      "Epoch: 1147/4000..  Training Loss: 0.019..  Test Loss: 1.033..  Test Accuracy: 0.808\n",
      "Epoch: 1148/4000..  Training Loss: 0.029..  Test Loss: 1.066..  Test Accuracy: 0.804\n",
      "Epoch: 1149/4000..  Training Loss: 0.032..  Test Loss: 1.057..  Test Accuracy: 0.804\n",
      "Epoch: 1150/4000..  Training Loss: 0.031..  Test Loss: 1.039..  Test Accuracy: 0.807\n",
      "Epoch: 1151/4000..  Training Loss: 0.025..  Test Loss: 1.034..  Test Accuracy: 0.810\n",
      "Epoch: 1152/4000..  Training Loss: 0.036..  Test Loss: 1.030..  Test Accuracy: 0.808\n",
      "Epoch: 1153/4000..  Training Loss: 0.039..  Test Loss: 0.991..  Test Accuracy: 0.814\n",
      "Epoch: 1154/4000..  Training Loss: 0.068..  Test Loss: 0.999..  Test Accuracy: 0.814\n",
      "Epoch: 1155/4000..  Training Loss: 0.037..  Test Loss: 0.962..  Test Accuracy: 0.816\n",
      "Epoch: 1156/4000..  Training Loss: 0.039..  Test Loss: 1.030..  Test Accuracy: 0.810\n",
      "Epoch: 1157/4000..  Training Loss: 0.028..  Test Loss: 1.007..  Test Accuracy: 0.811\n",
      "Epoch: 1158/4000..  Training Loss: 0.020..  Test Loss: 0.987..  Test Accuracy: 0.814\n",
      "Epoch: 1159/4000..  Training Loss: 0.025..  Test Loss: 0.980..  Test Accuracy: 0.816\n",
      "Epoch: 1160/4000..  Training Loss: 0.022..  Test Loss: 0.974..  Test Accuracy: 0.816\n",
      "Epoch: 1161/4000..  Training Loss: 0.018..  Test Loss: 1.003..  Test Accuracy: 0.812\n",
      "Epoch: 1162/4000..  Training Loss: 0.040..  Test Loss: 0.982..  Test Accuracy: 0.815\n",
      "Epoch: 1163/4000..  Training Loss: 0.049..  Test Loss: 1.055..  Test Accuracy: 0.801\n",
      "Epoch: 1164/4000..  Training Loss: 0.034..  Test Loss: 0.985..  Test Accuracy: 0.816\n",
      "Epoch: 1165/4000..  Training Loss: 0.016..  Test Loss: 0.992..  Test Accuracy: 0.813\n",
      "Epoch: 1166/4000..  Training Loss: 0.033..  Test Loss: 0.970..  Test Accuracy: 0.816\n",
      "Epoch: 1167/4000..  Training Loss: 0.027..  Test Loss: 0.965..  Test Accuracy: 0.818\n",
      "Epoch: 1168/4000..  Training Loss: 0.039..  Test Loss: 1.012..  Test Accuracy: 0.811\n",
      "Epoch: 1169/4000..  Training Loss: 0.076..  Test Loss: 1.054..  Test Accuracy: 0.807\n",
      "Epoch: 1170/4000..  Training Loss: 0.024..  Test Loss: 1.031..  Test Accuracy: 0.812\n",
      "Epoch: 1171/4000..  Training Loss: 0.020..  Test Loss: 1.000..  Test Accuracy: 0.814\n",
      "Epoch: 1172/4000..  Training Loss: 0.037..  Test Loss: 0.999..  Test Accuracy: 0.814\n",
      "Epoch: 1173/4000..  Training Loss: 0.024..  Test Loss: 1.009..  Test Accuracy: 0.813\n",
      "Epoch: 1174/4000..  Training Loss: 0.011..  Test Loss: 0.993..  Test Accuracy: 0.815\n",
      "Epoch: 1175/4000..  Training Loss: 0.032..  Test Loss: 0.986..  Test Accuracy: 0.816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1176/4000..  Training Loss: 0.029..  Test Loss: 0.983..  Test Accuracy: 0.820\n",
      "Epoch: 1177/4000..  Training Loss: 0.050..  Test Loss: 1.065..  Test Accuracy: 0.806\n",
      "Epoch: 1178/4000..  Training Loss: 0.027..  Test Loss: 1.016..  Test Accuracy: 0.813\n",
      "Epoch: 1179/4000..  Training Loss: 0.017..  Test Loss: 1.009..  Test Accuracy: 0.813\n",
      "Epoch: 1180/4000..  Training Loss: 0.058..  Test Loss: 0.972..  Test Accuracy: 0.818\n",
      "Epoch: 1181/4000..  Training Loss: 0.029..  Test Loss: 0.974..  Test Accuracy: 0.816\n",
      "Epoch: 1182/4000..  Training Loss: 0.045..  Test Loss: 0.962..  Test Accuracy: 0.819\n",
      "Epoch: 1183/4000..  Training Loss: 0.014..  Test Loss: 0.974..  Test Accuracy: 0.816\n",
      "Epoch: 1184/4000..  Training Loss: 0.025..  Test Loss: 0.997..  Test Accuracy: 0.811\n",
      "Epoch: 1185/4000..  Training Loss: 0.036..  Test Loss: 1.004..  Test Accuracy: 0.813\n",
      "Epoch: 1186/4000..  Training Loss: 0.035..  Test Loss: 1.027..  Test Accuracy: 0.808\n",
      "Epoch: 1187/4000..  Training Loss: 0.018..  Test Loss: 1.032..  Test Accuracy: 0.810\n",
      "Epoch: 1188/4000..  Training Loss: 0.014..  Test Loss: 1.018..  Test Accuracy: 0.811\n",
      "Epoch: 1189/4000..  Training Loss: 0.032..  Test Loss: 1.013..  Test Accuracy: 0.811\n",
      "Epoch: 1190/4000..  Training Loss: 0.023..  Test Loss: 0.998..  Test Accuracy: 0.813\n",
      "Epoch: 1191/4000..  Training Loss: 0.025..  Test Loss: 0.994..  Test Accuracy: 0.815\n",
      "Epoch: 1192/4000..  Training Loss: 0.021..  Test Loss: 1.006..  Test Accuracy: 0.813\n",
      "Epoch: 1193/4000..  Training Loss: 0.021..  Test Loss: 0.979..  Test Accuracy: 0.813\n",
      "Epoch: 1194/4000..  Training Loss: 0.022..  Test Loss: 0.985..  Test Accuracy: 0.813\n",
      "Epoch: 1195/4000..  Training Loss: 0.013..  Test Loss: 1.019..  Test Accuracy: 0.812\n",
      "Epoch: 1196/4000..  Training Loss: 0.022..  Test Loss: 1.029..  Test Accuracy: 0.810\n",
      "Epoch: 1197/4000..  Training Loss: 0.024..  Test Loss: 1.022..  Test Accuracy: 0.812\n",
      "Epoch: 1198/4000..  Training Loss: 0.023..  Test Loss: 0.991..  Test Accuracy: 0.816\n",
      "Epoch: 1199/4000..  Training Loss: 0.017..  Test Loss: 0.985..  Test Accuracy: 0.815\n",
      "Epoch: 1200/4000..  Training Loss: 0.016..  Test Loss: 0.985..  Test Accuracy: 0.816\n",
      "Epoch: 1201/4000..  Training Loss: 0.030..  Test Loss: 0.971..  Test Accuracy: 0.817\n",
      "Epoch: 1202/4000..  Training Loss: 0.033..  Test Loss: 0.971..  Test Accuracy: 0.817\n",
      "Epoch: 1203/4000..  Training Loss: 0.032..  Test Loss: 1.017..  Test Accuracy: 0.812\n",
      "Epoch: 1204/4000..  Training Loss: 0.036..  Test Loss: 0.978..  Test Accuracy: 0.817\n",
      "Epoch: 1205/4000..  Training Loss: 0.033..  Test Loss: 1.058..  Test Accuracy: 0.807\n",
      "Epoch: 1206/4000..  Training Loss: 0.037..  Test Loss: 1.027..  Test Accuracy: 0.813\n",
      "Epoch: 1207/4000..  Training Loss: 0.050..  Test Loss: 0.987..  Test Accuracy: 0.815\n",
      "Epoch: 1208/4000..  Training Loss: 0.014..  Test Loss: 1.000..  Test Accuracy: 0.814\n",
      "Epoch: 1209/4000..  Training Loss: 0.026..  Test Loss: 1.031..  Test Accuracy: 0.810\n",
      "Epoch: 1210/4000..  Training Loss: 0.023..  Test Loss: 1.006..  Test Accuracy: 0.814\n",
      "Epoch: 1211/4000..  Training Loss: 0.016..  Test Loss: 1.017..  Test Accuracy: 0.813\n",
      "Epoch: 1212/4000..  Training Loss: 0.016..  Test Loss: 1.065..  Test Accuracy: 0.809\n",
      "Epoch: 1213/4000..  Training Loss: 0.017..  Test Loss: 1.093..  Test Accuracy: 0.799\n",
      "Epoch: 1214/4000..  Training Loss: 0.017..  Test Loss: 1.043..  Test Accuracy: 0.810\n",
      "Epoch: 1215/4000..  Training Loss: 0.032..  Test Loss: 0.972..  Test Accuracy: 0.816\n",
      "Epoch: 1216/4000..  Training Loss: 0.031..  Test Loss: 1.020..  Test Accuracy: 0.811\n",
      "Epoch: 1217/4000..  Training Loss: 0.017..  Test Loss: 0.955..  Test Accuracy: 0.819\n",
      "Epoch: 1218/4000..  Training Loss: 0.034..  Test Loss: 1.108..  Test Accuracy: 0.798\n",
      "Epoch: 1219/4000..  Training Loss: 0.026..  Test Loss: 0.989..  Test Accuracy: 0.815\n",
      "Epoch: 1220/4000..  Training Loss: 0.038..  Test Loss: 1.025..  Test Accuracy: 0.812\n",
      "Epoch: 1221/4000..  Training Loss: 0.017..  Test Loss: 0.982..  Test Accuracy: 0.816\n",
      "Epoch: 1222/4000..  Training Loss: 0.026..  Test Loss: 1.002..  Test Accuracy: 0.811\n",
      "Epoch: 1223/4000..  Training Loss: 0.040..  Test Loss: 0.996..  Test Accuracy: 0.814\n",
      "Epoch: 1224/4000..  Training Loss: 0.019..  Test Loss: 1.009..  Test Accuracy: 0.813\n",
      "Epoch: 1225/4000..  Training Loss: 0.056..  Test Loss: 0.977..  Test Accuracy: 0.815\n",
      "Epoch: 1226/4000..  Training Loss: 0.026..  Test Loss: 1.020..  Test Accuracy: 0.810\n",
      "Epoch: 1227/4000..  Training Loss: 0.022..  Test Loss: 1.013..  Test Accuracy: 0.813\n",
      "Epoch: 1228/4000..  Training Loss: 0.062..  Test Loss: 1.030..  Test Accuracy: 0.809\n",
      "Epoch: 1229/4000..  Training Loss: 0.020..  Test Loss: 1.068..  Test Accuracy: 0.803\n",
      "Epoch: 1230/4000..  Training Loss: 0.036..  Test Loss: 1.042..  Test Accuracy: 0.809\n",
      "Epoch: 1231/4000..  Training Loss: 0.018..  Test Loss: 1.025..  Test Accuracy: 0.813\n",
      "Epoch: 1232/4000..  Training Loss: 0.019..  Test Loss: 1.068..  Test Accuracy: 0.800\n",
      "Epoch: 1233/4000..  Training Loss: 0.007..  Test Loss: 1.035..  Test Accuracy: 0.809\n",
      "Epoch: 1234/4000..  Training Loss: 0.031..  Test Loss: 0.976..  Test Accuracy: 0.818\n",
      "Epoch: 1235/4000..  Training Loss: 0.048..  Test Loss: 1.018..  Test Accuracy: 0.812\n",
      "Epoch: 1236/4000..  Training Loss: 0.020..  Test Loss: 0.971..  Test Accuracy: 0.816\n",
      "Epoch: 1237/4000..  Training Loss: 0.028..  Test Loss: 0.985..  Test Accuracy: 0.816\n",
      "Epoch: 1238/4000..  Training Loss: 0.038..  Test Loss: 0.992..  Test Accuracy: 0.815\n",
      "Epoch: 1239/4000..  Training Loss: 0.025..  Test Loss: 1.011..  Test Accuracy: 0.812\n",
      "Epoch: 1240/4000..  Training Loss: 0.019..  Test Loss: 1.024..  Test Accuracy: 0.811\n",
      "Epoch: 1241/4000..  Training Loss: 0.033..  Test Loss: 1.045..  Test Accuracy: 0.810\n",
      "Epoch: 1242/4000..  Training Loss: 0.031..  Test Loss: 1.002..  Test Accuracy: 0.815\n",
      "Epoch: 1243/4000..  Training Loss: 0.024..  Test Loss: 0.960..  Test Accuracy: 0.820\n",
      "Epoch: 1244/4000..  Training Loss: 0.031..  Test Loss: 1.034..  Test Accuracy: 0.811\n",
      "Epoch: 1245/4000..  Training Loss: 0.023..  Test Loss: 0.976..  Test Accuracy: 0.817\n",
      "Epoch: 1246/4000..  Training Loss: 0.023..  Test Loss: 1.001..  Test Accuracy: 0.814\n",
      "Epoch: 1247/4000..  Training Loss: 0.042..  Test Loss: 0.965..  Test Accuracy: 0.821\n",
      "Epoch: 1248/4000..  Training Loss: 0.009..  Test Loss: 1.008..  Test Accuracy: 0.814\n",
      "Epoch: 1249/4000..  Training Loss: 0.028..  Test Loss: 0.976..  Test Accuracy: 0.819\n",
      "Epoch: 1250/4000..  Training Loss: 0.027..  Test Loss: 0.994..  Test Accuracy: 0.814\n",
      "Epoch: 1251/4000..  Training Loss: 0.013..  Test Loss: 0.993..  Test Accuracy: 0.815\n",
      "Epoch: 1252/4000..  Training Loss: 0.048..  Test Loss: 0.994..  Test Accuracy: 0.816\n",
      "Epoch: 1253/4000..  Training Loss: 0.034..  Test Loss: 1.010..  Test Accuracy: 0.811\n",
      "Epoch: 1254/4000..  Training Loss: 0.019..  Test Loss: 1.034..  Test Accuracy: 0.812\n",
      "Epoch: 1255/4000..  Training Loss: 0.033..  Test Loss: 1.046..  Test Accuracy: 0.808\n",
      "Epoch: 1256/4000..  Training Loss: 0.035..  Test Loss: 0.952..  Test Accuracy: 0.822\n",
      "Epoch: 1257/4000..  Training Loss: 0.020..  Test Loss: 1.019..  Test Accuracy: 0.813\n",
      "Epoch: 1258/4000..  Training Loss: 0.017..  Test Loss: 0.992..  Test Accuracy: 0.817\n",
      "Epoch: 1259/4000..  Training Loss: 0.024..  Test Loss: 1.041..  Test Accuracy: 0.810\n",
      "Epoch: 1260/4000..  Training Loss: 0.030..  Test Loss: 1.001..  Test Accuracy: 0.814\n",
      "Epoch: 1261/4000..  Training Loss: 0.037..  Test Loss: 1.027..  Test Accuracy: 0.812\n",
      "Epoch: 1262/4000..  Training Loss: 0.036..  Test Loss: 0.989..  Test Accuracy: 0.816\n",
      "Epoch: 1263/4000..  Training Loss: 0.025..  Test Loss: 0.977..  Test Accuracy: 0.816\n",
      "Epoch: 1264/4000..  Training Loss: 0.014..  Test Loss: 1.001..  Test Accuracy: 0.814\n",
      "Epoch: 1265/4000..  Training Loss: 0.031..  Test Loss: 1.026..  Test Accuracy: 0.811\n",
      "Epoch: 1266/4000..  Training Loss: 0.028..  Test Loss: 1.015..  Test Accuracy: 0.813\n",
      "Epoch: 1267/4000..  Training Loss: 0.014..  Test Loss: 0.994..  Test Accuracy: 0.815\n",
      "Epoch: 1268/4000..  Training Loss: 0.013..  Test Loss: 0.996..  Test Accuracy: 0.816\n",
      "Epoch: 1269/4000..  Training Loss: 0.032..  Test Loss: 0.999..  Test Accuracy: 0.817\n",
      "Epoch: 1270/4000..  Training Loss: 0.034..  Test Loss: 1.023..  Test Accuracy: 0.812\n",
      "Epoch: 1271/4000..  Training Loss: 0.028..  Test Loss: 1.087..  Test Accuracy: 0.805\n",
      "Epoch: 1272/4000..  Training Loss: 0.066..  Test Loss: 1.123..  Test Accuracy: 0.801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1273/4000..  Training Loss: 0.026..  Test Loss: 1.025..  Test Accuracy: 0.815\n",
      "Epoch: 1274/4000..  Training Loss: 0.022..  Test Loss: 1.028..  Test Accuracy: 0.812\n",
      "Epoch: 1275/4000..  Training Loss: 0.018..  Test Loss: 1.004..  Test Accuracy: 0.816\n",
      "Epoch: 1276/4000..  Training Loss: 0.028..  Test Loss: 0.951..  Test Accuracy: 0.820\n",
      "Epoch: 1277/4000..  Training Loss: 0.043..  Test Loss: 1.049..  Test Accuracy: 0.810\n",
      "Epoch: 1278/4000..  Training Loss: 0.027..  Test Loss: 1.030..  Test Accuracy: 0.814\n",
      "Epoch: 1279/4000..  Training Loss: 0.023..  Test Loss: 1.049..  Test Accuracy: 0.811\n",
      "Epoch: 1280/4000..  Training Loss: 0.028..  Test Loss: 1.029..  Test Accuracy: 0.814\n",
      "Epoch: 1281/4000..  Training Loss: 0.014..  Test Loss: 1.029..  Test Accuracy: 0.815\n",
      "Epoch: 1282/4000..  Training Loss: 0.031..  Test Loss: 0.992..  Test Accuracy: 0.817\n",
      "Epoch: 1283/4000..  Training Loss: 0.047..  Test Loss: 0.968..  Test Accuracy: 0.819\n",
      "Epoch: 1284/4000..  Training Loss: 0.020..  Test Loss: 0.957..  Test Accuracy: 0.824\n",
      "Epoch: 1285/4000..  Training Loss: 0.022..  Test Loss: 1.014..  Test Accuracy: 0.814\n",
      "Epoch: 1286/4000..  Training Loss: 0.011..  Test Loss: 1.028..  Test Accuracy: 0.814\n",
      "Epoch: 1287/4000..  Training Loss: 0.033..  Test Loss: 0.993..  Test Accuracy: 0.817\n",
      "Epoch: 1288/4000..  Training Loss: 0.042..  Test Loss: 1.045..  Test Accuracy: 0.810\n",
      "Epoch: 1289/4000..  Training Loss: 0.022..  Test Loss: 0.981..  Test Accuracy: 0.821\n",
      "Epoch: 1290/4000..  Training Loss: 0.032..  Test Loss: 1.075..  Test Accuracy: 0.807\n",
      "Epoch: 1291/4000..  Training Loss: 0.010..  Test Loss: 1.003..  Test Accuracy: 0.816\n",
      "Epoch: 1292/4000..  Training Loss: 0.009..  Test Loss: 0.995..  Test Accuracy: 0.817\n",
      "Epoch: 1293/4000..  Training Loss: 0.009..  Test Loss: 1.013..  Test Accuracy: 0.815\n",
      "Epoch: 1294/4000..  Training Loss: 0.035..  Test Loss: 1.018..  Test Accuracy: 0.812\n",
      "Epoch: 1295/4000..  Training Loss: 0.035..  Test Loss: 1.142..  Test Accuracy: 0.798\n",
      "Epoch: 1296/4000..  Training Loss: 0.041..  Test Loss: 1.018..  Test Accuracy: 0.816\n",
      "Epoch: 1297/4000..  Training Loss: 0.028..  Test Loss: 1.038..  Test Accuracy: 0.807\n",
      "Epoch: 1298/4000..  Training Loss: 0.013..  Test Loss: 1.046..  Test Accuracy: 0.810\n",
      "Epoch: 1299/4000..  Training Loss: 0.028..  Test Loss: 0.997..  Test Accuracy: 0.815\n",
      "Epoch: 1300/4000..  Training Loss: 0.030..  Test Loss: 1.044..  Test Accuracy: 0.814\n",
      "Epoch: 1301/4000..  Training Loss: 0.038..  Test Loss: 0.977..  Test Accuracy: 0.821\n",
      "Epoch: 1302/4000..  Training Loss: 0.022..  Test Loss: 0.991..  Test Accuracy: 0.821\n",
      "Epoch: 1303/4000..  Training Loss: 0.017..  Test Loss: 1.010..  Test Accuracy: 0.815\n",
      "Epoch: 1304/4000..  Training Loss: 0.026..  Test Loss: 1.000..  Test Accuracy: 0.812\n",
      "Epoch: 1305/4000..  Training Loss: 0.040..  Test Loss: 0.986..  Test Accuracy: 0.817\n",
      "Epoch: 1306/4000..  Training Loss: 0.055..  Test Loss: 1.022..  Test Accuracy: 0.813\n",
      "Epoch: 1307/4000..  Training Loss: 0.043..  Test Loss: 1.090..  Test Accuracy: 0.807\n",
      "Epoch: 1308/4000..  Training Loss: 0.022..  Test Loss: 1.020..  Test Accuracy: 0.813\n",
      "Epoch: 1309/4000..  Training Loss: 0.028..  Test Loss: 0.975..  Test Accuracy: 0.820\n",
      "Epoch: 1310/4000..  Training Loss: 0.019..  Test Loss: 1.027..  Test Accuracy: 0.812\n",
      "Epoch: 1311/4000..  Training Loss: 0.016..  Test Loss: 0.979..  Test Accuracy: 0.819\n",
      "Epoch: 1312/4000..  Training Loss: 0.022..  Test Loss: 0.969..  Test Accuracy: 0.821\n",
      "Epoch: 1313/4000..  Training Loss: 0.012..  Test Loss: 0.994..  Test Accuracy: 0.817\n",
      "Epoch: 1314/4000..  Training Loss: 0.035..  Test Loss: 1.025..  Test Accuracy: 0.810\n",
      "Epoch: 1315/4000..  Training Loss: 0.051..  Test Loss: 1.019..  Test Accuracy: 0.814\n",
      "Epoch: 1316/4000..  Training Loss: 0.021..  Test Loss: 1.032..  Test Accuracy: 0.815\n",
      "Epoch: 1317/4000..  Training Loss: 0.020..  Test Loss: 1.014..  Test Accuracy: 0.816\n",
      "Epoch: 1318/4000..  Training Loss: 0.016..  Test Loss: 1.064..  Test Accuracy: 0.811\n",
      "Epoch: 1319/4000..  Training Loss: 0.031..  Test Loss: 1.000..  Test Accuracy: 0.819\n",
      "Epoch: 1320/4000..  Training Loss: 0.028..  Test Loss: 0.984..  Test Accuracy: 0.817\n",
      "Epoch: 1321/4000..  Training Loss: 0.022..  Test Loss: 1.032..  Test Accuracy: 0.812\n",
      "Epoch: 1322/4000..  Training Loss: 0.016..  Test Loss: 1.053..  Test Accuracy: 0.810\n",
      "Epoch: 1323/4000..  Training Loss: 0.021..  Test Loss: 1.076..  Test Accuracy: 0.809\n",
      "Epoch: 1324/4000..  Training Loss: 0.028..  Test Loss: 1.032..  Test Accuracy: 0.813\n",
      "Epoch: 1325/4000..  Training Loss: 0.019..  Test Loss: 0.973..  Test Accuracy: 0.821\n",
      "Epoch: 1326/4000..  Training Loss: 0.011..  Test Loss: 0.967..  Test Accuracy: 0.820\n",
      "Epoch: 1327/4000..  Training Loss: 0.014..  Test Loss: 1.017..  Test Accuracy: 0.814\n",
      "Epoch: 1328/4000..  Training Loss: 0.028..  Test Loss: 1.028..  Test Accuracy: 0.813\n",
      "Epoch: 1329/4000..  Training Loss: 0.044..  Test Loss: 1.068..  Test Accuracy: 0.809\n",
      "Epoch: 1330/4000..  Training Loss: 0.030..  Test Loss: 0.989..  Test Accuracy: 0.819\n",
      "Epoch: 1331/4000..  Training Loss: 0.018..  Test Loss: 0.991..  Test Accuracy: 0.820\n",
      "Epoch: 1332/4000..  Training Loss: 0.043..  Test Loss: 1.067..  Test Accuracy: 0.810\n",
      "Epoch: 1333/4000..  Training Loss: 0.041..  Test Loss: 0.989..  Test Accuracy: 0.817\n",
      "Epoch: 1334/4000..  Training Loss: 0.023..  Test Loss: 0.984..  Test Accuracy: 0.818\n",
      "Epoch: 1335/4000..  Training Loss: 0.032..  Test Loss: 1.002..  Test Accuracy: 0.817\n",
      "Epoch: 1336/4000..  Training Loss: 0.015..  Test Loss: 1.004..  Test Accuracy: 0.815\n",
      "Epoch: 1337/4000..  Training Loss: 0.022..  Test Loss: 1.019..  Test Accuracy: 0.815\n",
      "Epoch: 1338/4000..  Training Loss: 0.018..  Test Loss: 1.062..  Test Accuracy: 0.811\n",
      "Epoch: 1339/4000..  Training Loss: 0.013..  Test Loss: 1.042..  Test Accuracy: 0.811\n",
      "Epoch: 1340/4000..  Training Loss: 0.017..  Test Loss: 0.950..  Test Accuracy: 0.823\n",
      "Epoch: 1341/4000..  Training Loss: 0.019..  Test Loss: 1.063..  Test Accuracy: 0.811\n",
      "Epoch: 1342/4000..  Training Loss: 0.020..  Test Loss: 0.991..  Test Accuracy: 0.818\n",
      "Epoch: 1343/4000..  Training Loss: 0.029..  Test Loss: 1.026..  Test Accuracy: 0.816\n",
      "Epoch: 1344/4000..  Training Loss: 0.021..  Test Loss: 1.067..  Test Accuracy: 0.809\n",
      "Epoch: 1345/4000..  Training Loss: 0.030..  Test Loss: 1.025..  Test Accuracy: 0.815\n",
      "Epoch: 1346/4000..  Training Loss: 0.016..  Test Loss: 1.036..  Test Accuracy: 0.812\n",
      "Epoch: 1347/4000..  Training Loss: 0.055..  Test Loss: 0.999..  Test Accuracy: 0.818\n",
      "Epoch: 1348/4000..  Training Loss: 0.015..  Test Loss: 0.978..  Test Accuracy: 0.820\n",
      "Epoch: 1349/4000..  Training Loss: 0.022..  Test Loss: 0.923..  Test Accuracy: 0.824\n",
      "Epoch: 1350/4000..  Training Loss: 0.021..  Test Loss: 0.977..  Test Accuracy: 0.820\n",
      "Epoch: 1351/4000..  Training Loss: 0.008..  Test Loss: 0.989..  Test Accuracy: 0.817\n",
      "Epoch: 1352/4000..  Training Loss: 0.020..  Test Loss: 0.967..  Test Accuracy: 0.822\n",
      "Epoch: 1353/4000..  Training Loss: 0.012..  Test Loss: 0.999..  Test Accuracy: 0.816\n",
      "Epoch: 1354/4000..  Training Loss: 0.019..  Test Loss: 0.964..  Test Accuracy: 0.824\n",
      "Epoch: 1355/4000..  Training Loss: 0.017..  Test Loss: 0.979..  Test Accuracy: 0.820\n",
      "Epoch: 1356/4000..  Training Loss: 0.012..  Test Loss: 0.989..  Test Accuracy: 0.817\n",
      "Epoch: 1357/4000..  Training Loss: 0.016..  Test Loss: 0.978..  Test Accuracy: 0.819\n",
      "Epoch: 1358/4000..  Training Loss: 0.039..  Test Loss: 1.005..  Test Accuracy: 0.817\n",
      "Epoch: 1359/4000..  Training Loss: 0.023..  Test Loss: 0.968..  Test Accuracy: 0.821\n",
      "Epoch: 1360/4000..  Training Loss: 0.015..  Test Loss: 0.971..  Test Accuracy: 0.821\n",
      "Epoch: 1361/4000..  Training Loss: 0.018..  Test Loss: 0.999..  Test Accuracy: 0.819\n",
      "Epoch: 1362/4000..  Training Loss: 0.020..  Test Loss: 0.999..  Test Accuracy: 0.817\n",
      "Epoch: 1363/4000..  Training Loss: 0.023..  Test Loss: 1.077..  Test Accuracy: 0.811\n",
      "Epoch: 1364/4000..  Training Loss: 0.062..  Test Loss: 1.017..  Test Accuracy: 0.813\n",
      "Epoch: 1365/4000..  Training Loss: 0.012..  Test Loss: 1.016..  Test Accuracy: 0.816\n",
      "Epoch: 1366/4000..  Training Loss: 0.017..  Test Loss: 1.010..  Test Accuracy: 0.814\n",
      "Epoch: 1367/4000..  Training Loss: 0.055..  Test Loss: 0.948..  Test Accuracy: 0.823\n",
      "Epoch: 1368/4000..  Training Loss: 0.021..  Test Loss: 1.038..  Test Accuracy: 0.811\n",
      "Epoch: 1369/4000..  Training Loss: 0.028..  Test Loss: 1.044..  Test Accuracy: 0.814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1370/4000..  Training Loss: 0.010..  Test Loss: 1.020..  Test Accuracy: 0.816\n",
      "Epoch: 1371/4000..  Training Loss: 0.022..  Test Loss: 1.014..  Test Accuracy: 0.816\n",
      "Epoch: 1372/4000..  Training Loss: 0.028..  Test Loss: 0.983..  Test Accuracy: 0.820\n",
      "Epoch: 1373/4000..  Training Loss: 0.045..  Test Loss: 1.022..  Test Accuracy: 0.817\n",
      "Epoch: 1374/4000..  Training Loss: 0.015..  Test Loss: 1.049..  Test Accuracy: 0.814\n",
      "Epoch: 1375/4000..  Training Loss: 0.012..  Test Loss: 0.984..  Test Accuracy: 0.820\n",
      "Epoch: 1376/4000..  Training Loss: 0.042..  Test Loss: 1.011..  Test Accuracy: 0.817\n",
      "Epoch: 1377/4000..  Training Loss: 0.036..  Test Loss: 1.032..  Test Accuracy: 0.813\n",
      "Epoch: 1378/4000..  Training Loss: 0.020..  Test Loss: 0.995..  Test Accuracy: 0.819\n",
      "Epoch: 1379/4000..  Training Loss: 0.016..  Test Loss: 1.044..  Test Accuracy: 0.813\n",
      "Epoch: 1380/4000..  Training Loss: 0.012..  Test Loss: 1.053..  Test Accuracy: 0.814\n",
      "Epoch: 1381/4000..  Training Loss: 0.024..  Test Loss: 1.032..  Test Accuracy: 0.816\n",
      "Epoch: 1382/4000..  Training Loss: 0.020..  Test Loss: 1.049..  Test Accuracy: 0.813\n",
      "Epoch: 1383/4000..  Training Loss: 0.027..  Test Loss: 1.035..  Test Accuracy: 0.813\n",
      "Epoch: 1384/4000..  Training Loss: 0.029..  Test Loss: 0.969..  Test Accuracy: 0.820\n",
      "Epoch: 1385/4000..  Training Loss: 0.034..  Test Loss: 1.066..  Test Accuracy: 0.811\n",
      "Epoch: 1386/4000..  Training Loss: 0.020..  Test Loss: 1.024..  Test Accuracy: 0.812\n",
      "Epoch: 1387/4000..  Training Loss: 0.029..  Test Loss: 1.025..  Test Accuracy: 0.818\n",
      "Epoch: 1388/4000..  Training Loss: 0.026..  Test Loss: 1.026..  Test Accuracy: 0.818\n",
      "Epoch: 1389/4000..  Training Loss: 0.028..  Test Loss: 1.082..  Test Accuracy: 0.812\n",
      "Epoch: 1390/4000..  Training Loss: 0.016..  Test Loss: 0.993..  Test Accuracy: 0.818\n",
      "Epoch: 1391/4000..  Training Loss: 0.029..  Test Loss: 1.020..  Test Accuracy: 0.813\n",
      "Epoch: 1392/4000..  Training Loss: 0.016..  Test Loss: 1.000..  Test Accuracy: 0.816\n",
      "Epoch: 1393/4000..  Training Loss: 0.020..  Test Loss: 0.998..  Test Accuracy: 0.817\n",
      "Epoch: 1394/4000..  Training Loss: 0.015..  Test Loss: 0.995..  Test Accuracy: 0.818\n",
      "Epoch: 1395/4000..  Training Loss: 0.032..  Test Loss: 1.069..  Test Accuracy: 0.810\n",
      "Epoch: 1396/4000..  Training Loss: 0.028..  Test Loss: 1.023..  Test Accuracy: 0.817\n",
      "Epoch: 1397/4000..  Training Loss: 0.015..  Test Loss: 0.989..  Test Accuracy: 0.821\n",
      "Epoch: 1398/4000..  Training Loss: 0.041..  Test Loss: 1.031..  Test Accuracy: 0.813\n",
      "Epoch: 1399/4000..  Training Loss: 0.030..  Test Loss: 1.043..  Test Accuracy: 0.812\n",
      "Epoch: 1400/4000..  Training Loss: 0.021..  Test Loss: 1.017..  Test Accuracy: 0.816\n",
      "Epoch: 1401/4000..  Training Loss: 0.027..  Test Loss: 0.977..  Test Accuracy: 0.821\n",
      "Epoch: 1402/4000..  Training Loss: 0.043..  Test Loss: 0.975..  Test Accuracy: 0.822\n",
      "Epoch: 1403/4000..  Training Loss: 0.009..  Test Loss: 0.965..  Test Accuracy: 0.825\n",
      "Epoch: 1404/4000..  Training Loss: 0.047..  Test Loss: 0.939..  Test Accuracy: 0.825\n",
      "Epoch: 1405/4000..  Training Loss: 0.031..  Test Loss: 1.002..  Test Accuracy: 0.820\n",
      "Epoch: 1406/4000..  Training Loss: 0.045..  Test Loss: 1.037..  Test Accuracy: 0.814\n",
      "Epoch: 1407/4000..  Training Loss: 0.023..  Test Loss: 1.005..  Test Accuracy: 0.817\n",
      "Epoch: 1408/4000..  Training Loss: 0.023..  Test Loss: 0.999..  Test Accuracy: 0.817\n",
      "Epoch: 1409/4000..  Training Loss: 0.023..  Test Loss: 0.996..  Test Accuracy: 0.820\n",
      "Epoch: 1410/4000..  Training Loss: 0.025..  Test Loss: 1.002..  Test Accuracy: 0.819\n",
      "Epoch: 1411/4000..  Training Loss: 0.018..  Test Loss: 1.017..  Test Accuracy: 0.818\n",
      "Epoch: 1412/4000..  Training Loss: 0.020..  Test Loss: 1.005..  Test Accuracy: 0.818\n",
      "Epoch: 1413/4000..  Training Loss: 0.010..  Test Loss: 0.980..  Test Accuracy: 0.822\n",
      "Epoch: 1414/4000..  Training Loss: 0.031..  Test Loss: 1.005..  Test Accuracy: 0.820\n",
      "Epoch: 1415/4000..  Training Loss: 0.032..  Test Loss: 1.036..  Test Accuracy: 0.815\n",
      "Epoch: 1416/4000..  Training Loss: 0.034..  Test Loss: 1.030..  Test Accuracy: 0.817\n",
      "Epoch: 1417/4000..  Training Loss: 0.019..  Test Loss: 1.013..  Test Accuracy: 0.819\n",
      "Epoch: 1418/4000..  Training Loss: 0.022..  Test Loss: 0.999..  Test Accuracy: 0.820\n",
      "Epoch: 1419/4000..  Training Loss: 0.031..  Test Loss: 1.040..  Test Accuracy: 0.814\n",
      "Epoch: 1420/4000..  Training Loss: 0.024..  Test Loss: 0.971..  Test Accuracy: 0.823\n",
      "Epoch: 1421/4000..  Training Loss: 0.014..  Test Loss: 1.024..  Test Accuracy: 0.816\n",
      "Epoch: 1422/4000..  Training Loss: 0.021..  Test Loss: 0.987..  Test Accuracy: 0.821\n",
      "Epoch: 1423/4000..  Training Loss: 0.033..  Test Loss: 1.090..  Test Accuracy: 0.808\n",
      "Epoch: 1424/4000..  Training Loss: 0.023..  Test Loss: 1.106..  Test Accuracy: 0.808\n",
      "Epoch: 1425/4000..  Training Loss: 0.026..  Test Loss: 1.050..  Test Accuracy: 0.815\n",
      "Epoch: 1426/4000..  Training Loss: 0.021..  Test Loss: 0.970..  Test Accuracy: 0.821\n",
      "Epoch: 1427/4000..  Training Loss: 0.032..  Test Loss: 1.030..  Test Accuracy: 0.817\n",
      "Epoch: 1428/4000..  Training Loss: 0.007..  Test Loss: 1.032..  Test Accuracy: 0.816\n",
      "Epoch: 1429/4000..  Training Loss: 0.027..  Test Loss: 1.010..  Test Accuracy: 0.818\n",
      "Epoch: 1430/4000..  Training Loss: 0.027..  Test Loss: 1.029..  Test Accuracy: 0.816\n",
      "Epoch: 1431/4000..  Training Loss: 0.015..  Test Loss: 1.029..  Test Accuracy: 0.817\n",
      "Epoch: 1432/4000..  Training Loss: 0.013..  Test Loss: 1.059..  Test Accuracy: 0.814\n",
      "Epoch: 1433/4000..  Training Loss: 0.008..  Test Loss: 1.042..  Test Accuracy: 0.814\n",
      "Epoch: 1434/4000..  Training Loss: 0.012..  Test Loss: 0.998..  Test Accuracy: 0.820\n",
      "Epoch: 1435/4000..  Training Loss: 0.010..  Test Loss: 0.985..  Test Accuracy: 0.824\n",
      "Epoch: 1436/4000..  Training Loss: 0.027..  Test Loss: 1.072..  Test Accuracy: 0.813\n",
      "Epoch: 1437/4000..  Training Loss: 0.016..  Test Loss: 1.043..  Test Accuracy: 0.817\n",
      "Epoch: 1438/4000..  Training Loss: 0.020..  Test Loss: 1.030..  Test Accuracy: 0.818\n",
      "Epoch: 1439/4000..  Training Loss: 0.035..  Test Loss: 1.051..  Test Accuracy: 0.814\n",
      "Epoch: 1440/4000..  Training Loss: 0.034..  Test Loss: 1.087..  Test Accuracy: 0.811\n",
      "Epoch: 1441/4000..  Training Loss: 0.024..  Test Loss: 1.012..  Test Accuracy: 0.818\n",
      "Epoch: 1442/4000..  Training Loss: 0.023..  Test Loss: 1.000..  Test Accuracy: 0.820\n",
      "Epoch: 1443/4000..  Training Loss: 0.030..  Test Loss: 1.085..  Test Accuracy: 0.811\n",
      "Epoch: 1444/4000..  Training Loss: 0.009..  Test Loss: 1.059..  Test Accuracy: 0.813\n",
      "Epoch: 1445/4000..  Training Loss: 0.027..  Test Loss: 1.031..  Test Accuracy: 0.816\n",
      "Epoch: 1446/4000..  Training Loss: 0.018..  Test Loss: 1.052..  Test Accuracy: 0.817\n",
      "Epoch: 1447/4000..  Training Loss: 0.018..  Test Loss: 1.007..  Test Accuracy: 0.822\n",
      "Epoch: 1448/4000..  Training Loss: 0.021..  Test Loss: 0.966..  Test Accuracy: 0.824\n",
      "Epoch: 1449/4000..  Training Loss: 0.023..  Test Loss: 1.050..  Test Accuracy: 0.813\n",
      "Epoch: 1450/4000..  Training Loss: 0.038..  Test Loss: 1.082..  Test Accuracy: 0.808\n",
      "Epoch: 1451/4000..  Training Loss: 0.025..  Test Loss: 1.016..  Test Accuracy: 0.818\n",
      "Epoch: 1452/4000..  Training Loss: 0.018..  Test Loss: 1.027..  Test Accuracy: 0.817\n",
      "Epoch: 1453/4000..  Training Loss: 0.013..  Test Loss: 1.000..  Test Accuracy: 0.820\n",
      "Epoch: 1454/4000..  Training Loss: 0.009..  Test Loss: 1.002..  Test Accuracy: 0.819\n",
      "Epoch: 1455/4000..  Training Loss: 0.014..  Test Loss: 1.012..  Test Accuracy: 0.822\n",
      "Epoch: 1456/4000..  Training Loss: 0.010..  Test Loss: 1.011..  Test Accuracy: 0.820\n",
      "Epoch: 1457/4000..  Training Loss: 0.028..  Test Loss: 1.053..  Test Accuracy: 0.810\n",
      "Epoch: 1458/4000..  Training Loss: 0.023..  Test Loss: 0.983..  Test Accuracy: 0.823\n",
      "Epoch: 1459/4000..  Training Loss: 0.016..  Test Loss: 1.054..  Test Accuracy: 0.816\n",
      "Epoch: 1460/4000..  Training Loss: 0.014..  Test Loss: 1.012..  Test Accuracy: 0.820\n",
      "Epoch: 1461/4000..  Training Loss: 0.043..  Test Loss: 0.994..  Test Accuracy: 0.821\n",
      "Epoch: 1462/4000..  Training Loss: 0.026..  Test Loss: 1.024..  Test Accuracy: 0.817\n",
      "Epoch: 1463/4000..  Training Loss: 0.018..  Test Loss: 1.032..  Test Accuracy: 0.818\n",
      "Epoch: 1464/4000..  Training Loss: 0.014..  Test Loss: 1.089..  Test Accuracy: 0.813\n",
      "Epoch: 1465/4000..  Training Loss: 0.008..  Test Loss: 1.048..  Test Accuracy: 0.815\n",
      "Epoch: 1466/4000..  Training Loss: 0.021..  Test Loss: 1.062..  Test Accuracy: 0.816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1467/4000..  Training Loss: 0.015..  Test Loss: 1.021..  Test Accuracy: 0.818\n",
      "Epoch: 1468/4000..  Training Loss: 0.032..  Test Loss: 0.992..  Test Accuracy: 0.823\n",
      "Epoch: 1469/4000..  Training Loss: 0.025..  Test Loss: 1.001..  Test Accuracy: 0.822\n",
      "Epoch: 1470/4000..  Training Loss: 0.050..  Test Loss: 1.029..  Test Accuracy: 0.817\n",
      "Epoch: 1471/4000..  Training Loss: 0.045..  Test Loss: 1.024..  Test Accuracy: 0.820\n",
      "Epoch: 1472/4000..  Training Loss: 0.037..  Test Loss: 1.022..  Test Accuracy: 0.817\n",
      "Epoch: 1473/4000..  Training Loss: 0.011..  Test Loss: 0.985..  Test Accuracy: 0.822\n",
      "Epoch: 1474/4000..  Training Loss: 0.044..  Test Loss: 0.996..  Test Accuracy: 0.821\n",
      "Epoch: 1475/4000..  Training Loss: 0.024..  Test Loss: 0.975..  Test Accuracy: 0.824\n",
      "Epoch: 1476/4000..  Training Loss: 0.018..  Test Loss: 0.986..  Test Accuracy: 0.824\n",
      "Epoch: 1477/4000..  Training Loss: 0.038..  Test Loss: 0.998..  Test Accuracy: 0.821\n",
      "Epoch: 1478/4000..  Training Loss: 0.008..  Test Loss: 0.974..  Test Accuracy: 0.825\n",
      "Epoch: 1479/4000..  Training Loss: 0.007..  Test Loss: 0.972..  Test Accuracy: 0.825\n",
      "Epoch: 1480/4000..  Training Loss: 0.031..  Test Loss: 0.996..  Test Accuracy: 0.823\n",
      "Epoch: 1481/4000..  Training Loss: 0.033..  Test Loss: 1.005..  Test Accuracy: 0.820\n",
      "Epoch: 1482/4000..  Training Loss: 0.023..  Test Loss: 1.051..  Test Accuracy: 0.814\n",
      "Epoch: 1483/4000..  Training Loss: 0.011..  Test Loss: 1.010..  Test Accuracy: 0.820\n",
      "Epoch: 1484/4000..  Training Loss: 0.021..  Test Loss: 0.958..  Test Accuracy: 0.827\n",
      "Epoch: 1485/4000..  Training Loss: 0.011..  Test Loss: 0.985..  Test Accuracy: 0.822\n",
      "Epoch: 1486/4000..  Training Loss: 0.040..  Test Loss: 1.131..  Test Accuracy: 0.808\n",
      "Epoch: 1487/4000..  Training Loss: 0.034..  Test Loss: 1.012..  Test Accuracy: 0.821\n",
      "Epoch: 1488/4000..  Training Loss: 0.020..  Test Loss: 1.002..  Test Accuracy: 0.820\n",
      "Epoch: 1489/4000..  Training Loss: 0.015..  Test Loss: 1.007..  Test Accuracy: 0.820\n",
      "Epoch: 1490/4000..  Training Loss: 0.040..  Test Loss: 1.021..  Test Accuracy: 0.818\n",
      "Epoch: 1491/4000..  Training Loss: 0.015..  Test Loss: 1.029..  Test Accuracy: 0.819\n",
      "Epoch: 1492/4000..  Training Loss: 0.011..  Test Loss: 1.001..  Test Accuracy: 0.819\n",
      "Epoch: 1493/4000..  Training Loss: 0.018..  Test Loss: 1.020..  Test Accuracy: 0.819\n",
      "Epoch: 1494/4000..  Training Loss: 0.019..  Test Loss: 0.983..  Test Accuracy: 0.824\n",
      "Epoch: 1495/4000..  Training Loss: 0.041..  Test Loss: 0.982..  Test Accuracy: 0.825\n",
      "Epoch: 1496/4000..  Training Loss: 0.022..  Test Loss: 0.985..  Test Accuracy: 0.826\n",
      "Epoch: 1497/4000..  Training Loss: 0.017..  Test Loss: 1.030..  Test Accuracy: 0.818\n",
      "Epoch: 1498/4000..  Training Loss: 0.021..  Test Loss: 0.994..  Test Accuracy: 0.823\n",
      "Epoch: 1499/4000..  Training Loss: 0.029..  Test Loss: 1.022..  Test Accuracy: 0.818\n",
      "Epoch: 1500/4000..  Training Loss: 0.022..  Test Loss: 1.035..  Test Accuracy: 0.817\n",
      "Epoch: 1501/4000..  Training Loss: 0.011..  Test Loss: 1.018..  Test Accuracy: 0.820\n",
      "Epoch: 1502/4000..  Training Loss: 0.018..  Test Loss: 0.990..  Test Accuracy: 0.821\n",
      "Epoch: 1503/4000..  Training Loss: 0.013..  Test Loss: 1.045..  Test Accuracy: 0.817\n",
      "Epoch: 1504/4000..  Training Loss: 0.025..  Test Loss: 1.082..  Test Accuracy: 0.811\n",
      "Epoch: 1505/4000..  Training Loss: 0.020..  Test Loss: 1.049..  Test Accuracy: 0.815\n",
      "Epoch: 1506/4000..  Training Loss: 0.014..  Test Loss: 1.005..  Test Accuracy: 0.822\n",
      "Epoch: 1507/4000..  Training Loss: 0.042..  Test Loss: 1.006..  Test Accuracy: 0.818\n",
      "Epoch: 1508/4000..  Training Loss: 0.026..  Test Loss: 1.081..  Test Accuracy: 0.813\n",
      "Epoch: 1509/4000..  Training Loss: 0.020..  Test Loss: 1.041..  Test Accuracy: 0.816\n",
      "Epoch: 1510/4000..  Training Loss: 0.009..  Test Loss: 1.047..  Test Accuracy: 0.816\n",
      "Epoch: 1511/4000..  Training Loss: 0.031..  Test Loss: 1.000..  Test Accuracy: 0.823\n",
      "Epoch: 1512/4000..  Training Loss: 0.051..  Test Loss: 0.999..  Test Accuracy: 0.825\n",
      "Epoch: 1513/4000..  Training Loss: 0.012..  Test Loss: 0.999..  Test Accuracy: 0.821\n",
      "Epoch: 1514/4000..  Training Loss: 0.037..  Test Loss: 0.984..  Test Accuracy: 0.824\n",
      "Epoch: 1515/4000..  Training Loss: 0.037..  Test Loss: 1.018..  Test Accuracy: 0.821\n",
      "Epoch: 1516/4000..  Training Loss: 0.026..  Test Loss: 1.026..  Test Accuracy: 0.819\n",
      "Epoch: 1517/4000..  Training Loss: 0.023..  Test Loss: 1.026..  Test Accuracy: 0.819\n",
      "Epoch: 1518/4000..  Training Loss: 0.016..  Test Loss: 1.015..  Test Accuracy: 0.818\n",
      "Epoch: 1519/4000..  Training Loss: 0.045..  Test Loss: 1.053..  Test Accuracy: 0.816\n",
      "Epoch: 1520/4000..  Training Loss: 0.032..  Test Loss: 1.036..  Test Accuracy: 0.815\n",
      "Epoch: 1521/4000..  Training Loss: 0.016..  Test Loss: 1.048..  Test Accuracy: 0.815\n",
      "Epoch: 1522/4000..  Training Loss: 0.020..  Test Loss: 1.009..  Test Accuracy: 0.821\n",
      "Epoch: 1523/4000..  Training Loss: 0.011..  Test Loss: 1.021..  Test Accuracy: 0.821\n",
      "Epoch: 1524/4000..  Training Loss: 0.012..  Test Loss: 1.027..  Test Accuracy: 0.820\n",
      "Epoch: 1525/4000..  Training Loss: 0.012..  Test Loss: 1.030..  Test Accuracy: 0.819\n",
      "Epoch: 1526/4000..  Training Loss: 0.011..  Test Loss: 1.016..  Test Accuracy: 0.820\n",
      "Epoch: 1527/4000..  Training Loss: 0.022..  Test Loss: 0.998..  Test Accuracy: 0.821\n",
      "Epoch: 1528/4000..  Training Loss: 0.012..  Test Loss: 1.020..  Test Accuracy: 0.819\n",
      "Epoch: 1529/4000..  Training Loss: 0.030..  Test Loss: 1.067..  Test Accuracy: 0.814\n",
      "Epoch: 1530/4000..  Training Loss: 0.010..  Test Loss: 1.017..  Test Accuracy: 0.819\n",
      "Epoch: 1531/4000..  Training Loss: 0.020..  Test Loss: 1.044..  Test Accuracy: 0.817\n",
      "Epoch: 1532/4000..  Training Loss: 0.029..  Test Loss: 1.034..  Test Accuracy: 0.818\n",
      "Epoch: 1533/4000..  Training Loss: 0.023..  Test Loss: 1.025..  Test Accuracy: 0.816\n",
      "Epoch: 1534/4000..  Training Loss: 0.013..  Test Loss: 1.039..  Test Accuracy: 0.817\n",
      "Epoch: 1535/4000..  Training Loss: 0.031..  Test Loss: 0.968..  Test Accuracy: 0.827\n",
      "Epoch: 1536/4000..  Training Loss: 0.030..  Test Loss: 1.017..  Test Accuracy: 0.821\n",
      "Epoch: 1537/4000..  Training Loss: 0.013..  Test Loss: 0.986..  Test Accuracy: 0.823\n",
      "Epoch: 1538/4000..  Training Loss: 0.007..  Test Loss: 0.981..  Test Accuracy: 0.822\n",
      "Epoch: 1539/4000..  Training Loss: 0.036..  Test Loss: 0.974..  Test Accuracy: 0.825\n",
      "Epoch: 1540/4000..  Training Loss: 0.024..  Test Loss: 0.994..  Test Accuracy: 0.823\n",
      "Epoch: 1541/4000..  Training Loss: 0.005..  Test Loss: 0.991..  Test Accuracy: 0.824\n",
      "Epoch: 1542/4000..  Training Loss: 0.014..  Test Loss: 0.995..  Test Accuracy: 0.823\n",
      "Epoch: 1543/4000..  Training Loss: 0.034..  Test Loss: 0.966..  Test Accuracy: 0.827\n",
      "Epoch: 1544/4000..  Training Loss: 0.012..  Test Loss: 0.995..  Test Accuracy: 0.822\n",
      "Epoch: 1545/4000..  Training Loss: 0.036..  Test Loss: 1.018..  Test Accuracy: 0.821\n",
      "Epoch: 1546/4000..  Training Loss: 0.023..  Test Loss: 1.045..  Test Accuracy: 0.816\n",
      "Epoch: 1547/4000..  Training Loss: 0.011..  Test Loss: 0.989..  Test Accuracy: 0.822\n",
      "Epoch: 1548/4000..  Training Loss: 0.010..  Test Loss: 1.022..  Test Accuracy: 0.819\n",
      "Epoch: 1549/4000..  Training Loss: 0.040..  Test Loss: 1.135..  Test Accuracy: 0.806\n",
      "Epoch: 1550/4000..  Training Loss: 0.019..  Test Loss: 1.029..  Test Accuracy: 0.820\n",
      "Epoch: 1551/4000..  Training Loss: 0.067..  Test Loss: 1.009..  Test Accuracy: 0.824\n",
      "Epoch: 1552/4000..  Training Loss: 0.025..  Test Loss: 1.043..  Test Accuracy: 0.816\n",
      "Epoch: 1553/4000..  Training Loss: 0.021..  Test Loss: 1.017..  Test Accuracy: 0.820\n",
      "Epoch: 1554/4000..  Training Loss: 0.015..  Test Loss: 1.036..  Test Accuracy: 0.820\n",
      "Epoch: 1555/4000..  Training Loss: 0.016..  Test Loss: 1.065..  Test Accuracy: 0.817\n",
      "Epoch: 1556/4000..  Training Loss: 0.025..  Test Loss: 1.080..  Test Accuracy: 0.814\n",
      "Epoch: 1557/4000..  Training Loss: 0.028..  Test Loss: 1.049..  Test Accuracy: 0.817\n",
      "Epoch: 1558/4000..  Training Loss: 0.041..  Test Loss: 1.039..  Test Accuracy: 0.817\n",
      "Epoch: 1559/4000..  Training Loss: 0.029..  Test Loss: 0.981..  Test Accuracy: 0.825\n",
      "Epoch: 1560/4000..  Training Loss: 0.009..  Test Loss: 1.013..  Test Accuracy: 0.820\n",
      "Epoch: 1561/4000..  Training Loss: 0.021..  Test Loss: 1.066..  Test Accuracy: 0.814\n",
      "Epoch: 1562/4000..  Training Loss: 0.027..  Test Loss: 1.015..  Test Accuracy: 0.822\n",
      "Epoch: 1563/4000..  Training Loss: 0.046..  Test Loss: 1.029..  Test Accuracy: 0.818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1564/4000..  Training Loss: 0.012..  Test Loss: 0.990..  Test Accuracy: 0.825\n",
      "Epoch: 1565/4000..  Training Loss: 0.012..  Test Loss: 0.996..  Test Accuracy: 0.824\n",
      "Epoch: 1566/4000..  Training Loss: 0.010..  Test Loss: 0.996..  Test Accuracy: 0.824\n",
      "Epoch: 1567/4000..  Training Loss: 0.033..  Test Loss: 1.002..  Test Accuracy: 0.821\n",
      "Epoch: 1568/4000..  Training Loss: 0.027..  Test Loss: 1.029..  Test Accuracy: 0.819\n",
      "Epoch: 1569/4000..  Training Loss: 0.014..  Test Loss: 1.059..  Test Accuracy: 0.817\n",
      "Epoch: 1570/4000..  Training Loss: 0.016..  Test Loss: 1.105..  Test Accuracy: 0.811\n",
      "Epoch: 1571/4000..  Training Loss: 0.012..  Test Loss: 0.988..  Test Accuracy: 0.826\n",
      "Epoch: 1572/4000..  Training Loss: 0.024..  Test Loss: 1.077..  Test Accuracy: 0.815\n",
      "Epoch: 1573/4000..  Training Loss: 0.027..  Test Loss: 1.031..  Test Accuracy: 0.818\n",
      "Epoch: 1574/4000..  Training Loss: 0.050..  Test Loss: 1.054..  Test Accuracy: 0.816\n",
      "Epoch: 1575/4000..  Training Loss: 0.015..  Test Loss: 0.994..  Test Accuracy: 0.825\n",
      "Epoch: 1576/4000..  Training Loss: 0.020..  Test Loss: 1.035..  Test Accuracy: 0.819\n",
      "Epoch: 1577/4000..  Training Loss: 0.016..  Test Loss: 1.049..  Test Accuracy: 0.818\n",
      "Epoch: 1578/4000..  Training Loss: 0.020..  Test Loss: 1.018..  Test Accuracy: 0.821\n",
      "Epoch: 1579/4000..  Training Loss: 0.035..  Test Loss: 1.007..  Test Accuracy: 0.823\n",
      "Epoch: 1580/4000..  Training Loss: 0.019..  Test Loss: 0.983..  Test Accuracy: 0.826\n",
      "Epoch: 1581/4000..  Training Loss: 0.016..  Test Loss: 1.058..  Test Accuracy: 0.816\n",
      "Epoch: 1582/4000..  Training Loss: 0.019..  Test Loss: 0.990..  Test Accuracy: 0.824\n",
      "Epoch: 1583/4000..  Training Loss: 0.012..  Test Loss: 1.034..  Test Accuracy: 0.819\n",
      "Epoch: 1584/4000..  Training Loss: 0.022..  Test Loss: 1.023..  Test Accuracy: 0.819\n",
      "Epoch: 1585/4000..  Training Loss: 0.035..  Test Loss: 1.126..  Test Accuracy: 0.808\n",
      "Epoch: 1586/4000..  Training Loss: 0.022..  Test Loss: 1.053..  Test Accuracy: 0.818\n",
      "Epoch: 1587/4000..  Training Loss: 0.038..  Test Loss: 0.958..  Test Accuracy: 0.828\n",
      "Epoch: 1588/4000..  Training Loss: 0.015..  Test Loss: 0.976..  Test Accuracy: 0.827\n",
      "Epoch: 1589/4000..  Training Loss: 0.020..  Test Loss: 1.048..  Test Accuracy: 0.816\n",
      "Epoch: 1590/4000..  Training Loss: 0.018..  Test Loss: 1.080..  Test Accuracy: 0.811\n",
      "Epoch: 1591/4000..  Training Loss: 0.016..  Test Loss: 1.015..  Test Accuracy: 0.820\n",
      "Epoch: 1592/4000..  Training Loss: 0.016..  Test Loss: 0.980..  Test Accuracy: 0.827\n",
      "Epoch: 1593/4000..  Training Loss: 0.014..  Test Loss: 0.973..  Test Accuracy: 0.826\n",
      "Epoch: 1594/4000..  Training Loss: 0.012..  Test Loss: 1.022..  Test Accuracy: 0.821\n",
      "Epoch: 1595/4000..  Training Loss: 0.020..  Test Loss: 1.002..  Test Accuracy: 0.823\n",
      "Epoch: 1596/4000..  Training Loss: 0.012..  Test Loss: 1.020..  Test Accuracy: 0.820\n",
      "Epoch: 1597/4000..  Training Loss: 0.016..  Test Loss: 0.997..  Test Accuracy: 0.825\n",
      "Epoch: 1598/4000..  Training Loss: 0.011..  Test Loss: 0.968..  Test Accuracy: 0.828\n",
      "Epoch: 1599/4000..  Training Loss: 0.015..  Test Loss: 1.059..  Test Accuracy: 0.816\n",
      "Epoch: 1600/4000..  Training Loss: 0.016..  Test Loss: 0.985..  Test Accuracy: 0.824\n",
      "Epoch: 1601/4000..  Training Loss: 0.048..  Test Loss: 1.037..  Test Accuracy: 0.817\n",
      "Epoch: 1602/4000..  Training Loss: 0.007..  Test Loss: 1.011..  Test Accuracy: 0.822\n",
      "Epoch: 1603/4000..  Training Loss: 0.013..  Test Loss: 1.026..  Test Accuracy: 0.821\n",
      "Epoch: 1604/4000..  Training Loss: 0.024..  Test Loss: 1.088..  Test Accuracy: 0.814\n",
      "Epoch: 1605/4000..  Training Loss: 0.039..  Test Loss: 1.036..  Test Accuracy: 0.819\n",
      "Epoch: 1606/4000..  Training Loss: 0.026..  Test Loss: 1.053..  Test Accuracy: 0.815\n",
      "Epoch: 1607/4000..  Training Loss: 0.028..  Test Loss: 1.008..  Test Accuracy: 0.823\n",
      "Epoch: 1608/4000..  Training Loss: 0.018..  Test Loss: 1.013..  Test Accuracy: 0.822\n",
      "Epoch: 1609/4000..  Training Loss: 0.049..  Test Loss: 0.988..  Test Accuracy: 0.825\n",
      "Epoch: 1610/4000..  Training Loss: 0.037..  Test Loss: 0.970..  Test Accuracy: 0.828\n",
      "Epoch: 1611/4000..  Training Loss: 0.056..  Test Loss: 1.015..  Test Accuracy: 0.822\n",
      "Epoch: 1612/4000..  Training Loss: 0.016..  Test Loss: 1.050..  Test Accuracy: 0.818\n",
      "Epoch: 1613/4000..  Training Loss: 0.009..  Test Loss: 1.045..  Test Accuracy: 0.818\n",
      "Epoch: 1614/4000..  Training Loss: 0.011..  Test Loss: 1.023..  Test Accuracy: 0.822\n",
      "Epoch: 1615/4000..  Training Loss: 0.011..  Test Loss: 0.996..  Test Accuracy: 0.824\n",
      "Epoch: 1616/4000..  Training Loss: 0.018..  Test Loss: 1.032..  Test Accuracy: 0.820\n",
      "Epoch: 1617/4000..  Training Loss: 0.027..  Test Loss: 1.030..  Test Accuracy: 0.818\n",
      "Epoch: 1618/4000..  Training Loss: 0.022..  Test Loss: 1.000..  Test Accuracy: 0.823\n",
      "Epoch: 1619/4000..  Training Loss: 0.034..  Test Loss: 1.044..  Test Accuracy: 0.818\n",
      "Epoch: 1620/4000..  Training Loss: 0.011..  Test Loss: 1.008..  Test Accuracy: 0.823\n",
      "Epoch: 1621/4000..  Training Loss: 0.014..  Test Loss: 1.020..  Test Accuracy: 0.822\n",
      "Epoch: 1622/4000..  Training Loss: 0.016..  Test Loss: 0.954..  Test Accuracy: 0.829\n",
      "Epoch: 1623/4000..  Training Loss: 0.027..  Test Loss: 0.994..  Test Accuracy: 0.822\n",
      "Epoch: 1624/4000..  Training Loss: 0.019..  Test Loss: 1.004..  Test Accuracy: 0.824\n",
      "Epoch: 1625/4000..  Training Loss: 0.011..  Test Loss: 1.004..  Test Accuracy: 0.823\n",
      "Epoch: 1626/4000..  Training Loss: 0.022..  Test Loss: 1.006..  Test Accuracy: 0.823\n",
      "Epoch: 1627/4000..  Training Loss: 0.016..  Test Loss: 1.029..  Test Accuracy: 0.821\n",
      "Epoch: 1628/4000..  Training Loss: 0.031..  Test Loss: 0.973..  Test Accuracy: 0.828\n",
      "Epoch: 1629/4000..  Training Loss: 0.017..  Test Loss: 0.999..  Test Accuracy: 0.825\n",
      "Epoch: 1630/4000..  Training Loss: 0.017..  Test Loss: 1.079..  Test Accuracy: 0.814\n",
      "Epoch: 1631/4000..  Training Loss: 0.009..  Test Loss: 1.071..  Test Accuracy: 0.815\n",
      "Epoch: 1632/4000..  Training Loss: 0.022..  Test Loss: 1.056..  Test Accuracy: 0.818\n",
      "Epoch: 1633/4000..  Training Loss: 0.012..  Test Loss: 0.982..  Test Accuracy: 0.826\n",
      "Epoch: 1634/4000..  Training Loss: 0.013..  Test Loss: 1.023..  Test Accuracy: 0.822\n",
      "Epoch: 1635/4000..  Training Loss: 0.005..  Test Loss: 1.046..  Test Accuracy: 0.820\n",
      "Epoch: 1636/4000..  Training Loss: 0.034..  Test Loss: 1.041..  Test Accuracy: 0.821\n",
      "Epoch: 1637/4000..  Training Loss: 0.024..  Test Loss: 1.013..  Test Accuracy: 0.822\n",
      "Epoch: 1638/4000..  Training Loss: 0.012..  Test Loss: 0.945..  Test Accuracy: 0.830\n",
      "Epoch: 1639/4000..  Training Loss: 0.016..  Test Loss: 1.012..  Test Accuracy: 0.822\n",
      "Epoch: 1640/4000..  Training Loss: 0.016..  Test Loss: 1.084..  Test Accuracy: 0.813\n",
      "Epoch: 1641/4000..  Training Loss: 0.082..  Test Loss: 1.027..  Test Accuracy: 0.820\n",
      "Epoch: 1642/4000..  Training Loss: 0.014..  Test Loss: 1.036..  Test Accuracy: 0.819\n",
      "Epoch: 1643/4000..  Training Loss: 0.009..  Test Loss: 1.054..  Test Accuracy: 0.818\n",
      "Epoch: 1644/4000..  Training Loss: 0.016..  Test Loss: 1.094..  Test Accuracy: 0.815\n",
      "Epoch: 1645/4000..  Training Loss: 0.010..  Test Loss: 1.049..  Test Accuracy: 0.819\n",
      "Epoch: 1646/4000..  Training Loss: 0.015..  Test Loss: 1.008..  Test Accuracy: 0.824\n",
      "Epoch: 1647/4000..  Training Loss: 0.010..  Test Loss: 1.054..  Test Accuracy: 0.819\n",
      "Epoch: 1648/4000..  Training Loss: 0.015..  Test Loss: 0.988..  Test Accuracy: 0.826\n",
      "Epoch: 1649/4000..  Training Loss: 0.018..  Test Loss: 0.995..  Test Accuracy: 0.826\n",
      "Epoch: 1650/4000..  Training Loss: 0.015..  Test Loss: 1.044..  Test Accuracy: 0.820\n",
      "Epoch: 1651/4000..  Training Loss: 0.012..  Test Loss: 1.027..  Test Accuracy: 0.821\n",
      "Epoch: 1652/4000..  Training Loss: 0.014..  Test Loss: 0.961..  Test Accuracy: 0.828\n",
      "Epoch: 1653/4000..  Training Loss: 0.026..  Test Loss: 1.026..  Test Accuracy: 0.821\n",
      "Epoch: 1654/4000..  Training Loss: 0.010..  Test Loss: 1.030..  Test Accuracy: 0.821\n",
      "Epoch: 1655/4000..  Training Loss: 0.031..  Test Loss: 1.060..  Test Accuracy: 0.818\n",
      "Epoch: 1656/4000..  Training Loss: 0.009..  Test Loss: 0.971..  Test Accuracy: 0.828\n",
      "Epoch: 1657/4000..  Training Loss: 0.014..  Test Loss: 0.996..  Test Accuracy: 0.826\n",
      "Epoch: 1658/4000..  Training Loss: 0.021..  Test Loss: 1.075..  Test Accuracy: 0.816\n",
      "Epoch: 1659/4000..  Training Loss: 0.019..  Test Loss: 1.053..  Test Accuracy: 0.818\n",
      "Epoch: 1660/4000..  Training Loss: 0.012..  Test Loss: 1.123..  Test Accuracy: 0.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1661/4000..  Training Loss: 0.008..  Test Loss: 1.033..  Test Accuracy: 0.824\n",
      "Epoch: 1662/4000..  Training Loss: 0.009..  Test Loss: 1.061..  Test Accuracy: 0.819\n",
      "Epoch: 1663/4000..  Training Loss: 0.018..  Test Loss: 1.051..  Test Accuracy: 0.821\n",
      "Epoch: 1664/4000..  Training Loss: 0.011..  Test Loss: 1.033..  Test Accuracy: 0.822\n",
      "Epoch: 1665/4000..  Training Loss: 0.014..  Test Loss: 1.044..  Test Accuracy: 0.821\n",
      "Epoch: 1666/4000..  Training Loss: 0.018..  Test Loss: 1.028..  Test Accuracy: 0.822\n",
      "Epoch: 1667/4000..  Training Loss: 0.027..  Test Loss: 1.028..  Test Accuracy: 0.825\n",
      "Epoch: 1668/4000..  Training Loss: 0.033..  Test Loss: 1.038..  Test Accuracy: 0.822\n",
      "Epoch: 1669/4000..  Training Loss: 0.027..  Test Loss: 1.034..  Test Accuracy: 0.823\n",
      "Epoch: 1670/4000..  Training Loss: 0.019..  Test Loss: 0.990..  Test Accuracy: 0.828\n",
      "Epoch: 1671/4000..  Training Loss: 0.015..  Test Loss: 0.992..  Test Accuracy: 0.827\n",
      "Epoch: 1672/4000..  Training Loss: 0.016..  Test Loss: 1.049..  Test Accuracy: 0.822\n",
      "Epoch: 1673/4000..  Training Loss: 0.024..  Test Loss: 1.002..  Test Accuracy: 0.825\n",
      "Epoch: 1674/4000..  Training Loss: 0.009..  Test Loss: 1.025..  Test Accuracy: 0.822\n",
      "Epoch: 1675/4000..  Training Loss: 0.033..  Test Loss: 0.951..  Test Accuracy: 0.830\n",
      "Epoch: 1676/4000..  Training Loss: 0.023..  Test Loss: 1.019..  Test Accuracy: 0.822\n",
      "Epoch: 1677/4000..  Training Loss: 0.012..  Test Loss: 1.010..  Test Accuracy: 0.824\n",
      "Epoch: 1678/4000..  Training Loss: 0.014..  Test Loss: 0.984..  Test Accuracy: 0.827\n",
      "Epoch: 1679/4000..  Training Loss: 0.021..  Test Loss: 0.987..  Test Accuracy: 0.828\n",
      "Epoch: 1680/4000..  Training Loss: 0.023..  Test Loss: 1.003..  Test Accuracy: 0.826\n",
      "Epoch: 1681/4000..  Training Loss: 0.009..  Test Loss: 1.018..  Test Accuracy: 0.825\n",
      "Epoch: 1682/4000..  Training Loss: 0.006..  Test Loss: 1.009..  Test Accuracy: 0.825\n",
      "Epoch: 1683/4000..  Training Loss: 0.037..  Test Loss: 1.103..  Test Accuracy: 0.814\n",
      "Epoch: 1684/4000..  Training Loss: 0.008..  Test Loss: 1.054..  Test Accuracy: 0.821\n",
      "Epoch: 1685/4000..  Training Loss: 0.016..  Test Loss: 0.993..  Test Accuracy: 0.825\n",
      "Epoch: 1686/4000..  Training Loss: 0.008..  Test Loss: 1.003..  Test Accuracy: 0.826\n",
      "Epoch: 1687/4000..  Training Loss: 0.054..  Test Loss: 1.017..  Test Accuracy: 0.823\n",
      "Epoch: 1688/4000..  Training Loss: 0.036..  Test Loss: 1.083..  Test Accuracy: 0.816\n",
      "Epoch: 1689/4000..  Training Loss: 0.022..  Test Loss: 1.029..  Test Accuracy: 0.820\n",
      "Epoch: 1690/4000..  Training Loss: 0.026..  Test Loss: 1.008..  Test Accuracy: 0.825\n",
      "Epoch: 1691/4000..  Training Loss: 0.011..  Test Loss: 1.024..  Test Accuracy: 0.822\n",
      "Epoch: 1692/4000..  Training Loss: 0.017..  Test Loss: 1.005..  Test Accuracy: 0.825\n",
      "Epoch: 1693/4000..  Training Loss: 0.010..  Test Loss: 1.019..  Test Accuracy: 0.823\n",
      "Epoch: 1694/4000..  Training Loss: 0.012..  Test Loss: 1.012..  Test Accuracy: 0.824\n",
      "Epoch: 1695/4000..  Training Loss: 0.055..  Test Loss: 1.010..  Test Accuracy: 0.826\n",
      "Epoch: 1696/4000..  Training Loss: 0.011..  Test Loss: 1.020..  Test Accuracy: 0.824\n",
      "Epoch: 1697/4000..  Training Loss: 0.044..  Test Loss: 1.036..  Test Accuracy: 0.822\n",
      "Epoch: 1698/4000..  Training Loss: 0.014..  Test Loss: 1.002..  Test Accuracy: 0.825\n",
      "Epoch: 1699/4000..  Training Loss: 0.024..  Test Loss: 1.055..  Test Accuracy: 0.819\n",
      "Epoch: 1700/4000..  Training Loss: 0.020..  Test Loss: 1.018..  Test Accuracy: 0.824\n",
      "Epoch: 1701/4000..  Training Loss: 0.015..  Test Loss: 1.023..  Test Accuracy: 0.823\n",
      "Epoch: 1702/4000..  Training Loss: 0.012..  Test Loss: 0.969..  Test Accuracy: 0.830\n",
      "Epoch: 1703/4000..  Training Loss: 0.016..  Test Loss: 1.006..  Test Accuracy: 0.825\n",
      "Epoch: 1704/4000..  Training Loss: 0.018..  Test Loss: 1.083..  Test Accuracy: 0.814\n",
      "Epoch: 1705/4000..  Training Loss: 0.035..  Test Loss: 1.049..  Test Accuracy: 0.819\n",
      "Epoch: 1706/4000..  Training Loss: 0.036..  Test Loss: 1.005..  Test Accuracy: 0.825\n",
      "Epoch: 1707/4000..  Training Loss: 0.019..  Test Loss: 1.035..  Test Accuracy: 0.821\n",
      "Epoch: 1708/4000..  Training Loss: 0.027..  Test Loss: 1.034..  Test Accuracy: 0.823\n",
      "Epoch: 1709/4000..  Training Loss: 0.020..  Test Loss: 1.071..  Test Accuracy: 0.817\n",
      "Epoch: 1710/4000..  Training Loss: 0.009..  Test Loss: 1.076..  Test Accuracy: 0.817\n",
      "Epoch: 1711/4000..  Training Loss: 0.005..  Test Loss: 1.052..  Test Accuracy: 0.819\n",
      "Epoch: 1712/4000..  Training Loss: 0.014..  Test Loss: 1.044..  Test Accuracy: 0.819\n",
      "Epoch: 1713/4000..  Training Loss: 0.013..  Test Loss: 1.061..  Test Accuracy: 0.819\n",
      "Epoch: 1714/4000..  Training Loss: 0.015..  Test Loss: 1.079..  Test Accuracy: 0.813\n",
      "Epoch: 1715/4000..  Training Loss: 0.020..  Test Loss: 1.005..  Test Accuracy: 0.826\n",
      "Epoch: 1716/4000..  Training Loss: 0.023..  Test Loss: 1.058..  Test Accuracy: 0.818\n",
      "Epoch: 1717/4000..  Training Loss: 0.046..  Test Loss: 1.034..  Test Accuracy: 0.821\n",
      "Epoch: 1718/4000..  Training Loss: 0.015..  Test Loss: 1.006..  Test Accuracy: 0.823\n",
      "Epoch: 1719/4000..  Training Loss: 0.015..  Test Loss: 1.035..  Test Accuracy: 0.821\n",
      "Epoch: 1720/4000..  Training Loss: 0.019..  Test Loss: 1.001..  Test Accuracy: 0.827\n",
      "Epoch: 1721/4000..  Training Loss: 0.039..  Test Loss: 1.037..  Test Accuracy: 0.822\n",
      "Epoch: 1722/4000..  Training Loss: 0.027..  Test Loss: 1.039..  Test Accuracy: 0.820\n",
      "Epoch: 1723/4000..  Training Loss: 0.009..  Test Loss: 1.005..  Test Accuracy: 0.827\n",
      "Epoch: 1724/4000..  Training Loss: 0.023..  Test Loss: 0.997..  Test Accuracy: 0.827\n",
      "Epoch: 1725/4000..  Training Loss: 0.007..  Test Loss: 1.015..  Test Accuracy: 0.825\n",
      "Epoch: 1726/4000..  Training Loss: 0.020..  Test Loss: 1.094..  Test Accuracy: 0.814\n",
      "Epoch: 1727/4000..  Training Loss: 0.022..  Test Loss: 1.048..  Test Accuracy: 0.820\n",
      "Epoch: 1728/4000..  Training Loss: 0.013..  Test Loss: 1.083..  Test Accuracy: 0.816\n",
      "Epoch: 1729/4000..  Training Loss: 0.011..  Test Loss: 0.989..  Test Accuracy: 0.828\n",
      "Epoch: 1730/4000..  Training Loss: 0.009..  Test Loss: 1.026..  Test Accuracy: 0.822\n",
      "Epoch: 1731/4000..  Training Loss: 0.013..  Test Loss: 0.950..  Test Accuracy: 0.830\n",
      "Epoch: 1732/4000..  Training Loss: 0.034..  Test Loss: 1.034..  Test Accuracy: 0.822\n",
      "Epoch: 1733/4000..  Training Loss: 0.015..  Test Loss: 1.006..  Test Accuracy: 0.825\n",
      "Epoch: 1734/4000..  Training Loss: 0.012..  Test Loss: 1.017..  Test Accuracy: 0.824\n",
      "Epoch: 1735/4000..  Training Loss: 0.012..  Test Loss: 1.036..  Test Accuracy: 0.821\n",
      "Epoch: 1736/4000..  Training Loss: 0.013..  Test Loss: 1.008..  Test Accuracy: 0.827\n",
      "Epoch: 1737/4000..  Training Loss: 0.032..  Test Loss: 0.977..  Test Accuracy: 0.829\n",
      "Epoch: 1738/4000..  Training Loss: 0.008..  Test Loss: 0.990..  Test Accuracy: 0.828\n",
      "Epoch: 1739/4000..  Training Loss: 0.009..  Test Loss: 1.040..  Test Accuracy: 0.822\n",
      "Epoch: 1740/4000..  Training Loss: 0.021..  Test Loss: 0.966..  Test Accuracy: 0.830\n",
      "Epoch: 1741/4000..  Training Loss: 0.008..  Test Loss: 0.963..  Test Accuracy: 0.831\n",
      "Epoch: 1742/4000..  Training Loss: 0.018..  Test Loss: 1.040..  Test Accuracy: 0.823\n",
      "Epoch: 1743/4000..  Training Loss: 0.038..  Test Loss: 1.066..  Test Accuracy: 0.818\n",
      "Epoch: 1744/4000..  Training Loss: 0.061..  Test Loss: 1.133..  Test Accuracy: 0.810\n",
      "Epoch: 1745/4000..  Training Loss: 0.019..  Test Loss: 1.083..  Test Accuracy: 0.817\n",
      "Epoch: 1746/4000..  Training Loss: 0.021..  Test Loss: 1.068..  Test Accuracy: 0.819\n",
      "Epoch: 1747/4000..  Training Loss: 0.011..  Test Loss: 1.072..  Test Accuracy: 0.818\n",
      "Epoch: 1748/4000..  Training Loss: 0.019..  Test Loss: 1.041..  Test Accuracy: 0.823\n",
      "Epoch: 1749/4000..  Training Loss: 0.034..  Test Loss: 0.997..  Test Accuracy: 0.829\n",
      "Epoch: 1750/4000..  Training Loss: 0.009..  Test Loss: 1.025..  Test Accuracy: 0.825\n",
      "Epoch: 1751/4000..  Training Loss: 0.016..  Test Loss: 0.983..  Test Accuracy: 0.827\n",
      "Epoch: 1752/4000..  Training Loss: 0.006..  Test Loss: 0.996..  Test Accuracy: 0.828\n",
      "Epoch: 1753/4000..  Training Loss: 0.021..  Test Loss: 1.010..  Test Accuracy: 0.825\n",
      "Epoch: 1754/4000..  Training Loss: 0.007..  Test Loss: 0.996..  Test Accuracy: 0.829\n",
      "Epoch: 1755/4000..  Training Loss: 0.042..  Test Loss: 1.080..  Test Accuracy: 0.818\n",
      "Epoch: 1756/4000..  Training Loss: 0.014..  Test Loss: 1.018..  Test Accuracy: 0.826\n",
      "Epoch: 1757/4000..  Training Loss: 0.008..  Test Loss: 1.028..  Test Accuracy: 0.825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1758/4000..  Training Loss: 0.008..  Test Loss: 1.023..  Test Accuracy: 0.825\n",
      "Epoch: 1759/4000..  Training Loss: 0.007..  Test Loss: 1.011..  Test Accuracy: 0.826\n",
      "Epoch: 1760/4000..  Training Loss: 0.011..  Test Loss: 1.022..  Test Accuracy: 0.824\n",
      "Epoch: 1761/4000..  Training Loss: 0.018..  Test Loss: 1.028..  Test Accuracy: 0.823\n",
      "Epoch: 1762/4000..  Training Loss: 0.021..  Test Loss: 1.061..  Test Accuracy: 0.821\n",
      "Epoch: 1763/4000..  Training Loss: 0.011..  Test Loss: 1.034..  Test Accuracy: 0.820\n",
      "Epoch: 1764/4000..  Training Loss: 0.034..  Test Loss: 0.943..  Test Accuracy: 0.831\n",
      "Epoch: 1765/4000..  Training Loss: 0.033..  Test Loss: 0.967..  Test Accuracy: 0.830\n",
      "Epoch: 1766/4000..  Training Loss: 0.009..  Test Loss: 0.971..  Test Accuracy: 0.832\n",
      "Epoch: 1767/4000..  Training Loss: 0.028..  Test Loss: 1.004..  Test Accuracy: 0.823\n",
      "Epoch: 1768/4000..  Training Loss: 0.017..  Test Loss: 0.956..  Test Accuracy: 0.830\n",
      "Epoch: 1769/4000..  Training Loss: 0.009..  Test Loss: 0.999..  Test Accuracy: 0.827\n",
      "Epoch: 1770/4000..  Training Loss: 0.016..  Test Loss: 0.991..  Test Accuracy: 0.827\n",
      "Epoch: 1771/4000..  Training Loss: 0.015..  Test Loss: 1.067..  Test Accuracy: 0.820\n",
      "Epoch: 1772/4000..  Training Loss: 0.008..  Test Loss: 1.021..  Test Accuracy: 0.825\n",
      "Epoch: 1773/4000..  Training Loss: 0.048..  Test Loss: 1.009..  Test Accuracy: 0.825\n",
      "Epoch: 1774/4000..  Training Loss: 0.010..  Test Loss: 1.005..  Test Accuracy: 0.826\n",
      "Epoch: 1775/4000..  Training Loss: 0.009..  Test Loss: 0.996..  Test Accuracy: 0.827\n",
      "Epoch: 1776/4000..  Training Loss: 0.008..  Test Loss: 1.011..  Test Accuracy: 0.825\n",
      "Epoch: 1777/4000..  Training Loss: 0.009..  Test Loss: 1.056..  Test Accuracy: 0.820\n",
      "Epoch: 1778/4000..  Training Loss: 0.012..  Test Loss: 1.018..  Test Accuracy: 0.825\n",
      "Epoch: 1779/4000..  Training Loss: 0.018..  Test Loss: 0.990..  Test Accuracy: 0.830\n",
      "Epoch: 1780/4000..  Training Loss: 0.011..  Test Loss: 1.066..  Test Accuracy: 0.819\n",
      "Epoch: 1781/4000..  Training Loss: 0.016..  Test Loss: 1.051..  Test Accuracy: 0.820\n",
      "Epoch: 1782/4000..  Training Loss: 0.014..  Test Loss: 1.005..  Test Accuracy: 0.828\n",
      "Epoch: 1783/4000..  Training Loss: 0.032..  Test Loss: 1.092..  Test Accuracy: 0.816\n",
      "Epoch: 1784/4000..  Training Loss: 0.015..  Test Loss: 1.046..  Test Accuracy: 0.820\n",
      "Epoch: 1785/4000..  Training Loss: 0.012..  Test Loss: 1.081..  Test Accuracy: 0.817\n",
      "Epoch: 1786/4000..  Training Loss: 0.018..  Test Loss: 0.985..  Test Accuracy: 0.829\n",
      "Epoch: 1787/4000..  Training Loss: 0.010..  Test Loss: 0.987..  Test Accuracy: 0.830\n",
      "Epoch: 1788/4000..  Training Loss: 0.014..  Test Loss: 1.012..  Test Accuracy: 0.824\n",
      "Epoch: 1789/4000..  Training Loss: 0.010..  Test Loss: 0.999..  Test Accuracy: 0.828\n",
      "Epoch: 1790/4000..  Training Loss: 0.006..  Test Loss: 1.016..  Test Accuracy: 0.825\n",
      "Epoch: 1791/4000..  Training Loss: 0.014..  Test Loss: 0.999..  Test Accuracy: 0.826\n",
      "Epoch: 1792/4000..  Training Loss: 0.013..  Test Loss: 1.024..  Test Accuracy: 0.825\n",
      "Epoch: 1793/4000..  Training Loss: 0.015..  Test Loss: 0.980..  Test Accuracy: 0.828\n",
      "Epoch: 1794/4000..  Training Loss: 0.021..  Test Loss: 0.989..  Test Accuracy: 0.829\n",
      "Epoch: 1795/4000..  Training Loss: 0.044..  Test Loss: 1.047..  Test Accuracy: 0.821\n",
      "Epoch: 1796/4000..  Training Loss: 0.028..  Test Loss: 1.046..  Test Accuracy: 0.822\n",
      "Epoch: 1797/4000..  Training Loss: 0.020..  Test Loss: 0.990..  Test Accuracy: 0.828\n",
      "Epoch: 1798/4000..  Training Loss: 0.026..  Test Loss: 1.053..  Test Accuracy: 0.817\n",
      "Epoch: 1799/4000..  Training Loss: 0.017..  Test Loss: 1.043..  Test Accuracy: 0.821\n",
      "Epoch: 1800/4000..  Training Loss: 0.031..  Test Loss: 0.985..  Test Accuracy: 0.828\n",
      "Epoch: 1801/4000..  Training Loss: 0.013..  Test Loss: 1.044..  Test Accuracy: 0.821\n",
      "Epoch: 1802/4000..  Training Loss: 0.014..  Test Loss: 1.033..  Test Accuracy: 0.823\n",
      "Epoch: 1803/4000..  Training Loss: 0.023..  Test Loss: 1.008..  Test Accuracy: 0.827\n",
      "Epoch: 1804/4000..  Training Loss: 0.018..  Test Loss: 1.006..  Test Accuracy: 0.824\n",
      "Epoch: 1805/4000..  Training Loss: 0.022..  Test Loss: 1.041..  Test Accuracy: 0.823\n",
      "Epoch: 1806/4000..  Training Loss: 0.017..  Test Loss: 1.002..  Test Accuracy: 0.828\n",
      "Epoch: 1807/4000..  Training Loss: 0.015..  Test Loss: 1.008..  Test Accuracy: 0.827\n",
      "Epoch: 1808/4000..  Training Loss: 0.010..  Test Loss: 1.022..  Test Accuracy: 0.825\n",
      "Epoch: 1809/4000..  Training Loss: 0.012..  Test Loss: 0.964..  Test Accuracy: 0.832\n",
      "Epoch: 1810/4000..  Training Loss: 0.025..  Test Loss: 0.966..  Test Accuracy: 0.832\n",
      "Epoch: 1811/4000..  Training Loss: 0.023..  Test Loss: 1.060..  Test Accuracy: 0.819\n",
      "Epoch: 1812/4000..  Training Loss: 0.019..  Test Loss: 0.978..  Test Accuracy: 0.831\n",
      "Epoch: 1813/4000..  Training Loss: 0.013..  Test Loss: 1.028..  Test Accuracy: 0.826\n",
      "Epoch: 1814/4000..  Training Loss: 0.014..  Test Loss: 1.052..  Test Accuracy: 0.822\n",
      "Epoch: 1815/4000..  Training Loss: 0.013..  Test Loss: 1.017..  Test Accuracy: 0.826\n",
      "Epoch: 1816/4000..  Training Loss: 0.018..  Test Loss: 1.006..  Test Accuracy: 0.828\n",
      "Epoch: 1817/4000..  Training Loss: 0.015..  Test Loss: 0.967..  Test Accuracy: 0.830\n",
      "Epoch: 1818/4000..  Training Loss: 0.010..  Test Loss: 1.019..  Test Accuracy: 0.824\n",
      "Epoch: 1819/4000..  Training Loss: 0.019..  Test Loss: 1.009..  Test Accuracy: 0.826\n",
      "Epoch: 1820/4000..  Training Loss: 0.021..  Test Loss: 1.029..  Test Accuracy: 0.825\n",
      "Epoch: 1821/4000..  Training Loss: 0.010..  Test Loss: 1.014..  Test Accuracy: 0.825\n",
      "Epoch: 1822/4000..  Training Loss: 0.010..  Test Loss: 1.076..  Test Accuracy: 0.819\n",
      "Epoch: 1823/4000..  Training Loss: 0.011..  Test Loss: 1.060..  Test Accuracy: 0.820\n",
      "Epoch: 1824/4000..  Training Loss: 0.007..  Test Loss: 1.060..  Test Accuracy: 0.819\n",
      "Epoch: 1825/4000..  Training Loss: 0.010..  Test Loss: 1.044..  Test Accuracy: 0.823\n",
      "Epoch: 1826/4000..  Training Loss: 0.014..  Test Loss: 0.983..  Test Accuracy: 0.830\n",
      "Epoch: 1827/4000..  Training Loss: 0.013..  Test Loss: 1.036..  Test Accuracy: 0.823\n",
      "Epoch: 1828/4000..  Training Loss: 0.004..  Test Loss: 1.024..  Test Accuracy: 0.825\n",
      "Epoch: 1829/4000..  Training Loss: 0.034..  Test Loss: 1.025..  Test Accuracy: 0.821\n",
      "Epoch: 1830/4000..  Training Loss: 0.009..  Test Loss: 1.069..  Test Accuracy: 0.820\n",
      "Epoch: 1831/4000..  Training Loss: 0.017..  Test Loss: 1.094..  Test Accuracy: 0.816\n",
      "Epoch: 1832/4000..  Training Loss: 0.004..  Test Loss: 1.046..  Test Accuracy: 0.822\n",
      "Epoch: 1833/4000..  Training Loss: 0.013..  Test Loss: 1.069..  Test Accuracy: 0.819\n",
      "Epoch: 1834/4000..  Training Loss: 0.010..  Test Loss: 0.995..  Test Accuracy: 0.829\n",
      "Epoch: 1835/4000..  Training Loss: 0.007..  Test Loss: 1.014..  Test Accuracy: 0.826\n",
      "Epoch: 1836/4000..  Training Loss: 0.030..  Test Loss: 1.095..  Test Accuracy: 0.817\n",
      "Epoch: 1837/4000..  Training Loss: 0.012..  Test Loss: 1.047..  Test Accuracy: 0.821\n",
      "Epoch: 1838/4000..  Training Loss: 0.009..  Test Loss: 1.116..  Test Accuracy: 0.813\n",
      "Epoch: 1839/4000..  Training Loss: 0.029..  Test Loss: 1.143..  Test Accuracy: 0.806\n",
      "Epoch: 1840/4000..  Training Loss: 0.035..  Test Loss: 1.039..  Test Accuracy: 0.823\n",
      "Epoch: 1841/4000..  Training Loss: 0.027..  Test Loss: 1.107..  Test Accuracy: 0.815\n",
      "Epoch: 1842/4000..  Training Loss: 0.009..  Test Loss: 1.065..  Test Accuracy: 0.820\n",
      "Epoch: 1843/4000..  Training Loss: 0.008..  Test Loss: 1.082..  Test Accuracy: 0.818\n",
      "Epoch: 1844/4000..  Training Loss: 0.044..  Test Loss: 1.121..  Test Accuracy: 0.814\n",
      "Epoch: 1845/4000..  Training Loss: 0.017..  Test Loss: 1.100..  Test Accuracy: 0.817\n",
      "Epoch: 1846/4000..  Training Loss: 0.023..  Test Loss: 1.027..  Test Accuracy: 0.824\n",
      "Epoch: 1847/4000..  Training Loss: 0.018..  Test Loss: 1.000..  Test Accuracy: 0.827\n",
      "Epoch: 1848/4000..  Training Loss: 0.022..  Test Loss: 1.009..  Test Accuracy: 0.825\n",
      "Epoch: 1849/4000..  Training Loss: 0.018..  Test Loss: 1.053..  Test Accuracy: 0.820\n",
      "Epoch: 1850/4000..  Training Loss: 0.020..  Test Loss: 1.077..  Test Accuracy: 0.820\n",
      "Epoch: 1851/4000..  Training Loss: 0.011..  Test Loss: 1.088..  Test Accuracy: 0.817\n",
      "Epoch: 1852/4000..  Training Loss: 0.014..  Test Loss: 1.113..  Test Accuracy: 0.813\n",
      "Epoch: 1853/4000..  Training Loss: 0.040..  Test Loss: 1.021..  Test Accuracy: 0.824\n",
      "Epoch: 1854/4000..  Training Loss: 0.008..  Test Loss: 1.004..  Test Accuracy: 0.826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1855/4000..  Training Loss: 0.010..  Test Loss: 1.020..  Test Accuracy: 0.823\n",
      "Epoch: 1856/4000..  Training Loss: 0.016..  Test Loss: 1.021..  Test Accuracy: 0.825\n",
      "Epoch: 1857/4000..  Training Loss: 0.017..  Test Loss: 1.042..  Test Accuracy: 0.822\n",
      "Epoch: 1858/4000..  Training Loss: 0.012..  Test Loss: 0.989..  Test Accuracy: 0.829\n",
      "Epoch: 1859/4000..  Training Loss: 0.016..  Test Loss: 1.040..  Test Accuracy: 0.819\n",
      "Epoch: 1860/4000..  Training Loss: 0.022..  Test Loss: 1.109..  Test Accuracy: 0.816\n",
      "Epoch: 1861/4000..  Training Loss: 0.018..  Test Loss: 1.016..  Test Accuracy: 0.825\n",
      "Epoch: 1862/4000..  Training Loss: 0.012..  Test Loss: 1.084..  Test Accuracy: 0.818\n",
      "Epoch: 1863/4000..  Training Loss: 0.020..  Test Loss: 1.150..  Test Accuracy: 0.806\n",
      "Epoch: 1864/4000..  Training Loss: 0.016..  Test Loss: 1.092..  Test Accuracy: 0.816\n",
      "Epoch: 1865/4000..  Training Loss: 0.013..  Test Loss: 1.044..  Test Accuracy: 0.823\n",
      "Epoch: 1866/4000..  Training Loss: 0.011..  Test Loss: 1.048..  Test Accuracy: 0.824\n",
      "Epoch: 1867/4000..  Training Loss: 0.032..  Test Loss: 1.037..  Test Accuracy: 0.821\n",
      "Epoch: 1868/4000..  Training Loss: 0.019..  Test Loss: 1.021..  Test Accuracy: 0.826\n",
      "Epoch: 1869/4000..  Training Loss: 0.024..  Test Loss: 1.002..  Test Accuracy: 0.830\n",
      "Epoch: 1870/4000..  Training Loss: 0.017..  Test Loss: 1.061..  Test Accuracy: 0.822\n",
      "Epoch: 1871/4000..  Training Loss: 0.010..  Test Loss: 1.059..  Test Accuracy: 0.821\n",
      "Epoch: 1872/4000..  Training Loss: 0.015..  Test Loss: 0.991..  Test Accuracy: 0.829\n",
      "Epoch: 1873/4000..  Training Loss: 0.032..  Test Loss: 1.057..  Test Accuracy: 0.821\n",
      "Epoch: 1874/4000..  Training Loss: 0.009..  Test Loss: 1.063..  Test Accuracy: 0.821\n",
      "Epoch: 1875/4000..  Training Loss: 0.014..  Test Loss: 1.068..  Test Accuracy: 0.819\n",
      "Epoch: 1876/4000..  Training Loss: 0.012..  Test Loss: 1.111..  Test Accuracy: 0.813\n",
      "Epoch: 1877/4000..  Training Loss: 0.047..  Test Loss: 1.093..  Test Accuracy: 0.814\n",
      "Epoch: 1878/4000..  Training Loss: 0.028..  Test Loss: 1.076..  Test Accuracy: 0.821\n",
      "Epoch: 1879/4000..  Training Loss: 0.029..  Test Loss: 1.062..  Test Accuracy: 0.822\n",
      "Epoch: 1880/4000..  Training Loss: 0.014..  Test Loss: 1.026..  Test Accuracy: 0.826\n",
      "Epoch: 1881/4000..  Training Loss: 0.023..  Test Loss: 1.067..  Test Accuracy: 0.821\n",
      "Epoch: 1882/4000..  Training Loss: 0.024..  Test Loss: 1.006..  Test Accuracy: 0.827\n",
      "Epoch: 1883/4000..  Training Loss: 0.035..  Test Loss: 1.082..  Test Accuracy: 0.816\n",
      "Epoch: 1884/4000..  Training Loss: 0.006..  Test Loss: 1.021..  Test Accuracy: 0.827\n",
      "Epoch: 1885/4000..  Training Loss: 0.008..  Test Loss: 1.052..  Test Accuracy: 0.823\n",
      "Epoch: 1886/4000..  Training Loss: 0.008..  Test Loss: 1.042..  Test Accuracy: 0.825\n",
      "Epoch: 1887/4000..  Training Loss: 0.013..  Test Loss: 1.046..  Test Accuracy: 0.824\n",
      "Epoch: 1888/4000..  Training Loss: 0.034..  Test Loss: 1.018..  Test Accuracy: 0.827\n",
      "Epoch: 1889/4000..  Training Loss: 0.015..  Test Loss: 1.113..  Test Accuracy: 0.817\n",
      "Epoch: 1890/4000..  Training Loss: 0.021..  Test Loss: 1.118..  Test Accuracy: 0.817\n",
      "Epoch: 1891/4000..  Training Loss: 0.031..  Test Loss: 1.042..  Test Accuracy: 0.827\n",
      "Epoch: 1892/4000..  Training Loss: 0.007..  Test Loss: 1.050..  Test Accuracy: 0.825\n",
      "Epoch: 1893/4000..  Training Loss: 0.010..  Test Loss: 1.022..  Test Accuracy: 0.827\n",
      "Epoch: 1894/4000..  Training Loss: 0.035..  Test Loss: 1.029..  Test Accuracy: 0.824\n",
      "Epoch: 1895/4000..  Training Loss: 0.016..  Test Loss: 1.097..  Test Accuracy: 0.816\n",
      "Epoch: 1896/4000..  Training Loss: 0.021..  Test Loss: 1.137..  Test Accuracy: 0.813\n",
      "Epoch: 1897/4000..  Training Loss: 0.026..  Test Loss: 1.063..  Test Accuracy: 0.823\n",
      "Epoch: 1898/4000..  Training Loss: 0.037..  Test Loss: 1.090..  Test Accuracy: 0.815\n",
      "Epoch: 1899/4000..  Training Loss: 0.017..  Test Loss: 1.086..  Test Accuracy: 0.819\n",
      "Epoch: 1900/4000..  Training Loss: 0.016..  Test Loss: 1.069..  Test Accuracy: 0.822\n",
      "Epoch: 1901/4000..  Training Loss: 0.014..  Test Loss: 1.010..  Test Accuracy: 0.825\n",
      "Epoch: 1902/4000..  Training Loss: 0.019..  Test Loss: 1.038..  Test Accuracy: 0.821\n",
      "Epoch: 1903/4000..  Training Loss: 0.007..  Test Loss: 1.058..  Test Accuracy: 0.821\n",
      "Epoch: 1904/4000..  Training Loss: 0.008..  Test Loss: 1.060..  Test Accuracy: 0.821\n",
      "Epoch: 1905/4000..  Training Loss: 0.025..  Test Loss: 1.059..  Test Accuracy: 0.819\n",
      "Epoch: 1906/4000..  Training Loss: 0.018..  Test Loss: 1.081..  Test Accuracy: 0.818\n",
      "Epoch: 1907/4000..  Training Loss: 0.013..  Test Loss: 1.059..  Test Accuracy: 0.821\n",
      "Epoch: 1908/4000..  Training Loss: 0.014..  Test Loss: 1.057..  Test Accuracy: 0.824\n",
      "Epoch: 1909/4000..  Training Loss: 0.013..  Test Loss: 1.063..  Test Accuracy: 0.822\n",
      "Epoch: 1910/4000..  Training Loss: 0.013..  Test Loss: 1.123..  Test Accuracy: 0.814\n",
      "Epoch: 1911/4000..  Training Loss: 0.019..  Test Loss: 1.006..  Test Accuracy: 0.828\n",
      "Epoch: 1912/4000..  Training Loss: 0.018..  Test Loss: 1.070..  Test Accuracy: 0.821\n",
      "Epoch: 1913/4000..  Training Loss: 0.022..  Test Loss: 1.044..  Test Accuracy: 0.823\n",
      "Epoch: 1914/4000..  Training Loss: 0.039..  Test Loss: 0.975..  Test Accuracy: 0.828\n",
      "Epoch: 1915/4000..  Training Loss: 0.030..  Test Loss: 1.007..  Test Accuracy: 0.827\n",
      "Epoch: 1916/4000..  Training Loss: 0.070..  Test Loss: 1.097..  Test Accuracy: 0.818\n",
      "Epoch: 1917/4000..  Training Loss: 0.026..  Test Loss: 1.054..  Test Accuracy: 0.820\n",
      "Epoch: 1918/4000..  Training Loss: 0.009..  Test Loss: 1.024..  Test Accuracy: 0.825\n",
      "Epoch: 1919/4000..  Training Loss: 0.023..  Test Loss: 1.040..  Test Accuracy: 0.824\n",
      "Epoch: 1920/4000..  Training Loss: 0.022..  Test Loss: 1.085..  Test Accuracy: 0.820\n",
      "Epoch: 1921/4000..  Training Loss: 0.008..  Test Loss: 1.073..  Test Accuracy: 0.821\n",
      "Epoch: 1922/4000..  Training Loss: 0.014..  Test Loss: 1.104..  Test Accuracy: 0.818\n",
      "Epoch: 1923/4000..  Training Loss: 0.010..  Test Loss: 1.064..  Test Accuracy: 0.823\n",
      "Epoch: 1924/4000..  Training Loss: 0.037..  Test Loss: 1.120..  Test Accuracy: 0.815\n",
      "Epoch: 1925/4000..  Training Loss: 0.013..  Test Loss: 1.047..  Test Accuracy: 0.822\n",
      "Epoch: 1926/4000..  Training Loss: 0.009..  Test Loss: 1.114..  Test Accuracy: 0.817\n",
      "Epoch: 1927/4000..  Training Loss: 0.015..  Test Loss: 1.095..  Test Accuracy: 0.819\n",
      "Epoch: 1928/4000..  Training Loss: 0.011..  Test Loss: 1.141..  Test Accuracy: 0.814\n",
      "Epoch: 1929/4000..  Training Loss: 0.044..  Test Loss: 1.114..  Test Accuracy: 0.814\n",
      "Epoch: 1930/4000..  Training Loss: 0.025..  Test Loss: 1.135..  Test Accuracy: 0.815\n",
      "Epoch: 1931/4000..  Training Loss: 0.021..  Test Loss: 1.094..  Test Accuracy: 0.818\n",
      "Epoch: 1932/4000..  Training Loss: 0.011..  Test Loss: 1.012..  Test Accuracy: 0.829\n",
      "Epoch: 1933/4000..  Training Loss: 0.009..  Test Loss: 1.006..  Test Accuracy: 0.830\n",
      "Epoch: 1934/4000..  Training Loss: 0.024..  Test Loss: 1.134..  Test Accuracy: 0.808\n",
      "Epoch: 1935/4000..  Training Loss: 0.014..  Test Loss: 1.086..  Test Accuracy: 0.818\n",
      "Epoch: 1936/4000..  Training Loss: 0.008..  Test Loss: 1.018..  Test Accuracy: 0.826\n",
      "Epoch: 1937/4000..  Training Loss: 0.009..  Test Loss: 1.022..  Test Accuracy: 0.827\n",
      "Epoch: 1938/4000..  Training Loss: 0.053..  Test Loss: 1.065..  Test Accuracy: 0.823\n",
      "Epoch: 1939/4000..  Training Loss: 0.014..  Test Loss: 1.026..  Test Accuracy: 0.826\n",
      "Epoch: 1940/4000..  Training Loss: 0.029..  Test Loss: 1.075..  Test Accuracy: 0.820\n",
      "Epoch: 1941/4000..  Training Loss: 0.010..  Test Loss: 1.015..  Test Accuracy: 0.828\n",
      "Epoch: 1942/4000..  Training Loss: 0.006..  Test Loss: 1.059..  Test Accuracy: 0.825\n",
      "Epoch: 1943/4000..  Training Loss: 0.008..  Test Loss: 1.045..  Test Accuracy: 0.827\n",
      "Epoch: 1944/4000..  Training Loss: 0.016..  Test Loss: 1.019..  Test Accuracy: 0.827\n",
      "Epoch: 1945/4000..  Training Loss: 0.016..  Test Loss: 1.034..  Test Accuracy: 0.824\n",
      "Epoch: 1946/4000..  Training Loss: 0.025..  Test Loss: 1.057..  Test Accuracy: 0.821\n",
      "Epoch: 1947/4000..  Training Loss: 0.015..  Test Loss: 1.083..  Test Accuracy: 0.823\n",
      "Epoch: 1948/4000..  Training Loss: 0.011..  Test Loss: 1.129..  Test Accuracy: 0.817\n",
      "Epoch: 1949/4000..  Training Loss: 0.038..  Test Loss: 1.087..  Test Accuracy: 0.821\n",
      "Epoch: 1950/4000..  Training Loss: 0.010..  Test Loss: 1.071..  Test Accuracy: 0.824\n",
      "Epoch: 1951/4000..  Training Loss: 0.006..  Test Loss: 1.031..  Test Accuracy: 0.827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1952/4000..  Training Loss: 0.012..  Test Loss: 1.039..  Test Accuracy: 0.822\n",
      "Epoch: 1953/4000..  Training Loss: 0.009..  Test Loss: 1.010..  Test Accuracy: 0.828\n",
      "Epoch: 1954/4000..  Training Loss: 0.013..  Test Loss: 1.021..  Test Accuracy: 0.825\n",
      "Epoch: 1955/4000..  Training Loss: 0.014..  Test Loss: 1.011..  Test Accuracy: 0.828\n",
      "Epoch: 1956/4000..  Training Loss: 0.020..  Test Loss: 1.025..  Test Accuracy: 0.827\n",
      "Epoch: 1957/4000..  Training Loss: 0.007..  Test Loss: 1.046..  Test Accuracy: 0.822\n",
      "Epoch: 1958/4000..  Training Loss: 0.024..  Test Loss: 1.012..  Test Accuracy: 0.830\n",
      "Epoch: 1959/4000..  Training Loss: 0.021..  Test Loss: 1.053..  Test Accuracy: 0.824\n",
      "Epoch: 1960/4000..  Training Loss: 0.021..  Test Loss: 1.182..  Test Accuracy: 0.810\n",
      "Epoch: 1961/4000..  Training Loss: 0.039..  Test Loss: 1.077..  Test Accuracy: 0.820\n",
      "Epoch: 1962/4000..  Training Loss: 0.015..  Test Loss: 1.031..  Test Accuracy: 0.827\n",
      "Epoch: 1963/4000..  Training Loss: 0.016..  Test Loss: 1.058..  Test Accuracy: 0.824\n",
      "Epoch: 1964/4000..  Training Loss: 0.009..  Test Loss: 1.033..  Test Accuracy: 0.825\n",
      "Epoch: 1965/4000..  Training Loss: 0.013..  Test Loss: 1.071..  Test Accuracy: 0.822\n",
      "Epoch: 1966/4000..  Training Loss: 0.012..  Test Loss: 1.081..  Test Accuracy: 0.820\n",
      "Epoch: 1967/4000..  Training Loss: 0.015..  Test Loss: 1.099..  Test Accuracy: 0.818\n",
      "Epoch: 1968/4000..  Training Loss: 0.006..  Test Loss: 1.078..  Test Accuracy: 0.822\n",
      "Epoch: 1969/4000..  Training Loss: 0.035..  Test Loss: 1.050..  Test Accuracy: 0.823\n",
      "Epoch: 1970/4000..  Training Loss: 0.009..  Test Loss: 1.012..  Test Accuracy: 0.828\n",
      "Epoch: 1971/4000..  Training Loss: 0.007..  Test Loss: 1.016..  Test Accuracy: 0.827\n",
      "Epoch: 1972/4000..  Training Loss: 0.004..  Test Loss: 1.034..  Test Accuracy: 0.825\n",
      "Epoch: 1973/4000..  Training Loss: 0.007..  Test Loss: 1.053..  Test Accuracy: 0.821\n",
      "Epoch: 1974/4000..  Training Loss: 0.030..  Test Loss: 1.027..  Test Accuracy: 0.826\n",
      "Epoch: 1975/4000..  Training Loss: 0.020..  Test Loss: 1.055..  Test Accuracy: 0.820\n",
      "Epoch: 1976/4000..  Training Loss: 0.026..  Test Loss: 1.058..  Test Accuracy: 0.820\n",
      "Epoch: 1977/4000..  Training Loss: 0.017..  Test Loss: 1.043..  Test Accuracy: 0.822\n",
      "Epoch: 1978/4000..  Training Loss: 0.020..  Test Loss: 1.034..  Test Accuracy: 0.825\n",
      "Epoch: 1979/4000..  Training Loss: 0.023..  Test Loss: 1.013..  Test Accuracy: 0.829\n",
      "Epoch: 1980/4000..  Training Loss: 0.008..  Test Loss: 1.011..  Test Accuracy: 0.829\n",
      "Epoch: 1981/4000..  Training Loss: 0.028..  Test Loss: 1.053..  Test Accuracy: 0.824\n",
      "Epoch: 1982/4000..  Training Loss: 0.009..  Test Loss: 1.054..  Test Accuracy: 0.823\n",
      "Epoch: 1983/4000..  Training Loss: 0.007..  Test Loss: 1.031..  Test Accuracy: 0.827\n",
      "Epoch: 1984/4000..  Training Loss: 0.006..  Test Loss: 1.063..  Test Accuracy: 0.824\n",
      "Epoch: 1985/4000..  Training Loss: 0.074..  Test Loss: 0.966..  Test Accuracy: 0.833\n",
      "Epoch: 1986/4000..  Training Loss: 0.011..  Test Loss: 1.023..  Test Accuracy: 0.826\n",
      "Epoch: 1987/4000..  Training Loss: 0.014..  Test Loss: 1.076..  Test Accuracy: 0.821\n",
      "Epoch: 1988/4000..  Training Loss: 0.013..  Test Loss: 1.071..  Test Accuracy: 0.823\n",
      "Epoch: 1989/4000..  Training Loss: 0.012..  Test Loss: 1.048..  Test Accuracy: 0.826\n",
      "Epoch: 1990/4000..  Training Loss: 0.012..  Test Loss: 1.095..  Test Accuracy: 0.822\n",
      "Epoch: 1991/4000..  Training Loss: 0.013..  Test Loss: 1.090..  Test Accuracy: 0.819\n",
      "Epoch: 1992/4000..  Training Loss: 0.005..  Test Loss: 1.088..  Test Accuracy: 0.822\n",
      "Epoch: 1993/4000..  Training Loss: 0.011..  Test Loss: 1.011..  Test Accuracy: 0.828\n",
      "Epoch: 1994/4000..  Training Loss: 0.009..  Test Loss: 1.042..  Test Accuracy: 0.825\n",
      "Epoch: 1995/4000..  Training Loss: 0.004..  Test Loss: 1.034..  Test Accuracy: 0.827\n",
      "Epoch: 1996/4000..  Training Loss: 0.006..  Test Loss: 1.029..  Test Accuracy: 0.826\n",
      "Epoch: 1997/4000..  Training Loss: 0.009..  Test Loss: 1.044..  Test Accuracy: 0.824\n",
      "Epoch: 1998/4000..  Training Loss: 0.032..  Test Loss: 1.010..  Test Accuracy: 0.829\n",
      "Epoch: 1999/4000..  Training Loss: 0.017..  Test Loss: 1.116..  Test Accuracy: 0.816\n",
      "Epoch: 2000/4000..  Training Loss: 0.006..  Test Loss: 1.068..  Test Accuracy: 0.822\n",
      "Epoch: 2001/4000..  Training Loss: 0.018..  Test Loss: 1.066..  Test Accuracy: 0.822\n",
      "Epoch: 2002/4000..  Training Loss: 0.023..  Test Loss: 1.087..  Test Accuracy: 0.820\n",
      "Epoch: 2003/4000..  Training Loss: 0.033..  Test Loss: 1.051..  Test Accuracy: 0.823\n",
      "Epoch: 2004/4000..  Training Loss: 0.043..  Test Loss: 0.990..  Test Accuracy: 0.832\n",
      "Epoch: 2005/4000..  Training Loss: 0.008..  Test Loss: 0.995..  Test Accuracy: 0.829\n",
      "Epoch: 2006/4000..  Training Loss: 0.008..  Test Loss: 1.060..  Test Accuracy: 0.819\n",
      "Epoch: 2007/4000..  Training Loss: 0.004..  Test Loss: 1.052..  Test Accuracy: 0.824\n",
      "Epoch: 2008/4000..  Training Loss: 0.013..  Test Loss: 1.003..  Test Accuracy: 0.830\n",
      "Epoch: 2009/4000..  Training Loss: 0.007..  Test Loss: 1.046..  Test Accuracy: 0.825\n",
      "Epoch: 2010/4000..  Training Loss: 0.008..  Test Loss: 1.018..  Test Accuracy: 0.828\n",
      "Epoch: 2011/4000..  Training Loss: 0.017..  Test Loss: 1.083..  Test Accuracy: 0.818\n",
      "Epoch: 2012/4000..  Training Loss: 0.023..  Test Loss: 1.185..  Test Accuracy: 0.803\n",
      "Epoch: 2013/4000..  Training Loss: 0.019..  Test Loss: 1.065..  Test Accuracy: 0.821\n",
      "Epoch: 2014/4000..  Training Loss: 0.023..  Test Loss: 1.057..  Test Accuracy: 0.823\n",
      "Epoch: 2015/4000..  Training Loss: 0.031..  Test Loss: 1.062..  Test Accuracy: 0.822\n",
      "Epoch: 2016/4000..  Training Loss: 0.005..  Test Loss: 1.061..  Test Accuracy: 0.821\n",
      "Epoch: 2017/4000..  Training Loss: 0.008..  Test Loss: 1.046..  Test Accuracy: 0.825\n",
      "Epoch: 2018/4000..  Training Loss: 0.010..  Test Loss: 1.076..  Test Accuracy: 0.820\n",
      "Epoch: 2019/4000..  Training Loss: 0.018..  Test Loss: 1.051..  Test Accuracy: 0.823\n",
      "Epoch: 2020/4000..  Training Loss: 0.010..  Test Loss: 1.055..  Test Accuracy: 0.823\n",
      "Epoch: 2021/4000..  Training Loss: 0.009..  Test Loss: 1.054..  Test Accuracy: 0.825\n",
      "Epoch: 2022/4000..  Training Loss: 0.021..  Test Loss: 1.059..  Test Accuracy: 0.821\n",
      "Epoch: 2023/4000..  Training Loss: 0.014..  Test Loss: 1.003..  Test Accuracy: 0.832\n",
      "Epoch: 2024/4000..  Training Loss: 0.018..  Test Loss: 0.996..  Test Accuracy: 0.830\n",
      "Epoch: 2025/4000..  Training Loss: 0.028..  Test Loss: 1.048..  Test Accuracy: 0.823\n",
      "Epoch: 2026/4000..  Training Loss: 0.031..  Test Loss: 1.091..  Test Accuracy: 0.822\n",
      "Epoch: 2027/4000..  Training Loss: 0.008..  Test Loss: 1.040..  Test Accuracy: 0.826\n",
      "Epoch: 2028/4000..  Training Loss: 0.008..  Test Loss: 1.051..  Test Accuracy: 0.825\n",
      "Epoch: 2029/4000..  Training Loss: 0.014..  Test Loss: 1.032..  Test Accuracy: 0.828\n",
      "Epoch: 2030/4000..  Training Loss: 0.018..  Test Loss: 1.088..  Test Accuracy: 0.820\n",
      "Epoch: 2031/4000..  Training Loss: 0.011..  Test Loss: 1.051..  Test Accuracy: 0.824\n",
      "Epoch: 2032/4000..  Training Loss: 0.020..  Test Loss: 1.041..  Test Accuracy: 0.824\n",
      "Epoch: 2033/4000..  Training Loss: 0.025..  Test Loss: 1.031..  Test Accuracy: 0.828\n",
      "Epoch: 2034/4000..  Training Loss: 0.031..  Test Loss: 1.040..  Test Accuracy: 0.823\n",
      "Epoch: 2035/4000..  Training Loss: 0.013..  Test Loss: 1.079..  Test Accuracy: 0.819\n",
      "Epoch: 2036/4000..  Training Loss: 0.009..  Test Loss: 1.011..  Test Accuracy: 0.829\n",
      "Epoch: 2037/4000..  Training Loss: 0.011..  Test Loss: 1.035..  Test Accuracy: 0.827\n",
      "Epoch: 2038/4000..  Training Loss: 0.008..  Test Loss: 1.087..  Test Accuracy: 0.819\n",
      "Epoch: 2039/4000..  Training Loss: 0.012..  Test Loss: 1.041..  Test Accuracy: 0.826\n",
      "Epoch: 2040/4000..  Training Loss: 0.020..  Test Loss: 0.979..  Test Accuracy: 0.832\n",
      "Epoch: 2041/4000..  Training Loss: 0.011..  Test Loss: 0.998..  Test Accuracy: 0.829\n",
      "Epoch: 2042/4000..  Training Loss: 0.021..  Test Loss: 1.074..  Test Accuracy: 0.821\n",
      "Epoch: 2043/4000..  Training Loss: 0.017..  Test Loss: 1.081..  Test Accuracy: 0.822\n",
      "Epoch: 2044/4000..  Training Loss: 0.008..  Test Loss: 1.045..  Test Accuracy: 0.825\n",
      "Epoch: 2045/4000..  Training Loss: 0.006..  Test Loss: 1.033..  Test Accuracy: 0.826\n",
      "Epoch: 2046/4000..  Training Loss: 0.010..  Test Loss: 1.061..  Test Accuracy: 0.824\n",
      "Epoch: 2047/4000..  Training Loss: 0.007..  Test Loss: 1.076..  Test Accuracy: 0.822\n",
      "Epoch: 2048/4000..  Training Loss: 0.006..  Test Loss: 1.106..  Test Accuracy: 0.818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2049/4000..  Training Loss: 0.017..  Test Loss: 1.061..  Test Accuracy: 0.821\n",
      "Epoch: 2050/4000..  Training Loss: 0.014..  Test Loss: 1.059..  Test Accuracy: 0.824\n",
      "Epoch: 2051/4000..  Training Loss: 0.007..  Test Loss: 1.096..  Test Accuracy: 0.817\n",
      "Epoch: 2052/4000..  Training Loss: 0.013..  Test Loss: 1.020..  Test Accuracy: 0.827\n",
      "Epoch: 2053/4000..  Training Loss: 0.014..  Test Loss: 1.011..  Test Accuracy: 0.826\n",
      "Epoch: 2054/4000..  Training Loss: 0.010..  Test Loss: 1.034..  Test Accuracy: 0.828\n",
      "Epoch: 2055/4000..  Training Loss: 0.025..  Test Loss: 1.042..  Test Accuracy: 0.822\n",
      "Epoch: 2056/4000..  Training Loss: 0.027..  Test Loss: 1.081..  Test Accuracy: 0.821\n",
      "Epoch: 2057/4000..  Training Loss: 0.010..  Test Loss: 1.105..  Test Accuracy: 0.817\n",
      "Epoch: 2058/4000..  Training Loss: 0.024..  Test Loss: 1.076..  Test Accuracy: 0.820\n",
      "Epoch: 2059/4000..  Training Loss: 0.018..  Test Loss: 1.139..  Test Accuracy: 0.806\n",
      "Epoch: 2060/4000..  Training Loss: 0.027..  Test Loss: 1.052..  Test Accuracy: 0.823\n",
      "Epoch: 2061/4000..  Training Loss: 0.028..  Test Loss: 1.016..  Test Accuracy: 0.829\n",
      "Epoch: 2062/4000..  Training Loss: 0.005..  Test Loss: 1.021..  Test Accuracy: 0.830\n",
      "Epoch: 2063/4000..  Training Loss: 0.013..  Test Loss: 1.125..  Test Accuracy: 0.812\n",
      "Epoch: 2064/4000..  Training Loss: 0.016..  Test Loss: 1.019..  Test Accuracy: 0.827\n",
      "Epoch: 2065/4000..  Training Loss: 0.005..  Test Loss: 1.022..  Test Accuracy: 0.828\n",
      "Epoch: 2066/4000..  Training Loss: 0.029..  Test Loss: 1.152..  Test Accuracy: 0.812\n",
      "Epoch: 2067/4000..  Training Loss: 0.019..  Test Loss: 1.079..  Test Accuracy: 0.822\n",
      "Epoch: 2068/4000..  Training Loss: 0.009..  Test Loss: 1.079..  Test Accuracy: 0.822\n",
      "Epoch: 2069/4000..  Training Loss: 0.003..  Test Loss: 1.081..  Test Accuracy: 0.820\n",
      "Epoch: 2070/4000..  Training Loss: 0.022..  Test Loss: 1.054..  Test Accuracy: 0.823\n",
      "Epoch: 2071/4000..  Training Loss: 0.021..  Test Loss: 1.062..  Test Accuracy: 0.822\n",
      "Epoch: 2072/4000..  Training Loss: 0.021..  Test Loss: 1.060..  Test Accuracy: 0.820\n",
      "Epoch: 2073/4000..  Training Loss: 0.024..  Test Loss: 1.052..  Test Accuracy: 0.823\n",
      "Epoch: 2074/4000..  Training Loss: 0.006..  Test Loss: 1.044..  Test Accuracy: 0.825\n",
      "Epoch: 2075/4000..  Training Loss: 0.023..  Test Loss: 1.056..  Test Accuracy: 0.823\n",
      "Epoch: 2076/4000..  Training Loss: 0.019..  Test Loss: 1.088..  Test Accuracy: 0.818\n",
      "Epoch: 2077/4000..  Training Loss: 0.038..  Test Loss: 1.074..  Test Accuracy: 0.822\n",
      "Epoch: 2078/4000..  Training Loss: 0.012..  Test Loss: 1.059..  Test Accuracy: 0.824\n",
      "Epoch: 2079/4000..  Training Loss: 0.016..  Test Loss: 1.130..  Test Accuracy: 0.814\n",
      "Epoch: 2080/4000..  Training Loss: 0.012..  Test Loss: 1.099..  Test Accuracy: 0.815\n",
      "Epoch: 2081/4000..  Training Loss: 0.040..  Test Loss: 1.096..  Test Accuracy: 0.818\n",
      "Epoch: 2082/4000..  Training Loss: 0.015..  Test Loss: 1.047..  Test Accuracy: 0.826\n",
      "Epoch: 2083/4000..  Training Loss: 0.006..  Test Loss: 1.040..  Test Accuracy: 0.827\n",
      "Epoch: 2084/4000..  Training Loss: 0.026..  Test Loss: 1.080..  Test Accuracy: 0.817\n",
      "Epoch: 2085/4000..  Training Loss: 0.009..  Test Loss: 1.001..  Test Accuracy: 0.831\n",
      "Epoch: 2086/4000..  Training Loss: 0.010..  Test Loss: 1.116..  Test Accuracy: 0.818\n",
      "Epoch: 2087/4000..  Training Loss: 0.009..  Test Loss: 1.059..  Test Accuracy: 0.823\n",
      "Epoch: 2088/4000..  Training Loss: 0.011..  Test Loss: 1.031..  Test Accuracy: 0.826\n",
      "Epoch: 2089/4000..  Training Loss: 0.006..  Test Loss: 1.042..  Test Accuracy: 0.822\n",
      "Epoch: 2090/4000..  Training Loss: 0.023..  Test Loss: 1.074..  Test Accuracy: 0.823\n",
      "Epoch: 2091/4000..  Training Loss: 0.005..  Test Loss: 1.123..  Test Accuracy: 0.817\n",
      "Epoch: 2092/4000..  Training Loss: 0.017..  Test Loss: 1.091..  Test Accuracy: 0.821\n",
      "Epoch: 2093/4000..  Training Loss: 0.005..  Test Loss: 1.077..  Test Accuracy: 0.822\n",
      "Epoch: 2094/4000..  Training Loss: 0.019..  Test Loss: 1.071..  Test Accuracy: 0.822\n",
      "Epoch: 2095/4000..  Training Loss: 0.018..  Test Loss: 1.148..  Test Accuracy: 0.806\n",
      "Epoch: 2096/4000..  Training Loss: 0.020..  Test Loss: 1.044..  Test Accuracy: 0.825\n",
      "Epoch: 2097/4000..  Training Loss: 0.040..  Test Loss: 1.028..  Test Accuracy: 0.828\n",
      "Epoch: 2098/4000..  Training Loss: 0.006..  Test Loss: 1.034..  Test Accuracy: 0.828\n",
      "Epoch: 2099/4000..  Training Loss: 0.018..  Test Loss: 1.050..  Test Accuracy: 0.823\n",
      "Epoch: 2100/4000..  Training Loss: 0.012..  Test Loss: 1.064..  Test Accuracy: 0.819\n",
      "Epoch: 2101/4000..  Training Loss: 0.017..  Test Loss: 1.120..  Test Accuracy: 0.818\n",
      "Epoch: 2102/4000..  Training Loss: 0.013..  Test Loss: 1.056..  Test Accuracy: 0.827\n",
      "Epoch: 2103/4000..  Training Loss: 0.015..  Test Loss: 1.105..  Test Accuracy: 0.818\n",
      "Epoch: 2104/4000..  Training Loss: 0.015..  Test Loss: 1.008..  Test Accuracy: 0.831\n",
      "Epoch: 2105/4000..  Training Loss: 0.008..  Test Loss: 1.106..  Test Accuracy: 0.815\n",
      "Epoch: 2106/4000..  Training Loss: 0.013..  Test Loss: 1.039..  Test Accuracy: 0.828\n",
      "Epoch: 2107/4000..  Training Loss: 0.007..  Test Loss: 1.108..  Test Accuracy: 0.819\n",
      "Epoch: 2108/4000..  Training Loss: 0.023..  Test Loss: 1.025..  Test Accuracy: 0.827\n",
      "Epoch: 2109/4000..  Training Loss: 0.016..  Test Loss: 1.056..  Test Accuracy: 0.825\n",
      "Epoch: 2110/4000..  Training Loss: 0.010..  Test Loss: 1.102..  Test Accuracy: 0.820\n",
      "Epoch: 2111/4000..  Training Loss: 0.004..  Test Loss: 1.067..  Test Accuracy: 0.824\n",
      "Epoch: 2112/4000..  Training Loss: 0.028..  Test Loss: 1.070..  Test Accuracy: 0.826\n",
      "Epoch: 2113/4000..  Training Loss: 0.035..  Test Loss: 1.129..  Test Accuracy: 0.813\n",
      "Epoch: 2114/4000..  Training Loss: 0.012..  Test Loss: 1.068..  Test Accuracy: 0.824\n",
      "Epoch: 2115/4000..  Training Loss: 0.010..  Test Loss: 1.033..  Test Accuracy: 0.829\n",
      "Epoch: 2116/4000..  Training Loss: 0.020..  Test Loss: 1.092..  Test Accuracy: 0.823\n",
      "Epoch: 2117/4000..  Training Loss: 0.010..  Test Loss: 1.061..  Test Accuracy: 0.826\n",
      "Epoch: 2118/4000..  Training Loss: 0.010..  Test Loss: 1.053..  Test Accuracy: 0.825\n",
      "Epoch: 2119/4000..  Training Loss: 0.010..  Test Loss: 1.027..  Test Accuracy: 0.829\n",
      "Epoch: 2120/4000..  Training Loss: 0.009..  Test Loss: 1.081..  Test Accuracy: 0.823\n",
      "Epoch: 2121/4000..  Training Loss: 0.014..  Test Loss: 1.062..  Test Accuracy: 0.825\n",
      "Epoch: 2122/4000..  Training Loss: 0.025..  Test Loss: 1.153..  Test Accuracy: 0.816\n",
      "Epoch: 2123/4000..  Training Loss: 0.022..  Test Loss: 1.120..  Test Accuracy: 0.821\n",
      "Epoch: 2124/4000..  Training Loss: 0.016..  Test Loss: 1.112..  Test Accuracy: 0.813\n",
      "Epoch: 2125/4000..  Training Loss: 0.009..  Test Loss: 1.060..  Test Accuracy: 0.822\n",
      "Epoch: 2126/4000..  Training Loss: 0.020..  Test Loss: 1.075..  Test Accuracy: 0.819\n",
      "Epoch: 2127/4000..  Training Loss: 0.019..  Test Loss: 1.139..  Test Accuracy: 0.812\n",
      "Epoch: 2128/4000..  Training Loss: 0.034..  Test Loss: 1.076..  Test Accuracy: 0.823\n",
      "Epoch: 2129/4000..  Training Loss: 0.024..  Test Loss: 1.096..  Test Accuracy: 0.821\n",
      "Epoch: 2130/4000..  Training Loss: 0.014..  Test Loss: 1.057..  Test Accuracy: 0.825\n",
      "Epoch: 2131/4000..  Training Loss: 0.010..  Test Loss: 1.046..  Test Accuracy: 0.826\n",
      "Epoch: 2132/4000..  Training Loss: 0.006..  Test Loss: 1.075..  Test Accuracy: 0.823\n",
      "Epoch: 2133/4000..  Training Loss: 0.023..  Test Loss: 1.092..  Test Accuracy: 0.818\n",
      "Epoch: 2134/4000..  Training Loss: 0.013..  Test Loss: 0.997..  Test Accuracy: 0.832\n",
      "Epoch: 2135/4000..  Training Loss: 0.009..  Test Loss: 1.007..  Test Accuracy: 0.831\n",
      "Epoch: 2136/4000..  Training Loss: 0.012..  Test Loss: 1.122..  Test Accuracy: 0.813\n",
      "Epoch: 2137/4000..  Training Loss: 0.011..  Test Loss: 1.062..  Test Accuracy: 0.826\n",
      "Epoch: 2138/4000..  Training Loss: 0.026..  Test Loss: 1.060..  Test Accuracy: 0.823\n",
      "Epoch: 2139/4000..  Training Loss: 0.017..  Test Loss: 1.016..  Test Accuracy: 0.830\n",
      "Epoch: 2140/4000..  Training Loss: 0.017..  Test Loss: 1.030..  Test Accuracy: 0.827\n",
      "Epoch: 2141/4000..  Training Loss: 0.003..  Test Loss: 1.028..  Test Accuracy: 0.828\n",
      "Epoch: 2142/4000..  Training Loss: 0.007..  Test Loss: 1.029..  Test Accuracy: 0.827\n",
      "Epoch: 2143/4000..  Training Loss: 0.030..  Test Loss: 1.027..  Test Accuracy: 0.830\n",
      "Epoch: 2144/4000..  Training Loss: 0.010..  Test Loss: 1.113..  Test Accuracy: 0.819\n",
      "Epoch: 2145/4000..  Training Loss: 0.009..  Test Loss: 1.041..  Test Accuracy: 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2146/4000..  Training Loss: 0.004..  Test Loss: 1.033..  Test Accuracy: 0.829\n",
      "Epoch: 2147/4000..  Training Loss: 0.006..  Test Loss: 1.040..  Test Accuracy: 0.827\n",
      "Epoch: 2148/4000..  Training Loss: 0.018..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
      "Epoch: 2149/4000..  Training Loss: 0.027..  Test Loss: 1.199..  Test Accuracy: 0.811\n",
      "Epoch: 2150/4000..  Training Loss: 0.011..  Test Loss: 1.103..  Test Accuracy: 0.819\n",
      "Epoch: 2151/4000..  Training Loss: 0.013..  Test Loss: 1.082..  Test Accuracy: 0.820\n",
      "Epoch: 2152/4000..  Training Loss: 0.018..  Test Loss: 1.063..  Test Accuracy: 0.824\n",
      "Epoch: 2153/4000..  Training Loss: 0.008..  Test Loss: 1.053..  Test Accuracy: 0.825\n",
      "Epoch: 2154/4000..  Training Loss: 0.019..  Test Loss: 1.130..  Test Accuracy: 0.816\n",
      "Epoch: 2155/4000..  Training Loss: 0.014..  Test Loss: 1.102..  Test Accuracy: 0.819\n",
      "Epoch: 2156/4000..  Training Loss: 0.008..  Test Loss: 1.124..  Test Accuracy: 0.817\n",
      "Epoch: 2157/4000..  Training Loss: 0.042..  Test Loss: 0.990..  Test Accuracy: 0.833\n",
      "Epoch: 2158/4000..  Training Loss: 0.010..  Test Loss: 1.073..  Test Accuracy: 0.823\n",
      "Epoch: 2159/4000..  Training Loss: 0.007..  Test Loss: 1.098..  Test Accuracy: 0.820\n",
      "Epoch: 2160/4000..  Training Loss: 0.020..  Test Loss: 1.068..  Test Accuracy: 0.824\n",
      "Epoch: 2161/4000..  Training Loss: 0.005..  Test Loss: 1.128..  Test Accuracy: 0.820\n",
      "Epoch: 2162/4000..  Training Loss: 0.004..  Test Loss: 1.082..  Test Accuracy: 0.826\n",
      "Epoch: 2163/4000..  Training Loss: 0.024..  Test Loss: 1.052..  Test Accuracy: 0.824\n",
      "Epoch: 2164/4000..  Training Loss: 0.025..  Test Loss: 1.012..  Test Accuracy: 0.831\n",
      "Epoch: 2165/4000..  Training Loss: 0.028..  Test Loss: 1.021..  Test Accuracy: 0.831\n",
      "Epoch: 2166/4000..  Training Loss: 0.008..  Test Loss: 1.030..  Test Accuracy: 0.829\n",
      "Epoch: 2167/4000..  Training Loss: 0.012..  Test Loss: 1.056..  Test Accuracy: 0.826\n",
      "Epoch: 2168/4000..  Training Loss: 0.008..  Test Loss: 1.046..  Test Accuracy: 0.826\n",
      "Epoch: 2169/4000..  Training Loss: 0.009..  Test Loss: 1.111..  Test Accuracy: 0.816\n",
      "Epoch: 2170/4000..  Training Loss: 0.013..  Test Loss: 1.067..  Test Accuracy: 0.826\n",
      "Epoch: 2171/4000..  Training Loss: 0.011..  Test Loss: 1.063..  Test Accuracy: 0.827\n",
      "Epoch: 2172/4000..  Training Loss: 0.045..  Test Loss: 1.070..  Test Accuracy: 0.826\n",
      "Epoch: 2173/4000..  Training Loss: 0.011..  Test Loss: 1.097..  Test Accuracy: 0.822\n",
      "Epoch: 2174/4000..  Training Loss: 0.014..  Test Loss: 1.072..  Test Accuracy: 0.826\n",
      "Epoch: 2175/4000..  Training Loss: 0.024..  Test Loss: 1.072..  Test Accuracy: 0.822\n",
      "Epoch: 2176/4000..  Training Loss: 0.026..  Test Loss: 1.072..  Test Accuracy: 0.824\n",
      "Epoch: 2177/4000..  Training Loss: 0.016..  Test Loss: 1.077..  Test Accuracy: 0.824\n",
      "Epoch: 2178/4000..  Training Loss: 0.004..  Test Loss: 1.049..  Test Accuracy: 0.827\n",
      "Epoch: 2179/4000..  Training Loss: 0.012..  Test Loss: 1.067..  Test Accuracy: 0.823\n",
      "Epoch: 2180/4000..  Training Loss: 0.003..  Test Loss: 1.048..  Test Accuracy: 0.826\n",
      "Epoch: 2181/4000..  Training Loss: 0.007..  Test Loss: 0.999..  Test Accuracy: 0.833\n",
      "Epoch: 2182/4000..  Training Loss: 0.034..  Test Loss: 1.028..  Test Accuracy: 0.828\n",
      "Epoch: 2183/4000..  Training Loss: 0.029..  Test Loss: 1.043..  Test Accuracy: 0.826\n",
      "Epoch: 2184/4000..  Training Loss: 0.009..  Test Loss: 1.016..  Test Accuracy: 0.830\n",
      "Epoch: 2185/4000..  Training Loss: 0.006..  Test Loss: 1.066..  Test Accuracy: 0.825\n",
      "Epoch: 2186/4000..  Training Loss: 0.042..  Test Loss: 1.104..  Test Accuracy: 0.821\n",
      "Epoch: 2187/4000..  Training Loss: 0.018..  Test Loss: 1.073..  Test Accuracy: 0.825\n",
      "Epoch: 2188/4000..  Training Loss: 0.013..  Test Loss: 1.067..  Test Accuracy: 0.826\n",
      "Epoch: 2189/4000..  Training Loss: 0.009..  Test Loss: 1.055..  Test Accuracy: 0.827\n",
      "Epoch: 2190/4000..  Training Loss: 0.035..  Test Loss: 1.069..  Test Accuracy: 0.823\n",
      "Epoch: 2191/4000..  Training Loss: 0.019..  Test Loss: 1.024..  Test Accuracy: 0.829\n",
      "Epoch: 2192/4000..  Training Loss: 0.009..  Test Loss: 1.052..  Test Accuracy: 0.825\n",
      "Epoch: 2193/4000..  Training Loss: 0.015..  Test Loss: 1.130..  Test Accuracy: 0.815\n",
      "Epoch: 2194/4000..  Training Loss: 0.012..  Test Loss: 1.098..  Test Accuracy: 0.821\n",
      "Epoch: 2195/4000..  Training Loss: 0.017..  Test Loss: 1.116..  Test Accuracy: 0.819\n",
      "Epoch: 2196/4000..  Training Loss: 0.009..  Test Loss: 1.112..  Test Accuracy: 0.815\n",
      "Epoch: 2197/4000..  Training Loss: 0.022..  Test Loss: 1.091..  Test Accuracy: 0.816\n",
      "Epoch: 2198/4000..  Training Loss: 0.009..  Test Loss: 1.009..  Test Accuracy: 0.831\n",
      "Epoch: 2199/4000..  Training Loss: 0.004..  Test Loss: 1.066..  Test Accuracy: 0.826\n",
      "Epoch: 2200/4000..  Training Loss: 0.029..  Test Loss: 1.076..  Test Accuracy: 0.826\n",
      "Epoch: 2201/4000..  Training Loss: 0.021..  Test Loss: 1.126..  Test Accuracy: 0.820\n",
      "Epoch: 2202/4000..  Training Loss: 0.027..  Test Loss: 1.141..  Test Accuracy: 0.816\n",
      "Epoch: 2203/4000..  Training Loss: 0.010..  Test Loss: 1.105..  Test Accuracy: 0.819\n",
      "Epoch: 2204/4000..  Training Loss: 0.009..  Test Loss: 1.078..  Test Accuracy: 0.826\n",
      "Epoch: 2205/4000..  Training Loss: 0.017..  Test Loss: 1.073..  Test Accuracy: 0.822\n",
      "Epoch: 2206/4000..  Training Loss: 0.004..  Test Loss: 1.068..  Test Accuracy: 0.822\n",
      "Epoch: 2207/4000..  Training Loss: 0.025..  Test Loss: 1.131..  Test Accuracy: 0.811\n",
      "Epoch: 2208/4000..  Training Loss: 0.019..  Test Loss: 1.136..  Test Accuracy: 0.810\n",
      "Epoch: 2209/4000..  Training Loss: 0.030..  Test Loss: 1.082..  Test Accuracy: 0.820\n",
      "Epoch: 2210/4000..  Training Loss: 0.024..  Test Loss: 1.061..  Test Accuracy: 0.824\n",
      "Epoch: 2211/4000..  Training Loss: 0.016..  Test Loss: 1.078..  Test Accuracy: 0.823\n",
      "Epoch: 2212/4000..  Training Loss: 0.023..  Test Loss: 1.066..  Test Accuracy: 0.824\n",
      "Epoch: 2213/4000..  Training Loss: 0.008..  Test Loss: 1.069..  Test Accuracy: 0.823\n",
      "Epoch: 2214/4000..  Training Loss: 0.012..  Test Loss: 1.025..  Test Accuracy: 0.827\n",
      "Epoch: 2215/4000..  Training Loss: 0.015..  Test Loss: 1.052..  Test Accuracy: 0.823\n",
      "Epoch: 2216/4000..  Training Loss: 0.013..  Test Loss: 1.056..  Test Accuracy: 0.824\n",
      "Epoch: 2217/4000..  Training Loss: 0.014..  Test Loss: 1.089..  Test Accuracy: 0.822\n",
      "Epoch: 2218/4000..  Training Loss: 0.005..  Test Loss: 1.050..  Test Accuracy: 0.826\n",
      "Epoch: 2219/4000..  Training Loss: 0.031..  Test Loss: 1.054..  Test Accuracy: 0.823\n",
      "Epoch: 2220/4000..  Training Loss: 0.028..  Test Loss: 1.100..  Test Accuracy: 0.823\n",
      "Epoch: 2221/4000..  Training Loss: 0.013..  Test Loss: 1.021..  Test Accuracy: 0.830\n",
      "Epoch: 2222/4000..  Training Loss: 0.006..  Test Loss: 1.050..  Test Accuracy: 0.828\n",
      "Epoch: 2223/4000..  Training Loss: 0.010..  Test Loss: 1.062..  Test Accuracy: 0.825\n",
      "Epoch: 2224/4000..  Training Loss: 0.012..  Test Loss: 1.058..  Test Accuracy: 0.824\n",
      "Epoch: 2225/4000..  Training Loss: 0.023..  Test Loss: 1.074..  Test Accuracy: 0.824\n",
      "Epoch: 2226/4000..  Training Loss: 0.016..  Test Loss: 1.110..  Test Accuracy: 0.818\n",
      "Epoch: 2227/4000..  Training Loss: 0.014..  Test Loss: 1.081..  Test Accuracy: 0.820\n",
      "Epoch: 2228/4000..  Training Loss: 0.009..  Test Loss: 1.126..  Test Accuracy: 0.819\n",
      "Epoch: 2229/4000..  Training Loss: 0.005..  Test Loss: 1.052..  Test Accuracy: 0.826\n",
      "Epoch: 2230/4000..  Training Loss: 0.018..  Test Loss: 1.072..  Test Accuracy: 0.819\n",
      "Epoch: 2231/4000..  Training Loss: 0.019..  Test Loss: 1.068..  Test Accuracy: 0.829\n",
      "Epoch: 2232/4000..  Training Loss: 0.014..  Test Loss: 1.083..  Test Accuracy: 0.825\n",
      "Epoch: 2233/4000..  Training Loss: 0.011..  Test Loss: 1.071..  Test Accuracy: 0.822\n",
      "Epoch: 2234/4000..  Training Loss: 0.060..  Test Loss: 1.127..  Test Accuracy: 0.820\n",
      "Epoch: 2235/4000..  Training Loss: 0.012..  Test Loss: 1.118..  Test Accuracy: 0.819\n",
      "Epoch: 2236/4000..  Training Loss: 0.010..  Test Loss: 1.111..  Test Accuracy: 0.816\n",
      "Epoch: 2237/4000..  Training Loss: 0.007..  Test Loss: 1.078..  Test Accuracy: 0.821\n",
      "Epoch: 2238/4000..  Training Loss: 0.016..  Test Loss: 1.100..  Test Accuracy: 0.818\n",
      "Epoch: 2239/4000..  Training Loss: 0.006..  Test Loss: 1.062..  Test Accuracy: 0.824\n",
      "Epoch: 2240/4000..  Training Loss: 0.021..  Test Loss: 1.114..  Test Accuracy: 0.815\n",
      "Epoch: 2241/4000..  Training Loss: 0.017..  Test Loss: 1.093..  Test Accuracy: 0.824\n",
      "Epoch: 2242/4000..  Training Loss: 0.023..  Test Loss: 1.203..  Test Accuracy: 0.811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2243/4000..  Training Loss: 0.023..  Test Loss: 1.137..  Test Accuracy: 0.819\n",
      "Epoch: 2244/4000..  Training Loss: 0.014..  Test Loss: 1.102..  Test Accuracy: 0.821\n",
      "Epoch: 2245/4000..  Training Loss: 0.007..  Test Loss: 1.074..  Test Accuracy: 0.825\n",
      "Epoch: 2246/4000..  Training Loss: 0.018..  Test Loss: 1.064..  Test Accuracy: 0.824\n",
      "Epoch: 2247/4000..  Training Loss: 0.005..  Test Loss: 1.043..  Test Accuracy: 0.828\n",
      "Epoch: 2248/4000..  Training Loss: 0.008..  Test Loss: 1.109..  Test Accuracy: 0.819\n",
      "Epoch: 2249/4000..  Training Loss: 0.031..  Test Loss: 1.091..  Test Accuracy: 0.819\n",
      "Epoch: 2250/4000..  Training Loss: 0.010..  Test Loss: 1.023..  Test Accuracy: 0.828\n",
      "Epoch: 2251/4000..  Training Loss: 0.033..  Test Loss: 1.112..  Test Accuracy: 0.818\n",
      "Epoch: 2252/4000..  Training Loss: 0.005..  Test Loss: 1.096..  Test Accuracy: 0.821\n",
      "Epoch: 2253/4000..  Training Loss: 0.013..  Test Loss: 0.995..  Test Accuracy: 0.832\n",
      "Epoch: 2254/4000..  Training Loss: 0.004..  Test Loss: 0.988..  Test Accuracy: 0.833\n",
      "Epoch: 2255/4000..  Training Loss: 0.008..  Test Loss: 1.007..  Test Accuracy: 0.830\n",
      "Epoch: 2256/4000..  Training Loss: 0.019..  Test Loss: 1.021..  Test Accuracy: 0.826\n",
      "Epoch: 2257/4000..  Training Loss: 0.012..  Test Loss: 1.080..  Test Accuracy: 0.820\n",
      "Epoch: 2258/4000..  Training Loss: 0.006..  Test Loss: 1.097..  Test Accuracy: 0.820\n",
      "Epoch: 2259/4000..  Training Loss: 0.005..  Test Loss: 1.108..  Test Accuracy: 0.820\n",
      "Epoch: 2260/4000..  Training Loss: 0.012..  Test Loss: 1.092..  Test Accuracy: 0.821\n",
      "Epoch: 2261/4000..  Training Loss: 0.011..  Test Loss: 1.074..  Test Accuracy: 0.822\n",
      "Epoch: 2262/4000..  Training Loss: 0.019..  Test Loss: 1.080..  Test Accuracy: 0.820\n",
      "Epoch: 2263/4000..  Training Loss: 0.035..  Test Loss: 1.040..  Test Accuracy: 0.830\n",
      "Epoch: 2264/4000..  Training Loss: 0.009..  Test Loss: 1.051..  Test Accuracy: 0.826\n",
      "Epoch: 2265/4000..  Training Loss: 0.005..  Test Loss: 1.079..  Test Accuracy: 0.824\n",
      "Epoch: 2266/4000..  Training Loss: 0.010..  Test Loss: 1.156..  Test Accuracy: 0.816\n",
      "Epoch: 2267/4000..  Training Loss: 0.006..  Test Loss: 1.079..  Test Accuracy: 0.824\n",
      "Epoch: 2268/4000..  Training Loss: 0.008..  Test Loss: 1.067..  Test Accuracy: 0.825\n",
      "Epoch: 2269/4000..  Training Loss: 0.009..  Test Loss: 1.034..  Test Accuracy: 0.830\n",
      "Epoch: 2270/4000..  Training Loss: 0.010..  Test Loss: 1.125..  Test Accuracy: 0.819\n",
      "Epoch: 2271/4000..  Training Loss: 0.004..  Test Loss: 1.086..  Test Accuracy: 0.823\n",
      "Epoch: 2272/4000..  Training Loss: 0.045..  Test Loss: 1.089..  Test Accuracy: 0.822\n",
      "Epoch: 2273/4000..  Training Loss: 0.006..  Test Loss: 1.045..  Test Accuracy: 0.825\n",
      "Epoch: 2274/4000..  Training Loss: 0.006..  Test Loss: 1.063..  Test Accuracy: 0.825\n",
      "Epoch: 2275/4000..  Training Loss: 0.004..  Test Loss: 1.068..  Test Accuracy: 0.825\n",
      "Epoch: 2276/4000..  Training Loss: 0.007..  Test Loss: 1.062..  Test Accuracy: 0.824\n",
      "Epoch: 2277/4000..  Training Loss: 0.055..  Test Loss: 1.030..  Test Accuracy: 0.832\n",
      "Epoch: 2278/4000..  Training Loss: 0.008..  Test Loss: 1.041..  Test Accuracy: 0.829\n",
      "Epoch: 2279/4000..  Training Loss: 0.008..  Test Loss: 1.046..  Test Accuracy: 0.827\n",
      "Epoch: 2280/4000..  Training Loss: 0.012..  Test Loss: 1.113..  Test Accuracy: 0.819\n",
      "Epoch: 2281/4000..  Training Loss: 0.017..  Test Loss: 1.204..  Test Accuracy: 0.808\n",
      "Epoch: 2282/4000..  Training Loss: 0.008..  Test Loss: 1.130..  Test Accuracy: 0.816\n",
      "Epoch: 2283/4000..  Training Loss: 0.027..  Test Loss: 1.085..  Test Accuracy: 0.825\n",
      "Epoch: 2284/4000..  Training Loss: 0.011..  Test Loss: 1.081..  Test Accuracy: 0.825\n",
      "Epoch: 2285/4000..  Training Loss: 0.006..  Test Loss: 1.032..  Test Accuracy: 0.830\n",
      "Epoch: 2286/4000..  Training Loss: 0.013..  Test Loss: 1.030..  Test Accuracy: 0.830\n",
      "Epoch: 2287/4000..  Training Loss: 0.019..  Test Loss: 1.114..  Test Accuracy: 0.819\n",
      "Epoch: 2288/4000..  Training Loss: 0.029..  Test Loss: 1.120..  Test Accuracy: 0.819\n",
      "Epoch: 2289/4000..  Training Loss: 0.010..  Test Loss: 1.079..  Test Accuracy: 0.826\n",
      "Epoch: 2290/4000..  Training Loss: 0.018..  Test Loss: 1.050..  Test Accuracy: 0.827\n",
      "Epoch: 2291/4000..  Training Loss: 0.021..  Test Loss: 1.114..  Test Accuracy: 0.818\n",
      "Epoch: 2292/4000..  Training Loss: 0.017..  Test Loss: 1.145..  Test Accuracy: 0.814\n",
      "Epoch: 2293/4000..  Training Loss: 0.015..  Test Loss: 1.096..  Test Accuracy: 0.824\n",
      "Epoch: 2294/4000..  Training Loss: 0.026..  Test Loss: 1.078..  Test Accuracy: 0.827\n",
      "Epoch: 2295/4000..  Training Loss: 0.020..  Test Loss: 1.065..  Test Accuracy: 0.828\n",
      "Epoch: 2296/4000..  Training Loss: 0.012..  Test Loss: 1.059..  Test Accuracy: 0.824\n",
      "Epoch: 2297/4000..  Training Loss: 0.009..  Test Loss: 1.086..  Test Accuracy: 0.821\n",
      "Epoch: 2298/4000..  Training Loss: 0.020..  Test Loss: 1.094..  Test Accuracy: 0.823\n",
      "Epoch: 2299/4000..  Training Loss: 0.047..  Test Loss: 1.149..  Test Accuracy: 0.815\n",
      "Epoch: 2300/4000..  Training Loss: 0.015..  Test Loss: 1.103..  Test Accuracy: 0.823\n",
      "Epoch: 2301/4000..  Training Loss: 0.013..  Test Loss: 1.056..  Test Accuracy: 0.826\n",
      "Epoch: 2302/4000..  Training Loss: 0.017..  Test Loss: 1.090..  Test Accuracy: 0.818\n",
      "Epoch: 2303/4000..  Training Loss: 0.026..  Test Loss: 1.061..  Test Accuracy: 0.827\n",
      "Epoch: 2304/4000..  Training Loss: 0.007..  Test Loss: 1.016..  Test Accuracy: 0.831\n",
      "Epoch: 2305/4000..  Training Loss: 0.012..  Test Loss: 1.065..  Test Accuracy: 0.827\n",
      "Epoch: 2306/4000..  Training Loss: 0.021..  Test Loss: 1.076..  Test Accuracy: 0.822\n",
      "Epoch: 2307/4000..  Training Loss: 0.020..  Test Loss: 1.095..  Test Accuracy: 0.825\n",
      "Epoch: 2308/4000..  Training Loss: 0.024..  Test Loss: 1.111..  Test Accuracy: 0.816\n",
      "Epoch: 2309/4000..  Training Loss: 0.010..  Test Loss: 1.033..  Test Accuracy: 0.830\n",
      "Epoch: 2310/4000..  Training Loss: 0.005..  Test Loss: 1.043..  Test Accuracy: 0.829\n",
      "Epoch: 2311/4000..  Training Loss: 0.008..  Test Loss: 1.019..  Test Accuracy: 0.833\n",
      "Epoch: 2312/4000..  Training Loss: 0.006..  Test Loss: 1.054..  Test Accuracy: 0.829\n",
      "Epoch: 2313/4000..  Training Loss: 0.018..  Test Loss: 1.111..  Test Accuracy: 0.821\n",
      "Epoch: 2314/4000..  Training Loss: 0.006..  Test Loss: 1.038..  Test Accuracy: 0.827\n",
      "Epoch: 2315/4000..  Training Loss: 0.028..  Test Loss: 1.085..  Test Accuracy: 0.822\n",
      "Epoch: 2316/4000..  Training Loss: 0.009..  Test Loss: 1.105..  Test Accuracy: 0.822\n",
      "Epoch: 2317/4000..  Training Loss: 0.006..  Test Loss: 1.038..  Test Accuracy: 0.829\n",
      "Epoch: 2318/4000..  Training Loss: 0.006..  Test Loss: 1.054..  Test Accuracy: 0.826\n",
      "Epoch: 2319/4000..  Training Loss: 0.009..  Test Loss: 1.068..  Test Accuracy: 0.824\n",
      "Epoch: 2320/4000..  Training Loss: 0.007..  Test Loss: 1.165..  Test Accuracy: 0.815\n",
      "Epoch: 2321/4000..  Training Loss: 0.004..  Test Loss: 1.087..  Test Accuracy: 0.823\n",
      "Epoch: 2322/4000..  Training Loss: 0.003..  Test Loss: 1.089..  Test Accuracy: 0.822\n",
      "Epoch: 2323/4000..  Training Loss: 0.016..  Test Loss: 1.106..  Test Accuracy: 0.822\n",
      "Epoch: 2324/4000..  Training Loss: 0.043..  Test Loss: 1.143..  Test Accuracy: 0.814\n",
      "Epoch: 2325/4000..  Training Loss: 0.007..  Test Loss: 1.084..  Test Accuracy: 0.825\n",
      "Epoch: 2326/4000..  Training Loss: 0.015..  Test Loss: 1.107..  Test Accuracy: 0.822\n",
      "Epoch: 2327/4000..  Training Loss: 0.020..  Test Loss: 1.130..  Test Accuracy: 0.818\n",
      "Epoch: 2328/4000..  Training Loss: 0.020..  Test Loss: 1.093..  Test Accuracy: 0.822\n",
      "Epoch: 2329/4000..  Training Loss: 0.008..  Test Loss: 1.101..  Test Accuracy: 0.821\n",
      "Epoch: 2330/4000..  Training Loss: 0.011..  Test Loss: 1.127..  Test Accuracy: 0.817\n",
      "Epoch: 2331/4000..  Training Loss: 0.019..  Test Loss: 1.092..  Test Accuracy: 0.824\n",
      "Epoch: 2332/4000..  Training Loss: 0.021..  Test Loss: 1.045..  Test Accuracy: 0.828\n",
      "Epoch: 2333/4000..  Training Loss: 0.017..  Test Loss: 1.134..  Test Accuracy: 0.821\n",
      "Epoch: 2334/4000..  Training Loss: 0.013..  Test Loss: 1.133..  Test Accuracy: 0.819\n",
      "Epoch: 2335/4000..  Training Loss: 0.024..  Test Loss: 1.079..  Test Accuracy: 0.824\n",
      "Epoch: 2336/4000..  Training Loss: 0.011..  Test Loss: 1.169..  Test Accuracy: 0.815\n",
      "Epoch: 2337/4000..  Training Loss: 0.019..  Test Loss: 1.098..  Test Accuracy: 0.823\n",
      "Epoch: 2338/4000..  Training Loss: 0.009..  Test Loss: 1.162..  Test Accuracy: 0.815\n",
      "Epoch: 2339/4000..  Training Loss: 0.005..  Test Loss: 1.110..  Test Accuracy: 0.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2340/4000..  Training Loss: 0.004..  Test Loss: 1.088..  Test Accuracy: 0.823\n",
      "Epoch: 2341/4000..  Training Loss: 0.011..  Test Loss: 1.103..  Test Accuracy: 0.822\n",
      "Epoch: 2342/4000..  Training Loss: 0.007..  Test Loss: 1.107..  Test Accuracy: 0.820\n",
      "Epoch: 2343/4000..  Training Loss: 0.005..  Test Loss: 1.084..  Test Accuracy: 0.825\n",
      "Epoch: 2344/4000..  Training Loss: 0.017..  Test Loss: 1.124..  Test Accuracy: 0.819\n",
      "Epoch: 2345/4000..  Training Loss: 0.010..  Test Loss: 1.077..  Test Accuracy: 0.824\n",
      "Epoch: 2346/4000..  Training Loss: 0.007..  Test Loss: 1.042..  Test Accuracy: 0.828\n",
      "Epoch: 2347/4000..  Training Loss: 0.011..  Test Loss: 0.999..  Test Accuracy: 0.835\n",
      "Epoch: 2348/4000..  Training Loss: 0.027..  Test Loss: 1.066..  Test Accuracy: 0.826\n",
      "Epoch: 2349/4000..  Training Loss: 0.003..  Test Loss: 1.055..  Test Accuracy: 0.827\n",
      "Epoch: 2350/4000..  Training Loss: 0.009..  Test Loss: 1.038..  Test Accuracy: 0.831\n",
      "Epoch: 2351/4000..  Training Loss: 0.032..  Test Loss: 1.117..  Test Accuracy: 0.814\n",
      "Epoch: 2352/4000..  Training Loss: 0.016..  Test Loss: 1.158..  Test Accuracy: 0.817\n",
      "Epoch: 2353/4000..  Training Loss: 0.012..  Test Loss: 1.078..  Test Accuracy: 0.824\n",
      "Epoch: 2354/4000..  Training Loss: 0.023..  Test Loss: 1.111..  Test Accuracy: 0.818\n",
      "Epoch: 2355/4000..  Training Loss: 0.010..  Test Loss: 1.096..  Test Accuracy: 0.822\n",
      "Epoch: 2356/4000..  Training Loss: 0.011..  Test Loss: 1.021..  Test Accuracy: 0.833\n",
      "Epoch: 2357/4000..  Training Loss: 0.041..  Test Loss: 1.100..  Test Accuracy: 0.820\n",
      "Epoch: 2358/4000..  Training Loss: 0.049..  Test Loss: 1.085..  Test Accuracy: 0.826\n",
      "Epoch: 2359/4000..  Training Loss: 0.003..  Test Loss: 1.065..  Test Accuracy: 0.830\n",
      "Epoch: 2360/4000..  Training Loss: 0.009..  Test Loss: 1.053..  Test Accuracy: 0.831\n",
      "Epoch: 2361/4000..  Training Loss: 0.018..  Test Loss: 1.091..  Test Accuracy: 0.826\n",
      "Epoch: 2362/4000..  Training Loss: 0.005..  Test Loss: 1.090..  Test Accuracy: 0.825\n",
      "Epoch: 2363/4000..  Training Loss: 0.011..  Test Loss: 1.049..  Test Accuracy: 0.826\n",
      "Epoch: 2364/4000..  Training Loss: 0.006..  Test Loss: 1.031..  Test Accuracy: 0.828\n",
      "Epoch: 2365/4000..  Training Loss: 0.002..  Test Loss: 1.050..  Test Accuracy: 0.827\n",
      "Epoch: 2366/4000..  Training Loss: 0.007..  Test Loss: 1.144..  Test Accuracy: 0.816\n",
      "Epoch: 2367/4000..  Training Loss: 0.020..  Test Loss: 1.044..  Test Accuracy: 0.830\n",
      "Epoch: 2368/4000..  Training Loss: 0.012..  Test Loss: 1.103..  Test Accuracy: 0.822\n",
      "Epoch: 2369/4000..  Training Loss: 0.017..  Test Loss: 1.156..  Test Accuracy: 0.819\n",
      "Epoch: 2370/4000..  Training Loss: 0.013..  Test Loss: 1.085..  Test Accuracy: 0.825\n",
      "Epoch: 2371/4000..  Training Loss: 0.013..  Test Loss: 1.099..  Test Accuracy: 0.826\n",
      "Epoch: 2372/4000..  Training Loss: 0.017..  Test Loss: 1.144..  Test Accuracy: 0.815\n",
      "Epoch: 2373/4000..  Training Loss: 0.007..  Test Loss: 1.080..  Test Accuracy: 0.825\n",
      "Epoch: 2374/4000..  Training Loss: 0.008..  Test Loss: 1.083..  Test Accuracy: 0.826\n",
      "Epoch: 2375/4000..  Training Loss: 0.019..  Test Loss: 1.082..  Test Accuracy: 0.823\n",
      "Epoch: 2376/4000..  Training Loss: 0.016..  Test Loss: 1.102..  Test Accuracy: 0.823\n",
      "Epoch: 2377/4000..  Training Loss: 0.021..  Test Loss: 1.005..  Test Accuracy: 0.834\n",
      "Epoch: 2378/4000..  Training Loss: 0.039..  Test Loss: 1.064..  Test Accuracy: 0.828\n",
      "Epoch: 2379/4000..  Training Loss: 0.012..  Test Loss: 1.075..  Test Accuracy: 0.827\n",
      "Epoch: 2380/4000..  Training Loss: 0.008..  Test Loss: 1.070..  Test Accuracy: 0.827\n",
      "Epoch: 2381/4000..  Training Loss: 0.037..  Test Loss: 1.059..  Test Accuracy: 0.828\n",
      "Epoch: 2382/4000..  Training Loss: 0.009..  Test Loss: 1.093..  Test Accuracy: 0.823\n",
      "Epoch: 2383/4000..  Training Loss: 0.004..  Test Loss: 1.095..  Test Accuracy: 0.823\n",
      "Epoch: 2384/4000..  Training Loss: 0.014..  Test Loss: 1.078..  Test Accuracy: 0.824\n",
      "Epoch: 2385/4000..  Training Loss: 0.033..  Test Loss: 1.020..  Test Accuracy: 0.834\n",
      "Epoch: 2386/4000..  Training Loss: 0.042..  Test Loss: 1.080..  Test Accuracy: 0.824\n",
      "Epoch: 2387/4000..  Training Loss: 0.006..  Test Loss: 1.062..  Test Accuracy: 0.828\n",
      "Epoch: 2388/4000..  Training Loss: 0.047..  Test Loss: 1.115..  Test Accuracy: 0.819\n",
      "Epoch: 2389/4000..  Training Loss: 0.026..  Test Loss: 1.138..  Test Accuracy: 0.819\n",
      "Epoch: 2390/4000..  Training Loss: 0.010..  Test Loss: 1.168..  Test Accuracy: 0.816\n",
      "Epoch: 2391/4000..  Training Loss: 0.020..  Test Loss: 1.187..  Test Accuracy: 0.812\n",
      "Epoch: 2392/4000..  Training Loss: 0.003..  Test Loss: 1.139..  Test Accuracy: 0.819\n",
      "Epoch: 2393/4000..  Training Loss: 0.009..  Test Loss: 1.058..  Test Accuracy: 0.827\n",
      "Epoch: 2394/4000..  Training Loss: 0.011..  Test Loss: 1.100..  Test Accuracy: 0.822\n",
      "Epoch: 2395/4000..  Training Loss: 0.016..  Test Loss: 1.092..  Test Accuracy: 0.821\n",
      "Epoch: 2396/4000..  Training Loss: 0.014..  Test Loss: 1.048..  Test Accuracy: 0.828\n",
      "Epoch: 2397/4000..  Training Loss: 0.014..  Test Loss: 1.036..  Test Accuracy: 0.833\n",
      "Epoch: 2398/4000..  Training Loss: 0.006..  Test Loss: 1.082..  Test Accuracy: 0.826\n",
      "Epoch: 2399/4000..  Training Loss: 0.037..  Test Loss: 1.071..  Test Accuracy: 0.825\n",
      "Epoch: 2400/4000..  Training Loss: 0.008..  Test Loss: 1.039..  Test Accuracy: 0.830\n",
      "Epoch: 2401/4000..  Training Loss: 0.011..  Test Loss: 1.051..  Test Accuracy: 0.830\n",
      "Epoch: 2402/4000..  Training Loss: 0.017..  Test Loss: 1.097..  Test Accuracy: 0.826\n",
      "Epoch: 2403/4000..  Training Loss: 0.009..  Test Loss: 1.070..  Test Accuracy: 0.828\n",
      "Epoch: 2404/4000..  Training Loss: 0.002..  Test Loss: 1.071..  Test Accuracy: 0.826\n",
      "Epoch: 2405/4000..  Training Loss: 0.018..  Test Loss: 1.132..  Test Accuracy: 0.820\n",
      "Epoch: 2406/4000..  Training Loss: 0.004..  Test Loss: 1.113..  Test Accuracy: 0.822\n",
      "Epoch: 2407/4000..  Training Loss: 0.012..  Test Loss: 1.046..  Test Accuracy: 0.831\n",
      "Epoch: 2408/4000..  Training Loss: 0.007..  Test Loss: 1.047..  Test Accuracy: 0.828\n",
      "Epoch: 2409/4000..  Training Loss: 0.006..  Test Loss: 1.110..  Test Accuracy: 0.824\n",
      "Epoch: 2410/4000..  Training Loss: 0.011..  Test Loss: 1.168..  Test Accuracy: 0.811\n",
      "Epoch: 2411/4000..  Training Loss: 0.011..  Test Loss: 1.102..  Test Accuracy: 0.819\n",
      "Epoch: 2412/4000..  Training Loss: 0.014..  Test Loss: 1.077..  Test Accuracy: 0.827\n",
      "Epoch: 2413/4000..  Training Loss: 0.008..  Test Loss: 1.076..  Test Accuracy: 0.828\n",
      "Epoch: 2414/4000..  Training Loss: 0.023..  Test Loss: 1.052..  Test Accuracy: 0.832\n",
      "Epoch: 2415/4000..  Training Loss: 0.008..  Test Loss: 1.128..  Test Accuracy: 0.818\n",
      "Epoch: 2416/4000..  Training Loss: 0.016..  Test Loss: 1.086..  Test Accuracy: 0.825\n",
      "Epoch: 2417/4000..  Training Loss: 0.002..  Test Loss: 1.106..  Test Accuracy: 0.823\n",
      "Epoch: 2418/4000..  Training Loss: 0.032..  Test Loss: 1.044..  Test Accuracy: 0.829\n",
      "Epoch: 2419/4000..  Training Loss: 0.011..  Test Loss: 1.084..  Test Accuracy: 0.828\n",
      "Epoch: 2420/4000..  Training Loss: 0.059..  Test Loss: 1.115..  Test Accuracy: 0.820\n",
      "Epoch: 2421/4000..  Training Loss: 0.011..  Test Loss: 1.058..  Test Accuracy: 0.828\n",
      "Epoch: 2422/4000..  Training Loss: 0.007..  Test Loss: 1.066..  Test Accuracy: 0.827\n",
      "Epoch: 2423/4000..  Training Loss: 0.023..  Test Loss: 1.076..  Test Accuracy: 0.825\n",
      "Epoch: 2424/4000..  Training Loss: 0.018..  Test Loss: 1.050..  Test Accuracy: 0.829\n",
      "Epoch: 2425/4000..  Training Loss: 0.007..  Test Loss: 1.047..  Test Accuracy: 0.829\n",
      "Epoch: 2426/4000..  Training Loss: 0.004..  Test Loss: 1.085..  Test Accuracy: 0.825\n",
      "Epoch: 2427/4000..  Training Loss: 0.006..  Test Loss: 1.103..  Test Accuracy: 0.823\n",
      "Epoch: 2428/4000..  Training Loss: 0.010..  Test Loss: 1.099..  Test Accuracy: 0.824\n",
      "Epoch: 2429/4000..  Training Loss: 0.008..  Test Loss: 1.111..  Test Accuracy: 0.820\n",
      "Epoch: 2430/4000..  Training Loss: 0.022..  Test Loss: 1.097..  Test Accuracy: 0.823\n",
      "Epoch: 2431/4000..  Training Loss: 0.017..  Test Loss: 1.041..  Test Accuracy: 0.828\n",
      "Epoch: 2432/4000..  Training Loss: 0.015..  Test Loss: 1.115..  Test Accuracy: 0.821\n",
      "Epoch: 2433/4000..  Training Loss: 0.015..  Test Loss: 1.079..  Test Accuracy: 0.825\n",
      "Epoch: 2434/4000..  Training Loss: 0.017..  Test Loss: 1.110..  Test Accuracy: 0.823\n",
      "Epoch: 2435/4000..  Training Loss: 0.010..  Test Loss: 1.073..  Test Accuracy: 0.827\n",
      "Epoch: 2436/4000..  Training Loss: 0.017..  Test Loss: 1.034..  Test Accuracy: 0.831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2437/4000..  Training Loss: 0.011..  Test Loss: 1.044..  Test Accuracy: 0.829\n",
      "Epoch: 2438/4000..  Training Loss: 0.005..  Test Loss: 1.046..  Test Accuracy: 0.832\n",
      "Epoch: 2439/4000..  Training Loss: 0.018..  Test Loss: 1.105..  Test Accuracy: 0.826\n",
      "Epoch: 2440/4000..  Training Loss: 0.013..  Test Loss: 1.102..  Test Accuracy: 0.821\n",
      "Epoch: 2441/4000..  Training Loss: 0.007..  Test Loss: 1.118..  Test Accuracy: 0.820\n",
      "Epoch: 2442/4000..  Training Loss: 0.012..  Test Loss: 1.107..  Test Accuracy: 0.822\n",
      "Epoch: 2443/4000..  Training Loss: 0.008..  Test Loss: 1.066..  Test Accuracy: 0.828\n",
      "Epoch: 2444/4000..  Training Loss: 0.008..  Test Loss: 1.106..  Test Accuracy: 0.821\n",
      "Epoch: 2445/4000..  Training Loss: 0.007..  Test Loss: 1.064..  Test Accuracy: 0.827\n",
      "Epoch: 2446/4000..  Training Loss: 0.012..  Test Loss: 1.105..  Test Accuracy: 0.823\n",
      "Epoch: 2447/4000..  Training Loss: 0.019..  Test Loss: 1.087..  Test Accuracy: 0.823\n",
      "Epoch: 2448/4000..  Training Loss: 0.023..  Test Loss: 1.182..  Test Accuracy: 0.815\n",
      "Epoch: 2449/4000..  Training Loss: 0.021..  Test Loss: 1.033..  Test Accuracy: 0.830\n",
      "Epoch: 2450/4000..  Training Loss: 0.010..  Test Loss: 1.057..  Test Accuracy: 0.830\n",
      "Epoch: 2451/4000..  Training Loss: 0.033..  Test Loss: 1.127..  Test Accuracy: 0.821\n",
      "Epoch: 2452/4000..  Training Loss: 0.020..  Test Loss: 1.035..  Test Accuracy: 0.833\n",
      "Epoch: 2453/4000..  Training Loss: 0.029..  Test Loss: 1.065..  Test Accuracy: 0.828\n",
      "Epoch: 2454/4000..  Training Loss: 0.005..  Test Loss: 1.070..  Test Accuracy: 0.826\n",
      "Epoch: 2455/4000..  Training Loss: 0.038..  Test Loss: 1.052..  Test Accuracy: 0.830\n",
      "Epoch: 2456/4000..  Training Loss: 0.005..  Test Loss: 1.043..  Test Accuracy: 0.831\n",
      "Epoch: 2457/4000..  Training Loss: 0.007..  Test Loss: 1.063..  Test Accuracy: 0.830\n",
      "Epoch: 2458/4000..  Training Loss: 0.002..  Test Loss: 1.080..  Test Accuracy: 0.827\n",
      "Epoch: 2459/4000..  Training Loss: 0.028..  Test Loss: 1.011..  Test Accuracy: 0.836\n",
      "Epoch: 2460/4000..  Training Loss: 0.014..  Test Loss: 1.137..  Test Accuracy: 0.823\n",
      "Epoch: 2461/4000..  Training Loss: 0.016..  Test Loss: 1.099..  Test Accuracy: 0.827\n",
      "Epoch: 2462/4000..  Training Loss: 0.029..  Test Loss: 1.149..  Test Accuracy: 0.817\n",
      "Epoch: 2463/4000..  Training Loss: 0.038..  Test Loss: 1.028..  Test Accuracy: 0.835\n",
      "Epoch: 2464/4000..  Training Loss: 0.018..  Test Loss: 1.085..  Test Accuracy: 0.828\n",
      "Epoch: 2465/4000..  Training Loss: 0.017..  Test Loss: 1.054..  Test Accuracy: 0.829\n",
      "Epoch: 2466/4000..  Training Loss: 0.042..  Test Loss: 1.100..  Test Accuracy: 0.828\n",
      "Epoch: 2467/4000..  Training Loss: 0.009..  Test Loss: 1.089..  Test Accuracy: 0.825\n",
      "Epoch: 2468/4000..  Training Loss: 0.013..  Test Loss: 1.150..  Test Accuracy: 0.818\n",
      "Epoch: 2469/4000..  Training Loss: 0.005..  Test Loss: 1.097..  Test Accuracy: 0.824\n",
      "Epoch: 2470/4000..  Training Loss: 0.025..  Test Loss: 1.092..  Test Accuracy: 0.825\n",
      "Epoch: 2471/4000..  Training Loss: 0.029..  Test Loss: 1.042..  Test Accuracy: 0.829\n",
      "Epoch: 2472/4000..  Training Loss: 0.021..  Test Loss: 1.081..  Test Accuracy: 0.824\n",
      "Epoch: 2473/4000..  Training Loss: 0.030..  Test Loss: 1.140..  Test Accuracy: 0.821\n",
      "Epoch: 2474/4000..  Training Loss: 0.032..  Test Loss: 1.091..  Test Accuracy: 0.825\n",
      "Epoch: 2475/4000..  Training Loss: 0.032..  Test Loss: 1.031..  Test Accuracy: 0.833\n",
      "Epoch: 2476/4000..  Training Loss: 0.004..  Test Loss: 1.032..  Test Accuracy: 0.832\n",
      "Epoch: 2477/4000..  Training Loss: 0.008..  Test Loss: 1.056..  Test Accuracy: 0.828\n",
      "Epoch: 2478/4000..  Training Loss: 0.006..  Test Loss: 1.069..  Test Accuracy: 0.828\n",
      "Epoch: 2479/4000..  Training Loss: 0.011..  Test Loss: 1.061..  Test Accuracy: 0.828\n",
      "Epoch: 2480/4000..  Training Loss: 0.012..  Test Loss: 1.022..  Test Accuracy: 0.834\n",
      "Epoch: 2481/4000..  Training Loss: 0.030..  Test Loss: 1.140..  Test Accuracy: 0.815\n",
      "Epoch: 2482/4000..  Training Loss: 0.022..  Test Loss: 1.074..  Test Accuracy: 0.827\n",
      "Epoch: 2483/4000..  Training Loss: 0.006..  Test Loss: 1.093..  Test Accuracy: 0.826\n",
      "Epoch: 2484/4000..  Training Loss: 0.045..  Test Loss: 1.109..  Test Accuracy: 0.820\n",
      "Epoch: 2485/4000..  Training Loss: 0.007..  Test Loss: 1.067..  Test Accuracy: 0.828\n",
      "Epoch: 2486/4000..  Training Loss: 0.012..  Test Loss: 1.055..  Test Accuracy: 0.830\n",
      "Epoch: 2487/4000..  Training Loss: 0.016..  Test Loss: 1.113..  Test Accuracy: 0.823\n",
      "Epoch: 2488/4000..  Training Loss: 0.005..  Test Loss: 1.116..  Test Accuracy: 0.824\n",
      "Epoch: 2489/4000..  Training Loss: 0.019..  Test Loss: 1.052..  Test Accuracy: 0.831\n",
      "Epoch: 2490/4000..  Training Loss: 0.017..  Test Loss: 1.107..  Test Accuracy: 0.826\n",
      "Epoch: 2491/4000..  Training Loss: 0.003..  Test Loss: 1.065..  Test Accuracy: 0.829\n",
      "Epoch: 2492/4000..  Training Loss: 0.014..  Test Loss: 1.073..  Test Accuracy: 0.828\n",
      "Epoch: 2493/4000..  Training Loss: 0.005..  Test Loss: 1.064..  Test Accuracy: 0.830\n",
      "Epoch: 2494/4000..  Training Loss: 0.015..  Test Loss: 1.076..  Test Accuracy: 0.827\n",
      "Epoch: 2495/4000..  Training Loss: 0.033..  Test Loss: 1.088..  Test Accuracy: 0.826\n",
      "Epoch: 2496/4000..  Training Loss: 0.010..  Test Loss: 1.084..  Test Accuracy: 0.827\n",
      "Epoch: 2497/4000..  Training Loss: 0.012..  Test Loss: 1.052..  Test Accuracy: 0.828\n",
      "Epoch: 2498/4000..  Training Loss: 0.010..  Test Loss: 1.010..  Test Accuracy: 0.834\n",
      "Epoch: 2499/4000..  Training Loss: 0.006..  Test Loss: 1.034..  Test Accuracy: 0.832\n",
      "Epoch: 2500/4000..  Training Loss: 0.007..  Test Loss: 1.035..  Test Accuracy: 0.831\n",
      "Epoch: 2501/4000..  Training Loss: 0.007..  Test Loss: 1.103..  Test Accuracy: 0.822\n",
      "Epoch: 2502/4000..  Training Loss: 0.005..  Test Loss: 1.083..  Test Accuracy: 0.825\n",
      "Epoch: 2503/4000..  Training Loss: 0.026..  Test Loss: 1.076..  Test Accuracy: 0.822\n",
      "Epoch: 2504/4000..  Training Loss: 0.035..  Test Loss: 1.114..  Test Accuracy: 0.823\n",
      "Epoch: 2505/4000..  Training Loss: 0.003..  Test Loss: 1.099..  Test Accuracy: 0.825\n",
      "Epoch: 2506/4000..  Training Loss: 0.006..  Test Loss: 1.097..  Test Accuracy: 0.826\n",
      "Epoch: 2507/4000..  Training Loss: 0.011..  Test Loss: 1.033..  Test Accuracy: 0.831\n",
      "Epoch: 2508/4000..  Training Loss: 0.006..  Test Loss: 1.059..  Test Accuracy: 0.831\n",
      "Epoch: 2509/4000..  Training Loss: 0.017..  Test Loss: 1.091..  Test Accuracy: 0.826\n",
      "Epoch: 2510/4000..  Training Loss: 0.024..  Test Loss: 1.090..  Test Accuracy: 0.826\n",
      "Epoch: 2511/4000..  Training Loss: 0.014..  Test Loss: 1.114..  Test Accuracy: 0.822\n",
      "Epoch: 2512/4000..  Training Loss: 0.011..  Test Loss: 1.095..  Test Accuracy: 0.826\n",
      "Epoch: 2513/4000..  Training Loss: 0.020..  Test Loss: 1.044..  Test Accuracy: 0.830\n",
      "Epoch: 2514/4000..  Training Loss: 0.006..  Test Loss: 1.023..  Test Accuracy: 0.833\n",
      "Epoch: 2515/4000..  Training Loss: 0.009..  Test Loss: 1.114..  Test Accuracy: 0.825\n",
      "Epoch: 2516/4000..  Training Loss: 0.004..  Test Loss: 1.089..  Test Accuracy: 0.828\n",
      "Epoch: 2517/4000..  Training Loss: 0.016..  Test Loss: 1.083..  Test Accuracy: 0.828\n",
      "Epoch: 2518/4000..  Training Loss: 0.008..  Test Loss: 1.046..  Test Accuracy: 0.831\n",
      "Epoch: 2519/4000..  Training Loss: 0.005..  Test Loss: 1.054..  Test Accuracy: 0.830\n",
      "Epoch: 2520/4000..  Training Loss: 0.009..  Test Loss: 1.066..  Test Accuracy: 0.828\n",
      "Epoch: 2521/4000..  Training Loss: 0.011..  Test Loss: 1.063..  Test Accuracy: 0.830\n",
      "Epoch: 2522/4000..  Training Loss: 0.020..  Test Loss: 1.051..  Test Accuracy: 0.831\n",
      "Epoch: 2523/4000..  Training Loss: 0.017..  Test Loss: 1.056..  Test Accuracy: 0.828\n",
      "Epoch: 2524/4000..  Training Loss: 0.017..  Test Loss: 1.089..  Test Accuracy: 0.825\n",
      "Epoch: 2525/4000..  Training Loss: 0.007..  Test Loss: 1.067..  Test Accuracy: 0.829\n",
      "Epoch: 2526/4000..  Training Loss: 0.007..  Test Loss: 1.035..  Test Accuracy: 0.832\n",
      "Epoch: 2527/4000..  Training Loss: 0.015..  Test Loss: 1.071..  Test Accuracy: 0.828\n",
      "Epoch: 2528/4000..  Training Loss: 0.013..  Test Loss: 1.069..  Test Accuracy: 0.828\n",
      "Epoch: 2529/4000..  Training Loss: 0.010..  Test Loss: 1.106..  Test Accuracy: 0.820\n",
      "Epoch: 2530/4000..  Training Loss: 0.040..  Test Loss: 1.132..  Test Accuracy: 0.819\n",
      "Epoch: 2531/4000..  Training Loss: 0.016..  Test Loss: 1.196..  Test Accuracy: 0.814\n",
      "Epoch: 2532/4000..  Training Loss: 0.025..  Test Loss: 1.070..  Test Accuracy: 0.826\n",
      "Epoch: 2533/4000..  Training Loss: 0.013..  Test Loss: 1.060..  Test Accuracy: 0.831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2534/4000..  Training Loss: 0.007..  Test Loss: 1.020..  Test Accuracy: 0.833\n",
      "Epoch: 2535/4000..  Training Loss: 0.005..  Test Loss: 1.038..  Test Accuracy: 0.831\n",
      "Epoch: 2536/4000..  Training Loss: 0.018..  Test Loss: 1.072..  Test Accuracy: 0.828\n",
      "Epoch: 2537/4000..  Training Loss: 0.007..  Test Loss: 1.062..  Test Accuracy: 0.828\n",
      "Epoch: 2538/4000..  Training Loss: 0.016..  Test Loss: 1.154..  Test Accuracy: 0.818\n",
      "Epoch: 2539/4000..  Training Loss: 0.007..  Test Loss: 1.115..  Test Accuracy: 0.823\n",
      "Epoch: 2540/4000..  Training Loss: 0.013..  Test Loss: 1.093..  Test Accuracy: 0.826\n",
      "Epoch: 2541/4000..  Training Loss: 0.014..  Test Loss: 1.103..  Test Accuracy: 0.824\n",
      "Epoch: 2542/4000..  Training Loss: 0.038..  Test Loss: 1.087..  Test Accuracy: 0.825\n",
      "Epoch: 2543/4000..  Training Loss: 0.003..  Test Loss: 1.075..  Test Accuracy: 0.828\n",
      "Epoch: 2544/4000..  Training Loss: 0.015..  Test Loss: 1.148..  Test Accuracy: 0.818\n",
      "Epoch: 2545/4000..  Training Loss: 0.028..  Test Loss: 1.114..  Test Accuracy: 0.824\n",
      "Epoch: 2546/4000..  Training Loss: 0.010..  Test Loss: 1.093..  Test Accuracy: 0.828\n",
      "Epoch: 2547/4000..  Training Loss: 0.005..  Test Loss: 1.090..  Test Accuracy: 0.829\n",
      "Epoch: 2548/4000..  Training Loss: 0.004..  Test Loss: 1.069..  Test Accuracy: 0.829\n",
      "Epoch: 2549/4000..  Training Loss: 0.007..  Test Loss: 1.099..  Test Accuracy: 0.826\n",
      "Epoch: 2550/4000..  Training Loss: 0.013..  Test Loss: 1.094..  Test Accuracy: 0.826\n",
      "Epoch: 2551/4000..  Training Loss: 0.010..  Test Loss: 1.039..  Test Accuracy: 0.831\n",
      "Epoch: 2552/4000..  Training Loss: 0.006..  Test Loss: 1.078..  Test Accuracy: 0.827\n",
      "Epoch: 2553/4000..  Training Loss: 0.028..  Test Loss: 1.099..  Test Accuracy: 0.825\n",
      "Epoch: 2554/4000..  Training Loss: 0.021..  Test Loss: 1.071..  Test Accuracy: 0.827\n",
      "Epoch: 2555/4000..  Training Loss: 0.013..  Test Loss: 1.144..  Test Accuracy: 0.823\n",
      "Epoch: 2556/4000..  Training Loss: 0.035..  Test Loss: 1.133..  Test Accuracy: 0.822\n",
      "Epoch: 2557/4000..  Training Loss: 0.016..  Test Loss: 1.091..  Test Accuracy: 0.826\n",
      "Epoch: 2558/4000..  Training Loss: 0.005..  Test Loss: 1.060..  Test Accuracy: 0.830\n",
      "Epoch: 2559/4000..  Training Loss: 0.003..  Test Loss: 1.084..  Test Accuracy: 0.829\n",
      "Epoch: 2560/4000..  Training Loss: 0.005..  Test Loss: 1.084..  Test Accuracy: 0.829\n",
      "Epoch: 2561/4000..  Training Loss: 0.028..  Test Loss: 1.066..  Test Accuracy: 0.830\n",
      "Epoch: 2562/4000..  Training Loss: 0.008..  Test Loss: 1.041..  Test Accuracy: 0.830\n",
      "Epoch: 2563/4000..  Training Loss: 0.005..  Test Loss: 1.072..  Test Accuracy: 0.828\n",
      "Epoch: 2564/4000..  Training Loss: 0.004..  Test Loss: 1.088..  Test Accuracy: 0.824\n",
      "Epoch: 2565/4000..  Training Loss: 0.042..  Test Loss: 1.130..  Test Accuracy: 0.819\n",
      "Epoch: 2566/4000..  Training Loss: 0.012..  Test Loss: 1.054..  Test Accuracy: 0.831\n",
      "Epoch: 2567/4000..  Training Loss: 0.007..  Test Loss: 1.065..  Test Accuracy: 0.829\n",
      "Epoch: 2568/4000..  Training Loss: 0.027..  Test Loss: 1.018..  Test Accuracy: 0.836\n",
      "Epoch: 2569/4000..  Training Loss: 0.011..  Test Loss: 1.036..  Test Accuracy: 0.831\n",
      "Epoch: 2570/4000..  Training Loss: 0.008..  Test Loss: 1.032..  Test Accuracy: 0.831\n",
      "Epoch: 2571/4000..  Training Loss: 0.003..  Test Loss: 1.048..  Test Accuracy: 0.829\n",
      "Epoch: 2572/4000..  Training Loss: 0.004..  Test Loss: 1.043..  Test Accuracy: 0.832\n",
      "Epoch: 2573/4000..  Training Loss: 0.023..  Test Loss: 1.054..  Test Accuracy: 0.829\n",
      "Epoch: 2574/4000..  Training Loss: 0.020..  Test Loss: 1.113..  Test Accuracy: 0.823\n",
      "Epoch: 2575/4000..  Training Loss: 0.037..  Test Loss: 1.098..  Test Accuracy: 0.824\n",
      "Epoch: 2576/4000..  Training Loss: 0.009..  Test Loss: 1.093..  Test Accuracy: 0.826\n",
      "Epoch: 2577/4000..  Training Loss: 0.013..  Test Loss: 1.070..  Test Accuracy: 0.829\n",
      "Epoch: 2578/4000..  Training Loss: 0.007..  Test Loss: 1.009..  Test Accuracy: 0.837\n",
      "Epoch: 2579/4000..  Training Loss: 0.012..  Test Loss: 1.022..  Test Accuracy: 0.832\n",
      "Epoch: 2580/4000..  Training Loss: 0.006..  Test Loss: 1.039..  Test Accuracy: 0.829\n",
      "Epoch: 2581/4000..  Training Loss: 0.008..  Test Loss: 1.047..  Test Accuracy: 0.830\n",
      "Epoch: 2582/4000..  Training Loss: 0.023..  Test Loss: 1.051..  Test Accuracy: 0.829\n",
      "Epoch: 2583/4000..  Training Loss: 0.054..  Test Loss: 1.124..  Test Accuracy: 0.820\n",
      "Epoch: 2584/4000..  Training Loss: 0.031..  Test Loss: 1.120..  Test Accuracy: 0.822\n",
      "Epoch: 2585/4000..  Training Loss: 0.008..  Test Loss: 1.088..  Test Accuracy: 0.827\n",
      "Epoch: 2586/4000..  Training Loss: 0.006..  Test Loss: 1.126..  Test Accuracy: 0.821\n",
      "Epoch: 2587/4000..  Training Loss: 0.006..  Test Loss: 1.062..  Test Accuracy: 0.828\n",
      "Epoch: 2588/4000..  Training Loss: 0.025..  Test Loss: 1.082..  Test Accuracy: 0.824\n",
      "Epoch: 2589/4000..  Training Loss: 0.013..  Test Loss: 1.073..  Test Accuracy: 0.828\n",
      "Epoch: 2590/4000..  Training Loss: 0.017..  Test Loss: 1.004..  Test Accuracy: 0.837\n",
      "Epoch: 2591/4000..  Training Loss: 0.010..  Test Loss: 1.015..  Test Accuracy: 0.835\n",
      "Epoch: 2592/4000..  Training Loss: 0.009..  Test Loss: 0.999..  Test Accuracy: 0.837\n",
      "Epoch: 2593/4000..  Training Loss: 0.009..  Test Loss: 1.004..  Test Accuracy: 0.837\n",
      "Epoch: 2594/4000..  Training Loss: 0.012..  Test Loss: 1.019..  Test Accuracy: 0.835\n",
      "Epoch: 2595/4000..  Training Loss: 0.011..  Test Loss: 1.046..  Test Accuracy: 0.831\n",
      "Epoch: 2596/4000..  Training Loss: 0.013..  Test Loss: 1.037..  Test Accuracy: 0.833\n",
      "Epoch: 2597/4000..  Training Loss: 0.012..  Test Loss: 1.108..  Test Accuracy: 0.825\n",
      "Epoch: 2598/4000..  Training Loss: 0.017..  Test Loss: 1.122..  Test Accuracy: 0.822\n",
      "Epoch: 2599/4000..  Training Loss: 0.024..  Test Loss: 1.025..  Test Accuracy: 0.834\n",
      "Epoch: 2600/4000..  Training Loss: 0.036..  Test Loss: 1.069..  Test Accuracy: 0.828\n",
      "Epoch: 2601/4000..  Training Loss: 0.010..  Test Loss: 1.086..  Test Accuracy: 0.827\n",
      "Epoch: 2602/4000..  Training Loss: 0.005..  Test Loss: 1.083..  Test Accuracy: 0.827\n",
      "Epoch: 2603/4000..  Training Loss: 0.015..  Test Loss: 1.041..  Test Accuracy: 0.833\n",
      "Epoch: 2604/4000..  Training Loss: 0.015..  Test Loss: 1.103..  Test Accuracy: 0.827\n",
      "Epoch: 2605/4000..  Training Loss: 0.046..  Test Loss: 1.099..  Test Accuracy: 0.826\n",
      "Epoch: 2606/4000..  Training Loss: 0.012..  Test Loss: 1.048..  Test Accuracy: 0.833\n",
      "Epoch: 2607/4000..  Training Loss: 0.024..  Test Loss: 0.996..  Test Accuracy: 0.838\n",
      "Epoch: 2608/4000..  Training Loss: 0.015..  Test Loss: 1.102..  Test Accuracy: 0.826\n",
      "Epoch: 2609/4000..  Training Loss: 0.008..  Test Loss: 1.091..  Test Accuracy: 0.828\n",
      "Epoch: 2610/4000..  Training Loss: 0.024..  Test Loss: 1.060..  Test Accuracy: 0.831\n",
      "Epoch: 2611/4000..  Training Loss: 0.007..  Test Loss: 1.061..  Test Accuracy: 0.829\n",
      "Epoch: 2612/4000..  Training Loss: 0.047..  Test Loss: 1.033..  Test Accuracy: 0.833\n",
      "Epoch: 2613/4000..  Training Loss: 0.010..  Test Loss: 1.031..  Test Accuracy: 0.834\n",
      "Epoch: 2614/4000..  Training Loss: 0.009..  Test Loss: 1.025..  Test Accuracy: 0.835\n",
      "Epoch: 2615/4000..  Training Loss: 0.009..  Test Loss: 1.079..  Test Accuracy: 0.826\n",
      "Epoch: 2616/4000..  Training Loss: 0.007..  Test Loss: 1.050..  Test Accuracy: 0.832\n",
      "Epoch: 2617/4000..  Training Loss: 0.010..  Test Loss: 1.059..  Test Accuracy: 0.830\n",
      "Epoch: 2618/4000..  Training Loss: 0.035..  Test Loss: 1.025..  Test Accuracy: 0.834\n",
      "Epoch: 2619/4000..  Training Loss: 0.011..  Test Loss: 0.986..  Test Accuracy: 0.839\n",
      "Epoch: 2620/4000..  Training Loss: 0.047..  Test Loss: 1.065..  Test Accuracy: 0.829\n",
      "Epoch: 2621/4000..  Training Loss: 0.003..  Test Loss: 1.040..  Test Accuracy: 0.832\n",
      "Epoch: 2622/4000..  Training Loss: 0.006..  Test Loss: 1.068..  Test Accuracy: 0.828\n",
      "Epoch: 2623/4000..  Training Loss: 0.021..  Test Loss: 1.065..  Test Accuracy: 0.828\n",
      "Epoch: 2624/4000..  Training Loss: 0.018..  Test Loss: 1.067..  Test Accuracy: 0.828\n",
      "Epoch: 2625/4000..  Training Loss: 0.004..  Test Loss: 1.075..  Test Accuracy: 0.827\n",
      "Epoch: 2626/4000..  Training Loss: 0.009..  Test Loss: 1.050..  Test Accuracy: 0.831\n",
      "Epoch: 2627/4000..  Training Loss: 0.008..  Test Loss: 1.096..  Test Accuracy: 0.826\n",
      "Epoch: 2628/4000..  Training Loss: 0.003..  Test Loss: 1.088..  Test Accuracy: 0.827\n",
      "Epoch: 2629/4000..  Training Loss: 0.009..  Test Loss: 1.091..  Test Accuracy: 0.826\n",
      "Epoch: 2630/4000..  Training Loss: 0.010..  Test Loss: 1.106..  Test Accuracy: 0.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2631/4000..  Training Loss: 0.008..  Test Loss: 1.074..  Test Accuracy: 0.828\n",
      "Epoch: 2632/4000..  Training Loss: 0.072..  Test Loss: 1.017..  Test Accuracy: 0.836\n",
      "Epoch: 2633/4000..  Training Loss: 0.006..  Test Loss: 1.086..  Test Accuracy: 0.829\n",
      "Epoch: 2634/4000..  Training Loss: 0.011..  Test Loss: 1.099..  Test Accuracy: 0.827\n",
      "Epoch: 2635/4000..  Training Loss: 0.021..  Test Loss: 1.062..  Test Accuracy: 0.830\n",
      "Epoch: 2636/4000..  Training Loss: 0.017..  Test Loss: 1.143..  Test Accuracy: 0.821\n",
      "Epoch: 2637/4000..  Training Loss: 0.023..  Test Loss: 1.104..  Test Accuracy: 0.828\n",
      "Epoch: 2638/4000..  Training Loss: 0.017..  Test Loss: 1.099..  Test Accuracy: 0.827\n",
      "Epoch: 2639/4000..  Training Loss: 0.004..  Test Loss: 1.111..  Test Accuracy: 0.828\n",
      "Epoch: 2640/4000..  Training Loss: 0.002..  Test Loss: 1.101..  Test Accuracy: 0.827\n",
      "Epoch: 2641/4000..  Training Loss: 0.022..  Test Loss: 1.106..  Test Accuracy: 0.825\n",
      "Epoch: 2642/4000..  Training Loss: 0.011..  Test Loss: 1.081..  Test Accuracy: 0.828\n",
      "Epoch: 2643/4000..  Training Loss: 0.011..  Test Loss: 1.063..  Test Accuracy: 0.830\n",
      "Epoch: 2644/4000..  Training Loss: 0.008..  Test Loss: 1.152..  Test Accuracy: 0.822\n",
      "Epoch: 2645/4000..  Training Loss: 0.005..  Test Loss: 1.106..  Test Accuracy: 0.827\n",
      "Epoch: 2646/4000..  Training Loss: 0.015..  Test Loss: 1.060..  Test Accuracy: 0.832\n",
      "Epoch: 2647/4000..  Training Loss: 0.008..  Test Loss: 1.099..  Test Accuracy: 0.826\n",
      "Epoch: 2648/4000..  Training Loss: 0.006..  Test Loss: 1.103..  Test Accuracy: 0.824\n",
      "Epoch: 2649/4000..  Training Loss: 0.013..  Test Loss: 1.085..  Test Accuracy: 0.828\n",
      "Epoch: 2650/4000..  Training Loss: 0.020..  Test Loss: 1.023..  Test Accuracy: 0.837\n",
      "Epoch: 2651/4000..  Training Loss: 0.027..  Test Loss: 1.168..  Test Accuracy: 0.821\n",
      "Epoch: 2652/4000..  Training Loss: 0.015..  Test Loss: 1.139..  Test Accuracy: 0.823\n",
      "Epoch: 2653/4000..  Training Loss: 0.016..  Test Loss: 1.114..  Test Accuracy: 0.825\n",
      "Epoch: 2654/4000..  Training Loss: 0.035..  Test Loss: 1.063..  Test Accuracy: 0.832\n",
      "Epoch: 2655/4000..  Training Loss: 0.007..  Test Loss: 1.031..  Test Accuracy: 0.835\n",
      "Epoch: 2656/4000..  Training Loss: 0.012..  Test Loss: 1.062..  Test Accuracy: 0.830\n",
      "Epoch: 2657/4000..  Training Loss: 0.013..  Test Loss: 1.072..  Test Accuracy: 0.830\n",
      "Epoch: 2658/4000..  Training Loss: 0.037..  Test Loss: 1.072..  Test Accuracy: 0.829\n",
      "Epoch: 2659/4000..  Training Loss: 0.019..  Test Loss: 1.069..  Test Accuracy: 0.828\n",
      "Epoch: 2660/4000..  Training Loss: 0.035..  Test Loss: 1.133..  Test Accuracy: 0.824\n",
      "Epoch: 2661/4000..  Training Loss: 0.012..  Test Loss: 1.143..  Test Accuracy: 0.822\n",
      "Epoch: 2662/4000..  Training Loss: 0.015..  Test Loss: 1.115..  Test Accuracy: 0.824\n",
      "Epoch: 2663/4000..  Training Loss: 0.006..  Test Loss: 1.066..  Test Accuracy: 0.830\n",
      "Epoch: 2664/4000..  Training Loss: 0.009..  Test Loss: 1.099..  Test Accuracy: 0.825\n",
      "Epoch: 2665/4000..  Training Loss: 0.007..  Test Loss: 1.074..  Test Accuracy: 0.829\n",
      "Epoch: 2666/4000..  Training Loss: 0.015..  Test Loss: 1.077..  Test Accuracy: 0.829\n",
      "Epoch: 2667/4000..  Training Loss: 0.014..  Test Loss: 1.024..  Test Accuracy: 0.835\n",
      "Epoch: 2668/4000..  Training Loss: 0.006..  Test Loss: 1.070..  Test Accuracy: 0.829\n",
      "Epoch: 2669/4000..  Training Loss: 0.020..  Test Loss: 1.063..  Test Accuracy: 0.831\n",
      "Epoch: 2670/4000..  Training Loss: 0.013..  Test Loss: 1.109..  Test Accuracy: 0.825\n",
      "Epoch: 2671/4000..  Training Loss: 0.007..  Test Loss: 1.071..  Test Accuracy: 0.829\n",
      "Epoch: 2672/4000..  Training Loss: 0.007..  Test Loss: 1.124..  Test Accuracy: 0.821\n",
      "Epoch: 2673/4000..  Training Loss: 0.006..  Test Loss: 1.079..  Test Accuracy: 0.827\n",
      "Epoch: 2674/4000..  Training Loss: 0.004..  Test Loss: 1.094..  Test Accuracy: 0.827\n",
      "Epoch: 2675/4000..  Training Loss: 0.004..  Test Loss: 1.119..  Test Accuracy: 0.825\n",
      "Epoch: 2676/4000..  Training Loss: 0.015..  Test Loss: 1.010..  Test Accuracy: 0.837\n",
      "Epoch: 2677/4000..  Training Loss: 0.013..  Test Loss: 1.089..  Test Accuracy: 0.826\n",
      "Epoch: 2678/4000..  Training Loss: 0.010..  Test Loss: 1.072..  Test Accuracy: 0.830\n",
      "Epoch: 2679/4000..  Training Loss: 0.008..  Test Loss: 1.113..  Test Accuracy: 0.825\n",
      "Epoch: 2680/4000..  Training Loss: 0.004..  Test Loss: 1.103..  Test Accuracy: 0.826\n",
      "Epoch: 2681/4000..  Training Loss: 0.007..  Test Loss: 1.112..  Test Accuracy: 0.826\n",
      "Epoch: 2682/4000..  Training Loss: 0.007..  Test Loss: 1.134..  Test Accuracy: 0.821\n",
      "Epoch: 2683/4000..  Training Loss: 0.034..  Test Loss: 1.069..  Test Accuracy: 0.829\n",
      "Epoch: 2684/4000..  Training Loss: 0.005..  Test Loss: 1.024..  Test Accuracy: 0.835\n",
      "Epoch: 2685/4000..  Training Loss: 0.011..  Test Loss: 1.084..  Test Accuracy: 0.828\n",
      "Epoch: 2686/4000..  Training Loss: 0.017..  Test Loss: 1.041..  Test Accuracy: 0.832\n",
      "Epoch: 2687/4000..  Training Loss: 0.004..  Test Loss: 1.057..  Test Accuracy: 0.830\n",
      "Epoch: 2688/4000..  Training Loss: 0.010..  Test Loss: 1.117..  Test Accuracy: 0.821\n",
      "Epoch: 2689/4000..  Training Loss: 0.041..  Test Loss: 1.022..  Test Accuracy: 0.836\n",
      "Epoch: 2690/4000..  Training Loss: 0.006..  Test Loss: 1.085..  Test Accuracy: 0.829\n",
      "Epoch: 2691/4000..  Training Loss: 0.047..  Test Loss: 1.090..  Test Accuracy: 0.827\n",
      "Epoch: 2692/4000..  Training Loss: 0.025..  Test Loss: 0.997..  Test Accuracy: 0.839\n",
      "Epoch: 2693/4000..  Training Loss: 0.003..  Test Loss: 1.016..  Test Accuracy: 0.835\n",
      "Epoch: 2694/4000..  Training Loss: 0.027..  Test Loss: 1.082..  Test Accuracy: 0.828\n",
      "Epoch: 2695/4000..  Training Loss: 0.005..  Test Loss: 1.077..  Test Accuracy: 0.829\n",
      "Epoch: 2696/4000..  Training Loss: 0.020..  Test Loss: 1.103..  Test Accuracy: 0.827\n",
      "Epoch: 2697/4000..  Training Loss: 0.043..  Test Loss: 1.122..  Test Accuracy: 0.821\n",
      "Epoch: 2698/4000..  Training Loss: 0.013..  Test Loss: 1.106..  Test Accuracy: 0.825\n",
      "Epoch: 2699/4000..  Training Loss: 0.013..  Test Loss: 1.070..  Test Accuracy: 0.832\n",
      "Epoch: 2700/4000..  Training Loss: 0.007..  Test Loss: 1.037..  Test Accuracy: 0.835\n",
      "Epoch: 2701/4000..  Training Loss: 0.008..  Test Loss: 1.079..  Test Accuracy: 0.827\n",
      "Epoch: 2702/4000..  Training Loss: 0.012..  Test Loss: 1.078..  Test Accuracy: 0.828\n",
      "Epoch: 2703/4000..  Training Loss: 0.011..  Test Loss: 1.067..  Test Accuracy: 0.829\n",
      "Epoch: 2704/4000..  Training Loss: 0.017..  Test Loss: 1.040..  Test Accuracy: 0.834\n",
      "Epoch: 2705/4000..  Training Loss: 0.007..  Test Loss: 1.064..  Test Accuracy: 0.830\n",
      "Epoch: 2706/4000..  Training Loss: 0.004..  Test Loss: 1.064..  Test Accuracy: 0.831\n",
      "Epoch: 2707/4000..  Training Loss: 0.021..  Test Loss: 1.028..  Test Accuracy: 0.835\n",
      "Epoch: 2708/4000..  Training Loss: 0.004..  Test Loss: 1.056..  Test Accuracy: 0.832\n",
      "Epoch: 2709/4000..  Training Loss: 0.020..  Test Loss: 1.045..  Test Accuracy: 0.833\n",
      "Epoch: 2710/4000..  Training Loss: 0.016..  Test Loss: 1.046..  Test Accuracy: 0.834\n",
      "Epoch: 2711/4000..  Training Loss: 0.004..  Test Loss: 1.044..  Test Accuracy: 0.835\n",
      "Epoch: 2712/4000..  Training Loss: 0.005..  Test Loss: 1.033..  Test Accuracy: 0.834\n",
      "Epoch: 2713/4000..  Training Loss: 0.028..  Test Loss: 1.074..  Test Accuracy: 0.827\n",
      "Epoch: 2714/4000..  Training Loss: 0.022..  Test Loss: 1.085..  Test Accuracy: 0.827\n",
      "Epoch: 2715/4000..  Training Loss: 0.003..  Test Loss: 1.077..  Test Accuracy: 0.829\n",
      "Epoch: 2716/4000..  Training Loss: 0.013..  Test Loss: 1.102..  Test Accuracy: 0.825\n",
      "Epoch: 2717/4000..  Training Loss: 0.021..  Test Loss: 1.129..  Test Accuracy: 0.819\n",
      "Epoch: 2718/4000..  Training Loss: 0.009..  Test Loss: 1.097..  Test Accuracy: 0.827\n",
      "Epoch: 2719/4000..  Training Loss: 0.008..  Test Loss: 1.075..  Test Accuracy: 0.831\n",
      "Epoch: 2720/4000..  Training Loss: 0.006..  Test Loss: 1.048..  Test Accuracy: 0.832\n",
      "Epoch: 2721/4000..  Training Loss: 0.025..  Test Loss: 1.158..  Test Accuracy: 0.824\n",
      "Epoch: 2722/4000..  Training Loss: 0.024..  Test Loss: 1.166..  Test Accuracy: 0.819\n",
      "Epoch: 2723/4000..  Training Loss: 0.010..  Test Loss: 1.136..  Test Accuracy: 0.825\n",
      "Epoch: 2724/4000..  Training Loss: 0.015..  Test Loss: 1.078..  Test Accuracy: 0.831\n",
      "Epoch: 2725/4000..  Training Loss: 0.010..  Test Loss: 1.076..  Test Accuracy: 0.831\n",
      "Epoch: 2726/4000..  Training Loss: 0.005..  Test Loss: 1.068..  Test Accuracy: 0.833\n",
      "Epoch: 2727/4000..  Training Loss: 0.023..  Test Loss: 1.086..  Test Accuracy: 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2728/4000..  Training Loss: 0.011..  Test Loss: 1.087..  Test Accuracy: 0.829\n",
      "Epoch: 2729/4000..  Training Loss: 0.008..  Test Loss: 1.075..  Test Accuracy: 0.831\n",
      "Epoch: 2730/4000..  Training Loss: 0.013..  Test Loss: 1.089..  Test Accuracy: 0.829\n",
      "Epoch: 2731/4000..  Training Loss: 0.009..  Test Loss: 1.076..  Test Accuracy: 0.828\n",
      "Epoch: 2732/4000..  Training Loss: 0.006..  Test Loss: 1.048..  Test Accuracy: 0.833\n",
      "Epoch: 2733/4000..  Training Loss: 0.004..  Test Loss: 1.003..  Test Accuracy: 0.839\n",
      "Epoch: 2734/4000..  Training Loss: 0.020..  Test Loss: 1.032..  Test Accuracy: 0.835\n",
      "Epoch: 2735/4000..  Training Loss: 0.021..  Test Loss: 1.051..  Test Accuracy: 0.834\n",
      "Epoch: 2736/4000..  Training Loss: 0.005..  Test Loss: 1.039..  Test Accuracy: 0.834\n",
      "Epoch: 2737/4000..  Training Loss: 0.014..  Test Loss: 1.074..  Test Accuracy: 0.829\n",
      "Epoch: 2738/4000..  Training Loss: 0.022..  Test Loss: 1.093..  Test Accuracy: 0.828\n",
      "Epoch: 2739/4000..  Training Loss: 0.002..  Test Loss: 1.096..  Test Accuracy: 0.827\n",
      "Epoch: 2740/4000..  Training Loss: 0.021..  Test Loss: 1.142..  Test Accuracy: 0.820\n",
      "Epoch: 2741/4000..  Training Loss: 0.006..  Test Loss: 1.083..  Test Accuracy: 0.828\n",
      "Epoch: 2742/4000..  Training Loss: 0.017..  Test Loss: 1.130..  Test Accuracy: 0.826\n",
      "Epoch: 2743/4000..  Training Loss: 0.022..  Test Loss: 1.017..  Test Accuracy: 0.837\n",
      "Epoch: 2744/4000..  Training Loss: 0.012..  Test Loss: 1.056..  Test Accuracy: 0.832\n",
      "Epoch: 2745/4000..  Training Loss: 0.036..  Test Loss: 1.153..  Test Accuracy: 0.823\n",
      "Epoch: 2746/4000..  Training Loss: 0.008..  Test Loss: 1.117..  Test Accuracy: 0.825\n",
      "Epoch: 2747/4000..  Training Loss: 0.009..  Test Loss: 1.071..  Test Accuracy: 0.830\n",
      "Epoch: 2748/4000..  Training Loss: 0.011..  Test Loss: 1.101..  Test Accuracy: 0.828\n",
      "Epoch: 2749/4000..  Training Loss: 0.011..  Test Loss: 1.091..  Test Accuracy: 0.827\n",
      "Epoch: 2750/4000..  Training Loss: 0.011..  Test Loss: 1.097..  Test Accuracy: 0.827\n",
      "Epoch: 2751/4000..  Training Loss: 0.022..  Test Loss: 1.180..  Test Accuracy: 0.816\n",
      "Epoch: 2752/4000..  Training Loss: 0.007..  Test Loss: 1.122..  Test Accuracy: 0.826\n",
      "Epoch: 2753/4000..  Training Loss: 0.013..  Test Loss: 1.120..  Test Accuracy: 0.822\n",
      "Epoch: 2754/4000..  Training Loss: 0.010..  Test Loss: 1.112..  Test Accuracy: 0.825\n",
      "Epoch: 2755/4000..  Training Loss: 0.022..  Test Loss: 1.054..  Test Accuracy: 0.835\n",
      "Epoch: 2756/4000..  Training Loss: 0.015..  Test Loss: 1.086..  Test Accuracy: 0.831\n",
      "Epoch: 2757/4000..  Training Loss: 0.014..  Test Loss: 1.074..  Test Accuracy: 0.832\n",
      "Epoch: 2758/4000..  Training Loss: 0.019..  Test Loss: 1.150..  Test Accuracy: 0.823\n",
      "Epoch: 2759/4000..  Training Loss: 0.011..  Test Loss: 1.127..  Test Accuracy: 0.825\n",
      "Epoch: 2760/4000..  Training Loss: 0.004..  Test Loss: 1.106..  Test Accuracy: 0.828\n",
      "Epoch: 2761/4000..  Training Loss: 0.011..  Test Loss: 1.100..  Test Accuracy: 0.828\n",
      "Epoch: 2762/4000..  Training Loss: 0.004..  Test Loss: 1.078..  Test Accuracy: 0.830\n",
      "Epoch: 2763/4000..  Training Loss: 0.009..  Test Loss: 1.204..  Test Accuracy: 0.819\n",
      "Epoch: 2764/4000..  Training Loss: 0.013..  Test Loss: 1.233..  Test Accuracy: 0.812\n",
      "Epoch: 2765/4000..  Training Loss: 0.007..  Test Loss: 1.145..  Test Accuracy: 0.825\n",
      "Epoch: 2766/4000..  Training Loss: 0.003..  Test Loss: 1.140..  Test Accuracy: 0.825\n",
      "Epoch: 2767/4000..  Training Loss: 0.014..  Test Loss: 1.084..  Test Accuracy: 0.830\n",
      "Epoch: 2768/4000..  Training Loss: 0.006..  Test Loss: 1.097..  Test Accuracy: 0.829\n",
      "Epoch: 2769/4000..  Training Loss: 0.014..  Test Loss: 1.098..  Test Accuracy: 0.828\n",
      "Epoch: 2770/4000..  Training Loss: 0.024..  Test Loss: 1.118..  Test Accuracy: 0.826\n",
      "Epoch: 2771/4000..  Training Loss: 0.034..  Test Loss: 1.079..  Test Accuracy: 0.829\n",
      "Epoch: 2772/4000..  Training Loss: 0.013..  Test Loss: 1.134..  Test Accuracy: 0.823\n",
      "Epoch: 2773/4000..  Training Loss: 0.047..  Test Loss: 1.070..  Test Accuracy: 0.831\n",
      "Epoch: 2774/4000..  Training Loss: 0.008..  Test Loss: 1.069..  Test Accuracy: 0.832\n",
      "Epoch: 2775/4000..  Training Loss: 0.007..  Test Loss: 1.071..  Test Accuracy: 0.832\n",
      "Epoch: 2776/4000..  Training Loss: 0.003..  Test Loss: 1.067..  Test Accuracy: 0.832\n",
      "Epoch: 2777/4000..  Training Loss: 0.004..  Test Loss: 1.044..  Test Accuracy: 0.833\n",
      "Epoch: 2778/4000..  Training Loss: 0.036..  Test Loss: 1.050..  Test Accuracy: 0.834\n",
      "Epoch: 2779/4000..  Training Loss: 0.014..  Test Loss: 1.104..  Test Accuracy: 0.827\n",
      "Epoch: 2780/4000..  Training Loss: 0.007..  Test Loss: 1.077..  Test Accuracy: 0.831\n",
      "Epoch: 2781/4000..  Training Loss: 0.013..  Test Loss: 1.182..  Test Accuracy: 0.819\n",
      "Epoch: 2782/4000..  Training Loss: 0.012..  Test Loss: 1.144..  Test Accuracy: 0.822\n",
      "Epoch: 2783/4000..  Training Loss: 0.027..  Test Loss: 1.137..  Test Accuracy: 0.824\n",
      "Epoch: 2784/4000..  Training Loss: 0.009..  Test Loss: 1.133..  Test Accuracy: 0.826\n",
      "Epoch: 2785/4000..  Training Loss: 0.013..  Test Loss: 1.105..  Test Accuracy: 0.827\n",
      "Epoch: 2786/4000..  Training Loss: 0.009..  Test Loss: 1.103..  Test Accuracy: 0.827\n",
      "Epoch: 2787/4000..  Training Loss: 0.006..  Test Loss: 1.108..  Test Accuracy: 0.827\n",
      "Epoch: 2788/4000..  Training Loss: 0.005..  Test Loss: 1.025..  Test Accuracy: 0.836\n",
      "Epoch: 2789/4000..  Training Loss: 0.002..  Test Loss: 1.038..  Test Accuracy: 0.835\n",
      "Epoch: 2790/4000..  Training Loss: 0.004..  Test Loss: 1.038..  Test Accuracy: 0.837\n",
      "Epoch: 2791/4000..  Training Loss: 0.027..  Test Loss: 1.071..  Test Accuracy: 0.832\n",
      "Epoch: 2792/4000..  Training Loss: 0.014..  Test Loss: 1.063..  Test Accuracy: 0.830\n",
      "Epoch: 2793/4000..  Training Loss: 0.016..  Test Loss: 1.141..  Test Accuracy: 0.822\n",
      "Epoch: 2794/4000..  Training Loss: 0.045..  Test Loss: 1.100..  Test Accuracy: 0.828\n",
      "Epoch: 2795/4000..  Training Loss: 0.003..  Test Loss: 1.089..  Test Accuracy: 0.830\n",
      "Epoch: 2796/4000..  Training Loss: 0.009..  Test Loss: 1.126..  Test Accuracy: 0.828\n",
      "Epoch: 2797/4000..  Training Loss: 0.012..  Test Loss: 1.068..  Test Accuracy: 0.832\n",
      "Epoch: 2798/4000..  Training Loss: 0.010..  Test Loss: 1.107..  Test Accuracy: 0.828\n",
      "Epoch: 2799/4000..  Training Loss: 0.025..  Test Loss: 1.129..  Test Accuracy: 0.826\n",
      "Epoch: 2800/4000..  Training Loss: 0.030..  Test Loss: 1.133..  Test Accuracy: 0.821\n",
      "Epoch: 2801/4000..  Training Loss: 0.015..  Test Loss: 1.097..  Test Accuracy: 0.827\n",
      "Epoch: 2802/4000..  Training Loss: 0.024..  Test Loss: 1.109..  Test Accuracy: 0.826\n",
      "Epoch: 2803/4000..  Training Loss: 0.006..  Test Loss: 1.102..  Test Accuracy: 0.826\n",
      "Epoch: 2804/4000..  Training Loss: 0.027..  Test Loss: 1.079..  Test Accuracy: 0.831\n",
      "Epoch: 2805/4000..  Training Loss: 0.005..  Test Loss: 1.053..  Test Accuracy: 0.833\n",
      "Epoch: 2806/4000..  Training Loss: 0.046..  Test Loss: 1.009..  Test Accuracy: 0.838\n",
      "Epoch: 2807/4000..  Training Loss: 0.053..  Test Loss: 1.049..  Test Accuracy: 0.833\n",
      "Epoch: 2808/4000..  Training Loss: 0.027..  Test Loss: 1.104..  Test Accuracy: 0.829\n",
      "Epoch: 2809/4000..  Training Loss: 0.022..  Test Loss: 1.114..  Test Accuracy: 0.827\n",
      "Epoch: 2810/4000..  Training Loss: 0.008..  Test Loss: 1.126..  Test Accuracy: 0.827\n",
      "Epoch: 2811/4000..  Training Loss: 0.011..  Test Loss: 1.079..  Test Accuracy: 0.830\n",
      "Epoch: 2812/4000..  Training Loss: 0.009..  Test Loss: 1.060..  Test Accuracy: 0.832\n",
      "Epoch: 2813/4000..  Training Loss: 0.007..  Test Loss: 1.132..  Test Accuracy: 0.824\n",
      "Epoch: 2814/4000..  Training Loss: 0.032..  Test Loss: 1.171..  Test Accuracy: 0.819\n",
      "Epoch: 2815/4000..  Training Loss: 0.015..  Test Loss: 1.083..  Test Accuracy: 0.829\n",
      "Epoch: 2816/4000..  Training Loss: 0.029..  Test Loss: 1.074..  Test Accuracy: 0.831\n",
      "Epoch: 2817/4000..  Training Loss: 0.012..  Test Loss: 1.073..  Test Accuracy: 0.831\n",
      "Epoch: 2818/4000..  Training Loss: 0.007..  Test Loss: 1.105..  Test Accuracy: 0.827\n",
      "Epoch: 2819/4000..  Training Loss: 0.023..  Test Loss: 1.019..  Test Accuracy: 0.837\n",
      "Epoch: 2820/4000..  Training Loss: 0.005..  Test Loss: 1.055..  Test Accuracy: 0.832\n",
      "Epoch: 2821/4000..  Training Loss: 0.003..  Test Loss: 1.053..  Test Accuracy: 0.833\n",
      "Epoch: 2822/4000..  Training Loss: 0.016..  Test Loss: 1.072..  Test Accuracy: 0.830\n",
      "Epoch: 2823/4000..  Training Loss: 0.027..  Test Loss: 1.036..  Test Accuracy: 0.836\n",
      "Epoch: 2824/4000..  Training Loss: 0.011..  Test Loss: 1.056..  Test Accuracy: 0.834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2825/4000..  Training Loss: 0.004..  Test Loss: 1.089..  Test Accuracy: 0.831\n",
      "Epoch: 2826/4000..  Training Loss: 0.008..  Test Loss: 1.078..  Test Accuracy: 0.831\n",
      "Epoch: 2827/4000..  Training Loss: 0.009..  Test Loss: 1.099..  Test Accuracy: 0.829\n",
      "Epoch: 2828/4000..  Training Loss: 0.010..  Test Loss: 1.059..  Test Accuracy: 0.833\n",
      "Epoch: 2829/4000..  Training Loss: 0.009..  Test Loss: 1.109..  Test Accuracy: 0.826\n",
      "Epoch: 2830/4000..  Training Loss: 0.008..  Test Loss: 1.044..  Test Accuracy: 0.834\n",
      "Epoch: 2831/4000..  Training Loss: 0.010..  Test Loss: 1.120..  Test Accuracy: 0.826\n",
      "Epoch: 2832/4000..  Training Loss: 0.016..  Test Loss: 1.138..  Test Accuracy: 0.824\n",
      "Epoch: 2833/4000..  Training Loss: 0.018..  Test Loss: 1.045..  Test Accuracy: 0.834\n",
      "Epoch: 2834/4000..  Training Loss: 0.004..  Test Loss: 1.069..  Test Accuracy: 0.830\n",
      "Epoch: 2835/4000..  Training Loss: 0.003..  Test Loss: 1.052..  Test Accuracy: 0.834\n",
      "Epoch: 2836/4000..  Training Loss: 0.006..  Test Loss: 1.108..  Test Accuracy: 0.828\n",
      "Epoch: 2837/4000..  Training Loss: 0.008..  Test Loss: 1.113..  Test Accuracy: 0.826\n",
      "Epoch: 2838/4000..  Training Loss: 0.005..  Test Loss: 1.087..  Test Accuracy: 0.830\n",
      "Epoch: 2839/4000..  Training Loss: 0.003..  Test Loss: 1.060..  Test Accuracy: 0.831\n",
      "Epoch: 2840/4000..  Training Loss: 0.009..  Test Loss: 1.073..  Test Accuracy: 0.828\n",
      "Epoch: 2841/4000..  Training Loss: 0.009..  Test Loss: 1.085..  Test Accuracy: 0.831\n",
      "Epoch: 2842/4000..  Training Loss: 0.003..  Test Loss: 1.074..  Test Accuracy: 0.831\n",
      "Epoch: 2843/4000..  Training Loss: 0.019..  Test Loss: 1.064..  Test Accuracy: 0.830\n",
      "Epoch: 2844/4000..  Training Loss: 0.007..  Test Loss: 1.130..  Test Accuracy: 0.825\n",
      "Epoch: 2845/4000..  Training Loss: 0.016..  Test Loss: 1.124..  Test Accuracy: 0.822\n",
      "Epoch: 2846/4000..  Training Loss: 0.003..  Test Loss: 1.108..  Test Accuracy: 0.827\n",
      "Epoch: 2847/4000..  Training Loss: 0.010..  Test Loss: 1.084..  Test Accuracy: 0.831\n",
      "Epoch: 2848/4000..  Training Loss: 0.015..  Test Loss: 1.078..  Test Accuracy: 0.828\n",
      "Epoch: 2849/4000..  Training Loss: 0.010..  Test Loss: 1.068..  Test Accuracy: 0.831\n",
      "Epoch: 2850/4000..  Training Loss: 0.013..  Test Loss: 1.055..  Test Accuracy: 0.832\n",
      "Epoch: 2851/4000..  Training Loss: 0.015..  Test Loss: 1.133..  Test Accuracy: 0.824\n",
      "Epoch: 2852/4000..  Training Loss: 0.010..  Test Loss: 1.091..  Test Accuracy: 0.829\n",
      "Epoch: 2853/4000..  Training Loss: 0.008..  Test Loss: 1.141..  Test Accuracy: 0.824\n",
      "Epoch: 2854/4000..  Training Loss: 0.003..  Test Loss: 1.111..  Test Accuracy: 0.828\n",
      "Epoch: 2855/4000..  Training Loss: 0.004..  Test Loss: 1.129..  Test Accuracy: 0.825\n",
      "Epoch: 2856/4000..  Training Loss: 0.004..  Test Loss: 1.060..  Test Accuracy: 0.834\n",
      "Epoch: 2857/4000..  Training Loss: 0.004..  Test Loss: 1.091..  Test Accuracy: 0.830\n",
      "Epoch: 2858/4000..  Training Loss: 0.015..  Test Loss: 1.110..  Test Accuracy: 0.829\n",
      "Epoch: 2859/4000..  Training Loss: 0.021..  Test Loss: 1.077..  Test Accuracy: 0.832\n",
      "Epoch: 2860/4000..  Training Loss: 0.025..  Test Loss: 1.034..  Test Accuracy: 0.835\n",
      "Epoch: 2861/4000..  Training Loss: 0.003..  Test Loss: 1.069..  Test Accuracy: 0.830\n",
      "Epoch: 2862/4000..  Training Loss: 0.011..  Test Loss: 1.066..  Test Accuracy: 0.831\n",
      "Epoch: 2863/4000..  Training Loss: 0.002..  Test Loss: 1.067..  Test Accuracy: 0.832\n",
      "Epoch: 2864/4000..  Training Loss: 0.006..  Test Loss: 1.052..  Test Accuracy: 0.835\n",
      "Epoch: 2865/4000..  Training Loss: 0.004..  Test Loss: 1.051..  Test Accuracy: 0.833\n",
      "Epoch: 2866/4000..  Training Loss: 0.012..  Test Loss: 1.067..  Test Accuracy: 0.832\n",
      "Epoch: 2867/4000..  Training Loss: 0.006..  Test Loss: 1.092..  Test Accuracy: 0.830\n",
      "Epoch: 2868/4000..  Training Loss: 0.067..  Test Loss: 1.084..  Test Accuracy: 0.831\n",
      "Epoch: 2869/4000..  Training Loss: 0.015..  Test Loss: 1.111..  Test Accuracy: 0.830\n",
      "Epoch: 2870/4000..  Training Loss: 0.032..  Test Loss: 1.162..  Test Accuracy: 0.821\n",
      "Epoch: 2871/4000..  Training Loss: 0.004..  Test Loss: 1.108..  Test Accuracy: 0.829\n",
      "Epoch: 2872/4000..  Training Loss: 0.016..  Test Loss: 1.080..  Test Accuracy: 0.831\n",
      "Epoch: 2873/4000..  Training Loss: 0.021..  Test Loss: 1.114..  Test Accuracy: 0.828\n",
      "Epoch: 2874/4000..  Training Loss: 0.007..  Test Loss: 1.084..  Test Accuracy: 0.829\n",
      "Epoch: 2875/4000..  Training Loss: 0.019..  Test Loss: 1.102..  Test Accuracy: 0.827\n",
      "Epoch: 2876/4000..  Training Loss: 0.008..  Test Loss: 1.139..  Test Accuracy: 0.825\n",
      "Epoch: 2877/4000..  Training Loss: 0.009..  Test Loss: 1.155..  Test Accuracy: 0.825\n",
      "Epoch: 2878/4000..  Training Loss: 0.007..  Test Loss: 1.139..  Test Accuracy: 0.828\n",
      "Epoch: 2879/4000..  Training Loss: 0.003..  Test Loss: 1.117..  Test Accuracy: 0.830\n",
      "Epoch: 2880/4000..  Training Loss: 0.007..  Test Loss: 1.166..  Test Accuracy: 0.823\n",
      "Epoch: 2881/4000..  Training Loss: 0.025..  Test Loss: 1.133..  Test Accuracy: 0.826\n",
      "Epoch: 2882/4000..  Training Loss: 0.022..  Test Loss: 1.107..  Test Accuracy: 0.830\n",
      "Epoch: 2883/4000..  Training Loss: 0.009..  Test Loss: 1.102..  Test Accuracy: 0.828\n",
      "Epoch: 2884/4000..  Training Loss: 0.021..  Test Loss: 1.122..  Test Accuracy: 0.823\n",
      "Epoch: 2885/4000..  Training Loss: 0.007..  Test Loss: 1.081..  Test Accuracy: 0.830\n",
      "Epoch: 2886/4000..  Training Loss: 0.012..  Test Loss: 1.110..  Test Accuracy: 0.827\n",
      "Epoch: 2887/4000..  Training Loss: 0.002..  Test Loss: 1.112..  Test Accuracy: 0.827\n",
      "Epoch: 2888/4000..  Training Loss: 0.004..  Test Loss: 1.105..  Test Accuracy: 0.828\n",
      "Epoch: 2889/4000..  Training Loss: 0.005..  Test Loss: 1.076..  Test Accuracy: 0.832\n",
      "Epoch: 2890/4000..  Training Loss: 0.021..  Test Loss: 1.123..  Test Accuracy: 0.826\n",
      "Epoch: 2891/4000..  Training Loss: 0.014..  Test Loss: 1.116..  Test Accuracy: 0.827\n",
      "Epoch: 2892/4000..  Training Loss: 0.012..  Test Loss: 1.098..  Test Accuracy: 0.830\n",
      "Epoch: 2893/4000..  Training Loss: 0.015..  Test Loss: 1.117..  Test Accuracy: 0.827\n",
      "Epoch: 2894/4000..  Training Loss: 0.003..  Test Loss: 1.099..  Test Accuracy: 0.830\n",
      "Epoch: 2895/4000..  Training Loss: 0.023..  Test Loss: 1.066..  Test Accuracy: 0.833\n",
      "Epoch: 2896/4000..  Training Loss: 0.020..  Test Loss: 1.040..  Test Accuracy: 0.835\n",
      "Epoch: 2897/4000..  Training Loss: 0.007..  Test Loss: 1.062..  Test Accuracy: 0.833\n",
      "Epoch: 2898/4000..  Training Loss: 0.007..  Test Loss: 1.133..  Test Accuracy: 0.821\n",
      "Epoch: 2899/4000..  Training Loss: 0.007..  Test Loss: 1.086..  Test Accuracy: 0.830\n",
      "Epoch: 2900/4000..  Training Loss: 0.005..  Test Loss: 1.119..  Test Accuracy: 0.827\n",
      "Epoch: 2901/4000..  Training Loss: 0.002..  Test Loss: 1.112..  Test Accuracy: 0.827\n",
      "Epoch: 2902/4000..  Training Loss: 0.005..  Test Loss: 1.097..  Test Accuracy: 0.829\n",
      "Epoch: 2903/4000..  Training Loss: 0.004..  Test Loss: 1.110..  Test Accuracy: 0.828\n",
      "Epoch: 2904/4000..  Training Loss: 0.002..  Test Loss: 1.110..  Test Accuracy: 0.828\n",
      "Epoch: 2905/4000..  Training Loss: 0.008..  Test Loss: 1.097..  Test Accuracy: 0.830\n",
      "Epoch: 2906/4000..  Training Loss: 0.007..  Test Loss: 1.090..  Test Accuracy: 0.832\n",
      "Epoch: 2907/4000..  Training Loss: 0.029..  Test Loss: 1.175..  Test Accuracy: 0.823\n",
      "Epoch: 2908/4000..  Training Loss: 0.005..  Test Loss: 1.167..  Test Accuracy: 0.823\n",
      "Epoch: 2909/4000..  Training Loss: 0.040..  Test Loss: 1.051..  Test Accuracy: 0.834\n",
      "Epoch: 2910/4000..  Training Loss: 0.003..  Test Loss: 1.085..  Test Accuracy: 0.832\n",
      "Epoch: 2911/4000..  Training Loss: 0.009..  Test Loss: 1.077..  Test Accuracy: 0.833\n",
      "Epoch: 2912/4000..  Training Loss: 0.031..  Test Loss: 1.117..  Test Accuracy: 0.828\n",
      "Epoch: 2913/4000..  Training Loss: 0.013..  Test Loss: 1.095..  Test Accuracy: 0.829\n",
      "Epoch: 2914/4000..  Training Loss: 0.028..  Test Loss: 1.094..  Test Accuracy: 0.826\n",
      "Epoch: 2915/4000..  Training Loss: 0.017..  Test Loss: 1.219..  Test Accuracy: 0.813\n",
      "Epoch: 2916/4000..  Training Loss: 0.013..  Test Loss: 1.110..  Test Accuracy: 0.829\n",
      "Epoch: 2917/4000..  Training Loss: 0.006..  Test Loss: 1.147..  Test Accuracy: 0.824\n",
      "Epoch: 2918/4000..  Training Loss: 0.015..  Test Loss: 1.147..  Test Accuracy: 0.825\n",
      "Epoch: 2919/4000..  Training Loss: 0.008..  Test Loss: 1.157..  Test Accuracy: 0.819\n",
      "Epoch: 2920/4000..  Training Loss: 0.027..  Test Loss: 1.085..  Test Accuracy: 0.832\n",
      "Epoch: 2921/4000..  Training Loss: 0.021..  Test Loss: 1.099..  Test Accuracy: 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2922/4000..  Training Loss: 0.007..  Test Loss: 1.149..  Test Accuracy: 0.825\n",
      "Epoch: 2923/4000..  Training Loss: 0.012..  Test Loss: 1.108..  Test Accuracy: 0.828\n",
      "Epoch: 2924/4000..  Training Loss: 0.022..  Test Loss: 1.174..  Test Accuracy: 0.821\n",
      "Epoch: 2925/4000..  Training Loss: 0.006..  Test Loss: 1.140..  Test Accuracy: 0.825\n",
      "Epoch: 2926/4000..  Training Loss: 0.004..  Test Loss: 1.112..  Test Accuracy: 0.828\n",
      "Epoch: 2927/4000..  Training Loss: 0.008..  Test Loss: 1.108..  Test Accuracy: 0.828\n",
      "Epoch: 2928/4000..  Training Loss: 0.006..  Test Loss: 1.141..  Test Accuracy: 0.825\n",
      "Epoch: 2929/4000..  Training Loss: 0.018..  Test Loss: 1.144..  Test Accuracy: 0.825\n",
      "Epoch: 2930/4000..  Training Loss: 0.006..  Test Loss: 1.132..  Test Accuracy: 0.826\n",
      "Epoch: 2931/4000..  Training Loss: 0.007..  Test Loss: 1.157..  Test Accuracy: 0.822\n",
      "Epoch: 2932/4000..  Training Loss: 0.017..  Test Loss: 1.183..  Test Accuracy: 0.820\n",
      "Epoch: 2933/4000..  Training Loss: 0.022..  Test Loss: 1.268..  Test Accuracy: 0.812\n",
      "Epoch: 2934/4000..  Training Loss: 0.008..  Test Loss: 1.136..  Test Accuracy: 0.824\n",
      "Epoch: 2935/4000..  Training Loss: 0.013..  Test Loss: 1.114..  Test Accuracy: 0.828\n",
      "Epoch: 2936/4000..  Training Loss: 0.017..  Test Loss: 1.162..  Test Accuracy: 0.825\n",
      "Epoch: 2937/4000..  Training Loss: 0.011..  Test Loss: 1.121..  Test Accuracy: 0.828\n",
      "Epoch: 2938/4000..  Training Loss: 0.010..  Test Loss: 1.164..  Test Accuracy: 0.822\n",
      "Epoch: 2939/4000..  Training Loss: 0.002..  Test Loss: 1.168..  Test Accuracy: 0.822\n",
      "Epoch: 2940/4000..  Training Loss: 0.003..  Test Loss: 1.130..  Test Accuracy: 0.826\n",
      "Epoch: 2941/4000..  Training Loss: 0.014..  Test Loss: 1.101..  Test Accuracy: 0.830\n",
      "Epoch: 2942/4000..  Training Loss: 0.004..  Test Loss: 1.127..  Test Accuracy: 0.827\n",
      "Epoch: 2943/4000..  Training Loss: 0.008..  Test Loss: 1.115..  Test Accuracy: 0.828\n",
      "Epoch: 2944/4000..  Training Loss: 0.007..  Test Loss: 1.168..  Test Accuracy: 0.821\n",
      "Epoch: 2945/4000..  Training Loss: 0.009..  Test Loss: 1.100..  Test Accuracy: 0.831\n",
      "Epoch: 2946/4000..  Training Loss: 0.010..  Test Loss: 1.090..  Test Accuracy: 0.832\n",
      "Epoch: 2947/4000..  Training Loss: 0.020..  Test Loss: 1.188..  Test Accuracy: 0.815\n",
      "Epoch: 2948/4000..  Training Loss: 0.010..  Test Loss: 1.203..  Test Accuracy: 0.820\n",
      "Epoch: 2949/4000..  Training Loss: 0.007..  Test Loss: 1.171..  Test Accuracy: 0.824\n",
      "Epoch: 2950/4000..  Training Loss: 0.009..  Test Loss: 1.123..  Test Accuracy: 0.828\n",
      "Epoch: 2951/4000..  Training Loss: 0.013..  Test Loss: 1.129..  Test Accuracy: 0.827\n",
      "Epoch: 2952/4000..  Training Loss: 0.012..  Test Loss: 1.094..  Test Accuracy: 0.830\n",
      "Epoch: 2953/4000..  Training Loss: 0.002..  Test Loss: 1.109..  Test Accuracy: 0.829\n",
      "Epoch: 2954/4000..  Training Loss: 0.049..  Test Loss: 1.106..  Test Accuracy: 0.829\n",
      "Epoch: 2955/4000..  Training Loss: 0.005..  Test Loss: 1.119..  Test Accuracy: 0.827\n",
      "Epoch: 2956/4000..  Training Loss: 0.006..  Test Loss: 1.068..  Test Accuracy: 0.830\n",
      "Epoch: 2957/4000..  Training Loss: 0.012..  Test Loss: 1.160..  Test Accuracy: 0.820\n",
      "Epoch: 2958/4000..  Training Loss: 0.021..  Test Loss: 1.104..  Test Accuracy: 0.830\n",
      "Epoch: 2959/4000..  Training Loss: 0.004..  Test Loss: 1.151..  Test Accuracy: 0.825\n",
      "Epoch: 2960/4000..  Training Loss: 0.003..  Test Loss: 1.146..  Test Accuracy: 0.824\n",
      "Epoch: 2961/4000..  Training Loss: 0.018..  Test Loss: 1.094..  Test Accuracy: 0.831\n",
      "Epoch: 2962/4000..  Training Loss: 0.010..  Test Loss: 1.189..  Test Accuracy: 0.820\n",
      "Epoch: 2963/4000..  Training Loss: 0.006..  Test Loss: 1.046..  Test Accuracy: 0.836\n",
      "Epoch: 2964/4000..  Training Loss: 0.008..  Test Loss: 1.149..  Test Accuracy: 0.824\n",
      "Epoch: 2965/4000..  Training Loss: 0.008..  Test Loss: 1.142..  Test Accuracy: 0.824\n",
      "Epoch: 2966/4000..  Training Loss: 0.004..  Test Loss: 1.105..  Test Accuracy: 0.829\n",
      "Epoch: 2967/4000..  Training Loss: 0.021..  Test Loss: 1.159..  Test Accuracy: 0.823\n",
      "Epoch: 2968/4000..  Training Loss: 0.015..  Test Loss: 1.123..  Test Accuracy: 0.830\n",
      "Epoch: 2969/4000..  Training Loss: 0.018..  Test Loss: 1.154..  Test Accuracy: 0.825\n",
      "Epoch: 2970/4000..  Training Loss: 0.015..  Test Loss: 1.080..  Test Accuracy: 0.834\n",
      "Epoch: 2971/4000..  Training Loss: 0.006..  Test Loss: 1.083..  Test Accuracy: 0.834\n",
      "Epoch: 2972/4000..  Training Loss: 0.015..  Test Loss: 1.168..  Test Accuracy: 0.824\n",
      "Epoch: 2973/4000..  Training Loss: 0.015..  Test Loss: 1.266..  Test Accuracy: 0.815\n",
      "Epoch: 2974/4000..  Training Loss: 0.012..  Test Loss: 1.140..  Test Accuracy: 0.827\n",
      "Epoch: 2975/4000..  Training Loss: 0.017..  Test Loss: 1.179..  Test Accuracy: 0.821\n",
      "Epoch: 2976/4000..  Training Loss: 0.015..  Test Loss: 1.216..  Test Accuracy: 0.815\n",
      "Epoch: 2977/4000..  Training Loss: 0.011..  Test Loss: 1.185..  Test Accuracy: 0.824\n",
      "Epoch: 2978/4000..  Training Loss: 0.006..  Test Loss: 1.247..  Test Accuracy: 0.814\n",
      "Epoch: 2979/4000..  Training Loss: 0.005..  Test Loss: 1.175..  Test Accuracy: 0.822\n",
      "Epoch: 2980/4000..  Training Loss: 0.003..  Test Loss: 1.154..  Test Accuracy: 0.826\n",
      "Epoch: 2981/4000..  Training Loss: 0.005..  Test Loss: 1.076..  Test Accuracy: 0.834\n",
      "Epoch: 2982/4000..  Training Loss: 0.007..  Test Loss: 1.046..  Test Accuracy: 0.838\n",
      "Epoch: 2983/4000..  Training Loss: 0.006..  Test Loss: 1.148..  Test Accuracy: 0.824\n",
      "Epoch: 2984/4000..  Training Loss: 0.012..  Test Loss: 1.168..  Test Accuracy: 0.823\n",
      "Epoch: 2985/4000..  Training Loss: 0.006..  Test Loss: 1.187..  Test Accuracy: 0.818\n",
      "Epoch: 2986/4000..  Training Loss: 0.030..  Test Loss: 1.181..  Test Accuracy: 0.822\n",
      "Epoch: 2987/4000..  Training Loss: 0.024..  Test Loss: 1.224..  Test Accuracy: 0.818\n",
      "Epoch: 2988/4000..  Training Loss: 0.008..  Test Loss: 1.173..  Test Accuracy: 0.823\n",
      "Epoch: 2989/4000..  Training Loss: 0.012..  Test Loss: 1.113..  Test Accuracy: 0.829\n",
      "Epoch: 2990/4000..  Training Loss: 0.025..  Test Loss: 1.037..  Test Accuracy: 0.838\n",
      "Epoch: 2991/4000..  Training Loss: 0.014..  Test Loss: 1.040..  Test Accuracy: 0.838\n",
      "Epoch: 2992/4000..  Training Loss: 0.031..  Test Loss: 1.118..  Test Accuracy: 0.826\n",
      "Epoch: 2993/4000..  Training Loss: 0.018..  Test Loss: 1.128..  Test Accuracy: 0.827\n",
      "Epoch: 2994/4000..  Training Loss: 0.024..  Test Loss: 1.148..  Test Accuracy: 0.825\n",
      "Epoch: 2995/4000..  Training Loss: 0.009..  Test Loss: 1.143..  Test Accuracy: 0.824\n",
      "Epoch: 2996/4000..  Training Loss: 0.014..  Test Loss: 1.144..  Test Accuracy: 0.826\n",
      "Epoch: 2997/4000..  Training Loss: 0.020..  Test Loss: 1.166..  Test Accuracy: 0.824\n",
      "Epoch: 2998/4000..  Training Loss: 0.015..  Test Loss: 1.157..  Test Accuracy: 0.824\n",
      "Epoch: 2999/4000..  Training Loss: 0.022..  Test Loss: 1.127..  Test Accuracy: 0.828\n",
      "Epoch: 3000/4000..  Training Loss: 0.006..  Test Loss: 1.085..  Test Accuracy: 0.831\n",
      "Epoch: 3001/4000..  Training Loss: 0.027..  Test Loss: 1.133..  Test Accuracy: 0.827\n",
      "Epoch: 3002/4000..  Training Loss: 0.003..  Test Loss: 1.138..  Test Accuracy: 0.825\n",
      "Epoch: 3003/4000..  Training Loss: 0.002..  Test Loss: 1.149..  Test Accuracy: 0.824\n",
      "Epoch: 3004/4000..  Training Loss: 0.009..  Test Loss: 1.056..  Test Accuracy: 0.836\n",
      "Epoch: 3005/4000..  Training Loss: 0.003..  Test Loss: 1.103..  Test Accuracy: 0.830\n",
      "Epoch: 3006/4000..  Training Loss: 0.023..  Test Loss: 1.112..  Test Accuracy: 0.827\n",
      "Epoch: 3007/4000..  Training Loss: 0.003..  Test Loss: 1.108..  Test Accuracy: 0.829\n",
      "Epoch: 3008/4000..  Training Loss: 0.002..  Test Loss: 1.113..  Test Accuracy: 0.829\n",
      "Epoch: 3009/4000..  Training Loss: 0.001..  Test Loss: 1.118..  Test Accuracy: 0.829\n",
      "Epoch: 3010/4000..  Training Loss: 0.002..  Test Loss: 1.118..  Test Accuracy: 0.829\n",
      "Epoch: 3011/4000..  Training Loss: 0.009..  Test Loss: 1.150..  Test Accuracy: 0.823\n",
      "Epoch: 3012/4000..  Training Loss: 0.010..  Test Loss: 1.116..  Test Accuracy: 0.827\n",
      "Epoch: 3013/4000..  Training Loss: 0.033..  Test Loss: 1.183..  Test Accuracy: 0.820\n",
      "Epoch: 3014/4000..  Training Loss: 0.015..  Test Loss: 1.204..  Test Accuracy: 0.820\n",
      "Epoch: 3015/4000..  Training Loss: 0.018..  Test Loss: 1.173..  Test Accuracy: 0.822\n",
      "Epoch: 3016/4000..  Training Loss: 0.008..  Test Loss: 1.182..  Test Accuracy: 0.822\n",
      "Epoch: 3017/4000..  Training Loss: 0.011..  Test Loss: 1.165..  Test Accuracy: 0.824\n",
      "Epoch: 3018/4000..  Training Loss: 0.007..  Test Loss: 1.218..  Test Accuracy: 0.814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3019/4000..  Training Loss: 0.007..  Test Loss: 1.161..  Test Accuracy: 0.821\n",
      "Epoch: 3020/4000..  Training Loss: 0.017..  Test Loss: 1.108..  Test Accuracy: 0.830\n",
      "Epoch: 3021/4000..  Training Loss: 0.016..  Test Loss: 1.182..  Test Accuracy: 0.822\n",
      "Epoch: 3022/4000..  Training Loss: 0.007..  Test Loss: 1.181..  Test Accuracy: 0.822\n",
      "Epoch: 3023/4000..  Training Loss: 0.023..  Test Loss: 1.077..  Test Accuracy: 0.835\n",
      "Epoch: 3024/4000..  Training Loss: 0.016..  Test Loss: 1.117..  Test Accuracy: 0.828\n",
      "Epoch: 3025/4000..  Training Loss: 0.005..  Test Loss: 1.128..  Test Accuracy: 0.825\n",
      "Epoch: 3026/4000..  Training Loss: 0.005..  Test Loss: 1.076..  Test Accuracy: 0.832\n",
      "Epoch: 3027/4000..  Training Loss: 0.008..  Test Loss: 1.167..  Test Accuracy: 0.818\n",
      "Epoch: 3028/4000..  Training Loss: 0.009..  Test Loss: 1.156..  Test Accuracy: 0.824\n",
      "Epoch: 3029/4000..  Training Loss: 0.012..  Test Loss: 1.142..  Test Accuracy: 0.824\n",
      "Epoch: 3030/4000..  Training Loss: 0.009..  Test Loss: 1.102..  Test Accuracy: 0.827\n",
      "Epoch: 3031/4000..  Training Loss: 0.003..  Test Loss: 1.079..  Test Accuracy: 0.831\n",
      "Epoch: 3032/4000..  Training Loss: 0.017..  Test Loss: 1.081..  Test Accuracy: 0.833\n",
      "Epoch: 3033/4000..  Training Loss: 0.018..  Test Loss: 1.115..  Test Accuracy: 0.825\n",
      "Epoch: 3034/4000..  Training Loss: 0.012..  Test Loss: 1.174..  Test Accuracy: 0.817\n",
      "Epoch: 3035/4000..  Training Loss: 0.019..  Test Loss: 1.188..  Test Accuracy: 0.820\n",
      "Epoch: 3036/4000..  Training Loss: 0.011..  Test Loss: 1.157..  Test Accuracy: 0.823\n",
      "Epoch: 3037/4000..  Training Loss: 0.005..  Test Loss: 1.106..  Test Accuracy: 0.831\n",
      "Epoch: 3038/4000..  Training Loss: 0.006..  Test Loss: 1.143..  Test Accuracy: 0.825\n",
      "Epoch: 3039/4000..  Training Loss: 0.010..  Test Loss: 1.140..  Test Accuracy: 0.828\n",
      "Epoch: 3040/4000..  Training Loss: 0.010..  Test Loss: 1.077..  Test Accuracy: 0.834\n",
      "Epoch: 3041/4000..  Training Loss: 0.010..  Test Loss: 1.190..  Test Accuracy: 0.818\n",
      "Epoch: 3042/4000..  Training Loss: 0.007..  Test Loss: 1.156..  Test Accuracy: 0.825\n",
      "Epoch: 3043/4000..  Training Loss: 0.041..  Test Loss: 1.180..  Test Accuracy: 0.821\n",
      "Epoch: 3044/4000..  Training Loss: 0.004..  Test Loss: 1.176..  Test Accuracy: 0.824\n",
      "Epoch: 3045/4000..  Training Loss: 0.017..  Test Loss: 1.149..  Test Accuracy: 0.825\n",
      "Epoch: 3046/4000..  Training Loss: 0.012..  Test Loss: 1.188..  Test Accuracy: 0.821\n",
      "Epoch: 3047/4000..  Training Loss: 0.004..  Test Loss: 1.196..  Test Accuracy: 0.819\n",
      "Epoch: 3048/4000..  Training Loss: 0.006..  Test Loss: 1.171..  Test Accuracy: 0.820\n",
      "Epoch: 3049/4000..  Training Loss: 0.028..  Test Loss: 1.168..  Test Accuracy: 0.822\n",
      "Epoch: 3050/4000..  Training Loss: 0.008..  Test Loss: 1.079..  Test Accuracy: 0.831\n",
      "Epoch: 3051/4000..  Training Loss: 0.006..  Test Loss: 1.075..  Test Accuracy: 0.832\n",
      "Epoch: 3052/4000..  Training Loss: 0.032..  Test Loss: 1.086..  Test Accuracy: 0.831\n",
      "Epoch: 3053/4000..  Training Loss: 0.007..  Test Loss: 1.120..  Test Accuracy: 0.827\n",
      "Epoch: 3054/4000..  Training Loss: 0.007..  Test Loss: 1.195..  Test Accuracy: 0.818\n",
      "Epoch: 3055/4000..  Training Loss: 0.003..  Test Loss: 1.168..  Test Accuracy: 0.822\n",
      "Epoch: 3056/4000..  Training Loss: 0.006..  Test Loss: 1.169..  Test Accuracy: 0.824\n",
      "Epoch: 3057/4000..  Training Loss: 0.012..  Test Loss: 1.184..  Test Accuracy: 0.820\n",
      "Epoch: 3058/4000..  Training Loss: 0.006..  Test Loss: 1.163..  Test Accuracy: 0.824\n",
      "Epoch: 3059/4000..  Training Loss: 0.005..  Test Loss: 1.170..  Test Accuracy: 0.823\n",
      "Epoch: 3060/4000..  Training Loss: 0.006..  Test Loss: 1.125..  Test Accuracy: 0.828\n",
      "Epoch: 3061/4000..  Training Loss: 0.019..  Test Loss: 1.137..  Test Accuracy: 0.827\n",
      "Epoch: 3062/4000..  Training Loss: 0.005..  Test Loss: 1.163..  Test Accuracy: 0.825\n",
      "Epoch: 3063/4000..  Training Loss: 0.010..  Test Loss: 1.184..  Test Accuracy: 0.818\n",
      "Epoch: 3064/4000..  Training Loss: 0.019..  Test Loss: 1.285..  Test Accuracy: 0.811\n",
      "Epoch: 3065/4000..  Training Loss: 0.047..  Test Loss: 1.188..  Test Accuracy: 0.821\n",
      "Epoch: 3066/4000..  Training Loss: 0.010..  Test Loss: 1.171..  Test Accuracy: 0.824\n",
      "Epoch: 3067/4000..  Training Loss: 0.009..  Test Loss: 1.166..  Test Accuracy: 0.824\n",
      "Epoch: 3068/4000..  Training Loss: 0.016..  Test Loss: 1.225..  Test Accuracy: 0.815\n",
      "Epoch: 3069/4000..  Training Loss: 0.003..  Test Loss: 1.200..  Test Accuracy: 0.820\n",
      "Epoch: 3070/4000..  Training Loss: 0.003..  Test Loss: 1.192..  Test Accuracy: 0.820\n",
      "Epoch: 3071/4000..  Training Loss: 0.022..  Test Loss: 1.204..  Test Accuracy: 0.817\n",
      "Epoch: 3072/4000..  Training Loss: 0.022..  Test Loss: 1.179..  Test Accuracy: 0.822\n",
      "Epoch: 3073/4000..  Training Loss: 0.005..  Test Loss: 1.158..  Test Accuracy: 0.823\n",
      "Epoch: 3074/4000..  Training Loss: 0.010..  Test Loss: 1.209..  Test Accuracy: 0.813\n",
      "Epoch: 3075/4000..  Training Loss: 0.003..  Test Loss: 1.158..  Test Accuracy: 0.822\n",
      "Epoch: 3076/4000..  Training Loss: 0.007..  Test Loss: 1.181..  Test Accuracy: 0.822\n",
      "Epoch: 3077/4000..  Training Loss: 0.008..  Test Loss: 1.096..  Test Accuracy: 0.830\n",
      "Epoch: 3078/4000..  Training Loss: 0.004..  Test Loss: 1.156..  Test Accuracy: 0.825\n",
      "Epoch: 3079/4000..  Training Loss: 0.003..  Test Loss: 1.122..  Test Accuracy: 0.830\n",
      "Epoch: 3080/4000..  Training Loss: 0.009..  Test Loss: 1.141..  Test Accuracy: 0.827\n",
      "Epoch: 3081/4000..  Training Loss: 0.011..  Test Loss: 1.225..  Test Accuracy: 0.819\n",
      "Epoch: 3082/4000..  Training Loss: 0.009..  Test Loss: 1.273..  Test Accuracy: 0.812\n",
      "Epoch: 3083/4000..  Training Loss: 0.010..  Test Loss: 1.253..  Test Accuracy: 0.815\n",
      "Epoch: 3084/4000..  Training Loss: 0.030..  Test Loss: 1.242..  Test Accuracy: 0.817\n",
      "Epoch: 3085/4000..  Training Loss: 0.017..  Test Loss: 1.209..  Test Accuracy: 0.820\n",
      "Epoch: 3086/4000..  Training Loss: 0.015..  Test Loss: 1.253..  Test Accuracy: 0.816\n",
      "Epoch: 3087/4000..  Training Loss: 0.007..  Test Loss: 1.197..  Test Accuracy: 0.823\n",
      "Epoch: 3088/4000..  Training Loss: 0.004..  Test Loss: 1.205..  Test Accuracy: 0.824\n",
      "Epoch: 3089/4000..  Training Loss: 0.027..  Test Loss: 1.215..  Test Accuracy: 0.823\n",
      "Epoch: 3090/4000..  Training Loss: 0.026..  Test Loss: 1.179..  Test Accuracy: 0.827\n",
      "Epoch: 3091/4000..  Training Loss: 0.016..  Test Loss: 1.174..  Test Accuracy: 0.819\n",
      "Epoch: 3092/4000..  Training Loss: 0.009..  Test Loss: 1.207..  Test Accuracy: 0.820\n",
      "Epoch: 3093/4000..  Training Loss: 0.007..  Test Loss: 1.214..  Test Accuracy: 0.819\n",
      "Epoch: 3094/4000..  Training Loss: 0.010..  Test Loss: 1.210..  Test Accuracy: 0.820\n",
      "Epoch: 3095/4000..  Training Loss: 0.015..  Test Loss: 1.194..  Test Accuracy: 0.822\n",
      "Epoch: 3096/4000..  Training Loss: 0.025..  Test Loss: 1.160..  Test Accuracy: 0.823\n",
      "Epoch: 3097/4000..  Training Loss: 0.016..  Test Loss: 1.169..  Test Accuracy: 0.825\n",
      "Epoch: 3098/4000..  Training Loss: 0.007..  Test Loss: 1.207..  Test Accuracy: 0.820\n",
      "Epoch: 3099/4000..  Training Loss: 0.039..  Test Loss: 1.144..  Test Accuracy: 0.828\n",
      "Epoch: 3100/4000..  Training Loss: 0.011..  Test Loss: 1.202..  Test Accuracy: 0.824\n",
      "Epoch: 3101/4000..  Training Loss: 0.021..  Test Loss: 1.195..  Test Accuracy: 0.821\n",
      "Epoch: 3102/4000..  Training Loss: 0.006..  Test Loss: 1.157..  Test Accuracy: 0.827\n",
      "Epoch: 3103/4000..  Training Loss: 0.005..  Test Loss: 1.123..  Test Accuracy: 0.829\n",
      "Epoch: 3104/4000..  Training Loss: 0.019..  Test Loss: 1.187..  Test Accuracy: 0.822\n",
      "Epoch: 3105/4000..  Training Loss: 0.004..  Test Loss: 1.156..  Test Accuracy: 0.825\n",
      "Epoch: 3106/4000..  Training Loss: 0.012..  Test Loss: 1.180..  Test Accuracy: 0.817\n",
      "Epoch: 3107/4000..  Training Loss: 0.019..  Test Loss: 1.212..  Test Accuracy: 0.818\n",
      "Epoch: 3108/4000..  Training Loss: 0.007..  Test Loss: 1.161..  Test Accuracy: 0.825\n",
      "Epoch: 3109/4000..  Training Loss: 0.026..  Test Loss: 1.253..  Test Accuracy: 0.811\n",
      "Epoch: 3110/4000..  Training Loss: 0.009..  Test Loss: 1.236..  Test Accuracy: 0.813\n",
      "Epoch: 3111/4000..  Training Loss: 0.015..  Test Loss: 1.140..  Test Accuracy: 0.828\n",
      "Epoch: 3112/4000..  Training Loss: 0.018..  Test Loss: 1.136..  Test Accuracy: 0.828\n",
      "Epoch: 3113/4000..  Training Loss: 0.008..  Test Loss: 1.129..  Test Accuracy: 0.826\n",
      "Epoch: 3114/4000..  Training Loss: 0.003..  Test Loss: 1.155..  Test Accuracy: 0.826\n",
      "Epoch: 3115/4000..  Training Loss: 0.010..  Test Loss: 1.258..  Test Accuracy: 0.814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3116/4000..  Training Loss: 0.004..  Test Loss: 1.235..  Test Accuracy: 0.816\n",
      "Epoch: 3117/4000..  Training Loss: 0.007..  Test Loss: 1.275..  Test Accuracy: 0.809\n",
      "Epoch: 3118/4000..  Training Loss: 0.030..  Test Loss: 1.205..  Test Accuracy: 0.818\n",
      "Epoch: 3119/4000..  Training Loss: 0.002..  Test Loss: 1.203..  Test Accuracy: 0.819\n",
      "Epoch: 3120/4000..  Training Loss: 0.010..  Test Loss: 1.143..  Test Accuracy: 0.824\n",
      "Epoch: 3121/4000..  Training Loss: 0.007..  Test Loss: 1.100..  Test Accuracy: 0.830\n",
      "Epoch: 3122/4000..  Training Loss: 0.004..  Test Loss: 1.093..  Test Accuracy: 0.833\n",
      "Epoch: 3123/4000..  Training Loss: 0.002..  Test Loss: 1.085..  Test Accuracy: 0.834\n",
      "Epoch: 3124/4000..  Training Loss: 0.009..  Test Loss: 1.169..  Test Accuracy: 0.824\n",
      "Epoch: 3125/4000..  Training Loss: 0.008..  Test Loss: 1.160..  Test Accuracy: 0.822\n",
      "Epoch: 3126/4000..  Training Loss: 0.013..  Test Loss: 1.132..  Test Accuracy: 0.827\n",
      "Epoch: 3127/4000..  Training Loss: 0.011..  Test Loss: 1.137..  Test Accuracy: 0.826\n",
      "Epoch: 3128/4000..  Training Loss: 0.005..  Test Loss: 1.134..  Test Accuracy: 0.826\n",
      "Epoch: 3129/4000..  Training Loss: 0.005..  Test Loss: 1.104..  Test Accuracy: 0.832\n",
      "Epoch: 3130/4000..  Training Loss: 0.024..  Test Loss: 1.234..  Test Accuracy: 0.816\n",
      "Epoch: 3131/4000..  Training Loss: 0.009..  Test Loss: 1.188..  Test Accuracy: 0.822\n",
      "Epoch: 3132/4000..  Training Loss: 0.003..  Test Loss: 1.180..  Test Accuracy: 0.822\n",
      "Epoch: 3133/4000..  Training Loss: 0.006..  Test Loss: 1.175..  Test Accuracy: 0.824\n",
      "Epoch: 3134/4000..  Training Loss: 0.016..  Test Loss: 1.124..  Test Accuracy: 0.829\n",
      "Epoch: 3135/4000..  Training Loss: 0.007..  Test Loss: 1.112..  Test Accuracy: 0.831\n",
      "Epoch: 3136/4000..  Training Loss: 0.018..  Test Loss: 1.143..  Test Accuracy: 0.828\n",
      "Epoch: 3137/4000..  Training Loss: 0.008..  Test Loss: 1.105..  Test Accuracy: 0.830\n",
      "Epoch: 3138/4000..  Training Loss: 0.017..  Test Loss: 1.118..  Test Accuracy: 0.830\n",
      "Epoch: 3139/4000..  Training Loss: 0.012..  Test Loss: 1.157..  Test Accuracy: 0.824\n",
      "Epoch: 3140/4000..  Training Loss: 0.018..  Test Loss: 1.128..  Test Accuracy: 0.828\n",
      "Epoch: 3141/4000..  Training Loss: 0.015..  Test Loss: 1.130..  Test Accuracy: 0.829\n",
      "Epoch: 3142/4000..  Training Loss: 0.005..  Test Loss: 1.120..  Test Accuracy: 0.832\n",
      "Epoch: 3143/4000..  Training Loss: 0.005..  Test Loss: 1.120..  Test Accuracy: 0.831\n",
      "Epoch: 3144/4000..  Training Loss: 0.003..  Test Loss: 1.147..  Test Accuracy: 0.828\n",
      "Epoch: 3145/4000..  Training Loss: 0.005..  Test Loss: 1.139..  Test Accuracy: 0.831\n",
      "Epoch: 3146/4000..  Training Loss: 0.023..  Test Loss: 1.130..  Test Accuracy: 0.830\n",
      "Epoch: 3147/4000..  Training Loss: 0.016..  Test Loss: 1.088..  Test Accuracy: 0.832\n",
      "Epoch: 3148/4000..  Training Loss: 0.033..  Test Loss: 1.133..  Test Accuracy: 0.830\n",
      "Epoch: 3149/4000..  Training Loss: 0.013..  Test Loss: 1.152..  Test Accuracy: 0.826\n",
      "Epoch: 3150/4000..  Training Loss: 0.018..  Test Loss: 1.214..  Test Accuracy: 0.822\n",
      "Epoch: 3151/4000..  Training Loss: 0.008..  Test Loss: 1.177..  Test Accuracy: 0.826\n",
      "Epoch: 3152/4000..  Training Loss: 0.017..  Test Loss: 1.188..  Test Accuracy: 0.825\n",
      "Epoch: 3153/4000..  Training Loss: 0.015..  Test Loss: 1.167..  Test Accuracy: 0.827\n",
      "Epoch: 3154/4000..  Training Loss: 0.007..  Test Loss: 1.159..  Test Accuracy: 0.827\n",
      "Epoch: 3155/4000..  Training Loss: 0.015..  Test Loss: 1.180..  Test Accuracy: 0.823\n",
      "Epoch: 3156/4000..  Training Loss: 0.022..  Test Loss: 1.227..  Test Accuracy: 0.819\n",
      "Epoch: 3157/4000..  Training Loss: 0.012..  Test Loss: 1.121..  Test Accuracy: 0.831\n",
      "Epoch: 3158/4000..  Training Loss: 0.003..  Test Loss: 1.152..  Test Accuracy: 0.826\n",
      "Epoch: 3159/4000..  Training Loss: 0.007..  Test Loss: 1.153..  Test Accuracy: 0.824\n",
      "Epoch: 3160/4000..  Training Loss: 0.010..  Test Loss: 1.161..  Test Accuracy: 0.824\n",
      "Epoch: 3161/4000..  Training Loss: 0.037..  Test Loss: 1.141..  Test Accuracy: 0.827\n",
      "Epoch: 3162/4000..  Training Loss: 0.003..  Test Loss: 1.140..  Test Accuracy: 0.826\n",
      "Epoch: 3163/4000..  Training Loss: 0.024..  Test Loss: 1.137..  Test Accuracy: 0.827\n",
      "Epoch: 3164/4000..  Training Loss: 0.012..  Test Loss: 1.170..  Test Accuracy: 0.822\n",
      "Epoch: 3165/4000..  Training Loss: 0.004..  Test Loss: 1.153..  Test Accuracy: 0.826\n",
      "Epoch: 3166/4000..  Training Loss: 0.020..  Test Loss: 1.250..  Test Accuracy: 0.814\n",
      "Epoch: 3167/4000..  Training Loss: 0.008..  Test Loss: 1.196..  Test Accuracy: 0.819\n",
      "Epoch: 3168/4000..  Training Loss: 0.006..  Test Loss: 1.194..  Test Accuracy: 0.822\n",
      "Epoch: 3169/4000..  Training Loss: 0.009..  Test Loss: 1.168..  Test Accuracy: 0.824\n",
      "Epoch: 3170/4000..  Training Loss: 0.011..  Test Loss: 1.193..  Test Accuracy: 0.822\n",
      "Epoch: 3171/4000..  Training Loss: 0.004..  Test Loss: 1.175..  Test Accuracy: 0.825\n",
      "Epoch: 3172/4000..  Training Loss: 0.009..  Test Loss: 1.129..  Test Accuracy: 0.831\n",
      "Epoch: 3173/4000..  Training Loss: 0.004..  Test Loss: 1.156..  Test Accuracy: 0.829\n",
      "Epoch: 3174/4000..  Training Loss: 0.024..  Test Loss: 1.199..  Test Accuracy: 0.821\n",
      "Epoch: 3175/4000..  Training Loss: 0.015..  Test Loss: 1.177..  Test Accuracy: 0.823\n",
      "Epoch: 3176/4000..  Training Loss: 0.014..  Test Loss: 1.153..  Test Accuracy: 0.826\n",
      "Epoch: 3177/4000..  Training Loss: 0.027..  Test Loss: 1.113..  Test Accuracy: 0.829\n",
      "Epoch: 3178/4000..  Training Loss: 0.017..  Test Loss: 1.172..  Test Accuracy: 0.824\n",
      "Epoch: 3179/4000..  Training Loss: 0.006..  Test Loss: 1.168..  Test Accuracy: 0.823\n",
      "Epoch: 3180/4000..  Training Loss: 0.010..  Test Loss: 1.191..  Test Accuracy: 0.823\n",
      "Epoch: 3181/4000..  Training Loss: 0.013..  Test Loss: 1.144..  Test Accuracy: 0.827\n",
      "Epoch: 3182/4000..  Training Loss: 0.004..  Test Loss: 1.108..  Test Accuracy: 0.832\n",
      "Epoch: 3183/4000..  Training Loss: 0.003..  Test Loss: 1.099..  Test Accuracy: 0.834\n",
      "Epoch: 3184/4000..  Training Loss: 0.002..  Test Loss: 1.107..  Test Accuracy: 0.832\n",
      "Epoch: 3185/4000..  Training Loss: 0.011..  Test Loss: 1.233..  Test Accuracy: 0.819\n",
      "Epoch: 3186/4000..  Training Loss: 0.007..  Test Loss: 1.218..  Test Accuracy: 0.822\n",
      "Epoch: 3187/4000..  Training Loss: 0.051..  Test Loss: 1.221..  Test Accuracy: 0.819\n",
      "Epoch: 3188/4000..  Training Loss: 0.012..  Test Loss: 1.155..  Test Accuracy: 0.829\n",
      "Epoch: 3189/4000..  Training Loss: 0.009..  Test Loss: 1.191..  Test Accuracy: 0.823\n",
      "Epoch: 3190/4000..  Training Loss: 0.004..  Test Loss: 1.225..  Test Accuracy: 0.818\n",
      "Epoch: 3191/4000..  Training Loss: 0.015..  Test Loss: 1.151..  Test Accuracy: 0.827\n",
      "Epoch: 3192/4000..  Training Loss: 0.003..  Test Loss: 1.126..  Test Accuracy: 0.830\n",
      "Epoch: 3193/4000..  Training Loss: 0.018..  Test Loss: 1.207..  Test Accuracy: 0.819\n",
      "Epoch: 3194/4000..  Training Loss: 0.022..  Test Loss: 1.135..  Test Accuracy: 0.826\n",
      "Epoch: 3195/4000..  Training Loss: 0.016..  Test Loss: 1.176..  Test Accuracy: 0.824\n",
      "Epoch: 3196/4000..  Training Loss: 0.023..  Test Loss: 1.105..  Test Accuracy: 0.834\n",
      "Epoch: 3197/4000..  Training Loss: 0.002..  Test Loss: 1.107..  Test Accuracy: 0.833\n",
      "Epoch: 3198/4000..  Training Loss: 0.004..  Test Loss: 1.148..  Test Accuracy: 0.828\n",
      "Epoch: 3199/4000..  Training Loss: 0.004..  Test Loss: 1.155..  Test Accuracy: 0.828\n",
      "Epoch: 3200/4000..  Training Loss: 0.013..  Test Loss: 1.163..  Test Accuracy: 0.824\n",
      "Epoch: 3201/4000..  Training Loss: 0.013..  Test Loss: 1.169..  Test Accuracy: 0.823\n",
      "Epoch: 3202/4000..  Training Loss: 0.003..  Test Loss: 1.143..  Test Accuracy: 0.827\n",
      "Epoch: 3203/4000..  Training Loss: 0.005..  Test Loss: 1.136..  Test Accuracy: 0.830\n",
      "Epoch: 3204/4000..  Training Loss: 0.006..  Test Loss: 1.134..  Test Accuracy: 0.828\n",
      "Epoch: 3205/4000..  Training Loss: 0.005..  Test Loss: 1.105..  Test Accuracy: 0.832\n",
      "Epoch: 3206/4000..  Training Loss: 0.006..  Test Loss: 1.090..  Test Accuracy: 0.834\n",
      "Epoch: 3207/4000..  Training Loss: 0.017..  Test Loss: 1.256..  Test Accuracy: 0.816\n",
      "Epoch: 3208/4000..  Training Loss: 0.043..  Test Loss: 1.182..  Test Accuracy: 0.824\n",
      "Epoch: 3209/4000..  Training Loss: 0.011..  Test Loss: 1.214..  Test Accuracy: 0.819\n",
      "Epoch: 3210/4000..  Training Loss: 0.003..  Test Loss: 1.246..  Test Accuracy: 0.812\n",
      "Epoch: 3211/4000..  Training Loss: 0.003..  Test Loss: 1.176..  Test Accuracy: 0.824\n",
      "Epoch: 3212/4000..  Training Loss: 0.020..  Test Loss: 1.108..  Test Accuracy: 0.832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3213/4000..  Training Loss: 0.011..  Test Loss: 1.101..  Test Accuracy: 0.833\n",
      "Epoch: 3214/4000..  Training Loss: 0.010..  Test Loss: 1.205..  Test Accuracy: 0.818\n",
      "Epoch: 3215/4000..  Training Loss: 0.012..  Test Loss: 1.179..  Test Accuracy: 0.823\n",
      "Epoch: 3216/4000..  Training Loss: 0.015..  Test Loss: 1.169..  Test Accuracy: 0.821\n",
      "Epoch: 3217/4000..  Training Loss: 0.018..  Test Loss: 1.151..  Test Accuracy: 0.827\n",
      "Epoch: 3218/4000..  Training Loss: 0.008..  Test Loss: 1.145..  Test Accuracy: 0.828\n",
      "Epoch: 3219/4000..  Training Loss: 0.023..  Test Loss: 1.224..  Test Accuracy: 0.819\n",
      "Epoch: 3220/4000..  Training Loss: 0.002..  Test Loss: 1.189..  Test Accuracy: 0.824\n",
      "Epoch: 3221/4000..  Training Loss: 0.016..  Test Loss: 1.197..  Test Accuracy: 0.825\n",
      "Epoch: 3222/4000..  Training Loss: 0.008..  Test Loss: 1.168..  Test Accuracy: 0.826\n",
      "Epoch: 3223/4000..  Training Loss: 0.007..  Test Loss: 1.123..  Test Accuracy: 0.831\n",
      "Epoch: 3224/4000..  Training Loss: 0.003..  Test Loss: 1.148..  Test Accuracy: 0.828\n",
      "Epoch: 3225/4000..  Training Loss: 0.009..  Test Loss: 1.153..  Test Accuracy: 0.828\n",
      "Epoch: 3226/4000..  Training Loss: 0.007..  Test Loss: 1.172..  Test Accuracy: 0.826\n",
      "Epoch: 3227/4000..  Training Loss: 0.009..  Test Loss: 1.137..  Test Accuracy: 0.830\n",
      "Epoch: 3228/4000..  Training Loss: 0.021..  Test Loss: 1.116..  Test Accuracy: 0.833\n",
      "Epoch: 3229/4000..  Training Loss: 0.005..  Test Loss: 1.115..  Test Accuracy: 0.834\n",
      "Epoch: 3230/4000..  Training Loss: 0.035..  Test Loss: 1.154..  Test Accuracy: 0.828\n",
      "Epoch: 3231/4000..  Training Loss: 0.009..  Test Loss: 1.163..  Test Accuracy: 0.826\n",
      "Epoch: 3232/4000..  Training Loss: 0.005..  Test Loss: 1.158..  Test Accuracy: 0.826\n",
      "Epoch: 3233/4000..  Training Loss: 0.005..  Test Loss: 1.122..  Test Accuracy: 0.830\n",
      "Epoch: 3234/4000..  Training Loss: 0.014..  Test Loss: 1.185..  Test Accuracy: 0.824\n",
      "Epoch: 3235/4000..  Training Loss: 0.010..  Test Loss: 1.151..  Test Accuracy: 0.829\n",
      "Epoch: 3236/4000..  Training Loss: 0.023..  Test Loss: 1.217..  Test Accuracy: 0.821\n",
      "Epoch: 3237/4000..  Training Loss: 0.008..  Test Loss: 1.218..  Test Accuracy: 0.821\n",
      "Epoch: 3238/4000..  Training Loss: 0.005..  Test Loss: 1.178..  Test Accuracy: 0.825\n",
      "Epoch: 3239/4000..  Training Loss: 0.004..  Test Loss: 1.186..  Test Accuracy: 0.823\n",
      "Epoch: 3240/4000..  Training Loss: 0.003..  Test Loss: 1.142..  Test Accuracy: 0.828\n",
      "Epoch: 3241/4000..  Training Loss: 0.003..  Test Loss: 1.161..  Test Accuracy: 0.825\n",
      "Epoch: 3242/4000..  Training Loss: 0.004..  Test Loss: 1.192..  Test Accuracy: 0.823\n",
      "Epoch: 3243/4000..  Training Loss: 0.027..  Test Loss: 1.166..  Test Accuracy: 0.824\n",
      "Epoch: 3244/4000..  Training Loss: 0.015..  Test Loss: 1.183..  Test Accuracy: 0.821\n",
      "Epoch: 3245/4000..  Training Loss: 0.016..  Test Loss: 1.133..  Test Accuracy: 0.829\n",
      "Epoch: 3246/4000..  Training Loss: 0.032..  Test Loss: 1.114..  Test Accuracy: 0.833\n",
      "Epoch: 3247/4000..  Training Loss: 0.017..  Test Loss: 1.163..  Test Accuracy: 0.828\n",
      "Epoch: 3248/4000..  Training Loss: 0.014..  Test Loss: 1.196..  Test Accuracy: 0.823\n",
      "Epoch: 3249/4000..  Training Loss: 0.005..  Test Loss: 1.200..  Test Accuracy: 0.825\n",
      "Epoch: 3250/4000..  Training Loss: 0.024..  Test Loss: 1.202..  Test Accuracy: 0.823\n",
      "Epoch: 3251/4000..  Training Loss: 0.010..  Test Loss: 1.150..  Test Accuracy: 0.831\n",
      "Epoch: 3252/4000..  Training Loss: 0.006..  Test Loss: 1.121..  Test Accuracy: 0.833\n",
      "Epoch: 3253/4000..  Training Loss: 0.009..  Test Loss: 1.135..  Test Accuracy: 0.828\n",
      "Epoch: 3254/4000..  Training Loss: 0.008..  Test Loss: 1.094..  Test Accuracy: 0.833\n",
      "Epoch: 3255/4000..  Training Loss: 0.016..  Test Loss: 1.090..  Test Accuracy: 0.834\n",
      "Epoch: 3256/4000..  Training Loss: 0.020..  Test Loss: 1.111..  Test Accuracy: 0.830\n",
      "Epoch: 3257/4000..  Training Loss: 0.017..  Test Loss: 1.082..  Test Accuracy: 0.835\n",
      "Epoch: 3258/4000..  Training Loss: 0.005..  Test Loss: 1.184..  Test Accuracy: 0.824\n",
      "Epoch: 3259/4000..  Training Loss: 0.004..  Test Loss: 1.141..  Test Accuracy: 0.829\n",
      "Epoch: 3260/4000..  Training Loss: 0.005..  Test Loss: 1.092..  Test Accuracy: 0.833\n",
      "Epoch: 3261/4000..  Training Loss: 0.012..  Test Loss: 1.217..  Test Accuracy: 0.819\n",
      "Epoch: 3262/4000..  Training Loss: 0.021..  Test Loss: 1.202..  Test Accuracy: 0.822\n",
      "Epoch: 3263/4000..  Training Loss: 0.020..  Test Loss: 1.174..  Test Accuracy: 0.823\n",
      "Epoch: 3264/4000..  Training Loss: 0.004..  Test Loss: 1.150..  Test Accuracy: 0.825\n",
      "Epoch: 3265/4000..  Training Loss: 0.008..  Test Loss: 1.150..  Test Accuracy: 0.826\n",
      "Epoch: 3266/4000..  Training Loss: 0.017..  Test Loss: 1.164..  Test Accuracy: 0.824\n",
      "Epoch: 3267/4000..  Training Loss: 0.005..  Test Loss: 1.166..  Test Accuracy: 0.824\n",
      "Epoch: 3268/4000..  Training Loss: 0.006..  Test Loss: 1.176..  Test Accuracy: 0.824\n",
      "Epoch: 3269/4000..  Training Loss: 0.007..  Test Loss: 1.204..  Test Accuracy: 0.821\n",
      "Epoch: 3270/4000..  Training Loss: 0.021..  Test Loss: 1.130..  Test Accuracy: 0.831\n",
      "Epoch: 3271/4000..  Training Loss: 0.024..  Test Loss: 1.141..  Test Accuracy: 0.827\n",
      "Epoch: 3272/4000..  Training Loss: 0.008..  Test Loss: 1.146..  Test Accuracy: 0.827\n",
      "Epoch: 3273/4000..  Training Loss: 0.007..  Test Loss: 1.192..  Test Accuracy: 0.822\n",
      "Epoch: 3274/4000..  Training Loss: 0.012..  Test Loss: 1.195..  Test Accuracy: 0.821\n",
      "Epoch: 3275/4000..  Training Loss: 0.015..  Test Loss: 1.251..  Test Accuracy: 0.818\n",
      "Epoch: 3276/4000..  Training Loss: 0.003..  Test Loss: 1.192..  Test Accuracy: 0.824\n",
      "Epoch: 3277/4000..  Training Loss: 0.010..  Test Loss: 1.228..  Test Accuracy: 0.819\n",
      "Epoch: 3278/4000..  Training Loss: 0.014..  Test Loss: 1.174..  Test Accuracy: 0.827\n",
      "Epoch: 3279/4000..  Training Loss: 0.010..  Test Loss: 1.196..  Test Accuracy: 0.824\n",
      "Epoch: 3280/4000..  Training Loss: 0.020..  Test Loss: 1.257..  Test Accuracy: 0.817\n",
      "Epoch: 3281/4000..  Training Loss: 0.020..  Test Loss: 1.140..  Test Accuracy: 0.830\n",
      "Epoch: 3282/4000..  Training Loss: 0.024..  Test Loss: 1.111..  Test Accuracy: 0.833\n",
      "Epoch: 3283/4000..  Training Loss: 0.011..  Test Loss: 1.109..  Test Accuracy: 0.831\n",
      "Epoch: 3284/4000..  Training Loss: 0.017..  Test Loss: 1.138..  Test Accuracy: 0.830\n",
      "Epoch: 3285/4000..  Training Loss: 0.020..  Test Loss: 1.114..  Test Accuracy: 0.828\n",
      "Epoch: 3286/4000..  Training Loss: 0.034..  Test Loss: 1.082..  Test Accuracy: 0.835\n",
      "Epoch: 3287/4000..  Training Loss: 0.009..  Test Loss: 1.114..  Test Accuracy: 0.830\n",
      "Epoch: 3288/4000..  Training Loss: 0.009..  Test Loss: 1.143..  Test Accuracy: 0.830\n",
      "Epoch: 3289/4000..  Training Loss: 0.004..  Test Loss: 1.149..  Test Accuracy: 0.828\n",
      "Epoch: 3290/4000..  Training Loss: 0.007..  Test Loss: 1.211..  Test Accuracy: 0.821\n",
      "Epoch: 3291/4000..  Training Loss: 0.014..  Test Loss: 1.184..  Test Accuracy: 0.825\n",
      "Epoch: 3292/4000..  Training Loss: 0.008..  Test Loss: 1.210..  Test Accuracy: 0.821\n",
      "Epoch: 3293/4000..  Training Loss: 0.003..  Test Loss: 1.193..  Test Accuracy: 0.823\n",
      "Epoch: 3294/4000..  Training Loss: 0.004..  Test Loss: 1.166..  Test Accuracy: 0.826\n",
      "Epoch: 3295/4000..  Training Loss: 0.013..  Test Loss: 1.145..  Test Accuracy: 0.827\n",
      "Epoch: 3296/4000..  Training Loss: 0.004..  Test Loss: 1.155..  Test Accuracy: 0.829\n",
      "Epoch: 3297/4000..  Training Loss: 0.026..  Test Loss: 1.185..  Test Accuracy: 0.822\n",
      "Epoch: 3298/4000..  Training Loss: 0.019..  Test Loss: 1.184..  Test Accuracy: 0.825\n",
      "Epoch: 3299/4000..  Training Loss: 0.011..  Test Loss: 1.165..  Test Accuracy: 0.828\n",
      "Epoch: 3300/4000..  Training Loss: 0.013..  Test Loss: 1.186..  Test Accuracy: 0.825\n",
      "Epoch: 3301/4000..  Training Loss: 0.008..  Test Loss: 1.185..  Test Accuracy: 0.826\n",
      "Epoch: 3302/4000..  Training Loss: 0.005..  Test Loss: 1.151..  Test Accuracy: 0.829\n",
      "Epoch: 3303/4000..  Training Loss: 0.008..  Test Loss: 1.200..  Test Accuracy: 0.825\n",
      "Epoch: 3304/4000..  Training Loss: 0.002..  Test Loss: 1.198..  Test Accuracy: 0.825\n",
      "Epoch: 3305/4000..  Training Loss: 0.003..  Test Loss: 1.149..  Test Accuracy: 0.829\n",
      "Epoch: 3306/4000..  Training Loss: 0.002..  Test Loss: 1.132..  Test Accuracy: 0.831\n",
      "Epoch: 3307/4000..  Training Loss: 0.012..  Test Loss: 1.114..  Test Accuracy: 0.831\n",
      "Epoch: 3308/4000..  Training Loss: 0.024..  Test Loss: 1.215..  Test Accuracy: 0.814\n",
      "Epoch: 3309/4000..  Training Loss: 0.006..  Test Loss: 1.125..  Test Accuracy: 0.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3310/4000..  Training Loss: 0.004..  Test Loss: 1.116..  Test Accuracy: 0.832\n",
      "Epoch: 3311/4000..  Training Loss: 0.023..  Test Loss: 1.212..  Test Accuracy: 0.820\n",
      "Epoch: 3312/4000..  Training Loss: 0.010..  Test Loss: 1.175..  Test Accuracy: 0.823\n",
      "Epoch: 3313/4000..  Training Loss: 0.006..  Test Loss: 1.150..  Test Accuracy: 0.827\n",
      "Epoch: 3314/4000..  Training Loss: 0.010..  Test Loss: 1.154..  Test Accuracy: 0.825\n",
      "Epoch: 3315/4000..  Training Loss: 0.003..  Test Loss: 1.109..  Test Accuracy: 0.831\n",
      "Epoch: 3316/4000..  Training Loss: 0.002..  Test Loss: 1.104..  Test Accuracy: 0.832\n",
      "Epoch: 3317/4000..  Training Loss: 0.020..  Test Loss: 1.195..  Test Accuracy: 0.824\n",
      "Epoch: 3318/4000..  Training Loss: 0.004..  Test Loss: 1.158..  Test Accuracy: 0.827\n",
      "Epoch: 3319/4000..  Training Loss: 0.018..  Test Loss: 1.170..  Test Accuracy: 0.824\n",
      "Epoch: 3320/4000..  Training Loss: 0.008..  Test Loss: 1.099..  Test Accuracy: 0.835\n",
      "Epoch: 3321/4000..  Training Loss: 0.013..  Test Loss: 1.164..  Test Accuracy: 0.827\n",
      "Epoch: 3322/4000..  Training Loss: 0.011..  Test Loss: 1.144..  Test Accuracy: 0.829\n",
      "Epoch: 3323/4000..  Training Loss: 0.009..  Test Loss: 1.118..  Test Accuracy: 0.831\n",
      "Epoch: 3324/4000..  Training Loss: 0.002..  Test Loss: 1.136..  Test Accuracy: 0.828\n",
      "Epoch: 3325/4000..  Training Loss: 0.009..  Test Loss: 1.217..  Test Accuracy: 0.821\n",
      "Epoch: 3326/4000..  Training Loss: 0.006..  Test Loss: 1.150..  Test Accuracy: 0.828\n",
      "Epoch: 3327/4000..  Training Loss: 0.010..  Test Loss: 1.145..  Test Accuracy: 0.826\n",
      "Epoch: 3328/4000..  Training Loss: 0.018..  Test Loss: 1.153..  Test Accuracy: 0.825\n",
      "Epoch: 3329/4000..  Training Loss: 0.014..  Test Loss: 1.136..  Test Accuracy: 0.827\n",
      "Epoch: 3330/4000..  Training Loss: 0.020..  Test Loss: 1.208..  Test Accuracy: 0.820\n",
      "Epoch: 3331/4000..  Training Loss: 0.010..  Test Loss: 1.169..  Test Accuracy: 0.824\n",
      "Epoch: 3332/4000..  Training Loss: 0.007..  Test Loss: 1.190..  Test Accuracy: 0.824\n",
      "Epoch: 3333/4000..  Training Loss: 0.031..  Test Loss: 1.169..  Test Accuracy: 0.825\n",
      "Epoch: 3334/4000..  Training Loss: 0.009..  Test Loss: 1.217..  Test Accuracy: 0.824\n",
      "Epoch: 3335/4000..  Training Loss: 0.012..  Test Loss: 1.267..  Test Accuracy: 0.816\n",
      "Epoch: 3336/4000..  Training Loss: 0.014..  Test Loss: 1.206..  Test Accuracy: 0.818\n",
      "Epoch: 3337/4000..  Training Loss: 0.010..  Test Loss: 1.198..  Test Accuracy: 0.821\n",
      "Epoch: 3338/4000..  Training Loss: 0.018..  Test Loss: 1.218..  Test Accuracy: 0.817\n",
      "Epoch: 3339/4000..  Training Loss: 0.011..  Test Loss: 1.125..  Test Accuracy: 0.828\n",
      "Epoch: 3340/4000..  Training Loss: 0.010..  Test Loss: 1.172..  Test Accuracy: 0.824\n",
      "Epoch: 3341/4000..  Training Loss: 0.003..  Test Loss: 1.126..  Test Accuracy: 0.830\n",
      "Epoch: 3342/4000..  Training Loss: 0.023..  Test Loss: 1.127..  Test Accuracy: 0.828\n",
      "Epoch: 3343/4000..  Training Loss: 0.006..  Test Loss: 1.116..  Test Accuracy: 0.829\n",
      "Epoch: 3344/4000..  Training Loss: 0.002..  Test Loss: 1.142..  Test Accuracy: 0.828\n",
      "Epoch: 3345/4000..  Training Loss: 0.006..  Test Loss: 1.191..  Test Accuracy: 0.820\n",
      "Epoch: 3346/4000..  Training Loss: 0.005..  Test Loss: 1.141..  Test Accuracy: 0.828\n",
      "Epoch: 3347/4000..  Training Loss: 0.003..  Test Loss: 1.157..  Test Accuracy: 0.826\n",
      "Epoch: 3348/4000..  Training Loss: 0.011..  Test Loss: 1.194..  Test Accuracy: 0.824\n",
      "Epoch: 3349/4000..  Training Loss: 0.003..  Test Loss: 1.156..  Test Accuracy: 0.828\n",
      "Epoch: 3350/4000..  Training Loss: 0.016..  Test Loss: 1.259..  Test Accuracy: 0.815\n",
      "Epoch: 3351/4000..  Training Loss: 0.003..  Test Loss: 1.253..  Test Accuracy: 0.818\n",
      "Epoch: 3352/4000..  Training Loss: 0.003..  Test Loss: 1.217..  Test Accuracy: 0.821\n",
      "Epoch: 3353/4000..  Training Loss: 0.011..  Test Loss: 1.210..  Test Accuracy: 0.823\n",
      "Epoch: 3354/4000..  Training Loss: 0.003..  Test Loss: 1.180..  Test Accuracy: 0.824\n",
      "Epoch: 3355/4000..  Training Loss: 0.002..  Test Loss: 1.160..  Test Accuracy: 0.827\n",
      "Epoch: 3356/4000..  Training Loss: 0.028..  Test Loss: 1.163..  Test Accuracy: 0.824\n",
      "Epoch: 3357/4000..  Training Loss: 0.013..  Test Loss: 1.248..  Test Accuracy: 0.813\n",
      "Epoch: 3358/4000..  Training Loss: 0.010..  Test Loss: 1.175..  Test Accuracy: 0.822\n",
      "Epoch: 3359/4000..  Training Loss: 0.009..  Test Loss: 1.124..  Test Accuracy: 0.827\n",
      "Epoch: 3360/4000..  Training Loss: 0.009..  Test Loss: 1.151..  Test Accuracy: 0.826\n",
      "Epoch: 3361/4000..  Training Loss: 0.013..  Test Loss: 1.121..  Test Accuracy: 0.831\n",
      "Epoch: 3362/4000..  Training Loss: 0.004..  Test Loss: 1.148..  Test Accuracy: 0.828\n",
      "Epoch: 3363/4000..  Training Loss: 0.002..  Test Loss: 1.135..  Test Accuracy: 0.830\n",
      "Epoch: 3364/4000..  Training Loss: 0.008..  Test Loss: 1.146..  Test Accuracy: 0.828\n",
      "Epoch: 3365/4000..  Training Loss: 0.010..  Test Loss: 1.175..  Test Accuracy: 0.823\n",
      "Epoch: 3366/4000..  Training Loss: 0.003..  Test Loss: 1.130..  Test Accuracy: 0.828\n",
      "Epoch: 3367/4000..  Training Loss: 0.005..  Test Loss: 1.139..  Test Accuracy: 0.828\n",
      "Epoch: 3368/4000..  Training Loss: 0.005..  Test Loss: 1.086..  Test Accuracy: 0.836\n",
      "Epoch: 3369/4000..  Training Loss: 0.009..  Test Loss: 1.146..  Test Accuracy: 0.829\n",
      "Epoch: 3370/4000..  Training Loss: 0.002..  Test Loss: 1.179..  Test Accuracy: 0.823\n",
      "Epoch: 3371/4000..  Training Loss: 0.030..  Test Loss: 1.212..  Test Accuracy: 0.821\n",
      "Epoch: 3372/4000..  Training Loss: 0.026..  Test Loss: 1.153..  Test Accuracy: 0.828\n",
      "Epoch: 3373/4000..  Training Loss: 0.011..  Test Loss: 1.159..  Test Accuracy: 0.827\n",
      "Epoch: 3374/4000..  Training Loss: 0.004..  Test Loss: 1.156..  Test Accuracy: 0.828\n",
      "Epoch: 3375/4000..  Training Loss: 0.009..  Test Loss: 1.219..  Test Accuracy: 0.819\n",
      "Epoch: 3376/4000..  Training Loss: 0.013..  Test Loss: 1.094..  Test Accuracy: 0.833\n",
      "Epoch: 3377/4000..  Training Loss: 0.004..  Test Loss: 1.149..  Test Accuracy: 0.826\n",
      "Epoch: 3378/4000..  Training Loss: 0.011..  Test Loss: 1.143..  Test Accuracy: 0.828\n",
      "Epoch: 3379/4000..  Training Loss: 0.003..  Test Loss: 1.124..  Test Accuracy: 0.831\n",
      "Epoch: 3380/4000..  Training Loss: 0.020..  Test Loss: 1.223..  Test Accuracy: 0.817\n",
      "Epoch: 3381/4000..  Training Loss: 0.006..  Test Loss: 1.163..  Test Accuracy: 0.826\n",
      "Epoch: 3382/4000..  Training Loss: 0.015..  Test Loss: 1.187..  Test Accuracy: 0.823\n",
      "Epoch: 3383/4000..  Training Loss: 0.009..  Test Loss: 1.115..  Test Accuracy: 0.831\n",
      "Epoch: 3384/4000..  Training Loss: 0.008..  Test Loss: 1.122..  Test Accuracy: 0.829\n",
      "Epoch: 3385/4000..  Training Loss: 0.010..  Test Loss: 1.138..  Test Accuracy: 0.830\n",
      "Epoch: 3386/4000..  Training Loss: 0.006..  Test Loss: 1.138..  Test Accuracy: 0.829\n",
      "Epoch: 3387/4000..  Training Loss: 0.012..  Test Loss: 1.113..  Test Accuracy: 0.832\n",
      "Epoch: 3388/4000..  Training Loss: 0.013..  Test Loss: 1.166..  Test Accuracy: 0.826\n",
      "Epoch: 3389/4000..  Training Loss: 0.017..  Test Loss: 1.146..  Test Accuracy: 0.829\n",
      "Epoch: 3390/4000..  Training Loss: 0.017..  Test Loss: 1.083..  Test Accuracy: 0.836\n",
      "Epoch: 3391/4000..  Training Loss: 0.012..  Test Loss: 1.162..  Test Accuracy: 0.827\n",
      "Epoch: 3392/4000..  Training Loss: 0.003..  Test Loss: 1.200..  Test Accuracy: 0.824\n",
      "Epoch: 3393/4000..  Training Loss: 0.019..  Test Loss: 1.190..  Test Accuracy: 0.825\n",
      "Epoch: 3394/4000..  Training Loss: 0.004..  Test Loss: 1.147..  Test Accuracy: 0.827\n",
      "Epoch: 3395/4000..  Training Loss: 0.007..  Test Loss: 1.123..  Test Accuracy: 0.831\n",
      "Epoch: 3396/4000..  Training Loss: 0.009..  Test Loss: 1.156..  Test Accuracy: 0.826\n",
      "Epoch: 3397/4000..  Training Loss: 0.006..  Test Loss: 1.157..  Test Accuracy: 0.829\n",
      "Epoch: 3398/4000..  Training Loss: 0.003..  Test Loss: 1.161..  Test Accuracy: 0.828\n",
      "Epoch: 3399/4000..  Training Loss: 0.005..  Test Loss: 1.159..  Test Accuracy: 0.827\n",
      "Epoch: 3400/4000..  Training Loss: 0.004..  Test Loss: 1.181..  Test Accuracy: 0.825\n",
      "Epoch: 3401/4000..  Training Loss: 0.003..  Test Loss: 1.112..  Test Accuracy: 0.832\n",
      "Epoch: 3402/4000..  Training Loss: 0.004..  Test Loss: 1.162..  Test Accuracy: 0.829\n",
      "Epoch: 3403/4000..  Training Loss: 0.003..  Test Loss: 1.207..  Test Accuracy: 0.823\n",
      "Epoch: 3404/4000..  Training Loss: 0.004..  Test Loss: 1.208..  Test Accuracy: 0.824\n",
      "Epoch: 3405/4000..  Training Loss: 0.002..  Test Loss: 1.166..  Test Accuracy: 0.829\n",
      "Epoch: 3406/4000..  Training Loss: 0.034..  Test Loss: 1.141..  Test Accuracy: 0.826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3407/4000..  Training Loss: 0.022..  Test Loss: 1.167..  Test Accuracy: 0.824\n",
      "Epoch: 3408/4000..  Training Loss: 0.006..  Test Loss: 1.174..  Test Accuracy: 0.825\n",
      "Epoch: 3409/4000..  Training Loss: 0.002..  Test Loss: 1.190..  Test Accuracy: 0.825\n",
      "Epoch: 3410/4000..  Training Loss: 0.004..  Test Loss: 1.148..  Test Accuracy: 0.828\n",
      "Epoch: 3411/4000..  Training Loss: 0.012..  Test Loss: 1.166..  Test Accuracy: 0.830\n",
      "Epoch: 3412/4000..  Training Loss: 0.007..  Test Loss: 1.217..  Test Accuracy: 0.820\n",
      "Epoch: 3413/4000..  Training Loss: 0.015..  Test Loss: 1.196..  Test Accuracy: 0.825\n",
      "Epoch: 3414/4000..  Training Loss: 0.004..  Test Loss: 1.192..  Test Accuracy: 0.824\n",
      "Epoch: 3415/4000..  Training Loss: 0.002..  Test Loss: 1.144..  Test Accuracy: 0.828\n",
      "Epoch: 3416/4000..  Training Loss: 0.011..  Test Loss: 1.132..  Test Accuracy: 0.828\n",
      "Epoch: 3417/4000..  Training Loss: 0.016..  Test Loss: 1.156..  Test Accuracy: 0.828\n",
      "Epoch: 3418/4000..  Training Loss: 0.003..  Test Loss: 1.176..  Test Accuracy: 0.826\n",
      "Epoch: 3419/4000..  Training Loss: 0.004..  Test Loss: 1.156..  Test Accuracy: 0.829\n",
      "Epoch: 3420/4000..  Training Loss: 0.001..  Test Loss: 1.166..  Test Accuracy: 0.828\n",
      "Epoch: 3421/4000..  Training Loss: 0.005..  Test Loss: 1.170..  Test Accuracy: 0.828\n",
      "Epoch: 3422/4000..  Training Loss: 0.008..  Test Loss: 1.244..  Test Accuracy: 0.819\n",
      "Epoch: 3423/4000..  Training Loss: 0.005..  Test Loss: 1.165..  Test Accuracy: 0.827\n",
      "Epoch: 3424/4000..  Training Loss: 0.016..  Test Loss: 1.165..  Test Accuracy: 0.826\n",
      "Epoch: 3425/4000..  Training Loss: 0.003..  Test Loss: 1.162..  Test Accuracy: 0.827\n",
      "Epoch: 3426/4000..  Training Loss: 0.012..  Test Loss: 1.123..  Test Accuracy: 0.830\n",
      "Epoch: 3427/4000..  Training Loss: 0.023..  Test Loss: 1.216..  Test Accuracy: 0.818\n",
      "Epoch: 3428/4000..  Training Loss: 0.006..  Test Loss: 1.170..  Test Accuracy: 0.826\n",
      "Epoch: 3429/4000..  Training Loss: 0.002..  Test Loss: 1.162..  Test Accuracy: 0.828\n",
      "Epoch: 3430/4000..  Training Loss: 0.004..  Test Loss: 1.178..  Test Accuracy: 0.826\n",
      "Epoch: 3431/4000..  Training Loss: 0.002..  Test Loss: 1.165..  Test Accuracy: 0.827\n",
      "Epoch: 3432/4000..  Training Loss: 0.005..  Test Loss: 1.181..  Test Accuracy: 0.825\n",
      "Epoch: 3433/4000..  Training Loss: 0.008..  Test Loss: 1.160..  Test Accuracy: 0.827\n",
      "Epoch: 3434/4000..  Training Loss: 0.009..  Test Loss: 1.255..  Test Accuracy: 0.817\n",
      "Epoch: 3435/4000..  Training Loss: 0.004..  Test Loss: 1.188..  Test Accuracy: 0.824\n",
      "Epoch: 3436/4000..  Training Loss: 0.004..  Test Loss: 1.140..  Test Accuracy: 0.830\n",
      "Epoch: 3437/4000..  Training Loss: 0.004..  Test Loss: 1.239..  Test Accuracy: 0.819\n",
      "Epoch: 3438/4000..  Training Loss: 0.008..  Test Loss: 1.178..  Test Accuracy: 0.822\n",
      "Epoch: 3439/4000..  Training Loss: 0.007..  Test Loss: 1.136..  Test Accuracy: 0.829\n",
      "Epoch: 3440/4000..  Training Loss: 0.017..  Test Loss: 1.224..  Test Accuracy: 0.821\n",
      "Epoch: 3441/4000..  Training Loss: 0.018..  Test Loss: 1.132..  Test Accuracy: 0.832\n",
      "Epoch: 3442/4000..  Training Loss: 0.013..  Test Loss: 1.169..  Test Accuracy: 0.827\n",
      "Epoch: 3443/4000..  Training Loss: 0.002..  Test Loss: 1.204..  Test Accuracy: 0.824\n",
      "Epoch: 3444/4000..  Training Loss: 0.024..  Test Loss: 1.234..  Test Accuracy: 0.821\n",
      "Epoch: 3445/4000..  Training Loss: 0.009..  Test Loss: 1.172..  Test Accuracy: 0.828\n",
      "Epoch: 3446/4000..  Training Loss: 0.008..  Test Loss: 1.212..  Test Accuracy: 0.824\n",
      "Epoch: 3447/4000..  Training Loss: 0.007..  Test Loss: 1.294..  Test Accuracy: 0.816\n",
      "Epoch: 3448/4000..  Training Loss: 0.037..  Test Loss: 1.222..  Test Accuracy: 0.821\n",
      "Epoch: 3449/4000..  Training Loss: 0.005..  Test Loss: 1.181..  Test Accuracy: 0.827\n",
      "Epoch: 3450/4000..  Training Loss: 0.005..  Test Loss: 1.161..  Test Accuracy: 0.830\n",
      "Epoch: 3451/4000..  Training Loss: 0.020..  Test Loss: 1.227..  Test Accuracy: 0.822\n",
      "Epoch: 3452/4000..  Training Loss: 0.003..  Test Loss: 1.203..  Test Accuracy: 0.822\n",
      "Epoch: 3453/4000..  Training Loss: 0.021..  Test Loss: 1.209..  Test Accuracy: 0.821\n",
      "Epoch: 3454/4000..  Training Loss: 0.013..  Test Loss: 1.145..  Test Accuracy: 0.829\n",
      "Epoch: 3455/4000..  Training Loss: 0.010..  Test Loss: 1.102..  Test Accuracy: 0.834\n",
      "Epoch: 3456/4000..  Training Loss: 0.018..  Test Loss: 1.159..  Test Accuracy: 0.827\n",
      "Epoch: 3457/4000..  Training Loss: 0.008..  Test Loss: 1.164..  Test Accuracy: 0.827\n",
      "Epoch: 3458/4000..  Training Loss: 0.006..  Test Loss: 1.227..  Test Accuracy: 0.822\n",
      "Epoch: 3459/4000..  Training Loss: 0.004..  Test Loss: 1.174..  Test Accuracy: 0.827\n",
      "Epoch: 3460/4000..  Training Loss: 0.009..  Test Loss: 1.143..  Test Accuracy: 0.831\n",
      "Epoch: 3461/4000..  Training Loss: 0.003..  Test Loss: 1.177..  Test Accuracy: 0.829\n",
      "Epoch: 3462/4000..  Training Loss: 0.010..  Test Loss: 1.218..  Test Accuracy: 0.823\n",
      "Epoch: 3463/4000..  Training Loss: 0.010..  Test Loss: 1.161..  Test Accuracy: 0.829\n",
      "Epoch: 3464/4000..  Training Loss: 0.010..  Test Loss: 1.184..  Test Accuracy: 0.825\n",
      "Epoch: 3465/4000..  Training Loss: 0.009..  Test Loss: 1.163..  Test Accuracy: 0.828\n",
      "Epoch: 3466/4000..  Training Loss: 0.004..  Test Loss: 1.164..  Test Accuracy: 0.828\n",
      "Epoch: 3467/4000..  Training Loss: 0.004..  Test Loss: 1.202..  Test Accuracy: 0.824\n",
      "Epoch: 3468/4000..  Training Loss: 0.002..  Test Loss: 1.204..  Test Accuracy: 0.824\n",
      "Epoch: 3469/4000..  Training Loss: 0.004..  Test Loss: 1.199..  Test Accuracy: 0.825\n",
      "Epoch: 3470/4000..  Training Loss: 0.016..  Test Loss: 1.190..  Test Accuracy: 0.826\n",
      "Epoch: 3471/4000..  Training Loss: 0.015..  Test Loss: 1.200..  Test Accuracy: 0.822\n",
      "Epoch: 3472/4000..  Training Loss: 0.014..  Test Loss: 1.184..  Test Accuracy: 0.826\n",
      "Epoch: 3473/4000..  Training Loss: 0.032..  Test Loss: 1.145..  Test Accuracy: 0.829\n",
      "Epoch: 3474/4000..  Training Loss: 0.004..  Test Loss: 1.161..  Test Accuracy: 0.829\n",
      "Epoch: 3475/4000..  Training Loss: 0.003..  Test Loss: 1.172..  Test Accuracy: 0.825\n",
      "Epoch: 3476/4000..  Training Loss: 0.006..  Test Loss: 1.147..  Test Accuracy: 0.830\n",
      "Epoch: 3477/4000..  Training Loss: 0.006..  Test Loss: 1.160..  Test Accuracy: 0.825\n",
      "Epoch: 3478/4000..  Training Loss: 0.011..  Test Loss: 1.169..  Test Accuracy: 0.827\n",
      "Epoch: 3479/4000..  Training Loss: 0.013..  Test Loss: 1.159..  Test Accuracy: 0.828\n",
      "Epoch: 3480/4000..  Training Loss: 0.016..  Test Loss: 1.215..  Test Accuracy: 0.822\n",
      "Epoch: 3481/4000..  Training Loss: 0.014..  Test Loss: 1.179..  Test Accuracy: 0.827\n",
      "Epoch: 3482/4000..  Training Loss: 0.010..  Test Loss: 1.140..  Test Accuracy: 0.832\n",
      "Epoch: 3483/4000..  Training Loss: 0.012..  Test Loss: 1.213..  Test Accuracy: 0.822\n",
      "Epoch: 3484/4000..  Training Loss: 0.002..  Test Loss: 1.226..  Test Accuracy: 0.822\n",
      "Epoch: 3485/4000..  Training Loss: 0.016..  Test Loss: 1.278..  Test Accuracy: 0.813\n",
      "Epoch: 3486/4000..  Training Loss: 0.011..  Test Loss: 1.216..  Test Accuracy: 0.823\n",
      "Epoch: 3487/4000..  Training Loss: 0.008..  Test Loss: 1.144..  Test Accuracy: 0.831\n",
      "Epoch: 3488/4000..  Training Loss: 0.018..  Test Loss: 1.254..  Test Accuracy: 0.818\n",
      "Epoch: 3489/4000..  Training Loss: 0.005..  Test Loss: 1.257..  Test Accuracy: 0.816\n",
      "Epoch: 3490/4000..  Training Loss: 0.011..  Test Loss: 1.240..  Test Accuracy: 0.819\n",
      "Epoch: 3491/4000..  Training Loss: 0.005..  Test Loss: 1.243..  Test Accuracy: 0.820\n",
      "Epoch: 3492/4000..  Training Loss: 0.005..  Test Loss: 1.197..  Test Accuracy: 0.825\n",
      "Epoch: 3493/4000..  Training Loss: 0.005..  Test Loss: 1.209..  Test Accuracy: 0.824\n",
      "Epoch: 3494/4000..  Training Loss: 0.007..  Test Loss: 1.181..  Test Accuracy: 0.826\n",
      "Epoch: 3495/4000..  Training Loss: 0.020..  Test Loss: 1.254..  Test Accuracy: 0.815\n",
      "Epoch: 3496/4000..  Training Loss: 0.010..  Test Loss: 1.140..  Test Accuracy: 0.829\n",
      "Epoch: 3497/4000..  Training Loss: 0.008..  Test Loss: 1.150..  Test Accuracy: 0.829\n",
      "Epoch: 3498/4000..  Training Loss: 0.005..  Test Loss: 1.226..  Test Accuracy: 0.819\n",
      "Epoch: 3499/4000..  Training Loss: 0.050..  Test Loss: 1.144..  Test Accuracy: 0.830\n",
      "Epoch: 3500/4000..  Training Loss: 0.009..  Test Loss: 1.191..  Test Accuracy: 0.823\n",
      "Epoch: 3501/4000..  Training Loss: 0.011..  Test Loss: 1.164..  Test Accuracy: 0.828\n",
      "Epoch: 3502/4000..  Training Loss: 0.015..  Test Loss: 1.235..  Test Accuracy: 0.824\n",
      "Epoch: 3503/4000..  Training Loss: 0.003..  Test Loss: 1.226..  Test Accuracy: 0.824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3504/4000..  Training Loss: 0.002..  Test Loss: 1.231..  Test Accuracy: 0.823\n",
      "Epoch: 3505/4000..  Training Loss: 0.001..  Test Loss: 1.200..  Test Accuracy: 0.826\n",
      "Epoch: 3506/4000..  Training Loss: 0.005..  Test Loss: 1.295..  Test Accuracy: 0.816\n",
      "Epoch: 3507/4000..  Training Loss: 0.003..  Test Loss: 1.262..  Test Accuracy: 0.819\n",
      "Epoch: 3508/4000..  Training Loss: 0.003..  Test Loss: 1.259..  Test Accuracy: 0.820\n",
      "Epoch: 3509/4000..  Training Loss: 0.003..  Test Loss: 1.292..  Test Accuracy: 0.815\n",
      "Epoch: 3510/4000..  Training Loss: 0.012..  Test Loss: 1.134..  Test Accuracy: 0.832\n",
      "Epoch: 3511/4000..  Training Loss: 0.009..  Test Loss: 1.148..  Test Accuracy: 0.830\n",
      "Epoch: 3512/4000..  Training Loss: 0.008..  Test Loss: 1.174..  Test Accuracy: 0.826\n",
      "Epoch: 3513/4000..  Training Loss: 0.004..  Test Loss: 1.152..  Test Accuracy: 0.830\n",
      "Epoch: 3514/4000..  Training Loss: 0.017..  Test Loss: 1.139..  Test Accuracy: 0.832\n",
      "Epoch: 3515/4000..  Training Loss: 0.007..  Test Loss: 1.154..  Test Accuracy: 0.829\n",
      "Epoch: 3516/4000..  Training Loss: 0.009..  Test Loss: 1.160..  Test Accuracy: 0.829\n",
      "Epoch: 3517/4000..  Training Loss: 0.011..  Test Loss: 1.155..  Test Accuracy: 0.830\n",
      "Epoch: 3518/4000..  Training Loss: 0.007..  Test Loss: 1.119..  Test Accuracy: 0.834\n",
      "Epoch: 3519/4000..  Training Loss: 0.003..  Test Loss: 1.131..  Test Accuracy: 0.832\n",
      "Epoch: 3520/4000..  Training Loss: 0.010..  Test Loss: 1.204..  Test Accuracy: 0.827\n",
      "Epoch: 3521/4000..  Training Loss: 0.012..  Test Loss: 1.203..  Test Accuracy: 0.825\n",
      "Epoch: 3522/4000..  Training Loss: 0.003..  Test Loss: 1.200..  Test Accuracy: 0.824\n",
      "Epoch: 3523/4000..  Training Loss: 0.012..  Test Loss: 1.187..  Test Accuracy: 0.824\n",
      "Epoch: 3524/4000..  Training Loss: 0.003..  Test Loss: 1.190..  Test Accuracy: 0.824\n",
      "Epoch: 3525/4000..  Training Loss: 0.016..  Test Loss: 1.196..  Test Accuracy: 0.823\n",
      "Epoch: 3526/4000..  Training Loss: 0.035..  Test Loss: 1.155..  Test Accuracy: 0.825\n",
      "Epoch: 3527/4000..  Training Loss: 0.029..  Test Loss: 1.181..  Test Accuracy: 0.825\n",
      "Epoch: 3528/4000..  Training Loss: 0.017..  Test Loss: 1.272..  Test Accuracy: 0.816\n",
      "Epoch: 3529/4000..  Training Loss: 0.019..  Test Loss: 1.172..  Test Accuracy: 0.825\n",
      "Epoch: 3530/4000..  Training Loss: 0.003..  Test Loss: 1.158..  Test Accuracy: 0.828\n",
      "Epoch: 3531/4000..  Training Loss: 0.003..  Test Loss: 1.158..  Test Accuracy: 0.830\n",
      "Epoch: 3532/4000..  Training Loss: 0.012..  Test Loss: 1.224..  Test Accuracy: 0.821\n",
      "Epoch: 3533/4000..  Training Loss: 0.010..  Test Loss: 1.193..  Test Accuracy: 0.825\n",
      "Epoch: 3534/4000..  Training Loss: 0.014..  Test Loss: 1.145..  Test Accuracy: 0.829\n",
      "Epoch: 3535/4000..  Training Loss: 0.012..  Test Loss: 1.206..  Test Accuracy: 0.821\n",
      "Epoch: 3536/4000..  Training Loss: 0.010..  Test Loss: 1.177..  Test Accuracy: 0.826\n",
      "Epoch: 3537/4000..  Training Loss: 0.012..  Test Loss: 1.185..  Test Accuracy: 0.826\n",
      "Epoch: 3538/4000..  Training Loss: 0.037..  Test Loss: 1.137..  Test Accuracy: 0.830\n",
      "Epoch: 3539/4000..  Training Loss: 0.022..  Test Loss: 1.200..  Test Accuracy: 0.823\n",
      "Epoch: 3540/4000..  Training Loss: 0.008..  Test Loss: 1.146..  Test Accuracy: 0.829\n",
      "Epoch: 3541/4000..  Training Loss: 0.011..  Test Loss: 1.138..  Test Accuracy: 0.832\n",
      "Epoch: 3542/4000..  Training Loss: 0.002..  Test Loss: 1.136..  Test Accuracy: 0.832\n",
      "Epoch: 3543/4000..  Training Loss: 0.004..  Test Loss: 1.152..  Test Accuracy: 0.831\n",
      "Epoch: 3544/4000..  Training Loss: 0.039..  Test Loss: 1.219..  Test Accuracy: 0.822\n",
      "Epoch: 3545/4000..  Training Loss: 0.017..  Test Loss: 1.274..  Test Accuracy: 0.819\n",
      "Epoch: 3546/4000..  Training Loss: 0.012..  Test Loss: 1.246..  Test Accuracy: 0.823\n",
      "Epoch: 3547/4000..  Training Loss: 0.010..  Test Loss: 1.220..  Test Accuracy: 0.823\n",
      "Epoch: 3548/4000..  Training Loss: 0.017..  Test Loss: 1.183..  Test Accuracy: 0.828\n",
      "Epoch: 3549/4000..  Training Loss: 0.010..  Test Loss: 1.195..  Test Accuracy: 0.826\n",
      "Epoch: 3550/4000..  Training Loss: 0.055..  Test Loss: 1.214..  Test Accuracy: 0.822\n",
      "Epoch: 3551/4000..  Training Loss: 0.004..  Test Loss: 1.224..  Test Accuracy: 0.822\n",
      "Epoch: 3552/4000..  Training Loss: 0.003..  Test Loss: 1.198..  Test Accuracy: 0.824\n",
      "Epoch: 3553/4000..  Training Loss: 0.006..  Test Loss: 1.253..  Test Accuracy: 0.820\n",
      "Epoch: 3554/4000..  Training Loss: 0.015..  Test Loss: 1.206..  Test Accuracy: 0.824\n",
      "Epoch: 3555/4000..  Training Loss: 0.015..  Test Loss: 1.154..  Test Accuracy: 0.828\n",
      "Epoch: 3556/4000..  Training Loss: 0.003..  Test Loss: 1.186..  Test Accuracy: 0.827\n",
      "Epoch: 3557/4000..  Training Loss: 0.004..  Test Loss: 1.135..  Test Accuracy: 0.830\n",
      "Epoch: 3558/4000..  Training Loss: 0.013..  Test Loss: 1.233..  Test Accuracy: 0.821\n",
      "Epoch: 3559/4000..  Training Loss: 0.030..  Test Loss: 1.122..  Test Accuracy: 0.833\n",
      "Epoch: 3560/4000..  Training Loss: 0.016..  Test Loss: 1.208..  Test Accuracy: 0.826\n",
      "Epoch: 3561/4000..  Training Loss: 0.015..  Test Loss: 1.251..  Test Accuracy: 0.819\n",
      "Epoch: 3562/4000..  Training Loss: 0.005..  Test Loss: 1.205..  Test Accuracy: 0.823\n",
      "Epoch: 3563/4000..  Training Loss: 0.014..  Test Loss: 1.285..  Test Accuracy: 0.813\n",
      "Epoch: 3564/4000..  Training Loss: 0.007..  Test Loss: 1.240..  Test Accuracy: 0.820\n",
      "Epoch: 3565/4000..  Training Loss: 0.008..  Test Loss: 1.205..  Test Accuracy: 0.824\n",
      "Epoch: 3566/4000..  Training Loss: 0.017..  Test Loss: 1.166..  Test Accuracy: 0.828\n",
      "Epoch: 3567/4000..  Training Loss: 0.007..  Test Loss: 1.179..  Test Accuracy: 0.826\n",
      "Epoch: 3568/4000..  Training Loss: 0.004..  Test Loss: 1.203..  Test Accuracy: 0.825\n",
      "Epoch: 3569/4000..  Training Loss: 0.018..  Test Loss: 1.163..  Test Accuracy: 0.829\n",
      "Epoch: 3570/4000..  Training Loss: 0.002..  Test Loss: 1.206..  Test Accuracy: 0.821\n",
      "Epoch: 3571/4000..  Training Loss: 0.017..  Test Loss: 1.201..  Test Accuracy: 0.820\n",
      "Epoch: 3572/4000..  Training Loss: 0.029..  Test Loss: 1.187..  Test Accuracy: 0.826\n",
      "Epoch: 3573/4000..  Training Loss: 0.003..  Test Loss: 1.160..  Test Accuracy: 0.829\n",
      "Epoch: 3574/4000..  Training Loss: 0.013..  Test Loss: 1.138..  Test Accuracy: 0.830\n",
      "Epoch: 3575/4000..  Training Loss: 0.004..  Test Loss: 1.160..  Test Accuracy: 0.827\n",
      "Epoch: 3576/4000..  Training Loss: 0.005..  Test Loss: 1.184..  Test Accuracy: 0.826\n",
      "Epoch: 3577/4000..  Training Loss: 0.027..  Test Loss: 1.133..  Test Accuracy: 0.831\n",
      "Epoch: 3578/4000..  Training Loss: 0.006..  Test Loss: 1.131..  Test Accuracy: 0.832\n",
      "Epoch: 3579/4000..  Training Loss: 0.029..  Test Loss: 1.144..  Test Accuracy: 0.830\n",
      "Epoch: 3580/4000..  Training Loss: 0.016..  Test Loss: 1.207..  Test Accuracy: 0.823\n",
      "Epoch: 3581/4000..  Training Loss: 0.012..  Test Loss: 1.170..  Test Accuracy: 0.827\n",
      "Epoch: 3582/4000..  Training Loss: 0.008..  Test Loss: 1.147..  Test Accuracy: 0.830\n",
      "Epoch: 3583/4000..  Training Loss: 0.003..  Test Loss: 1.148..  Test Accuracy: 0.829\n",
      "Epoch: 3584/4000..  Training Loss: 0.010..  Test Loss: 1.178..  Test Accuracy: 0.826\n",
      "Epoch: 3585/4000..  Training Loss: 0.010..  Test Loss: 1.174..  Test Accuracy: 0.826\n",
      "Epoch: 3586/4000..  Training Loss: 0.019..  Test Loss: 1.196..  Test Accuracy: 0.824\n",
      "Epoch: 3587/4000..  Training Loss: 0.024..  Test Loss: 1.172..  Test Accuracy: 0.826\n",
      "Epoch: 3588/4000..  Training Loss: 0.014..  Test Loss: 1.246..  Test Accuracy: 0.818\n",
      "Epoch: 3589/4000..  Training Loss: 0.035..  Test Loss: 1.226..  Test Accuracy: 0.821\n",
      "Epoch: 3590/4000..  Training Loss: 0.010..  Test Loss: 1.270..  Test Accuracy: 0.814\n",
      "Epoch: 3591/4000..  Training Loss: 0.011..  Test Loss: 1.250..  Test Accuracy: 0.815\n",
      "Epoch: 3592/4000..  Training Loss: 0.006..  Test Loss: 1.242..  Test Accuracy: 0.816\n",
      "Epoch: 3593/4000..  Training Loss: 0.005..  Test Loss: 1.213..  Test Accuracy: 0.823\n",
      "Epoch: 3594/4000..  Training Loss: 0.003..  Test Loss: 1.209..  Test Accuracy: 0.823\n",
      "Epoch: 3595/4000..  Training Loss: 0.004..  Test Loss: 1.188..  Test Accuracy: 0.825\n",
      "Epoch: 3596/4000..  Training Loss: 0.021..  Test Loss: 1.211..  Test Accuracy: 0.824\n",
      "Epoch: 3597/4000..  Training Loss: 0.033..  Test Loss: 1.255..  Test Accuracy: 0.817\n",
      "Epoch: 3598/4000..  Training Loss: 0.014..  Test Loss: 1.197..  Test Accuracy: 0.822\n",
      "Epoch: 3599/4000..  Training Loss: 0.024..  Test Loss: 1.304..  Test Accuracy: 0.813\n",
      "Epoch: 3600/4000..  Training Loss: 0.013..  Test Loss: 1.147..  Test Accuracy: 0.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3601/4000..  Training Loss: 0.017..  Test Loss: 1.156..  Test Accuracy: 0.829\n",
      "Epoch: 3602/4000..  Training Loss: 0.002..  Test Loss: 1.148..  Test Accuracy: 0.829\n",
      "Epoch: 3603/4000..  Training Loss: 0.004..  Test Loss: 1.173..  Test Accuracy: 0.827\n",
      "Epoch: 3604/4000..  Training Loss: 0.030..  Test Loss: 1.242..  Test Accuracy: 0.818\n",
      "Epoch: 3605/4000..  Training Loss: 0.004..  Test Loss: 1.178..  Test Accuracy: 0.823\n",
      "Epoch: 3606/4000..  Training Loss: 0.008..  Test Loss: 1.185..  Test Accuracy: 0.825\n",
      "Epoch: 3607/4000..  Training Loss: 0.009..  Test Loss: 1.169..  Test Accuracy: 0.827\n",
      "Epoch: 3608/4000..  Training Loss: 0.008..  Test Loss: 1.250..  Test Accuracy: 0.818\n",
      "Epoch: 3609/4000..  Training Loss: 0.002..  Test Loss: 1.234..  Test Accuracy: 0.818\n",
      "Epoch: 3610/4000..  Training Loss: 0.011..  Test Loss: 1.353..  Test Accuracy: 0.810\n",
      "Epoch: 3611/4000..  Training Loss: 0.006..  Test Loss: 1.199..  Test Accuracy: 0.823\n",
      "Epoch: 3612/4000..  Training Loss: 0.006..  Test Loss: 1.210..  Test Accuracy: 0.824\n",
      "Epoch: 3613/4000..  Training Loss: 0.026..  Test Loss: 1.138..  Test Accuracy: 0.832\n",
      "Epoch: 3614/4000..  Training Loss: 0.008..  Test Loss: 1.122..  Test Accuracy: 0.835\n",
      "Epoch: 3615/4000..  Training Loss: 0.011..  Test Loss: 1.169..  Test Accuracy: 0.828\n",
      "Epoch: 3616/4000..  Training Loss: 0.008..  Test Loss: 1.220..  Test Accuracy: 0.824\n",
      "Epoch: 3617/4000..  Training Loss: 0.024..  Test Loss: 1.290..  Test Accuracy: 0.816\n",
      "Epoch: 3618/4000..  Training Loss: 0.004..  Test Loss: 1.270..  Test Accuracy: 0.819\n",
      "Epoch: 3619/4000..  Training Loss: 0.004..  Test Loss: 1.235..  Test Accuracy: 0.824\n",
      "Epoch: 3620/4000..  Training Loss: 0.002..  Test Loss: 1.206..  Test Accuracy: 0.827\n",
      "Epoch: 3621/4000..  Training Loss: 0.001..  Test Loss: 1.198..  Test Accuracy: 0.827\n",
      "Epoch: 3622/4000..  Training Loss: 0.010..  Test Loss: 1.219..  Test Accuracy: 0.823\n",
      "Epoch: 3623/4000..  Training Loss: 0.022..  Test Loss: 1.120..  Test Accuracy: 0.833\n",
      "Epoch: 3624/4000..  Training Loss: 0.005..  Test Loss: 1.138..  Test Accuracy: 0.830\n",
      "Epoch: 3625/4000..  Training Loss: 0.004..  Test Loss: 1.128..  Test Accuracy: 0.832\n",
      "Epoch: 3626/4000..  Training Loss: 0.012..  Test Loss: 1.134..  Test Accuracy: 0.831\n",
      "Epoch: 3627/4000..  Training Loss: 0.006..  Test Loss: 1.152..  Test Accuracy: 0.828\n",
      "Epoch: 3628/4000..  Training Loss: 0.006..  Test Loss: 1.182..  Test Accuracy: 0.827\n",
      "Epoch: 3629/4000..  Training Loss: 0.017..  Test Loss: 1.212..  Test Accuracy: 0.826\n",
      "Epoch: 3630/4000..  Training Loss: 0.004..  Test Loss: 1.197..  Test Accuracy: 0.827\n",
      "Epoch: 3631/4000..  Training Loss: 0.003..  Test Loss: 1.227..  Test Accuracy: 0.824\n",
      "Epoch: 3632/4000..  Training Loss: 0.011..  Test Loss: 1.202..  Test Accuracy: 0.827\n",
      "Epoch: 3633/4000..  Training Loss: 0.011..  Test Loss: 1.283..  Test Accuracy: 0.815\n",
      "Epoch: 3634/4000..  Training Loss: 0.004..  Test Loss: 1.256..  Test Accuracy: 0.819\n",
      "Epoch: 3635/4000..  Training Loss: 0.007..  Test Loss: 1.201..  Test Accuracy: 0.825\n",
      "Epoch: 3636/4000..  Training Loss: 0.028..  Test Loss: 1.106..  Test Accuracy: 0.836\n",
      "Epoch: 3637/4000..  Training Loss: 0.010..  Test Loss: 1.125..  Test Accuracy: 0.833\n",
      "Epoch: 3638/4000..  Training Loss: 0.010..  Test Loss: 1.178..  Test Accuracy: 0.825\n",
      "Epoch: 3639/4000..  Training Loss: 0.004..  Test Loss: 1.197..  Test Accuracy: 0.823\n",
      "Epoch: 3640/4000..  Training Loss: 0.009..  Test Loss: 1.180..  Test Accuracy: 0.826\n",
      "Epoch: 3641/4000..  Training Loss: 0.002..  Test Loss: 1.197..  Test Accuracy: 0.826\n",
      "Epoch: 3642/4000..  Training Loss: 0.002..  Test Loss: 1.196..  Test Accuracy: 0.827\n",
      "Epoch: 3643/4000..  Training Loss: 0.015..  Test Loss: 1.194..  Test Accuracy: 0.825\n",
      "Epoch: 3644/4000..  Training Loss: 0.007..  Test Loss: 1.267..  Test Accuracy: 0.816\n",
      "Epoch: 3645/4000..  Training Loss: 0.006..  Test Loss: 1.200..  Test Accuracy: 0.824\n",
      "Epoch: 3646/4000..  Training Loss: 0.002..  Test Loss: 1.171..  Test Accuracy: 0.827\n",
      "Epoch: 3647/4000..  Training Loss: 0.009..  Test Loss: 1.184..  Test Accuracy: 0.826\n",
      "Epoch: 3648/4000..  Training Loss: 0.003..  Test Loss: 1.191..  Test Accuracy: 0.825\n",
      "Epoch: 3649/4000..  Training Loss: 0.004..  Test Loss: 1.166..  Test Accuracy: 0.827\n",
      "Epoch: 3650/4000..  Training Loss: 0.003..  Test Loss: 1.181..  Test Accuracy: 0.826\n",
      "Epoch: 3651/4000..  Training Loss: 0.009..  Test Loss: 1.174..  Test Accuracy: 0.824\n",
      "Epoch: 3652/4000..  Training Loss: 0.012..  Test Loss: 1.185..  Test Accuracy: 0.826\n",
      "Epoch: 3653/4000..  Training Loss: 0.013..  Test Loss: 1.236..  Test Accuracy: 0.820\n",
      "Epoch: 3654/4000..  Training Loss: 0.010..  Test Loss: 1.175..  Test Accuracy: 0.828\n",
      "Epoch: 3655/4000..  Training Loss: 0.008..  Test Loss: 1.192..  Test Accuracy: 0.825\n",
      "Epoch: 3656/4000..  Training Loss: 0.005..  Test Loss: 1.159..  Test Accuracy: 0.827\n",
      "Epoch: 3657/4000..  Training Loss: 0.006..  Test Loss: 1.140..  Test Accuracy: 0.830\n",
      "Epoch: 3658/4000..  Training Loss: 0.028..  Test Loss: 1.152..  Test Accuracy: 0.831\n",
      "Epoch: 3659/4000..  Training Loss: 0.004..  Test Loss: 1.156..  Test Accuracy: 0.830\n",
      "Epoch: 3660/4000..  Training Loss: 0.014..  Test Loss: 1.233..  Test Accuracy: 0.821\n",
      "Epoch: 3661/4000..  Training Loss: 0.015..  Test Loss: 1.165..  Test Accuracy: 0.828\n",
      "Epoch: 3662/4000..  Training Loss: 0.016..  Test Loss: 1.227..  Test Accuracy: 0.821\n",
      "Epoch: 3663/4000..  Training Loss: 0.015..  Test Loss: 1.211..  Test Accuracy: 0.824\n",
      "Epoch: 3664/4000..  Training Loss: 0.008..  Test Loss: 1.169..  Test Accuracy: 0.828\n",
      "Epoch: 3665/4000..  Training Loss: 0.016..  Test Loss: 1.153..  Test Accuracy: 0.830\n",
      "Epoch: 3666/4000..  Training Loss: 0.009..  Test Loss: 1.172..  Test Accuracy: 0.824\n",
      "Epoch: 3667/4000..  Training Loss: 0.004..  Test Loss: 1.157..  Test Accuracy: 0.829\n",
      "Epoch: 3668/4000..  Training Loss: 0.007..  Test Loss: 1.131..  Test Accuracy: 0.831\n",
      "Epoch: 3669/4000..  Training Loss: 0.011..  Test Loss: 1.279..  Test Accuracy: 0.818\n",
      "Epoch: 3670/4000..  Training Loss: 0.004..  Test Loss: 1.175..  Test Accuracy: 0.826\n",
      "Epoch: 3671/4000..  Training Loss: 0.007..  Test Loss: 1.112..  Test Accuracy: 0.834\n",
      "Epoch: 3672/4000..  Training Loss: 0.002..  Test Loss: 1.187..  Test Accuracy: 0.826\n",
      "Epoch: 3673/4000..  Training Loss: 0.008..  Test Loss: 1.185..  Test Accuracy: 0.826\n",
      "Epoch: 3674/4000..  Training Loss: 0.005..  Test Loss: 1.199..  Test Accuracy: 0.824\n",
      "Epoch: 3675/4000..  Training Loss: 0.007..  Test Loss: 1.152..  Test Accuracy: 0.829\n",
      "Epoch: 3676/4000..  Training Loss: 0.029..  Test Loss: 1.339..  Test Accuracy: 0.809\n",
      "Epoch: 3677/4000..  Training Loss: 0.012..  Test Loss: 1.148..  Test Accuracy: 0.834\n",
      "Epoch: 3678/4000..  Training Loss: 0.026..  Test Loss: 1.197..  Test Accuracy: 0.826\n",
      "Epoch: 3679/4000..  Training Loss: 0.004..  Test Loss: 1.235..  Test Accuracy: 0.819\n",
      "Epoch: 3680/4000..  Training Loss: 0.005..  Test Loss: 1.176..  Test Accuracy: 0.826\n",
      "Epoch: 3681/4000..  Training Loss: 0.004..  Test Loss: 1.143..  Test Accuracy: 0.830\n",
      "Epoch: 3682/4000..  Training Loss: 0.008..  Test Loss: 1.161..  Test Accuracy: 0.826\n",
      "Epoch: 3683/4000..  Training Loss: 0.008..  Test Loss: 1.214..  Test Accuracy: 0.823\n",
      "Epoch: 3684/4000..  Training Loss: 0.003..  Test Loss: 1.194..  Test Accuracy: 0.825\n",
      "Epoch: 3685/4000..  Training Loss: 0.024..  Test Loss: 1.101..  Test Accuracy: 0.837\n",
      "Epoch: 3686/4000..  Training Loss: 0.010..  Test Loss: 1.186..  Test Accuracy: 0.827\n",
      "Epoch: 3687/4000..  Training Loss: 0.010..  Test Loss: 1.170..  Test Accuracy: 0.828\n",
      "Epoch: 3688/4000..  Training Loss: 0.014..  Test Loss: 1.218..  Test Accuracy: 0.820\n",
      "Epoch: 3689/4000..  Training Loss: 0.005..  Test Loss: 1.172..  Test Accuracy: 0.828\n",
      "Epoch: 3690/4000..  Training Loss: 0.017..  Test Loss: 1.168..  Test Accuracy: 0.828\n",
      "Epoch: 3691/4000..  Training Loss: 0.004..  Test Loss: 1.188..  Test Accuracy: 0.827\n",
      "Epoch: 3692/4000..  Training Loss: 0.001..  Test Loss: 1.173..  Test Accuracy: 0.829\n",
      "Epoch: 3693/4000..  Training Loss: 0.025..  Test Loss: 1.230..  Test Accuracy: 0.824\n",
      "Epoch: 3694/4000..  Training Loss: 0.004..  Test Loss: 1.159..  Test Accuracy: 0.830\n",
      "Epoch: 3695/4000..  Training Loss: 0.010..  Test Loss: 1.153..  Test Accuracy: 0.828\n",
      "Epoch: 3696/4000..  Training Loss: 0.002..  Test Loss: 1.162..  Test Accuracy: 0.828\n",
      "Epoch: 3697/4000..  Training Loss: 0.012..  Test Loss: 1.157..  Test Accuracy: 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3698/4000..  Training Loss: 0.019..  Test Loss: 1.237..  Test Accuracy: 0.822\n",
      "Epoch: 3699/4000..  Training Loss: 0.010..  Test Loss: 1.148..  Test Accuracy: 0.830\n",
      "Epoch: 3700/4000..  Training Loss: 0.008..  Test Loss: 1.175..  Test Accuracy: 0.827\n",
      "Epoch: 3701/4000..  Training Loss: 0.016..  Test Loss: 1.141..  Test Accuracy: 0.832\n",
      "Epoch: 3702/4000..  Training Loss: 0.008..  Test Loss: 1.231..  Test Accuracy: 0.819\n",
      "Epoch: 3703/4000..  Training Loss: 0.013..  Test Loss: 1.173..  Test Accuracy: 0.827\n",
      "Epoch: 3704/4000..  Training Loss: 0.005..  Test Loss: 1.173..  Test Accuracy: 0.828\n",
      "Epoch: 3705/4000..  Training Loss: 0.009..  Test Loss: 1.158..  Test Accuracy: 0.830\n",
      "Epoch: 3706/4000..  Training Loss: 0.012..  Test Loss: 1.169..  Test Accuracy: 0.830\n",
      "Epoch: 3707/4000..  Training Loss: 0.020..  Test Loss: 1.184..  Test Accuracy: 0.827\n",
      "Epoch: 3708/4000..  Training Loss: 0.030..  Test Loss: 1.151..  Test Accuracy: 0.830\n",
      "Epoch: 3709/4000..  Training Loss: 0.006..  Test Loss: 1.177..  Test Accuracy: 0.828\n",
      "Epoch: 3710/4000..  Training Loss: 0.023..  Test Loss: 1.180..  Test Accuracy: 0.826\n",
      "Epoch: 3711/4000..  Training Loss: 0.010..  Test Loss: 1.162..  Test Accuracy: 0.826\n",
      "Epoch: 3712/4000..  Training Loss: 0.010..  Test Loss: 1.095..  Test Accuracy: 0.836\n",
      "Epoch: 3713/4000..  Training Loss: 0.002..  Test Loss: 1.104..  Test Accuracy: 0.835\n",
      "Epoch: 3714/4000..  Training Loss: 0.008..  Test Loss: 1.096..  Test Accuracy: 0.836\n",
      "Epoch: 3715/4000..  Training Loss: 0.031..  Test Loss: 1.159..  Test Accuracy: 0.826\n",
      "Epoch: 3716/4000..  Training Loss: 0.010..  Test Loss: 1.170..  Test Accuracy: 0.825\n",
      "Epoch: 3717/4000..  Training Loss: 0.002..  Test Loss: 1.150..  Test Accuracy: 0.827\n",
      "Epoch: 3718/4000..  Training Loss: 0.002..  Test Loss: 1.152..  Test Accuracy: 0.828\n",
      "Epoch: 3719/4000..  Training Loss: 0.023..  Test Loss: 1.147..  Test Accuracy: 0.831\n",
      "Epoch: 3720/4000..  Training Loss: 0.002..  Test Loss: 1.115..  Test Accuracy: 0.834\n",
      "Epoch: 3721/4000..  Training Loss: 0.004..  Test Loss: 1.173..  Test Accuracy: 0.828\n",
      "Epoch: 3722/4000..  Training Loss: 0.004..  Test Loss: 1.123..  Test Accuracy: 0.834\n",
      "Epoch: 3723/4000..  Training Loss: 0.005..  Test Loss: 1.147..  Test Accuracy: 0.831\n",
      "Epoch: 3724/4000..  Training Loss: 0.009..  Test Loss: 1.163..  Test Accuracy: 0.828\n",
      "Epoch: 3725/4000..  Training Loss: 0.006..  Test Loss: 1.140..  Test Accuracy: 0.830\n",
      "Epoch: 3726/4000..  Training Loss: 0.002..  Test Loss: 1.131..  Test Accuracy: 0.832\n",
      "Epoch: 3727/4000..  Training Loss: 0.015..  Test Loss: 1.206..  Test Accuracy: 0.823\n",
      "Epoch: 3728/4000..  Training Loss: 0.003..  Test Loss: 1.205..  Test Accuracy: 0.825\n",
      "Epoch: 3729/4000..  Training Loss: 0.027..  Test Loss: 1.154..  Test Accuracy: 0.829\n",
      "Epoch: 3730/4000..  Training Loss: 0.018..  Test Loss: 1.132..  Test Accuracy: 0.830\n",
      "Epoch: 3731/4000..  Training Loss: 0.003..  Test Loss: 1.180..  Test Accuracy: 0.824\n",
      "Epoch: 3732/4000..  Training Loss: 0.013..  Test Loss: 1.301..  Test Accuracy: 0.815\n",
      "Epoch: 3733/4000..  Training Loss: 0.035..  Test Loss: 1.254..  Test Accuracy: 0.820\n",
      "Epoch: 3734/4000..  Training Loss: 0.002..  Test Loss: 1.205..  Test Accuracy: 0.824\n",
      "Epoch: 3735/4000..  Training Loss: 0.018..  Test Loss: 1.209..  Test Accuracy: 0.823\n",
      "Epoch: 3736/4000..  Training Loss: 0.002..  Test Loss: 1.191..  Test Accuracy: 0.827\n",
      "Epoch: 3737/4000..  Training Loss: 0.004..  Test Loss: 1.188..  Test Accuracy: 0.827\n",
      "Epoch: 3738/4000..  Training Loss: 0.001..  Test Loss: 1.176..  Test Accuracy: 0.828\n",
      "Epoch: 3739/4000..  Training Loss: 0.002..  Test Loss: 1.172..  Test Accuracy: 0.828\n",
      "Epoch: 3740/4000..  Training Loss: 0.001..  Test Loss: 1.179..  Test Accuracy: 0.826\n",
      "Epoch: 3741/4000..  Training Loss: 0.003..  Test Loss: 1.155..  Test Accuracy: 0.829\n",
      "Epoch: 3742/4000..  Training Loss: 0.007..  Test Loss: 1.136..  Test Accuracy: 0.831\n",
      "Epoch: 3743/4000..  Training Loss: 0.020..  Test Loss: 1.135..  Test Accuracy: 0.829\n",
      "Epoch: 3744/4000..  Training Loss: 0.013..  Test Loss: 1.156..  Test Accuracy: 0.825\n",
      "Epoch: 3745/4000..  Training Loss: 0.009..  Test Loss: 1.239..  Test Accuracy: 0.819\n",
      "Epoch: 3746/4000..  Training Loss: 0.004..  Test Loss: 1.173..  Test Accuracy: 0.827\n",
      "Epoch: 3747/4000..  Training Loss: 0.006..  Test Loss: 1.159..  Test Accuracy: 0.826\n",
      "Epoch: 3748/4000..  Training Loss: 0.004..  Test Loss: 1.169..  Test Accuracy: 0.829\n",
      "Epoch: 3749/4000..  Training Loss: 0.002..  Test Loss: 1.156..  Test Accuracy: 0.830\n",
      "Epoch: 3750/4000..  Training Loss: 0.004..  Test Loss: 1.178..  Test Accuracy: 0.826\n",
      "Epoch: 3751/4000..  Training Loss: 0.012..  Test Loss: 1.179..  Test Accuracy: 0.826\n",
      "Epoch: 3752/4000..  Training Loss: 0.003..  Test Loss: 1.167..  Test Accuracy: 0.827\n",
      "Epoch: 3753/4000..  Training Loss: 0.002..  Test Loss: 1.142..  Test Accuracy: 0.829\n",
      "Epoch: 3754/4000..  Training Loss: 0.013..  Test Loss: 1.096..  Test Accuracy: 0.837\n",
      "Epoch: 3755/4000..  Training Loss: 0.020..  Test Loss: 1.101..  Test Accuracy: 0.837\n",
      "Epoch: 3756/4000..  Training Loss: 0.004..  Test Loss: 1.130..  Test Accuracy: 0.833\n",
      "Epoch: 3757/4000..  Training Loss: 0.004..  Test Loss: 1.133..  Test Accuracy: 0.832\n",
      "Epoch: 3758/4000..  Training Loss: 0.005..  Test Loss: 1.134..  Test Accuracy: 0.832\n",
      "Epoch: 3759/4000..  Training Loss: 0.007..  Test Loss: 1.123..  Test Accuracy: 0.834\n",
      "Epoch: 3760/4000..  Training Loss: 0.008..  Test Loss: 1.145..  Test Accuracy: 0.831\n",
      "Epoch: 3761/4000..  Training Loss: 0.005..  Test Loss: 1.158..  Test Accuracy: 0.829\n",
      "Epoch: 3762/4000..  Training Loss: 0.002..  Test Loss: 1.167..  Test Accuracy: 0.827\n",
      "Epoch: 3763/4000..  Training Loss: 0.009..  Test Loss: 1.182..  Test Accuracy: 0.828\n",
      "Epoch: 3764/4000..  Training Loss: 0.003..  Test Loss: 1.206..  Test Accuracy: 0.824\n",
      "Epoch: 3765/4000..  Training Loss: 0.004..  Test Loss: 1.182..  Test Accuracy: 0.827\n",
      "Epoch: 3766/4000..  Training Loss: 0.002..  Test Loss: 1.179..  Test Accuracy: 0.829\n",
      "Epoch: 3767/4000..  Training Loss: 0.002..  Test Loss: 1.151..  Test Accuracy: 0.829\n",
      "Epoch: 3768/4000..  Training Loss: 0.007..  Test Loss: 1.098..  Test Accuracy: 0.838\n",
      "Epoch: 3769/4000..  Training Loss: 0.006..  Test Loss: 1.170..  Test Accuracy: 0.826\n",
      "Epoch: 3770/4000..  Training Loss: 0.004..  Test Loss: 1.192..  Test Accuracy: 0.824\n",
      "Epoch: 3771/4000..  Training Loss: 0.005..  Test Loss: 1.173..  Test Accuracy: 0.828\n",
      "Epoch: 3772/4000..  Training Loss: 0.004..  Test Loss: 1.173..  Test Accuracy: 0.827\n",
      "Epoch: 3773/4000..  Training Loss: 0.010..  Test Loss: 1.177..  Test Accuracy: 0.827\n",
      "Epoch: 3774/4000..  Training Loss: 0.068..  Test Loss: 1.163..  Test Accuracy: 0.829\n",
      "Epoch: 3775/4000..  Training Loss: 0.002..  Test Loss: 1.170..  Test Accuracy: 0.828\n",
      "Epoch: 3776/4000..  Training Loss: 0.013..  Test Loss: 1.195..  Test Accuracy: 0.824\n",
      "Epoch: 3777/4000..  Training Loss: 0.003..  Test Loss: 1.261..  Test Accuracy: 0.819\n",
      "Epoch: 3778/4000..  Training Loss: 0.003..  Test Loss: 1.189..  Test Accuracy: 0.828\n",
      "Epoch: 3779/4000..  Training Loss: 0.001..  Test Loss: 1.190..  Test Accuracy: 0.827\n",
      "Epoch: 3780/4000..  Training Loss: 0.002..  Test Loss: 1.174..  Test Accuracy: 0.827\n",
      "Epoch: 3781/4000..  Training Loss: 0.002..  Test Loss: 1.132..  Test Accuracy: 0.832\n",
      "Epoch: 3782/4000..  Training Loss: 0.001..  Test Loss: 1.137..  Test Accuracy: 0.830\n",
      "Epoch: 3783/4000..  Training Loss: 0.004..  Test Loss: 1.221..  Test Accuracy: 0.820\n",
      "Epoch: 3784/4000..  Training Loss: 0.035..  Test Loss: 1.146..  Test Accuracy: 0.831\n",
      "Epoch: 3785/4000..  Training Loss: 0.003..  Test Loss: 1.173..  Test Accuracy: 0.829\n",
      "Epoch: 3786/4000..  Training Loss: 0.006..  Test Loss: 1.156..  Test Accuracy: 0.830\n",
      "Epoch: 3787/4000..  Training Loss: 0.008..  Test Loss: 1.140..  Test Accuracy: 0.831\n",
      "Epoch: 3788/4000..  Training Loss: 0.011..  Test Loss: 1.139..  Test Accuracy: 0.832\n",
      "Epoch: 3789/4000..  Training Loss: 0.008..  Test Loss: 1.180..  Test Accuracy: 0.825\n",
      "Epoch: 3790/4000..  Training Loss: 0.011..  Test Loss: 1.194..  Test Accuracy: 0.826\n",
      "Epoch: 3791/4000..  Training Loss: 0.014..  Test Loss: 1.200..  Test Accuracy: 0.826\n",
      "Epoch: 3792/4000..  Training Loss: 0.006..  Test Loss: 1.137..  Test Accuracy: 0.832\n",
      "Epoch: 3793/4000..  Training Loss: 0.005..  Test Loss: 1.137..  Test Accuracy: 0.832\n",
      "Epoch: 3794/4000..  Training Loss: 0.008..  Test Loss: 1.164..  Test Accuracy: 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3795/4000..  Training Loss: 0.020..  Test Loss: 1.206..  Test Accuracy: 0.824\n",
      "Epoch: 3796/4000..  Training Loss: 0.026..  Test Loss: 1.142..  Test Accuracy: 0.831\n",
      "Epoch: 3797/4000..  Training Loss: 0.009..  Test Loss: 1.149..  Test Accuracy: 0.831\n",
      "Epoch: 3798/4000..  Training Loss: 0.004..  Test Loss: 1.145..  Test Accuracy: 0.828\n",
      "Epoch: 3799/4000..  Training Loss: 0.006..  Test Loss: 1.132..  Test Accuracy: 0.831\n",
      "Epoch: 3800/4000..  Training Loss: 0.004..  Test Loss: 1.188..  Test Accuracy: 0.828\n",
      "Epoch: 3801/4000..  Training Loss: 0.003..  Test Loss: 1.209..  Test Accuracy: 0.826\n",
      "Epoch: 3802/4000..  Training Loss: 0.004..  Test Loss: 1.251..  Test Accuracy: 0.820\n",
      "Epoch: 3803/4000..  Training Loss: 0.038..  Test Loss: 1.181..  Test Accuracy: 0.825\n",
      "Epoch: 3804/4000..  Training Loss: 0.035..  Test Loss: 1.254..  Test Accuracy: 0.819\n",
      "Epoch: 3805/4000..  Training Loss: 0.004..  Test Loss: 1.179..  Test Accuracy: 0.827\n",
      "Epoch: 3806/4000..  Training Loss: 0.008..  Test Loss: 1.122..  Test Accuracy: 0.833\n",
      "Epoch: 3807/4000..  Training Loss: 0.007..  Test Loss: 1.083..  Test Accuracy: 0.839\n",
      "Epoch: 3808/4000..  Training Loss: 0.016..  Test Loss: 1.211..  Test Accuracy: 0.821\n",
      "Epoch: 3809/4000..  Training Loss: 0.013..  Test Loss: 1.192..  Test Accuracy: 0.829\n",
      "Epoch: 3810/4000..  Training Loss: 0.002..  Test Loss: 1.195..  Test Accuracy: 0.830\n",
      "Epoch: 3811/4000..  Training Loss: 0.013..  Test Loss: 1.196..  Test Accuracy: 0.828\n",
      "Epoch: 3812/4000..  Training Loss: 0.006..  Test Loss: 1.168..  Test Accuracy: 0.831\n",
      "Epoch: 3813/4000..  Training Loss: 0.008..  Test Loss: 1.164..  Test Accuracy: 0.828\n",
      "Epoch: 3814/4000..  Training Loss: 0.003..  Test Loss: 1.159..  Test Accuracy: 0.833\n",
      "Epoch: 3815/4000..  Training Loss: 0.001..  Test Loss: 1.163..  Test Accuracy: 0.831\n",
      "Epoch: 3816/4000..  Training Loss: 0.004..  Test Loss: 1.151..  Test Accuracy: 0.832\n",
      "Epoch: 3817/4000..  Training Loss: 0.007..  Test Loss: 1.169..  Test Accuracy: 0.833\n",
      "Epoch: 3818/4000..  Training Loss: 0.006..  Test Loss: 1.171..  Test Accuracy: 0.829\n",
      "Epoch: 3819/4000..  Training Loss: 0.023..  Test Loss: 1.229..  Test Accuracy: 0.824\n",
      "Epoch: 3820/4000..  Training Loss: 0.003..  Test Loss: 1.225..  Test Accuracy: 0.823\n",
      "Epoch: 3821/4000..  Training Loss: 0.010..  Test Loss: 1.217..  Test Accuracy: 0.823\n",
      "Epoch: 3822/4000..  Training Loss: 0.010..  Test Loss: 1.218..  Test Accuracy: 0.824\n",
      "Epoch: 3823/4000..  Training Loss: 0.006..  Test Loss: 1.155..  Test Accuracy: 0.829\n",
      "Epoch: 3824/4000..  Training Loss: 0.001..  Test Loss: 1.141..  Test Accuracy: 0.831\n",
      "Epoch: 3825/4000..  Training Loss: 0.029..  Test Loss: 1.183..  Test Accuracy: 0.828\n",
      "Epoch: 3826/4000..  Training Loss: 0.002..  Test Loss: 1.184..  Test Accuracy: 0.828\n",
      "Epoch: 3827/4000..  Training Loss: 0.007..  Test Loss: 1.193..  Test Accuracy: 0.825\n",
      "Epoch: 3828/4000..  Training Loss: 0.006..  Test Loss: 1.158..  Test Accuracy: 0.831\n",
      "Epoch: 3829/4000..  Training Loss: 0.005..  Test Loss: 1.184..  Test Accuracy: 0.830\n",
      "Epoch: 3830/4000..  Training Loss: 0.003..  Test Loss: 1.146..  Test Accuracy: 0.831\n",
      "Epoch: 3831/4000..  Training Loss: 0.003..  Test Loss: 1.157..  Test Accuracy: 0.830\n",
      "Epoch: 3832/4000..  Training Loss: 0.009..  Test Loss: 1.240..  Test Accuracy: 0.823\n",
      "Epoch: 3833/4000..  Training Loss: 0.036..  Test Loss: 1.157..  Test Accuracy: 0.829\n",
      "Epoch: 3834/4000..  Training Loss: 0.003..  Test Loss: 1.148..  Test Accuracy: 0.829\n",
      "Epoch: 3835/4000..  Training Loss: 0.004..  Test Loss: 1.154..  Test Accuracy: 0.831\n",
      "Epoch: 3836/4000..  Training Loss: 0.009..  Test Loss: 1.116..  Test Accuracy: 0.835\n",
      "Epoch: 3837/4000..  Training Loss: 0.002..  Test Loss: 1.118..  Test Accuracy: 0.835\n",
      "Epoch: 3838/4000..  Training Loss: 0.008..  Test Loss: 1.205..  Test Accuracy: 0.826\n",
      "Epoch: 3839/4000..  Training Loss: 0.009..  Test Loss: 1.092..  Test Accuracy: 0.837\n",
      "Epoch: 3840/4000..  Training Loss: 0.006..  Test Loss: 1.096..  Test Accuracy: 0.837\n",
      "Epoch: 3841/4000..  Training Loss: 0.031..  Test Loss: 1.088..  Test Accuracy: 0.838\n",
      "Epoch: 3842/4000..  Training Loss: 0.016..  Test Loss: 1.126..  Test Accuracy: 0.832\n",
      "Epoch: 3843/4000..  Training Loss: 0.021..  Test Loss: 1.121..  Test Accuracy: 0.834\n",
      "Epoch: 3844/4000..  Training Loss: 0.008..  Test Loss: 1.182..  Test Accuracy: 0.830\n",
      "Epoch: 3845/4000..  Training Loss: 0.010..  Test Loss: 1.178..  Test Accuracy: 0.828\n",
      "Epoch: 3846/4000..  Training Loss: 0.008..  Test Loss: 1.167..  Test Accuracy: 0.827\n",
      "Epoch: 3847/4000..  Training Loss: 0.011..  Test Loss: 1.151..  Test Accuracy: 0.828\n",
      "Epoch: 3848/4000..  Training Loss: 0.014..  Test Loss: 1.133..  Test Accuracy: 0.832\n",
      "Epoch: 3849/4000..  Training Loss: 0.010..  Test Loss: 1.186..  Test Accuracy: 0.828\n",
      "Epoch: 3850/4000..  Training Loss: 0.005..  Test Loss: 1.127..  Test Accuracy: 0.834\n",
      "Epoch: 3851/4000..  Training Loss: 0.004..  Test Loss: 1.180..  Test Accuracy: 0.830\n",
      "Epoch: 3852/4000..  Training Loss: 0.005..  Test Loss: 1.222..  Test Accuracy: 0.827\n",
      "Epoch: 3853/4000..  Training Loss: 0.014..  Test Loss: 1.210..  Test Accuracy: 0.826\n",
      "Epoch: 3854/4000..  Training Loss: 0.015..  Test Loss: 1.240..  Test Accuracy: 0.824\n",
      "Epoch: 3855/4000..  Training Loss: 0.009..  Test Loss: 1.222..  Test Accuracy: 0.825\n",
      "Epoch: 3856/4000..  Training Loss: 0.004..  Test Loss: 1.170..  Test Accuracy: 0.831\n",
      "Epoch: 3857/4000..  Training Loss: 0.004..  Test Loss: 1.170..  Test Accuracy: 0.830\n",
      "Epoch: 3858/4000..  Training Loss: 0.018..  Test Loss: 1.164..  Test Accuracy: 0.830\n",
      "Epoch: 3859/4000..  Training Loss: 0.002..  Test Loss: 1.160..  Test Accuracy: 0.831\n",
      "Epoch: 3860/4000..  Training Loss: 0.005..  Test Loss: 1.133..  Test Accuracy: 0.832\n",
      "Epoch: 3861/4000..  Training Loss: 0.020..  Test Loss: 1.197..  Test Accuracy: 0.829\n",
      "Epoch: 3862/4000..  Training Loss: 0.010..  Test Loss: 1.191..  Test Accuracy: 0.826\n",
      "Epoch: 3863/4000..  Training Loss: 0.011..  Test Loss: 1.185..  Test Accuracy: 0.829\n",
      "Epoch: 3864/4000..  Training Loss: 0.002..  Test Loss: 1.180..  Test Accuracy: 0.829\n",
      "Epoch: 3865/4000..  Training Loss: 0.002..  Test Loss: 1.183..  Test Accuracy: 0.828\n",
      "Epoch: 3866/4000..  Training Loss: 0.003..  Test Loss: 1.146..  Test Accuracy: 0.831\n",
      "Epoch: 3867/4000..  Training Loss: 0.001..  Test Loss: 1.141..  Test Accuracy: 0.831\n",
      "Epoch: 3868/4000..  Training Loss: 0.024..  Test Loss: 1.211..  Test Accuracy: 0.823\n",
      "Epoch: 3869/4000..  Training Loss: 0.006..  Test Loss: 1.126..  Test Accuracy: 0.836\n",
      "Epoch: 3870/4000..  Training Loss: 0.014..  Test Loss: 1.147..  Test Accuracy: 0.830\n",
      "Epoch: 3871/4000..  Training Loss: 0.003..  Test Loss: 1.151..  Test Accuracy: 0.830\n",
      "Epoch: 3872/4000..  Training Loss: 0.006..  Test Loss: 1.150..  Test Accuracy: 0.831\n",
      "Epoch: 3873/4000..  Training Loss: 0.004..  Test Loss: 1.170..  Test Accuracy: 0.828\n",
      "Epoch: 3874/4000..  Training Loss: 0.003..  Test Loss: 1.162..  Test Accuracy: 0.830\n",
      "Epoch: 3875/4000..  Training Loss: 0.014..  Test Loss: 1.214..  Test Accuracy: 0.823\n",
      "Epoch: 3876/4000..  Training Loss: 0.005..  Test Loss: 1.224..  Test Accuracy: 0.823\n",
      "Epoch: 3877/4000..  Training Loss: 0.002..  Test Loss: 1.188..  Test Accuracy: 0.827\n",
      "Epoch: 3878/4000..  Training Loss: 0.003..  Test Loss: 1.155..  Test Accuracy: 0.832\n",
      "Epoch: 3879/4000..  Training Loss: 0.003..  Test Loss: 1.116..  Test Accuracy: 0.838\n",
      "Epoch: 3880/4000..  Training Loss: 0.008..  Test Loss: 1.306..  Test Accuracy: 0.812\n",
      "Epoch: 3881/4000..  Training Loss: 0.035..  Test Loss: 1.185..  Test Accuracy: 0.829\n",
      "Epoch: 3882/4000..  Training Loss: 0.014..  Test Loss: 1.181..  Test Accuracy: 0.830\n",
      "Epoch: 3883/4000..  Training Loss: 0.004..  Test Loss: 1.172..  Test Accuracy: 0.830\n",
      "Epoch: 3884/4000..  Training Loss: 0.010..  Test Loss: 1.163..  Test Accuracy: 0.830\n",
      "Epoch: 3885/4000..  Training Loss: 0.007..  Test Loss: 1.154..  Test Accuracy: 0.831\n",
      "Epoch: 3886/4000..  Training Loss: 0.006..  Test Loss: 1.218..  Test Accuracy: 0.826\n",
      "Epoch: 3887/4000..  Training Loss: 0.011..  Test Loss: 1.250..  Test Accuracy: 0.824\n",
      "Epoch: 3888/4000..  Training Loss: 0.010..  Test Loss: 1.235..  Test Accuracy: 0.823\n",
      "Epoch: 3889/4000..  Training Loss: 0.006..  Test Loss: 1.216..  Test Accuracy: 0.825\n",
      "Epoch: 3890/4000..  Training Loss: 0.005..  Test Loss: 1.179..  Test Accuracy: 0.830\n",
      "Epoch: 3891/4000..  Training Loss: 0.002..  Test Loss: 1.168..  Test Accuracy: 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3892/4000..  Training Loss: 0.007..  Test Loss: 1.189..  Test Accuracy: 0.825\n",
      "Epoch: 3893/4000..  Training Loss: 0.006..  Test Loss: 1.291..  Test Accuracy: 0.818\n",
      "Epoch: 3894/4000..  Training Loss: 0.014..  Test Loss: 1.110..  Test Accuracy: 0.837\n",
      "Epoch: 3895/4000..  Training Loss: 0.023..  Test Loss: 1.312..  Test Accuracy: 0.813\n",
      "Epoch: 3896/4000..  Training Loss: 0.014..  Test Loss: 1.198..  Test Accuracy: 0.828\n",
      "Epoch: 3897/4000..  Training Loss: 0.006..  Test Loss: 1.195..  Test Accuracy: 0.828\n",
      "Epoch: 3898/4000..  Training Loss: 0.002..  Test Loss: 1.148..  Test Accuracy: 0.832\n",
      "Epoch: 3899/4000..  Training Loss: 0.007..  Test Loss: 1.177..  Test Accuracy: 0.829\n",
      "Epoch: 3900/4000..  Training Loss: 0.017..  Test Loss: 1.133..  Test Accuracy: 0.837\n",
      "Epoch: 3901/4000..  Training Loss: 0.025..  Test Loss: 1.181..  Test Accuracy: 0.831\n",
      "Epoch: 3902/4000..  Training Loss: 0.007..  Test Loss: 1.154..  Test Accuracy: 0.834\n",
      "Epoch: 3903/4000..  Training Loss: 0.004..  Test Loss: 1.194..  Test Accuracy: 0.829\n",
      "Epoch: 3904/4000..  Training Loss: 0.015..  Test Loss: 1.135..  Test Accuracy: 0.836\n",
      "Epoch: 3905/4000..  Training Loss: 0.003..  Test Loss: 1.086..  Test Accuracy: 0.842\n",
      "Epoch: 3906/4000..  Training Loss: 0.003..  Test Loss: 1.100..  Test Accuracy: 0.840\n",
      "Epoch: 3907/4000..  Training Loss: 0.068..  Test Loss: 1.190..  Test Accuracy: 0.831\n",
      "Epoch: 3908/4000..  Training Loss: 0.003..  Test Loss: 1.177..  Test Accuracy: 0.832\n",
      "Epoch: 3909/4000..  Training Loss: 0.020..  Test Loss: 1.176..  Test Accuracy: 0.832\n",
      "Epoch: 3910/4000..  Training Loss: 0.002..  Test Loss: 1.169..  Test Accuracy: 0.832\n",
      "Epoch: 3911/4000..  Training Loss: 0.004..  Test Loss: 1.175..  Test Accuracy: 0.829\n",
      "Epoch: 3912/4000..  Training Loss: 0.013..  Test Loss: 1.220..  Test Accuracy: 0.824\n",
      "Epoch: 3913/4000..  Training Loss: 0.012..  Test Loss: 1.179..  Test Accuracy: 0.829\n",
      "Epoch: 3914/4000..  Training Loss: 0.013..  Test Loss: 1.174..  Test Accuracy: 0.830\n",
      "Epoch: 3915/4000..  Training Loss: 0.006..  Test Loss: 1.245..  Test Accuracy: 0.823\n",
      "Epoch: 3916/4000..  Training Loss: 0.008..  Test Loss: 1.299..  Test Accuracy: 0.816\n",
      "Epoch: 3917/4000..  Training Loss: 0.005..  Test Loss: 1.232..  Test Accuracy: 0.824\n",
      "Epoch: 3918/4000..  Training Loss: 0.006..  Test Loss: 1.273..  Test Accuracy: 0.821\n",
      "Epoch: 3919/4000..  Training Loss: 0.012..  Test Loss: 1.269..  Test Accuracy: 0.821\n",
      "Epoch: 3920/4000..  Training Loss: 0.013..  Test Loss: 1.235..  Test Accuracy: 0.822\n",
      "Epoch: 3921/4000..  Training Loss: 0.013..  Test Loss: 1.201..  Test Accuracy: 0.825\n",
      "Epoch: 3922/4000..  Training Loss: 0.008..  Test Loss: 1.196..  Test Accuracy: 0.830\n",
      "Epoch: 3923/4000..  Training Loss: 0.041..  Test Loss: 1.125..  Test Accuracy: 0.839\n",
      "Epoch: 3924/4000..  Training Loss: 0.005..  Test Loss: 1.138..  Test Accuracy: 0.837\n",
      "Epoch: 3925/4000..  Training Loss: 0.006..  Test Loss: 1.111..  Test Accuracy: 0.838\n",
      "Epoch: 3926/4000..  Training Loss: 0.036..  Test Loss: 1.164..  Test Accuracy: 0.831\n",
      "Epoch: 3927/4000..  Training Loss: 0.016..  Test Loss: 1.125..  Test Accuracy: 0.834\n",
      "Epoch: 3928/4000..  Training Loss: 0.011..  Test Loss: 1.135..  Test Accuracy: 0.834\n",
      "Epoch: 3929/4000..  Training Loss: 0.013..  Test Loss: 1.098..  Test Accuracy: 0.839\n",
      "Epoch: 3930/4000..  Training Loss: 0.012..  Test Loss: 1.098..  Test Accuracy: 0.839\n",
      "Epoch: 3931/4000..  Training Loss: 0.022..  Test Loss: 1.118..  Test Accuracy: 0.836\n",
      "Epoch: 3932/4000..  Training Loss: 0.004..  Test Loss: 1.106..  Test Accuracy: 0.838\n",
      "Epoch: 3933/4000..  Training Loss: 0.004..  Test Loss: 1.116..  Test Accuracy: 0.837\n",
      "Epoch: 3934/4000..  Training Loss: 0.008..  Test Loss: 1.145..  Test Accuracy: 0.832\n",
      "Epoch: 3935/4000..  Training Loss: 0.011..  Test Loss: 1.129..  Test Accuracy: 0.833\n",
      "Epoch: 3936/4000..  Training Loss: 0.002..  Test Loss: 1.127..  Test Accuracy: 0.834\n",
      "Epoch: 3937/4000..  Training Loss: 0.003..  Test Loss: 1.137..  Test Accuracy: 0.833\n",
      "Epoch: 3938/4000..  Training Loss: 0.004..  Test Loss: 1.154..  Test Accuracy: 0.834\n",
      "Epoch: 3939/4000..  Training Loss: 0.008..  Test Loss: 1.182..  Test Accuracy: 0.830\n",
      "Epoch: 3940/4000..  Training Loss: 0.006..  Test Loss: 1.150..  Test Accuracy: 0.834\n",
      "Epoch: 3941/4000..  Training Loss: 0.015..  Test Loss: 1.138..  Test Accuracy: 0.835\n",
      "Epoch: 3942/4000..  Training Loss: 0.003..  Test Loss: 1.196..  Test Accuracy: 0.827\n",
      "Epoch: 3943/4000..  Training Loss: 0.006..  Test Loss: 1.203..  Test Accuracy: 0.829\n",
      "Epoch: 3944/4000..  Training Loss: 0.018..  Test Loss: 1.220..  Test Accuracy: 0.826\n",
      "Epoch: 3945/4000..  Training Loss: 0.009..  Test Loss: 1.245..  Test Accuracy: 0.824\n",
      "Epoch: 3946/4000..  Training Loss: 0.008..  Test Loss: 1.276..  Test Accuracy: 0.822\n",
      "Epoch: 3947/4000..  Training Loss: 0.003..  Test Loss: 1.187..  Test Accuracy: 0.831\n",
      "Epoch: 3948/4000..  Training Loss: 0.007..  Test Loss: 1.134..  Test Accuracy: 0.836\n",
      "Epoch: 3949/4000..  Training Loss: 0.030..  Test Loss: 1.206..  Test Accuracy: 0.830\n",
      "Epoch: 3950/4000..  Training Loss: 0.006..  Test Loss: 1.217..  Test Accuracy: 0.830\n",
      "Epoch: 3951/4000..  Training Loss: 0.010..  Test Loss: 1.184..  Test Accuracy: 0.830\n",
      "Epoch: 3952/4000..  Training Loss: 0.014..  Test Loss: 1.246..  Test Accuracy: 0.824\n",
      "Epoch: 3953/4000..  Training Loss: 0.008..  Test Loss: 1.214..  Test Accuracy: 0.827\n",
      "Epoch: 3954/4000..  Training Loss: 0.002..  Test Loss: 1.218..  Test Accuracy: 0.825\n",
      "Epoch: 3955/4000..  Training Loss: 0.002..  Test Loss: 1.193..  Test Accuracy: 0.827\n",
      "Epoch: 3956/4000..  Training Loss: 0.003..  Test Loss: 1.187..  Test Accuracy: 0.828\n",
      "Epoch: 3957/4000..  Training Loss: 0.022..  Test Loss: 1.171..  Test Accuracy: 0.829\n",
      "Epoch: 3958/4000..  Training Loss: 0.005..  Test Loss: 1.206..  Test Accuracy: 0.829\n",
      "Epoch: 3959/4000..  Training Loss: 0.004..  Test Loss: 1.163..  Test Accuracy: 0.829\n",
      "Epoch: 3960/4000..  Training Loss: 0.004..  Test Loss: 1.176..  Test Accuracy: 0.828\n",
      "Epoch: 3961/4000..  Training Loss: 0.030..  Test Loss: 1.139..  Test Accuracy: 0.834\n",
      "Epoch: 3962/4000..  Training Loss: 0.017..  Test Loss: 1.204..  Test Accuracy: 0.828\n",
      "Epoch: 3963/4000..  Training Loss: 0.038..  Test Loss: 1.216..  Test Accuracy: 0.825\n",
      "Epoch: 3964/4000..  Training Loss: 0.043..  Test Loss: 1.197..  Test Accuracy: 0.828\n",
      "Epoch: 3965/4000..  Training Loss: 0.002..  Test Loss: 1.151..  Test Accuracy: 0.833\n",
      "Epoch: 3966/4000..  Training Loss: 0.002..  Test Loss: 1.141..  Test Accuracy: 0.833\n",
      "Epoch: 3967/4000..  Training Loss: 0.018..  Test Loss: 1.157..  Test Accuracy: 0.832\n",
      "Epoch: 3968/4000..  Training Loss: 0.001..  Test Loss: 1.160..  Test Accuracy: 0.831\n",
      "Epoch: 3969/4000..  Training Loss: 0.003..  Test Loss: 1.149..  Test Accuracy: 0.832\n",
      "Epoch: 3970/4000..  Training Loss: 0.008..  Test Loss: 1.187..  Test Accuracy: 0.829\n",
      "Epoch: 3971/4000..  Training Loss: 0.014..  Test Loss: 1.106..  Test Accuracy: 0.838\n",
      "Epoch: 3972/4000..  Training Loss: 0.006..  Test Loss: 1.139..  Test Accuracy: 0.833\n",
      "Epoch: 3973/4000..  Training Loss: 0.005..  Test Loss: 1.178..  Test Accuracy: 0.829\n",
      "Epoch: 3974/4000..  Training Loss: 0.008..  Test Loss: 1.130..  Test Accuracy: 0.835\n",
      "Epoch: 3975/4000..  Training Loss: 0.007..  Test Loss: 1.226..  Test Accuracy: 0.824\n",
      "Epoch: 3976/4000..  Training Loss: 0.006..  Test Loss: 1.288..  Test Accuracy: 0.820\n",
      "Epoch: 3977/4000..  Training Loss: 0.016..  Test Loss: 1.208..  Test Accuracy: 0.827\n",
      "Epoch: 3978/4000..  Training Loss: 0.008..  Test Loss: 1.188..  Test Accuracy: 0.825\n",
      "Epoch: 3979/4000..  Training Loss: 0.036..  Test Loss: 1.195..  Test Accuracy: 0.828\n",
      "Epoch: 3980/4000..  Training Loss: 0.013..  Test Loss: 1.276..  Test Accuracy: 0.820\n",
      "Epoch: 3981/4000..  Training Loss: 0.002..  Test Loss: 1.207..  Test Accuracy: 0.826\n",
      "Epoch: 3982/4000..  Training Loss: 0.022..  Test Loss: 1.079..  Test Accuracy: 0.840\n",
      "Epoch: 3983/4000..  Training Loss: 0.025..  Test Loss: 1.159..  Test Accuracy: 0.829\n",
      "Epoch: 3984/4000..  Training Loss: 0.005..  Test Loss: 1.177..  Test Accuracy: 0.830\n",
      "Epoch: 3985/4000..  Training Loss: 0.016..  Test Loss: 1.159..  Test Accuracy: 0.831\n",
      "Epoch: 3986/4000..  Training Loss: 0.007..  Test Loss: 1.146..  Test Accuracy: 0.832\n",
      "Epoch: 3987/4000..  Training Loss: 0.004..  Test Loss: 1.154..  Test Accuracy: 0.833\n",
      "Epoch: 3988/4000..  Training Loss: 0.002..  Test Loss: 1.172..  Test Accuracy: 0.830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3989/4000..  Training Loss: 0.004..  Test Loss: 1.156..  Test Accuracy: 0.832\n",
      "Epoch: 3990/4000..  Training Loss: 0.034..  Test Loss: 1.163..  Test Accuracy: 0.832\n",
      "Epoch: 3991/4000..  Training Loss: 0.005..  Test Loss: 1.126..  Test Accuracy: 0.835\n",
      "Epoch: 3992/4000..  Training Loss: 0.002..  Test Loss: 1.144..  Test Accuracy: 0.832\n",
      "Epoch: 3993/4000..  Training Loss: 0.007..  Test Loss: 1.174..  Test Accuracy: 0.831\n",
      "Epoch: 3994/4000..  Training Loss: 0.007..  Test Loss: 1.169..  Test Accuracy: 0.830\n",
      "Epoch: 3995/4000..  Training Loss: 0.003..  Test Loss: 1.130..  Test Accuracy: 0.836\n",
      "Epoch: 3996/4000..  Training Loss: 0.004..  Test Loss: 1.140..  Test Accuracy: 0.834\n",
      "Epoch: 3997/4000..  Training Loss: 0.003..  Test Loss: 1.133..  Test Accuracy: 0.835\n",
      "Epoch: 3998/4000..  Training Loss: 0.028..  Test Loss: 1.217..  Test Accuracy: 0.824\n",
      "Epoch: 3999/4000..  Training Loss: 0.008..  Test Loss: 1.196..  Test Accuracy: 0.827\n",
      "Epoch: 4000/4000..  Training Loss: 0.002..  Test Loss: 1.164..  Test Accuracy: 0.829\n"
     ]
    }
   ],
   "source": [
    "epochs = 4000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    mask_loss = 0\n",
    "\n",
    "    currentdropout = 0.95\n",
    "    \n",
    "    if(epoch>400):\n",
    "      currentdropout=0.75\n",
    "    else:\n",
    "      currentdropout = 0.95 - epoch*(0.15/400)\n",
    "\n",
    "    i=0\n",
    "\n",
    "    for images,labels in train_loader:\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        if(i==0 and epoch%10==0):\n",
    "          sample_images_gcnn.append(train.clone().detach().numpy())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        drop = nn.Dropout(p=currentdropout)\n",
    "        mask = drop(torch.rand(images.shape).double())\n",
    "\n",
    "        images = images + mask\n",
    "        images = torch.minimum(images, torch.ones(images.shape))\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "\n",
    "        if(i==0 and epoch%10==0):\n",
    "          sample_masked_gcnn.append(train.clone().detach().numpy())\n",
    "\n",
    "        output = gcnn(train)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        i+=1\n",
    "\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad(): #Turning off gradients to speed up\n",
    "            gcnn.eval()\n",
    "            for images,labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(-1,1,28,28))\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "                log_ps = gcnn(test)\n",
    "                test_loss += criterion(log_ps,labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim = 1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "        gcnn.train()        \n",
    "        train_losses_gcnn.append(running_loss/len(train_loader))\n",
    "        test_losses_gcnn.append(test_loss/len(test_loader))\n",
    "        accuracy_graph_gcnn.append(accuracy/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "qickz47TlpZN",
    "outputId": "2fff21d0-251e-422c-c924-73963ec5d5ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x202c13e0fa0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses_gcnn, label='Training loss')\n",
    "plt.plot(test_losses_gcnn, label='Validation loss')\n",
    "plt.plot(accuracy_graph_gcnn, label='Accuracy')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcnn2=CNN()\n",
    "gcnn2=gcnn2.double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gcnn2.parameters(), lr=0.0001)\n",
    "\n",
    "train_losses_gcnn2, test_losses_gcnn2, accuracy_graph_gcnn2 = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000..  Training Loss: 0.275..  Test Loss: 0.694..  Test Accuracy: 0.853\n",
      "Epoch: 2/1000..  Training Loss: 0.111..  Test Loss: 0.725..  Test Accuracy: 0.847\n",
      "Epoch: 3/1000..  Training Loss: 0.256..  Test Loss: 0.727..  Test Accuracy: 0.848\n",
      "Epoch: 4/1000..  Training Loss: 0.176..  Test Loss: 0.729..  Test Accuracy: 0.847\n",
      "Epoch: 5/1000..  Training Loss: 0.198..  Test Loss: 0.712..  Test Accuracy: 0.847\n",
      "Epoch: 6/1000..  Training Loss: 0.192..  Test Loss: 0.719..  Test Accuracy: 0.845\n",
      "Epoch: 7/1000..  Training Loss: 0.182..  Test Loss: 0.715..  Test Accuracy: 0.847\n",
      "Epoch: 8/1000..  Training Loss: 0.250..  Test Loss: 0.721..  Test Accuracy: 0.850\n",
      "Epoch: 9/1000..  Training Loss: 0.260..  Test Loss: 0.702..  Test Accuracy: 0.850\n",
      "Epoch: 10/1000..  Training Loss: 0.278..  Test Loss: 0.729..  Test Accuracy: 0.849\n",
      "Epoch: 11/1000..  Training Loss: 0.164..  Test Loss: 0.699..  Test Accuracy: 0.852\n",
      "Epoch: 12/1000..  Training Loss: 0.217..  Test Loss: 0.718..  Test Accuracy: 0.849\n",
      "Epoch: 13/1000..  Training Loss: 0.150..  Test Loss: 0.704..  Test Accuracy: 0.849\n",
      "Epoch: 14/1000..  Training Loss: 0.241..  Test Loss: 0.711..  Test Accuracy: 0.851\n",
      "Epoch: 15/1000..  Training Loss: 0.189..  Test Loss: 0.717..  Test Accuracy: 0.848\n",
      "Epoch: 16/1000..  Training Loss: 0.204..  Test Loss: 0.730..  Test Accuracy: 0.844\n",
      "Epoch: 17/1000..  Training Loss: 0.239..  Test Loss: 0.721..  Test Accuracy: 0.848\n",
      "Epoch: 18/1000..  Training Loss: 0.205..  Test Loss: 0.740..  Test Accuracy: 0.846\n",
      "Epoch: 19/1000..  Training Loss: 0.243..  Test Loss: 0.740..  Test Accuracy: 0.841\n",
      "Epoch: 20/1000..  Training Loss: 0.195..  Test Loss: 0.704..  Test Accuracy: 0.853\n",
      "Epoch: 21/1000..  Training Loss: 0.250..  Test Loss: 0.707..  Test Accuracy: 0.850\n",
      "Epoch: 22/1000..  Training Loss: 0.208..  Test Loss: 0.721..  Test Accuracy: 0.847\n",
      "Epoch: 23/1000..  Training Loss: 0.178..  Test Loss: 0.732..  Test Accuracy: 0.846\n",
      "Epoch: 24/1000..  Training Loss: 0.170..  Test Loss: 0.710..  Test Accuracy: 0.849\n",
      "Epoch: 25/1000..  Training Loss: 0.239..  Test Loss: 0.732..  Test Accuracy: 0.847\n",
      "Epoch: 26/1000..  Training Loss: 0.206..  Test Loss: 0.724..  Test Accuracy: 0.851\n",
      "Epoch: 27/1000..  Training Loss: 0.210..  Test Loss: 0.713..  Test Accuracy: 0.850\n",
      "Epoch: 28/1000..  Training Loss: 0.216..  Test Loss: 0.723..  Test Accuracy: 0.847\n",
      "Epoch: 29/1000..  Training Loss: 0.185..  Test Loss: 0.720..  Test Accuracy: 0.847\n",
      "Epoch: 30/1000..  Training Loss: 0.224..  Test Loss: 0.736..  Test Accuracy: 0.846\n",
      "Epoch: 31/1000..  Training Loss: 0.248..  Test Loss: 0.728..  Test Accuracy: 0.847\n",
      "Epoch: 32/1000..  Training Loss: 0.165..  Test Loss: 0.723..  Test Accuracy: 0.847\n",
      "Epoch: 33/1000..  Training Loss: 0.203..  Test Loss: 0.704..  Test Accuracy: 0.852\n",
      "Epoch: 34/1000..  Training Loss: 0.208..  Test Loss: 0.704..  Test Accuracy: 0.852\n",
      "Epoch: 35/1000..  Training Loss: 0.190..  Test Loss: 0.714..  Test Accuracy: 0.850\n",
      "Epoch: 36/1000..  Training Loss: 0.289..  Test Loss: 0.720..  Test Accuracy: 0.850\n",
      "Epoch: 37/1000..  Training Loss: 0.191..  Test Loss: 0.709..  Test Accuracy: 0.850\n",
      "Epoch: 38/1000..  Training Loss: 0.171..  Test Loss: 0.721..  Test Accuracy: 0.847\n",
      "Epoch: 39/1000..  Training Loss: 0.083..  Test Loss: 0.718..  Test Accuracy: 0.848\n",
      "Epoch: 40/1000..  Training Loss: 0.253..  Test Loss: 0.711..  Test Accuracy: 0.848\n",
      "Epoch: 41/1000..  Training Loss: 0.210..  Test Loss: 0.697..  Test Accuracy: 0.851\n",
      "Epoch: 42/1000..  Training Loss: 0.236..  Test Loss: 0.727..  Test Accuracy: 0.846\n",
      "Epoch: 43/1000..  Training Loss: 0.329..  Test Loss: 0.706..  Test Accuracy: 0.850\n",
      "Epoch: 44/1000..  Training Loss: 0.156..  Test Loss: 0.723..  Test Accuracy: 0.847\n",
      "Epoch: 45/1000..  Training Loss: 0.207..  Test Loss: 0.742..  Test Accuracy: 0.844\n",
      "Epoch: 46/1000..  Training Loss: 0.207..  Test Loss: 0.712..  Test Accuracy: 0.848\n",
      "Epoch: 47/1000..  Training Loss: 0.095..  Test Loss: 0.724..  Test Accuracy: 0.847\n",
      "Epoch: 48/1000..  Training Loss: 0.159..  Test Loss: 0.721..  Test Accuracy: 0.848\n",
      "Epoch: 49/1000..  Training Loss: 0.280..  Test Loss: 0.736..  Test Accuracy: 0.846\n",
      "Epoch: 50/1000..  Training Loss: 0.163..  Test Loss: 0.734..  Test Accuracy: 0.844\n",
      "Epoch: 51/1000..  Training Loss: 0.227..  Test Loss: 0.740..  Test Accuracy: 0.845\n",
      "Epoch: 52/1000..  Training Loss: 0.152..  Test Loss: 0.744..  Test Accuracy: 0.845\n",
      "Epoch: 53/1000..  Training Loss: 0.226..  Test Loss: 0.739..  Test Accuracy: 0.845\n",
      "Epoch: 54/1000..  Training Loss: 0.199..  Test Loss: 0.705..  Test Accuracy: 0.852\n",
      "Epoch: 55/1000..  Training Loss: 0.203..  Test Loss: 0.712..  Test Accuracy: 0.849\n",
      "Epoch: 56/1000..  Training Loss: 0.283..  Test Loss: 0.706..  Test Accuracy: 0.848\n",
      "Epoch: 57/1000..  Training Loss: 0.177..  Test Loss: 0.713..  Test Accuracy: 0.848\n",
      "Epoch: 58/1000..  Training Loss: 0.211..  Test Loss: 0.730..  Test Accuracy: 0.845\n",
      "Epoch: 59/1000..  Training Loss: 0.187..  Test Loss: 0.718..  Test Accuracy: 0.849\n",
      "Epoch: 60/1000..  Training Loss: 0.186..  Test Loss: 0.692..  Test Accuracy: 0.853\n",
      "Epoch: 61/1000..  Training Loss: 0.196..  Test Loss: 0.712..  Test Accuracy: 0.850\n",
      "Epoch: 62/1000..  Training Loss: 0.239..  Test Loss: 0.713..  Test Accuracy: 0.849\n",
      "Epoch: 63/1000..  Training Loss: 0.239..  Test Loss: 0.705..  Test Accuracy: 0.851\n",
      "Epoch: 64/1000..  Training Loss: 0.188..  Test Loss: 0.728..  Test Accuracy: 0.846\n",
      "Epoch: 65/1000..  Training Loss: 0.197..  Test Loss: 0.720..  Test Accuracy: 0.848\n",
      "Epoch: 66/1000..  Training Loss: 0.212..  Test Loss: 0.724..  Test Accuracy: 0.847\n",
      "Epoch: 67/1000..  Training Loss: 0.148..  Test Loss: 0.699..  Test Accuracy: 0.851\n",
      "Epoch: 68/1000..  Training Loss: 0.240..  Test Loss: 0.701..  Test Accuracy: 0.853\n",
      "Epoch: 69/1000..  Training Loss: 0.197..  Test Loss: 0.733..  Test Accuracy: 0.844\n",
      "Epoch: 70/1000..  Training Loss: 0.241..  Test Loss: 0.740..  Test Accuracy: 0.846\n",
      "Epoch: 71/1000..  Training Loss: 0.209..  Test Loss: 0.705..  Test Accuracy: 0.851\n",
      "Epoch: 72/1000..  Training Loss: 0.131..  Test Loss: 0.716..  Test Accuracy: 0.850\n",
      "Epoch: 73/1000..  Training Loss: 0.117..  Test Loss: 0.740..  Test Accuracy: 0.844\n",
      "Epoch: 74/1000..  Training Loss: 0.159..  Test Loss: 0.708..  Test Accuracy: 0.852\n",
      "Epoch: 75/1000..  Training Loss: 0.160..  Test Loss: 0.708..  Test Accuracy: 0.852\n",
      "Epoch: 76/1000..  Training Loss: 0.192..  Test Loss: 0.724..  Test Accuracy: 0.845\n",
      "Epoch: 77/1000..  Training Loss: 0.195..  Test Loss: 0.705..  Test Accuracy: 0.851\n",
      "Epoch: 78/1000..  Training Loss: 0.233..  Test Loss: 0.702..  Test Accuracy: 0.854\n",
      "Epoch: 79/1000..  Training Loss: 0.221..  Test Loss: 0.706..  Test Accuracy: 0.850\n",
      "Epoch: 80/1000..  Training Loss: 0.182..  Test Loss: 0.704..  Test Accuracy: 0.852\n",
      "Epoch: 81/1000..  Training Loss: 0.160..  Test Loss: 0.726..  Test Accuracy: 0.847\n",
      "Epoch: 82/1000..  Training Loss: 0.231..  Test Loss: 0.726..  Test Accuracy: 0.849\n",
      "Epoch: 83/1000..  Training Loss: 0.172..  Test Loss: 0.716..  Test Accuracy: 0.849\n",
      "Epoch: 84/1000..  Training Loss: 0.139..  Test Loss: 0.704..  Test Accuracy: 0.851\n",
      "Epoch: 85/1000..  Training Loss: 0.163..  Test Loss: 0.719..  Test Accuracy: 0.846\n",
      "Epoch: 86/1000..  Training Loss: 0.214..  Test Loss: 0.710..  Test Accuracy: 0.849\n",
      "Epoch: 87/1000..  Training Loss: 0.251..  Test Loss: 0.742..  Test Accuracy: 0.847\n",
      "Epoch: 88/1000..  Training Loss: 0.232..  Test Loss: 0.727..  Test Accuracy: 0.848\n",
      "Epoch: 89/1000..  Training Loss: 0.269..  Test Loss: 0.705..  Test Accuracy: 0.852\n",
      "Epoch: 90/1000..  Training Loss: 0.182..  Test Loss: 0.736..  Test Accuracy: 0.847\n",
      "Epoch: 91/1000..  Training Loss: 0.252..  Test Loss: 0.729..  Test Accuracy: 0.847\n",
      "Epoch: 92/1000..  Training Loss: 0.209..  Test Loss: 0.721..  Test Accuracy: 0.848\n",
      "Epoch: 93/1000..  Training Loss: 0.186..  Test Loss: 0.726..  Test Accuracy: 0.848\n",
      "Epoch: 94/1000..  Training Loss: 0.204..  Test Loss: 0.713..  Test Accuracy: 0.848\n",
      "Epoch: 95/1000..  Training Loss: 0.191..  Test Loss: 0.732..  Test Accuracy: 0.847\n",
      "Epoch: 96/1000..  Training Loss: 0.233..  Test Loss: 0.736..  Test Accuracy: 0.848\n",
      "Epoch: 97/1000..  Training Loss: 0.223..  Test Loss: 0.733..  Test Accuracy: 0.848\n",
      "Epoch: 98/1000..  Training Loss: 0.208..  Test Loss: 0.733..  Test Accuracy: 0.848\n",
      "Epoch: 99/1000..  Training Loss: 0.140..  Test Loss: 0.737..  Test Accuracy: 0.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/1000..  Training Loss: 0.202..  Test Loss: 0.722..  Test Accuracy: 0.850\n",
      "Epoch: 101/1000..  Training Loss: 0.117..  Test Loss: 0.767..  Test Accuracy: 0.842\n",
      "Epoch: 102/1000..  Training Loss: 0.161..  Test Loss: 0.726..  Test Accuracy: 0.849\n",
      "Epoch: 103/1000..  Training Loss: 0.259..  Test Loss: 0.734..  Test Accuracy: 0.844\n",
      "Epoch: 104/1000..  Training Loss: 0.184..  Test Loss: 0.740..  Test Accuracy: 0.845\n",
      "Epoch: 105/1000..  Training Loss: 0.164..  Test Loss: 0.733..  Test Accuracy: 0.844\n",
      "Epoch: 106/1000..  Training Loss: 0.206..  Test Loss: 0.751..  Test Accuracy: 0.843\n",
      "Epoch: 107/1000..  Training Loss: 0.203..  Test Loss: 0.739..  Test Accuracy: 0.846\n",
      "Epoch: 108/1000..  Training Loss: 0.164..  Test Loss: 0.725..  Test Accuracy: 0.847\n",
      "Epoch: 109/1000..  Training Loss: 0.212..  Test Loss: 0.728..  Test Accuracy: 0.847\n",
      "Epoch: 110/1000..  Training Loss: 0.240..  Test Loss: 0.728..  Test Accuracy: 0.849\n",
      "Epoch: 111/1000..  Training Loss: 0.149..  Test Loss: 0.721..  Test Accuracy: 0.848\n",
      "Epoch: 112/1000..  Training Loss: 0.231..  Test Loss: 0.725..  Test Accuracy: 0.849\n",
      "Epoch: 113/1000..  Training Loss: 0.202..  Test Loss: 0.707..  Test Accuracy: 0.852\n",
      "Epoch: 114/1000..  Training Loss: 0.177..  Test Loss: 0.723..  Test Accuracy: 0.849\n",
      "Epoch: 115/1000..  Training Loss: 0.238..  Test Loss: 0.727..  Test Accuracy: 0.848\n",
      "Epoch: 116/1000..  Training Loss: 0.202..  Test Loss: 0.747..  Test Accuracy: 0.844\n",
      "Epoch: 117/1000..  Training Loss: 0.193..  Test Loss: 0.711..  Test Accuracy: 0.850\n",
      "Epoch: 118/1000..  Training Loss: 0.155..  Test Loss: 0.749..  Test Accuracy: 0.845\n",
      "Epoch: 119/1000..  Training Loss: 0.224..  Test Loss: 0.723..  Test Accuracy: 0.850\n",
      "Epoch: 120/1000..  Training Loss: 0.213..  Test Loss: 0.716..  Test Accuracy: 0.849\n",
      "Epoch: 121/1000..  Training Loss: 0.132..  Test Loss: 0.720..  Test Accuracy: 0.849\n",
      "Epoch: 122/1000..  Training Loss: 0.193..  Test Loss: 0.735..  Test Accuracy: 0.845\n",
      "Epoch: 123/1000..  Training Loss: 0.215..  Test Loss: 0.747..  Test Accuracy: 0.847\n",
      "Epoch: 124/1000..  Training Loss: 0.241..  Test Loss: 0.737..  Test Accuracy: 0.846\n",
      "Epoch: 125/1000..  Training Loss: 0.271..  Test Loss: 0.752..  Test Accuracy: 0.843\n",
      "Epoch: 126/1000..  Training Loss: 0.245..  Test Loss: 0.719..  Test Accuracy: 0.849\n",
      "Epoch: 127/1000..  Training Loss: 0.243..  Test Loss: 0.735..  Test Accuracy: 0.848\n",
      "Epoch: 128/1000..  Training Loss: 0.163..  Test Loss: 0.734..  Test Accuracy: 0.850\n",
      "Epoch: 129/1000..  Training Loss: 0.229..  Test Loss: 0.707..  Test Accuracy: 0.851\n",
      "Epoch: 130/1000..  Training Loss: 0.178..  Test Loss: 0.724..  Test Accuracy: 0.849\n",
      "Epoch: 131/1000..  Training Loss: 0.206..  Test Loss: 0.723..  Test Accuracy: 0.850\n",
      "Epoch: 132/1000..  Training Loss: 0.255..  Test Loss: 0.721..  Test Accuracy: 0.849\n",
      "Epoch: 133/1000..  Training Loss: 0.248..  Test Loss: 0.714..  Test Accuracy: 0.848\n",
      "Epoch: 134/1000..  Training Loss: 0.334..  Test Loss: 0.724..  Test Accuracy: 0.848\n",
      "Epoch: 135/1000..  Training Loss: 0.183..  Test Loss: 0.723..  Test Accuracy: 0.849\n",
      "Epoch: 136/1000..  Training Loss: 0.190..  Test Loss: 0.727..  Test Accuracy: 0.848\n",
      "Epoch: 137/1000..  Training Loss: 0.126..  Test Loss: 0.724..  Test Accuracy: 0.850\n",
      "Epoch: 138/1000..  Training Loss: 0.180..  Test Loss: 0.720..  Test Accuracy: 0.848\n",
      "Epoch: 139/1000..  Training Loss: 0.248..  Test Loss: 0.735..  Test Accuracy: 0.845\n",
      "Epoch: 140/1000..  Training Loss: 0.192..  Test Loss: 0.740..  Test Accuracy: 0.845\n",
      "Epoch: 141/1000..  Training Loss: 0.194..  Test Loss: 0.742..  Test Accuracy: 0.847\n",
      "Epoch: 142/1000..  Training Loss: 0.151..  Test Loss: 0.742..  Test Accuracy: 0.847\n",
      "Epoch: 143/1000..  Training Loss: 0.181..  Test Loss: 0.747..  Test Accuracy: 0.843\n",
      "Epoch: 144/1000..  Training Loss: 0.113..  Test Loss: 0.733..  Test Accuracy: 0.846\n",
      "Epoch: 145/1000..  Training Loss: 0.162..  Test Loss: 0.721..  Test Accuracy: 0.848\n",
      "Epoch: 146/1000..  Training Loss: 0.189..  Test Loss: 0.717..  Test Accuracy: 0.848\n",
      "Epoch: 147/1000..  Training Loss: 0.125..  Test Loss: 0.724..  Test Accuracy: 0.849\n",
      "Epoch: 148/1000..  Training Loss: 0.178..  Test Loss: 0.718..  Test Accuracy: 0.849\n",
      "Epoch: 149/1000..  Training Loss: 0.099..  Test Loss: 0.729..  Test Accuracy: 0.847\n",
      "Epoch: 150/1000..  Training Loss: 0.232..  Test Loss: 0.730..  Test Accuracy: 0.849\n",
      "Epoch: 151/1000..  Training Loss: 0.172..  Test Loss: 0.739..  Test Accuracy: 0.846\n",
      "Epoch: 152/1000..  Training Loss: 0.218..  Test Loss: 0.754..  Test Accuracy: 0.846\n",
      "Epoch: 153/1000..  Training Loss: 0.187..  Test Loss: 0.739..  Test Accuracy: 0.847\n",
      "Epoch: 154/1000..  Training Loss: 0.197..  Test Loss: 0.744..  Test Accuracy: 0.846\n",
      "Epoch: 155/1000..  Training Loss: 0.271..  Test Loss: 0.746..  Test Accuracy: 0.848\n",
      "Epoch: 156/1000..  Training Loss: 0.135..  Test Loss: 0.733..  Test Accuracy: 0.847\n",
      "Epoch: 157/1000..  Training Loss: 0.138..  Test Loss: 0.737..  Test Accuracy: 0.847\n",
      "Epoch: 158/1000..  Training Loss: 0.217..  Test Loss: 0.731..  Test Accuracy: 0.847\n",
      "Epoch: 159/1000..  Training Loss: 0.202..  Test Loss: 0.720..  Test Accuracy: 0.849\n",
      "Epoch: 160/1000..  Training Loss: 0.245..  Test Loss: 0.762..  Test Accuracy: 0.843\n",
      "Epoch: 161/1000..  Training Loss: 0.150..  Test Loss: 0.746..  Test Accuracy: 0.846\n",
      "Epoch: 162/1000..  Training Loss: 0.179..  Test Loss: 0.745..  Test Accuracy: 0.846\n",
      "Epoch: 163/1000..  Training Loss: 0.204..  Test Loss: 0.718..  Test Accuracy: 0.849\n",
      "Epoch: 164/1000..  Training Loss: 0.199..  Test Loss: 0.722..  Test Accuracy: 0.850\n",
      "Epoch: 165/1000..  Training Loss: 0.231..  Test Loss: 0.715..  Test Accuracy: 0.850\n",
      "Epoch: 166/1000..  Training Loss: 0.172..  Test Loss: 0.719..  Test Accuracy: 0.851\n",
      "Epoch: 167/1000..  Training Loss: 0.312..  Test Loss: 0.708..  Test Accuracy: 0.850\n",
      "Epoch: 168/1000..  Training Loss: 0.165..  Test Loss: 0.733..  Test Accuracy: 0.850\n",
      "Epoch: 169/1000..  Training Loss: 0.185..  Test Loss: 0.706..  Test Accuracy: 0.854\n",
      "Epoch: 170/1000..  Training Loss: 0.148..  Test Loss: 0.689..  Test Accuracy: 0.854\n",
      "Epoch: 171/1000..  Training Loss: 0.181..  Test Loss: 0.704..  Test Accuracy: 0.853\n",
      "Epoch: 172/1000..  Training Loss: 0.192..  Test Loss: 0.705..  Test Accuracy: 0.850\n",
      "Epoch: 173/1000..  Training Loss: 0.208..  Test Loss: 0.709..  Test Accuracy: 0.852\n",
      "Epoch: 174/1000..  Training Loss: 0.184..  Test Loss: 0.717..  Test Accuracy: 0.850\n",
      "Epoch: 175/1000..  Training Loss: 0.214..  Test Loss: 0.740..  Test Accuracy: 0.844\n",
      "Epoch: 176/1000..  Training Loss: 0.166..  Test Loss: 0.720..  Test Accuracy: 0.850\n",
      "Epoch: 177/1000..  Training Loss: 0.215..  Test Loss: 0.701..  Test Accuracy: 0.852\n",
      "Epoch: 178/1000..  Training Loss: 0.262..  Test Loss: 0.706..  Test Accuracy: 0.850\n",
      "Epoch: 179/1000..  Training Loss: 0.175..  Test Loss: 0.708..  Test Accuracy: 0.852\n",
      "Epoch: 180/1000..  Training Loss: 0.180..  Test Loss: 0.707..  Test Accuracy: 0.852\n",
      "Epoch: 181/1000..  Training Loss: 0.206..  Test Loss: 0.724..  Test Accuracy: 0.848\n",
      "Epoch: 182/1000..  Training Loss: 0.142..  Test Loss: 0.699..  Test Accuracy: 0.852\n",
      "Epoch: 183/1000..  Training Loss: 0.145..  Test Loss: 0.710..  Test Accuracy: 0.851\n",
      "Epoch: 184/1000..  Training Loss: 0.254..  Test Loss: 0.708..  Test Accuracy: 0.851\n",
      "Epoch: 185/1000..  Training Loss: 0.144..  Test Loss: 0.696..  Test Accuracy: 0.853\n",
      "Epoch: 186/1000..  Training Loss: 0.205..  Test Loss: 0.710..  Test Accuracy: 0.850\n",
      "Epoch: 187/1000..  Training Loss: 0.215..  Test Loss: 0.699..  Test Accuracy: 0.852\n",
      "Epoch: 188/1000..  Training Loss: 0.186..  Test Loss: 0.717..  Test Accuracy: 0.849\n",
      "Epoch: 189/1000..  Training Loss: 0.186..  Test Loss: 0.724..  Test Accuracy: 0.850\n",
      "Epoch: 190/1000..  Training Loss: 0.132..  Test Loss: 0.722..  Test Accuracy: 0.849\n",
      "Epoch: 191/1000..  Training Loss: 0.133..  Test Loss: 0.703..  Test Accuracy: 0.851\n",
      "Epoch: 192/1000..  Training Loss: 0.157..  Test Loss: 0.718..  Test Accuracy: 0.851\n",
      "Epoch: 193/1000..  Training Loss: 0.224..  Test Loss: 0.708..  Test Accuracy: 0.852\n",
      "Epoch: 194/1000..  Training Loss: 0.155..  Test Loss: 0.691..  Test Accuracy: 0.855\n",
      "Epoch: 195/1000..  Training Loss: 0.177..  Test Loss: 0.744..  Test Accuracy: 0.848\n",
      "Epoch: 196/1000..  Training Loss: 0.206..  Test Loss: 0.738..  Test Accuracy: 0.845\n",
      "Epoch: 197/1000..  Training Loss: 0.259..  Test Loss: 0.709..  Test Accuracy: 0.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 198/1000..  Training Loss: 0.203..  Test Loss: 0.729..  Test Accuracy: 0.845\n",
      "Epoch: 199/1000..  Training Loss: 0.157..  Test Loss: 0.727..  Test Accuracy: 0.848\n",
      "Epoch: 200/1000..  Training Loss: 0.163..  Test Loss: 0.719..  Test Accuracy: 0.849\n",
      "Epoch: 201/1000..  Training Loss: 0.147..  Test Loss: 0.712..  Test Accuracy: 0.851\n",
      "Epoch: 202/1000..  Training Loss: 0.191..  Test Loss: 0.726..  Test Accuracy: 0.848\n",
      "Epoch: 203/1000..  Training Loss: 0.150..  Test Loss: 0.710..  Test Accuracy: 0.851\n",
      "Epoch: 204/1000..  Training Loss: 0.141..  Test Loss: 0.715..  Test Accuracy: 0.850\n",
      "Epoch: 205/1000..  Training Loss: 0.172..  Test Loss: 0.723..  Test Accuracy: 0.848\n",
      "Epoch: 206/1000..  Training Loss: 0.296..  Test Loss: 0.728..  Test Accuracy: 0.849\n",
      "Epoch: 207/1000..  Training Loss: 0.179..  Test Loss: 0.714..  Test Accuracy: 0.850\n",
      "Epoch: 208/1000..  Training Loss: 0.211..  Test Loss: 0.707..  Test Accuracy: 0.851\n",
      "Epoch: 209/1000..  Training Loss: 0.157..  Test Loss: 0.722..  Test Accuracy: 0.849\n",
      "Epoch: 210/1000..  Training Loss: 0.198..  Test Loss: 0.741..  Test Accuracy: 0.846\n",
      "Epoch: 211/1000..  Training Loss: 0.172..  Test Loss: 0.741..  Test Accuracy: 0.845\n",
      "Epoch: 212/1000..  Training Loss: 0.210..  Test Loss: 0.733..  Test Accuracy: 0.849\n",
      "Epoch: 213/1000..  Training Loss: 0.185..  Test Loss: 0.712..  Test Accuracy: 0.852\n",
      "Epoch: 214/1000..  Training Loss: 0.213..  Test Loss: 0.712..  Test Accuracy: 0.851\n",
      "Epoch: 215/1000..  Training Loss: 0.244..  Test Loss: 0.713..  Test Accuracy: 0.850\n",
      "Epoch: 216/1000..  Training Loss: 0.188..  Test Loss: 0.712..  Test Accuracy: 0.850\n",
      "Epoch: 217/1000..  Training Loss: 0.226..  Test Loss: 0.704..  Test Accuracy: 0.852\n",
      "Epoch: 218/1000..  Training Loss: 0.261..  Test Loss: 0.716..  Test Accuracy: 0.849\n",
      "Epoch: 219/1000..  Training Loss: 0.161..  Test Loss: 0.714..  Test Accuracy: 0.851\n",
      "Epoch: 220/1000..  Training Loss: 0.189..  Test Loss: 0.743..  Test Accuracy: 0.846\n",
      "Epoch: 221/1000..  Training Loss: 0.211..  Test Loss: 0.711..  Test Accuracy: 0.850\n",
      "Epoch: 222/1000..  Training Loss: 0.245..  Test Loss: 0.728..  Test Accuracy: 0.845\n",
      "Epoch: 223/1000..  Training Loss: 0.120..  Test Loss: 0.717..  Test Accuracy: 0.850\n",
      "Epoch: 224/1000..  Training Loss: 0.143..  Test Loss: 0.721..  Test Accuracy: 0.850\n",
      "Epoch: 225/1000..  Training Loss: 0.281..  Test Loss: 0.730..  Test Accuracy: 0.850\n",
      "Epoch: 226/1000..  Training Loss: 0.166..  Test Loss: 0.726..  Test Accuracy: 0.848\n",
      "Epoch: 227/1000..  Training Loss: 0.167..  Test Loss: 0.715..  Test Accuracy: 0.850\n",
      "Epoch: 228/1000..  Training Loss: 0.159..  Test Loss: 0.738..  Test Accuracy: 0.845\n",
      "Epoch: 229/1000..  Training Loss: 0.154..  Test Loss: 0.739..  Test Accuracy: 0.846\n",
      "Epoch: 230/1000..  Training Loss: 0.184..  Test Loss: 0.695..  Test Accuracy: 0.854\n",
      "Epoch: 231/1000..  Training Loss: 0.242..  Test Loss: 0.701..  Test Accuracy: 0.854\n",
      "Epoch: 232/1000..  Training Loss: 0.159..  Test Loss: 0.719..  Test Accuracy: 0.850\n",
      "Epoch: 233/1000..  Training Loss: 0.208..  Test Loss: 0.714..  Test Accuracy: 0.850\n",
      "Epoch: 234/1000..  Training Loss: 0.171..  Test Loss: 0.727..  Test Accuracy: 0.848\n",
      "Epoch: 235/1000..  Training Loss: 0.208..  Test Loss: 0.727..  Test Accuracy: 0.850\n",
      "Epoch: 236/1000..  Training Loss: 0.140..  Test Loss: 0.722..  Test Accuracy: 0.849\n",
      "Epoch: 237/1000..  Training Loss: 0.271..  Test Loss: 0.744..  Test Accuracy: 0.845\n",
      "Epoch: 238/1000..  Training Loss: 0.165..  Test Loss: 0.739..  Test Accuracy: 0.848\n",
      "Epoch: 239/1000..  Training Loss: 0.222..  Test Loss: 0.719..  Test Accuracy: 0.850\n",
      "Epoch: 240/1000..  Training Loss: 0.227..  Test Loss: 0.716..  Test Accuracy: 0.853\n",
      "Epoch: 241/1000..  Training Loss: 0.206..  Test Loss: 0.693..  Test Accuracy: 0.853\n",
      "Epoch: 242/1000..  Training Loss: 0.139..  Test Loss: 0.713..  Test Accuracy: 0.850\n",
      "Epoch: 243/1000..  Training Loss: 0.193..  Test Loss: 0.732..  Test Accuracy: 0.848\n",
      "Epoch: 244/1000..  Training Loss: 0.192..  Test Loss: 0.742..  Test Accuracy: 0.848\n",
      "Epoch: 245/1000..  Training Loss: 0.238..  Test Loss: 0.728..  Test Accuracy: 0.850\n",
      "Epoch: 246/1000..  Training Loss: 0.242..  Test Loss: 0.708..  Test Accuracy: 0.854\n",
      "Epoch: 247/1000..  Training Loss: 0.268..  Test Loss: 0.693..  Test Accuracy: 0.855\n",
      "Epoch: 248/1000..  Training Loss: 0.223..  Test Loss: 0.718..  Test Accuracy: 0.855\n",
      "Epoch: 249/1000..  Training Loss: 0.173..  Test Loss: 0.699..  Test Accuracy: 0.855\n",
      "Epoch: 250/1000..  Training Loss: 0.165..  Test Loss: 0.715..  Test Accuracy: 0.853\n",
      "Epoch: 251/1000..  Training Loss: 0.223..  Test Loss: 0.717..  Test Accuracy: 0.850\n",
      "Epoch: 252/1000..  Training Loss: 0.163..  Test Loss: 0.694..  Test Accuracy: 0.853\n",
      "Epoch: 253/1000..  Training Loss: 0.198..  Test Loss: 0.726..  Test Accuracy: 0.849\n",
      "Epoch: 254/1000..  Training Loss: 0.230..  Test Loss: 0.738..  Test Accuracy: 0.849\n",
      "Epoch: 255/1000..  Training Loss: 0.189..  Test Loss: 0.716..  Test Accuracy: 0.853\n",
      "Epoch: 256/1000..  Training Loss: 0.130..  Test Loss: 0.723..  Test Accuracy: 0.849\n",
      "Epoch: 257/1000..  Training Loss: 0.214..  Test Loss: 0.725..  Test Accuracy: 0.849\n",
      "Epoch: 258/1000..  Training Loss: 0.145..  Test Loss: 0.731..  Test Accuracy: 0.849\n",
      "Epoch: 259/1000..  Training Loss: 0.196..  Test Loss: 0.715..  Test Accuracy: 0.852\n",
      "Epoch: 260/1000..  Training Loss: 0.174..  Test Loss: 0.710..  Test Accuracy: 0.851\n",
      "Epoch: 261/1000..  Training Loss: 0.203..  Test Loss: 0.746..  Test Accuracy: 0.848\n",
      "Epoch: 262/1000..  Training Loss: 0.192..  Test Loss: 0.718..  Test Accuracy: 0.849\n",
      "Epoch: 263/1000..  Training Loss: 0.123..  Test Loss: 0.732..  Test Accuracy: 0.850\n",
      "Epoch: 264/1000..  Training Loss: 0.180..  Test Loss: 0.720..  Test Accuracy: 0.849\n",
      "Epoch: 265/1000..  Training Loss: 0.208..  Test Loss: 0.704..  Test Accuracy: 0.852\n",
      "Epoch: 266/1000..  Training Loss: 0.249..  Test Loss: 0.725..  Test Accuracy: 0.847\n",
      "Epoch: 267/1000..  Training Loss: 0.229..  Test Loss: 0.710..  Test Accuracy: 0.853\n",
      "Epoch: 268/1000..  Training Loss: 0.152..  Test Loss: 0.714..  Test Accuracy: 0.853\n",
      "Epoch: 269/1000..  Training Loss: 0.172..  Test Loss: 0.712..  Test Accuracy: 0.852\n",
      "Epoch: 270/1000..  Training Loss: 0.233..  Test Loss: 0.714..  Test Accuracy: 0.853\n",
      "Epoch: 271/1000..  Training Loss: 0.238..  Test Loss: 0.757..  Test Accuracy: 0.844\n",
      "Epoch: 272/1000..  Training Loss: 0.274..  Test Loss: 0.722..  Test Accuracy: 0.851\n",
      "Epoch: 273/1000..  Training Loss: 0.212..  Test Loss: 0.719..  Test Accuracy: 0.852\n",
      "Epoch: 274/1000..  Training Loss: 0.158..  Test Loss: 0.710..  Test Accuracy: 0.852\n",
      "Epoch: 275/1000..  Training Loss: 0.242..  Test Loss: 0.693..  Test Accuracy: 0.855\n",
      "Epoch: 276/1000..  Training Loss: 0.119..  Test Loss: 0.699..  Test Accuracy: 0.854\n",
      "Epoch: 277/1000..  Training Loss: 0.135..  Test Loss: 0.722..  Test Accuracy: 0.852\n",
      "Epoch: 278/1000..  Training Loss: 0.164..  Test Loss: 0.716..  Test Accuracy: 0.850\n",
      "Epoch: 279/1000..  Training Loss: 0.227..  Test Loss: 0.721..  Test Accuracy: 0.851\n",
      "Epoch: 280/1000..  Training Loss: 0.234..  Test Loss: 0.728..  Test Accuracy: 0.851\n",
      "Epoch: 281/1000..  Training Loss: 0.198..  Test Loss: 0.723..  Test Accuracy: 0.851\n",
      "Epoch: 282/1000..  Training Loss: 0.154..  Test Loss: 0.727..  Test Accuracy: 0.851\n",
      "Epoch: 283/1000..  Training Loss: 0.254..  Test Loss: 0.716..  Test Accuracy: 0.852\n",
      "Epoch: 284/1000..  Training Loss: 0.188..  Test Loss: 0.719..  Test Accuracy: 0.851\n",
      "Epoch: 285/1000..  Training Loss: 0.157..  Test Loss: 0.711..  Test Accuracy: 0.853\n",
      "Epoch: 286/1000..  Training Loss: 0.174..  Test Loss: 0.715..  Test Accuracy: 0.852\n",
      "Epoch: 287/1000..  Training Loss: 0.179..  Test Loss: 0.712..  Test Accuracy: 0.852\n",
      "Epoch: 288/1000..  Training Loss: 0.228..  Test Loss: 0.718..  Test Accuracy: 0.851\n",
      "Epoch: 289/1000..  Training Loss: 0.192..  Test Loss: 0.739..  Test Accuracy: 0.849\n",
      "Epoch: 290/1000..  Training Loss: 0.185..  Test Loss: 0.716..  Test Accuracy: 0.853\n",
      "Epoch: 291/1000..  Training Loss: 0.159..  Test Loss: 0.716..  Test Accuracy: 0.852\n",
      "Epoch: 292/1000..  Training Loss: 0.137..  Test Loss: 0.713..  Test Accuracy: 0.853\n",
      "Epoch: 293/1000..  Training Loss: 0.221..  Test Loss: 0.741..  Test Accuracy: 0.850\n",
      "Epoch: 294/1000..  Training Loss: 0.206..  Test Loss: 0.720..  Test Accuracy: 0.849\n",
      "Epoch: 295/1000..  Training Loss: 0.185..  Test Loss: 0.726..  Test Accuracy: 0.849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 296/1000..  Training Loss: 0.174..  Test Loss: 0.727..  Test Accuracy: 0.851\n",
      "Epoch: 297/1000..  Training Loss: 0.126..  Test Loss: 0.729..  Test Accuracy: 0.850\n",
      "Epoch: 298/1000..  Training Loss: 0.282..  Test Loss: 0.713..  Test Accuracy: 0.853\n",
      "Epoch: 299/1000..  Training Loss: 0.182..  Test Loss: 0.706..  Test Accuracy: 0.854\n",
      "Epoch: 300/1000..  Training Loss: 0.152..  Test Loss: 0.717..  Test Accuracy: 0.852\n",
      "Epoch: 301/1000..  Training Loss: 0.191..  Test Loss: 0.740..  Test Accuracy: 0.850\n",
      "Epoch: 302/1000..  Training Loss: 0.204..  Test Loss: 0.743..  Test Accuracy: 0.847\n",
      "Epoch: 303/1000..  Training Loss: 0.221..  Test Loss: 0.698..  Test Accuracy: 0.853\n",
      "Epoch: 304/1000..  Training Loss: 0.211..  Test Loss: 0.717..  Test Accuracy: 0.852\n",
      "Epoch: 305/1000..  Training Loss: 0.173..  Test Loss: 0.731..  Test Accuracy: 0.850\n",
      "Epoch: 306/1000..  Training Loss: 0.242..  Test Loss: 0.732..  Test Accuracy: 0.847\n",
      "Epoch: 307/1000..  Training Loss: 0.188..  Test Loss: 0.731..  Test Accuracy: 0.848\n",
      "Epoch: 308/1000..  Training Loss: 0.187..  Test Loss: 0.725..  Test Accuracy: 0.848\n",
      "Epoch: 309/1000..  Training Loss: 0.258..  Test Loss: 0.727..  Test Accuracy: 0.851\n",
      "Epoch: 310/1000..  Training Loss: 0.153..  Test Loss: 0.723..  Test Accuracy: 0.849\n",
      "Epoch: 311/1000..  Training Loss: 0.228..  Test Loss: 0.728..  Test Accuracy: 0.849\n",
      "Epoch: 312/1000..  Training Loss: 0.171..  Test Loss: 0.755..  Test Accuracy: 0.847\n",
      "Epoch: 313/1000..  Training Loss: 0.150..  Test Loss: 0.730..  Test Accuracy: 0.847\n",
      "Epoch: 314/1000..  Training Loss: 0.187..  Test Loss: 0.744..  Test Accuracy: 0.846\n",
      "Epoch: 315/1000..  Training Loss: 0.202..  Test Loss: 0.737..  Test Accuracy: 0.849\n",
      "Epoch: 316/1000..  Training Loss: 0.208..  Test Loss: 0.752..  Test Accuracy: 0.845\n",
      "Epoch: 317/1000..  Training Loss: 0.147..  Test Loss: 0.737..  Test Accuracy: 0.848\n",
      "Epoch: 318/1000..  Training Loss: 0.159..  Test Loss: 0.724..  Test Accuracy: 0.849\n",
      "Epoch: 319/1000..  Training Loss: 0.275..  Test Loss: 0.737..  Test Accuracy: 0.849\n",
      "Epoch: 320/1000..  Training Loss: 0.264..  Test Loss: 0.728..  Test Accuracy: 0.849\n",
      "Epoch: 321/1000..  Training Loss: 0.237..  Test Loss: 0.729..  Test Accuracy: 0.850\n",
      "Epoch: 322/1000..  Training Loss: 0.283..  Test Loss: 0.723..  Test Accuracy: 0.846\n",
      "Epoch: 323/1000..  Training Loss: 0.220..  Test Loss: 0.733..  Test Accuracy: 0.850\n",
      "Epoch: 324/1000..  Training Loss: 0.221..  Test Loss: 0.733..  Test Accuracy: 0.849\n",
      "Epoch: 325/1000..  Training Loss: 0.283..  Test Loss: 0.714..  Test Accuracy: 0.851\n",
      "Epoch: 326/1000..  Training Loss: 0.205..  Test Loss: 0.726..  Test Accuracy: 0.850\n",
      "Epoch: 327/1000..  Training Loss: 0.232..  Test Loss: 0.733..  Test Accuracy: 0.849\n",
      "Epoch: 328/1000..  Training Loss: 0.178..  Test Loss: 0.737..  Test Accuracy: 0.848\n",
      "Epoch: 329/1000..  Training Loss: 0.173..  Test Loss: 0.733..  Test Accuracy: 0.849\n",
      "Epoch: 330/1000..  Training Loss: 0.148..  Test Loss: 0.712..  Test Accuracy: 0.851\n",
      "Epoch: 331/1000..  Training Loss: 0.179..  Test Loss: 0.710..  Test Accuracy: 0.852\n",
      "Epoch: 332/1000..  Training Loss: 0.164..  Test Loss: 0.731..  Test Accuracy: 0.848\n",
      "Epoch: 333/1000..  Training Loss: 0.264..  Test Loss: 0.749..  Test Accuracy: 0.847\n",
      "Epoch: 334/1000..  Training Loss: 0.228..  Test Loss: 0.742..  Test Accuracy: 0.847\n",
      "Epoch: 335/1000..  Training Loss: 0.174..  Test Loss: 0.744..  Test Accuracy: 0.847\n",
      "Epoch: 336/1000..  Training Loss: 0.243..  Test Loss: 0.707..  Test Accuracy: 0.852\n",
      "Epoch: 337/1000..  Training Loss: 0.214..  Test Loss: 0.736..  Test Accuracy: 0.848\n",
      "Epoch: 338/1000..  Training Loss: 0.244..  Test Loss: 0.719..  Test Accuracy: 0.850\n",
      "Epoch: 339/1000..  Training Loss: 0.264..  Test Loss: 0.744..  Test Accuracy: 0.848\n",
      "Epoch: 340/1000..  Training Loss: 0.199..  Test Loss: 0.738..  Test Accuracy: 0.848\n",
      "Epoch: 341/1000..  Training Loss: 0.168..  Test Loss: 0.716..  Test Accuracy: 0.852\n",
      "Epoch: 342/1000..  Training Loss: 0.137..  Test Loss: 0.712..  Test Accuracy: 0.851\n",
      "Epoch: 343/1000..  Training Loss: 0.225..  Test Loss: 0.747..  Test Accuracy: 0.847\n",
      "Epoch: 344/1000..  Training Loss: 0.181..  Test Loss: 0.739..  Test Accuracy: 0.846\n",
      "Epoch: 345/1000..  Training Loss: 0.173..  Test Loss: 0.730..  Test Accuracy: 0.849\n",
      "Epoch: 346/1000..  Training Loss: 0.196..  Test Loss: 0.758..  Test Accuracy: 0.846\n",
      "Epoch: 347/1000..  Training Loss: 0.169..  Test Loss: 0.742..  Test Accuracy: 0.848\n",
      "Epoch: 348/1000..  Training Loss: 0.142..  Test Loss: 0.731..  Test Accuracy: 0.851\n",
      "Epoch: 349/1000..  Training Loss: 0.227..  Test Loss: 0.711..  Test Accuracy: 0.852\n",
      "Epoch: 350/1000..  Training Loss: 0.178..  Test Loss: 0.733..  Test Accuracy: 0.849\n",
      "Epoch: 351/1000..  Training Loss: 0.139..  Test Loss: 0.745..  Test Accuracy: 0.848\n",
      "Epoch: 352/1000..  Training Loss: 0.187..  Test Loss: 0.737..  Test Accuracy: 0.849\n",
      "Epoch: 353/1000..  Training Loss: 0.180..  Test Loss: 0.744..  Test Accuracy: 0.847\n",
      "Epoch: 354/1000..  Training Loss: 0.242..  Test Loss: 0.732..  Test Accuracy: 0.850\n",
      "Epoch: 355/1000..  Training Loss: 0.124..  Test Loss: 0.739..  Test Accuracy: 0.848\n",
      "Epoch: 356/1000..  Training Loss: 0.232..  Test Loss: 0.759..  Test Accuracy: 0.848\n",
      "Epoch: 357/1000..  Training Loss: 0.276..  Test Loss: 0.730..  Test Accuracy: 0.850\n",
      "Epoch: 358/1000..  Training Loss: 0.218..  Test Loss: 0.752..  Test Accuracy: 0.844\n",
      "Epoch: 359/1000..  Training Loss: 0.210..  Test Loss: 0.725..  Test Accuracy: 0.850\n",
      "Epoch: 360/1000..  Training Loss: 0.168..  Test Loss: 0.724..  Test Accuracy: 0.851\n",
      "Epoch: 361/1000..  Training Loss: 0.283..  Test Loss: 0.746..  Test Accuracy: 0.847\n",
      "Epoch: 362/1000..  Training Loss: 0.184..  Test Loss: 0.746..  Test Accuracy: 0.848\n",
      "Epoch: 363/1000..  Training Loss: 0.108..  Test Loss: 0.717..  Test Accuracy: 0.852\n",
      "Epoch: 364/1000..  Training Loss: 0.150..  Test Loss: 0.710..  Test Accuracy: 0.852\n",
      "Epoch: 365/1000..  Training Loss: 0.175..  Test Loss: 0.719..  Test Accuracy: 0.850\n",
      "Epoch: 366/1000..  Training Loss: 0.211..  Test Loss: 0.733..  Test Accuracy: 0.848\n",
      "Epoch: 367/1000..  Training Loss: 0.183..  Test Loss: 0.750..  Test Accuracy: 0.846\n",
      "Epoch: 368/1000..  Training Loss: 0.239..  Test Loss: 0.764..  Test Accuracy: 0.844\n",
      "Epoch: 369/1000..  Training Loss: 0.141..  Test Loss: 0.731..  Test Accuracy: 0.848\n",
      "Epoch: 370/1000..  Training Loss: 0.190..  Test Loss: 0.727..  Test Accuracy: 0.849\n",
      "Epoch: 371/1000..  Training Loss: 0.212..  Test Loss: 0.742..  Test Accuracy: 0.848\n",
      "Epoch: 372/1000..  Training Loss: 0.207..  Test Loss: 0.715..  Test Accuracy: 0.851\n",
      "Epoch: 373/1000..  Training Loss: 0.185..  Test Loss: 0.732..  Test Accuracy: 0.850\n",
      "Epoch: 374/1000..  Training Loss: 0.181..  Test Loss: 0.743..  Test Accuracy: 0.846\n",
      "Epoch: 375/1000..  Training Loss: 0.229..  Test Loss: 0.746..  Test Accuracy: 0.844\n",
      "Epoch: 376/1000..  Training Loss: 0.181..  Test Loss: 0.747..  Test Accuracy: 0.846\n",
      "Epoch: 377/1000..  Training Loss: 0.188..  Test Loss: 0.743..  Test Accuracy: 0.849\n",
      "Epoch: 378/1000..  Training Loss: 0.212..  Test Loss: 0.775..  Test Accuracy: 0.842\n",
      "Epoch: 379/1000..  Training Loss: 0.160..  Test Loss: 0.755..  Test Accuracy: 0.846\n",
      "Epoch: 380/1000..  Training Loss: 0.196..  Test Loss: 0.738..  Test Accuracy: 0.848\n",
      "Epoch: 381/1000..  Training Loss: 0.142..  Test Loss: 0.748..  Test Accuracy: 0.846\n",
      "Epoch: 382/1000..  Training Loss: 0.192..  Test Loss: 0.727..  Test Accuracy: 0.850\n",
      "Epoch: 383/1000..  Training Loss: 0.206..  Test Loss: 0.727..  Test Accuracy: 0.848\n",
      "Epoch: 384/1000..  Training Loss: 0.159..  Test Loss: 0.722..  Test Accuracy: 0.848\n",
      "Epoch: 385/1000..  Training Loss: 0.203..  Test Loss: 0.755..  Test Accuracy: 0.845\n",
      "Epoch: 386/1000..  Training Loss: 0.217..  Test Loss: 0.736..  Test Accuracy: 0.845\n",
      "Epoch: 387/1000..  Training Loss: 0.200..  Test Loss: 0.735..  Test Accuracy: 0.845\n",
      "Epoch: 388/1000..  Training Loss: 0.202..  Test Loss: 0.729..  Test Accuracy: 0.850\n",
      "Epoch: 389/1000..  Training Loss: 0.252..  Test Loss: 0.731..  Test Accuracy: 0.851\n",
      "Epoch: 390/1000..  Training Loss: 0.294..  Test Loss: 0.750..  Test Accuracy: 0.847\n",
      "Epoch: 391/1000..  Training Loss: 0.219..  Test Loss: 0.722..  Test Accuracy: 0.852\n",
      "Epoch: 392/1000..  Training Loss: 0.201..  Test Loss: 0.737..  Test Accuracy: 0.847\n",
      "Epoch: 393/1000..  Training Loss: 0.165..  Test Loss: 0.736..  Test Accuracy: 0.849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 394/1000..  Training Loss: 0.249..  Test Loss: 0.738..  Test Accuracy: 0.847\n",
      "Epoch: 395/1000..  Training Loss: 0.209..  Test Loss: 0.720..  Test Accuracy: 0.850\n",
      "Epoch: 396/1000..  Training Loss: 0.185..  Test Loss: 0.739..  Test Accuracy: 0.848\n",
      "Epoch: 397/1000..  Training Loss: 0.157..  Test Loss: 0.752..  Test Accuracy: 0.846\n",
      "Epoch: 398/1000..  Training Loss: 0.180..  Test Loss: 0.730..  Test Accuracy: 0.847\n",
      "Epoch: 399/1000..  Training Loss: 0.157..  Test Loss: 0.740..  Test Accuracy: 0.845\n",
      "Epoch: 400/1000..  Training Loss: 0.173..  Test Loss: 0.751..  Test Accuracy: 0.846\n",
      "Epoch: 401/1000..  Training Loss: 0.240..  Test Loss: 0.735..  Test Accuracy: 0.848\n",
      "Epoch: 402/1000..  Training Loss: 0.221..  Test Loss: 0.741..  Test Accuracy: 0.847\n",
      "Epoch: 403/1000..  Training Loss: 0.194..  Test Loss: 0.749..  Test Accuracy: 0.845\n",
      "Epoch: 404/1000..  Training Loss: 0.202..  Test Loss: 0.767..  Test Accuracy: 0.842\n",
      "Epoch: 405/1000..  Training Loss: 0.216..  Test Loss: 0.759..  Test Accuracy: 0.846\n",
      "Epoch: 406/1000..  Training Loss: 0.227..  Test Loss: 0.756..  Test Accuracy: 0.846\n",
      "Epoch: 407/1000..  Training Loss: 0.184..  Test Loss: 0.747..  Test Accuracy: 0.846\n",
      "Epoch: 408/1000..  Training Loss: 0.256..  Test Loss: 0.756..  Test Accuracy: 0.844\n",
      "Epoch: 409/1000..  Training Loss: 0.165..  Test Loss: 0.728..  Test Accuracy: 0.849\n",
      "Epoch: 410/1000..  Training Loss: 0.211..  Test Loss: 0.758..  Test Accuracy: 0.844\n",
      "Epoch: 411/1000..  Training Loss: 0.135..  Test Loss: 0.756..  Test Accuracy: 0.846\n",
      "Epoch: 412/1000..  Training Loss: 0.171..  Test Loss: 0.730..  Test Accuracy: 0.851\n",
      "Epoch: 413/1000..  Training Loss: 0.171..  Test Loss: 0.768..  Test Accuracy: 0.846\n",
      "Epoch: 414/1000..  Training Loss: 0.189..  Test Loss: 0.763..  Test Accuracy: 0.847\n",
      "Epoch: 415/1000..  Training Loss: 0.218..  Test Loss: 0.741..  Test Accuracy: 0.850\n",
      "Epoch: 416/1000..  Training Loss: 0.143..  Test Loss: 0.749..  Test Accuracy: 0.846\n",
      "Epoch: 417/1000..  Training Loss: 0.204..  Test Loss: 0.754..  Test Accuracy: 0.842\n",
      "Epoch: 418/1000..  Training Loss: 0.233..  Test Loss: 0.750..  Test Accuracy: 0.847\n",
      "Epoch: 419/1000..  Training Loss: 0.161..  Test Loss: 0.743..  Test Accuracy: 0.845\n",
      "Epoch: 420/1000..  Training Loss: 0.177..  Test Loss: 0.731..  Test Accuracy: 0.849\n",
      "Epoch: 421/1000..  Training Loss: 0.204..  Test Loss: 0.768..  Test Accuracy: 0.844\n",
      "Epoch: 422/1000..  Training Loss: 0.234..  Test Loss: 0.759..  Test Accuracy: 0.845\n",
      "Epoch: 423/1000..  Training Loss: 0.192..  Test Loss: 0.737..  Test Accuracy: 0.848\n",
      "Epoch: 424/1000..  Training Loss: 0.166..  Test Loss: 0.751..  Test Accuracy: 0.847\n",
      "Epoch: 425/1000..  Training Loss: 0.201..  Test Loss: 0.740..  Test Accuracy: 0.845\n",
      "Epoch: 426/1000..  Training Loss: 0.181..  Test Loss: 0.760..  Test Accuracy: 0.845\n",
      "Epoch: 427/1000..  Training Loss: 0.188..  Test Loss: 0.758..  Test Accuracy: 0.843\n",
      "Epoch: 428/1000..  Training Loss: 0.266..  Test Loss: 0.780..  Test Accuracy: 0.839\n",
      "Epoch: 429/1000..  Training Loss: 0.151..  Test Loss: 0.745..  Test Accuracy: 0.847\n",
      "Epoch: 430/1000..  Training Loss: 0.215..  Test Loss: 0.725..  Test Accuracy: 0.848\n",
      "Epoch: 431/1000..  Training Loss: 0.157..  Test Loss: 0.750..  Test Accuracy: 0.843\n",
      "Epoch: 432/1000..  Training Loss: 0.219..  Test Loss: 0.737..  Test Accuracy: 0.845\n",
      "Epoch: 433/1000..  Training Loss: 0.151..  Test Loss: 0.731..  Test Accuracy: 0.848\n",
      "Epoch: 434/1000..  Training Loss: 0.131..  Test Loss: 0.763..  Test Accuracy: 0.842\n",
      "Epoch: 435/1000..  Training Loss: 0.237..  Test Loss: 0.746..  Test Accuracy: 0.847\n",
      "Epoch: 436/1000..  Training Loss: 0.231..  Test Loss: 0.740..  Test Accuracy: 0.848\n",
      "Epoch: 437/1000..  Training Loss: 0.192..  Test Loss: 0.746..  Test Accuracy: 0.847\n",
      "Epoch: 438/1000..  Training Loss: 0.216..  Test Loss: 0.755..  Test Accuracy: 0.847\n",
      "Epoch: 439/1000..  Training Loss: 0.233..  Test Loss: 0.776..  Test Accuracy: 0.843\n",
      "Epoch: 440/1000..  Training Loss: 0.178..  Test Loss: 0.761..  Test Accuracy: 0.844\n",
      "Epoch: 441/1000..  Training Loss: 0.238..  Test Loss: 0.757..  Test Accuracy: 0.844\n",
      "Epoch: 442/1000..  Training Loss: 0.182..  Test Loss: 0.747..  Test Accuracy: 0.846\n",
      "Epoch: 443/1000..  Training Loss: 0.183..  Test Loss: 0.769..  Test Accuracy: 0.845\n",
      "Epoch: 444/1000..  Training Loss: 0.191..  Test Loss: 0.776..  Test Accuracy: 0.841\n",
      "Epoch: 445/1000..  Training Loss: 0.165..  Test Loss: 0.768..  Test Accuracy: 0.843\n",
      "Epoch: 446/1000..  Training Loss: 0.219..  Test Loss: 0.748..  Test Accuracy: 0.846\n",
      "Epoch: 447/1000..  Training Loss: 0.195..  Test Loss: 0.775..  Test Accuracy: 0.841\n",
      "Epoch: 448/1000..  Training Loss: 0.190..  Test Loss: 0.769..  Test Accuracy: 0.842\n",
      "Epoch: 449/1000..  Training Loss: 0.178..  Test Loss: 0.781..  Test Accuracy: 0.844\n",
      "Epoch: 450/1000..  Training Loss: 0.231..  Test Loss: 0.749..  Test Accuracy: 0.846\n",
      "Epoch: 451/1000..  Training Loss: 0.146..  Test Loss: 0.780..  Test Accuracy: 0.844\n",
      "Epoch: 452/1000..  Training Loss: 0.163..  Test Loss: 0.742..  Test Accuracy: 0.850\n",
      "Epoch: 453/1000..  Training Loss: 0.200..  Test Loss: 0.772..  Test Accuracy: 0.842\n",
      "Epoch: 454/1000..  Training Loss: 0.167..  Test Loss: 0.736..  Test Accuracy: 0.847\n",
      "Epoch: 455/1000..  Training Loss: 0.188..  Test Loss: 0.753..  Test Accuracy: 0.845\n",
      "Epoch: 456/1000..  Training Loss: 0.161..  Test Loss: 0.754..  Test Accuracy: 0.846\n",
      "Epoch: 457/1000..  Training Loss: 0.142..  Test Loss: 0.765..  Test Accuracy: 0.844\n",
      "Epoch: 458/1000..  Training Loss: 0.198..  Test Loss: 0.746..  Test Accuracy: 0.844\n",
      "Epoch: 459/1000..  Training Loss: 0.162..  Test Loss: 0.746..  Test Accuracy: 0.847\n",
      "Epoch: 460/1000..  Training Loss: 0.182..  Test Loss: 0.783..  Test Accuracy: 0.842\n",
      "Epoch: 461/1000..  Training Loss: 0.167..  Test Loss: 0.751..  Test Accuracy: 0.846\n",
      "Epoch: 462/1000..  Training Loss: 0.161..  Test Loss: 0.760..  Test Accuracy: 0.845\n",
      "Epoch: 463/1000..  Training Loss: 0.292..  Test Loss: 0.745..  Test Accuracy: 0.844\n",
      "Epoch: 464/1000..  Training Loss: 0.215..  Test Loss: 0.756..  Test Accuracy: 0.846\n",
      "Epoch: 465/1000..  Training Loss: 0.144..  Test Loss: 0.771..  Test Accuracy: 0.842\n",
      "Epoch: 466/1000..  Training Loss: 0.186..  Test Loss: 0.761..  Test Accuracy: 0.843\n",
      "Epoch: 467/1000..  Training Loss: 0.121..  Test Loss: 0.762..  Test Accuracy: 0.843\n",
      "Epoch: 468/1000..  Training Loss: 0.243..  Test Loss: 0.760..  Test Accuracy: 0.844\n",
      "Epoch: 469/1000..  Training Loss: 0.186..  Test Loss: 0.753..  Test Accuracy: 0.845\n",
      "Epoch: 470/1000..  Training Loss: 0.274..  Test Loss: 0.745..  Test Accuracy: 0.847\n",
      "Epoch: 471/1000..  Training Loss: 0.268..  Test Loss: 0.759..  Test Accuracy: 0.846\n",
      "Epoch: 472/1000..  Training Loss: 0.200..  Test Loss: 0.761..  Test Accuracy: 0.844\n",
      "Epoch: 473/1000..  Training Loss: 0.211..  Test Loss: 0.773..  Test Accuracy: 0.846\n",
      "Epoch: 474/1000..  Training Loss: 0.152..  Test Loss: 0.800..  Test Accuracy: 0.838\n",
      "Epoch: 475/1000..  Training Loss: 0.200..  Test Loss: 0.743..  Test Accuracy: 0.847\n",
      "Epoch: 476/1000..  Training Loss: 0.194..  Test Loss: 0.770..  Test Accuracy: 0.844\n",
      "Epoch: 477/1000..  Training Loss: 0.150..  Test Loss: 0.753..  Test Accuracy: 0.846\n",
      "Epoch: 478/1000..  Training Loss: 0.184..  Test Loss: 0.756..  Test Accuracy: 0.847\n",
      "Epoch: 479/1000..  Training Loss: 0.200..  Test Loss: 0.796..  Test Accuracy: 0.839\n",
      "Epoch: 480/1000..  Training Loss: 0.244..  Test Loss: 0.788..  Test Accuracy: 0.843\n",
      "Epoch: 481/1000..  Training Loss: 0.118..  Test Loss: 0.777..  Test Accuracy: 0.844\n",
      "Epoch: 482/1000..  Training Loss: 0.166..  Test Loss: 0.778..  Test Accuracy: 0.844\n",
      "Epoch: 483/1000..  Training Loss: 0.147..  Test Loss: 0.745..  Test Accuracy: 0.847\n",
      "Epoch: 484/1000..  Training Loss: 0.221..  Test Loss: 0.773..  Test Accuracy: 0.844\n",
      "Epoch: 485/1000..  Training Loss: 0.191..  Test Loss: 0.767..  Test Accuracy: 0.843\n",
      "Epoch: 486/1000..  Training Loss: 0.167..  Test Loss: 0.770..  Test Accuracy: 0.842\n",
      "Epoch: 487/1000..  Training Loss: 0.200..  Test Loss: 0.764..  Test Accuracy: 0.845\n",
      "Epoch: 488/1000..  Training Loss: 0.224..  Test Loss: 0.744..  Test Accuracy: 0.844\n",
      "Epoch: 489/1000..  Training Loss: 0.182..  Test Loss: 0.760..  Test Accuracy: 0.843\n",
      "Epoch: 490/1000..  Training Loss: 0.156..  Test Loss: 0.744..  Test Accuracy: 0.847\n",
      "Epoch: 491/1000..  Training Loss: 0.117..  Test Loss: 0.744..  Test Accuracy: 0.846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 492/1000..  Training Loss: 0.226..  Test Loss: 0.752..  Test Accuracy: 0.846\n",
      "Epoch: 493/1000..  Training Loss: 0.228..  Test Loss: 0.751..  Test Accuracy: 0.846\n",
      "Epoch: 494/1000..  Training Loss: 0.118..  Test Loss: 0.761..  Test Accuracy: 0.845\n",
      "Epoch: 495/1000..  Training Loss: 0.191..  Test Loss: 0.754..  Test Accuracy: 0.847\n",
      "Epoch: 496/1000..  Training Loss: 0.111..  Test Loss: 0.760..  Test Accuracy: 0.845\n",
      "Epoch: 497/1000..  Training Loss: 0.159..  Test Loss: 0.735..  Test Accuracy: 0.848\n",
      "Epoch: 498/1000..  Training Loss: 0.205..  Test Loss: 0.768..  Test Accuracy: 0.846\n",
      "Epoch: 499/1000..  Training Loss: 0.234..  Test Loss: 0.756..  Test Accuracy: 0.845\n",
      "Epoch: 500/1000..  Training Loss: 0.131..  Test Loss: 0.785..  Test Accuracy: 0.843\n",
      "Epoch: 501/1000..  Training Loss: 0.175..  Test Loss: 0.763..  Test Accuracy: 0.845\n",
      "Epoch: 502/1000..  Training Loss: 0.174..  Test Loss: 0.760..  Test Accuracy: 0.844\n",
      "Epoch: 503/1000..  Training Loss: 0.268..  Test Loss: 0.789..  Test Accuracy: 0.840\n",
      "Epoch: 504/1000..  Training Loss: 0.217..  Test Loss: 0.800..  Test Accuracy: 0.839\n",
      "Epoch: 505/1000..  Training Loss: 0.258..  Test Loss: 0.780..  Test Accuracy: 0.843\n",
      "Epoch: 506/1000..  Training Loss: 0.217..  Test Loss: 0.752..  Test Accuracy: 0.844\n",
      "Epoch: 507/1000..  Training Loss: 0.166..  Test Loss: 0.762..  Test Accuracy: 0.844\n",
      "Epoch: 508/1000..  Training Loss: 0.204..  Test Loss: 0.748..  Test Accuracy: 0.847\n",
      "Epoch: 509/1000..  Training Loss: 0.173..  Test Loss: 0.728..  Test Accuracy: 0.847\n",
      "Epoch: 510/1000..  Training Loss: 0.196..  Test Loss: 0.772..  Test Accuracy: 0.845\n",
      "Epoch: 511/1000..  Training Loss: 0.207..  Test Loss: 0.752..  Test Accuracy: 0.850\n",
      "Epoch: 512/1000..  Training Loss: 0.158..  Test Loss: 0.780..  Test Accuracy: 0.844\n",
      "Epoch: 513/1000..  Training Loss: 0.124..  Test Loss: 0.768..  Test Accuracy: 0.842\n",
      "Epoch: 514/1000..  Training Loss: 0.142..  Test Loss: 0.766..  Test Accuracy: 0.845\n",
      "Epoch: 515/1000..  Training Loss: 0.154..  Test Loss: 0.754..  Test Accuracy: 0.846\n",
      "Epoch: 516/1000..  Training Loss: 0.128..  Test Loss: 0.745..  Test Accuracy: 0.847\n",
      "Epoch: 517/1000..  Training Loss: 0.209..  Test Loss: 0.731..  Test Accuracy: 0.849\n",
      "Epoch: 518/1000..  Training Loss: 0.156..  Test Loss: 0.720..  Test Accuracy: 0.849\n",
      "Epoch: 519/1000..  Training Loss: 0.190..  Test Loss: 0.756..  Test Accuracy: 0.845\n",
      "Epoch: 520/1000..  Training Loss: 0.162..  Test Loss: 0.773..  Test Accuracy: 0.844\n",
      "Epoch: 521/1000..  Training Loss: 0.199..  Test Loss: 0.756..  Test Accuracy: 0.845\n",
      "Epoch: 522/1000..  Training Loss: 0.152..  Test Loss: 0.805..  Test Accuracy: 0.839\n",
      "Epoch: 523/1000..  Training Loss: 0.214..  Test Loss: 0.797..  Test Accuracy: 0.839\n",
      "Epoch: 524/1000..  Training Loss: 0.142..  Test Loss: 0.763..  Test Accuracy: 0.844\n",
      "Epoch: 525/1000..  Training Loss: 0.180..  Test Loss: 0.751..  Test Accuracy: 0.847\n",
      "Epoch: 526/1000..  Training Loss: 0.160..  Test Loss: 0.751..  Test Accuracy: 0.846\n",
      "Epoch: 527/1000..  Training Loss: 0.143..  Test Loss: 0.757..  Test Accuracy: 0.842\n",
      "Epoch: 528/1000..  Training Loss: 0.190..  Test Loss: 0.760..  Test Accuracy: 0.844\n",
      "Epoch: 529/1000..  Training Loss: 0.183..  Test Loss: 0.761..  Test Accuracy: 0.844\n",
      "Epoch: 530/1000..  Training Loss: 0.131..  Test Loss: 0.773..  Test Accuracy: 0.844\n",
      "Epoch: 531/1000..  Training Loss: 0.207..  Test Loss: 0.731..  Test Accuracy: 0.850\n",
      "Epoch: 532/1000..  Training Loss: 0.182..  Test Loss: 0.745..  Test Accuracy: 0.848\n",
      "Epoch: 533/1000..  Training Loss: 0.155..  Test Loss: 0.765..  Test Accuracy: 0.847\n",
      "Epoch: 534/1000..  Training Loss: 0.218..  Test Loss: 0.752..  Test Accuracy: 0.847\n",
      "Epoch: 535/1000..  Training Loss: 0.234..  Test Loss: 0.753..  Test Accuracy: 0.846\n",
      "Epoch: 536/1000..  Training Loss: 0.201..  Test Loss: 0.766..  Test Accuracy: 0.844\n",
      "Epoch: 537/1000..  Training Loss: 0.211..  Test Loss: 0.754..  Test Accuracy: 0.846\n",
      "Epoch: 538/1000..  Training Loss: 0.155..  Test Loss: 0.750..  Test Accuracy: 0.848\n",
      "Epoch: 539/1000..  Training Loss: 0.247..  Test Loss: 0.759..  Test Accuracy: 0.845\n",
      "Epoch: 540/1000..  Training Loss: 0.162..  Test Loss: 0.748..  Test Accuracy: 0.847\n",
      "Epoch: 541/1000..  Training Loss: 0.190..  Test Loss: 0.760..  Test Accuracy: 0.848\n",
      "Epoch: 542/1000..  Training Loss: 0.193..  Test Loss: 0.770..  Test Accuracy: 0.842\n",
      "Epoch: 543/1000..  Training Loss: 0.146..  Test Loss: 0.757..  Test Accuracy: 0.847\n",
      "Epoch: 544/1000..  Training Loss: 0.199..  Test Loss: 0.762..  Test Accuracy: 0.843\n",
      "Epoch: 545/1000..  Training Loss: 0.223..  Test Loss: 0.767..  Test Accuracy: 0.843\n",
      "Epoch: 546/1000..  Training Loss: 0.137..  Test Loss: 0.752..  Test Accuracy: 0.849\n",
      "Epoch: 547/1000..  Training Loss: 0.218..  Test Loss: 0.753..  Test Accuracy: 0.844\n",
      "Epoch: 548/1000..  Training Loss: 0.219..  Test Loss: 0.731..  Test Accuracy: 0.848\n",
      "Epoch: 549/1000..  Training Loss: 0.177..  Test Loss: 0.757..  Test Accuracy: 0.845\n",
      "Epoch: 550/1000..  Training Loss: 0.160..  Test Loss: 0.766..  Test Accuracy: 0.844\n",
      "Epoch: 551/1000..  Training Loss: 0.152..  Test Loss: 0.763..  Test Accuracy: 0.844\n",
      "Epoch: 552/1000..  Training Loss: 0.187..  Test Loss: 0.748..  Test Accuracy: 0.846\n",
      "Epoch: 553/1000..  Training Loss: 0.159..  Test Loss: 0.748..  Test Accuracy: 0.850\n",
      "Epoch: 554/1000..  Training Loss: 0.179..  Test Loss: 0.759..  Test Accuracy: 0.845\n",
      "Epoch: 555/1000..  Training Loss: 0.148..  Test Loss: 0.759..  Test Accuracy: 0.847\n",
      "Epoch: 556/1000..  Training Loss: 0.187..  Test Loss: 0.781..  Test Accuracy: 0.841\n",
      "Epoch: 557/1000..  Training Loss: 0.224..  Test Loss: 0.742..  Test Accuracy: 0.850\n",
      "Epoch: 558/1000..  Training Loss: 0.132..  Test Loss: 0.756..  Test Accuracy: 0.847\n",
      "Epoch: 559/1000..  Training Loss: 0.149..  Test Loss: 0.749..  Test Accuracy: 0.845\n",
      "Epoch: 560/1000..  Training Loss: 0.170..  Test Loss: 0.739..  Test Accuracy: 0.848\n",
      "Epoch: 561/1000..  Training Loss: 0.178..  Test Loss: 0.750..  Test Accuracy: 0.848\n",
      "Epoch: 562/1000..  Training Loss: 0.176..  Test Loss: 0.765..  Test Accuracy: 0.845\n",
      "Epoch: 563/1000..  Training Loss: 0.150..  Test Loss: 0.759..  Test Accuracy: 0.848\n",
      "Epoch: 564/1000..  Training Loss: 0.259..  Test Loss: 0.733..  Test Accuracy: 0.851\n",
      "Epoch: 565/1000..  Training Loss: 0.198..  Test Loss: 0.754..  Test Accuracy: 0.847\n",
      "Epoch: 566/1000..  Training Loss: 0.166..  Test Loss: 0.756..  Test Accuracy: 0.848\n",
      "Epoch: 567/1000..  Training Loss: 0.196..  Test Loss: 0.766..  Test Accuracy: 0.845\n",
      "Epoch: 568/1000..  Training Loss: 0.169..  Test Loss: 0.749..  Test Accuracy: 0.847\n",
      "Epoch: 569/1000..  Training Loss: 0.268..  Test Loss: 0.747..  Test Accuracy: 0.850\n",
      "Epoch: 570/1000..  Training Loss: 0.208..  Test Loss: 0.733..  Test Accuracy: 0.850\n",
      "Epoch: 571/1000..  Training Loss: 0.232..  Test Loss: 0.769..  Test Accuracy: 0.847\n",
      "Epoch: 572/1000..  Training Loss: 0.181..  Test Loss: 0.777..  Test Accuracy: 0.844\n",
      "Epoch: 573/1000..  Training Loss: 0.142..  Test Loss: 0.763..  Test Accuracy: 0.844\n",
      "Epoch: 574/1000..  Training Loss: 0.228..  Test Loss: 0.768..  Test Accuracy: 0.844\n",
      "Epoch: 575/1000..  Training Loss: 0.210..  Test Loss: 0.750..  Test Accuracy: 0.849\n",
      "Epoch: 576/1000..  Training Loss: 0.228..  Test Loss: 0.757..  Test Accuracy: 0.848\n",
      "Epoch: 577/1000..  Training Loss: 0.167..  Test Loss: 0.747..  Test Accuracy: 0.849\n",
      "Epoch: 578/1000..  Training Loss: 0.273..  Test Loss: 0.743..  Test Accuracy: 0.847\n",
      "Epoch: 579/1000..  Training Loss: 0.147..  Test Loss: 0.763..  Test Accuracy: 0.843\n",
      "Epoch: 580/1000..  Training Loss: 0.199..  Test Loss: 0.768..  Test Accuracy: 0.844\n",
      "Epoch: 581/1000..  Training Loss: 0.201..  Test Loss: 0.774..  Test Accuracy: 0.842\n",
      "Epoch: 582/1000..  Training Loss: 0.224..  Test Loss: 0.785..  Test Accuracy: 0.843\n",
      "Epoch: 583/1000..  Training Loss: 0.125..  Test Loss: 0.751..  Test Accuracy: 0.846\n",
      "Epoch: 584/1000..  Training Loss: 0.219..  Test Loss: 0.754..  Test Accuracy: 0.849\n",
      "Epoch: 585/1000..  Training Loss: 0.201..  Test Loss: 0.779..  Test Accuracy: 0.845\n",
      "Epoch: 586/1000..  Training Loss: 0.226..  Test Loss: 0.752..  Test Accuracy: 0.849\n",
      "Epoch: 587/1000..  Training Loss: 0.193..  Test Loss: 0.737..  Test Accuracy: 0.850\n",
      "Epoch: 588/1000..  Training Loss: 0.183..  Test Loss: 0.758..  Test Accuracy: 0.847\n",
      "Epoch: 589/1000..  Training Loss: 0.174..  Test Loss: 0.762..  Test Accuracy: 0.849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 590/1000..  Training Loss: 0.173..  Test Loss: 0.753..  Test Accuracy: 0.846\n",
      "Epoch: 591/1000..  Training Loss: 0.224..  Test Loss: 0.741..  Test Accuracy: 0.849\n",
      "Epoch: 592/1000..  Training Loss: 0.189..  Test Loss: 0.760..  Test Accuracy: 0.848\n",
      "Epoch: 593/1000..  Training Loss: 0.137..  Test Loss: 0.744..  Test Accuracy: 0.849\n",
      "Epoch: 594/1000..  Training Loss: 0.179..  Test Loss: 0.764..  Test Accuracy: 0.846\n",
      "Epoch: 595/1000..  Training Loss: 0.110..  Test Loss: 0.762..  Test Accuracy: 0.848\n",
      "Epoch: 596/1000..  Training Loss: 0.249..  Test Loss: 0.784..  Test Accuracy: 0.843\n",
      "Epoch: 597/1000..  Training Loss: 0.237..  Test Loss: 0.785..  Test Accuracy: 0.839\n",
      "Epoch: 598/1000..  Training Loss: 0.177..  Test Loss: 0.763..  Test Accuracy: 0.845\n",
      "Epoch: 599/1000..  Training Loss: 0.282..  Test Loss: 0.736..  Test Accuracy: 0.848\n",
      "Epoch: 600/1000..  Training Loss: 0.218..  Test Loss: 0.742..  Test Accuracy: 0.850\n",
      "Epoch: 601/1000..  Training Loss: 0.192..  Test Loss: 0.779..  Test Accuracy: 0.841\n",
      "Epoch: 602/1000..  Training Loss: 0.151..  Test Loss: 0.780..  Test Accuracy: 0.845\n",
      "Epoch: 603/1000..  Training Loss: 0.179..  Test Loss: 0.754..  Test Accuracy: 0.845\n",
      "Epoch: 604/1000..  Training Loss: 0.149..  Test Loss: 0.753..  Test Accuracy: 0.845\n",
      "Epoch: 605/1000..  Training Loss: 0.193..  Test Loss: 0.733..  Test Accuracy: 0.851\n",
      "Epoch: 606/1000..  Training Loss: 0.241..  Test Loss: 0.743..  Test Accuracy: 0.845\n",
      "Epoch: 607/1000..  Training Loss: 0.186..  Test Loss: 0.732..  Test Accuracy: 0.851\n",
      "Epoch: 608/1000..  Training Loss: 0.177..  Test Loss: 0.741..  Test Accuracy: 0.850\n",
      "Epoch: 609/1000..  Training Loss: 0.179..  Test Loss: 0.766..  Test Accuracy: 0.846\n",
      "Epoch: 610/1000..  Training Loss: 0.176..  Test Loss: 0.765..  Test Accuracy: 0.847\n",
      "Epoch: 611/1000..  Training Loss: 0.156..  Test Loss: 0.760..  Test Accuracy: 0.844\n",
      "Epoch: 612/1000..  Training Loss: 0.135..  Test Loss: 0.758..  Test Accuracy: 0.846\n",
      "Epoch: 613/1000..  Training Loss: 0.079..  Test Loss: 0.761..  Test Accuracy: 0.846\n",
      "Epoch: 614/1000..  Training Loss: 0.164..  Test Loss: 0.757..  Test Accuracy: 0.846\n",
      "Epoch: 615/1000..  Training Loss: 0.183..  Test Loss: 0.756..  Test Accuracy: 0.849\n",
      "Epoch: 616/1000..  Training Loss: 0.205..  Test Loss: 0.751..  Test Accuracy: 0.847\n",
      "Epoch: 617/1000..  Training Loss: 0.162..  Test Loss: 0.767..  Test Accuracy: 0.848\n",
      "Epoch: 618/1000..  Training Loss: 0.097..  Test Loss: 0.749..  Test Accuracy: 0.848\n",
      "Epoch: 619/1000..  Training Loss: 0.169..  Test Loss: 0.776..  Test Accuracy: 0.847\n",
      "Epoch: 620/1000..  Training Loss: 0.174..  Test Loss: 0.752..  Test Accuracy: 0.849\n",
      "Epoch: 621/1000..  Training Loss: 0.160..  Test Loss: 0.749..  Test Accuracy: 0.849\n",
      "Epoch: 622/1000..  Training Loss: 0.159..  Test Loss: 0.761..  Test Accuracy: 0.845\n",
      "Epoch: 623/1000..  Training Loss: 0.222..  Test Loss: 0.748..  Test Accuracy: 0.846\n",
      "Epoch: 624/1000..  Training Loss: 0.169..  Test Loss: 0.754..  Test Accuracy: 0.847\n",
      "Epoch: 625/1000..  Training Loss: 0.198..  Test Loss: 0.776..  Test Accuracy: 0.844\n",
      "Epoch: 626/1000..  Training Loss: 0.218..  Test Loss: 0.783..  Test Accuracy: 0.841\n",
      "Epoch: 627/1000..  Training Loss: 0.168..  Test Loss: 0.758..  Test Accuracy: 0.846\n",
      "Epoch: 628/1000..  Training Loss: 0.183..  Test Loss: 0.759..  Test Accuracy: 0.846\n",
      "Epoch: 629/1000..  Training Loss: 0.148..  Test Loss: 0.750..  Test Accuracy: 0.848\n",
      "Epoch: 630/1000..  Training Loss: 0.245..  Test Loss: 0.770..  Test Accuracy: 0.847\n",
      "Epoch: 631/1000..  Training Loss: 0.185..  Test Loss: 0.789..  Test Accuracy: 0.842\n",
      "Epoch: 632/1000..  Training Loss: 0.157..  Test Loss: 0.765..  Test Accuracy: 0.848\n",
      "Epoch: 633/1000..  Training Loss: 0.167..  Test Loss: 0.775..  Test Accuracy: 0.844\n",
      "Epoch: 634/1000..  Training Loss: 0.164..  Test Loss: 0.738..  Test Accuracy: 0.847\n",
      "Epoch: 635/1000..  Training Loss: 0.174..  Test Loss: 0.760..  Test Accuracy: 0.844\n",
      "Epoch: 636/1000..  Training Loss: 0.179..  Test Loss: 0.758..  Test Accuracy: 0.847\n",
      "Epoch: 637/1000..  Training Loss: 0.219..  Test Loss: 0.759..  Test Accuracy: 0.846\n",
      "Epoch: 638/1000..  Training Loss: 0.186..  Test Loss: 0.762..  Test Accuracy: 0.847\n",
      "Epoch: 639/1000..  Training Loss: 0.162..  Test Loss: 0.767..  Test Accuracy: 0.846\n",
      "Epoch: 640/1000..  Training Loss: 0.202..  Test Loss: 0.759..  Test Accuracy: 0.845\n",
      "Epoch: 641/1000..  Training Loss: 0.224..  Test Loss: 0.764..  Test Accuracy: 0.845\n",
      "Epoch: 642/1000..  Training Loss: 0.121..  Test Loss: 0.778..  Test Accuracy: 0.843\n",
      "Epoch: 643/1000..  Training Loss: 0.212..  Test Loss: 0.775..  Test Accuracy: 0.845\n",
      "Epoch: 644/1000..  Training Loss: 0.226..  Test Loss: 0.749..  Test Accuracy: 0.848\n",
      "Epoch: 645/1000..  Training Loss: 0.215..  Test Loss: 0.766..  Test Accuracy: 0.846\n",
      "Epoch: 646/1000..  Training Loss: 0.143..  Test Loss: 0.763..  Test Accuracy: 0.847\n",
      "Epoch: 647/1000..  Training Loss: 0.186..  Test Loss: 0.807..  Test Accuracy: 0.842\n",
      "Epoch: 648/1000..  Training Loss: 0.207..  Test Loss: 0.761..  Test Accuracy: 0.847\n",
      "Epoch: 649/1000..  Training Loss: 0.178..  Test Loss: 0.757..  Test Accuracy: 0.847\n",
      "Epoch: 650/1000..  Training Loss: 0.126..  Test Loss: 0.765..  Test Accuracy: 0.846\n",
      "Epoch: 651/1000..  Training Loss: 0.191..  Test Loss: 0.797..  Test Accuracy: 0.842\n",
      "Epoch: 652/1000..  Training Loss: 0.202..  Test Loss: 0.788..  Test Accuracy: 0.841\n",
      "Epoch: 653/1000..  Training Loss: 0.161..  Test Loss: 0.757..  Test Accuracy: 0.844\n",
      "Epoch: 654/1000..  Training Loss: 0.184..  Test Loss: 0.737..  Test Accuracy: 0.850\n",
      "Epoch: 655/1000..  Training Loss: 0.167..  Test Loss: 0.762..  Test Accuracy: 0.845\n",
      "Epoch: 656/1000..  Training Loss: 0.102..  Test Loss: 0.753..  Test Accuracy: 0.849\n",
      "Epoch: 657/1000..  Training Loss: 0.147..  Test Loss: 0.757..  Test Accuracy: 0.846\n",
      "Epoch: 658/1000..  Training Loss: 0.169..  Test Loss: 0.759..  Test Accuracy: 0.847\n",
      "Epoch: 659/1000..  Training Loss: 0.181..  Test Loss: 0.778..  Test Accuracy: 0.844\n",
      "Epoch: 660/1000..  Training Loss: 0.195..  Test Loss: 0.761..  Test Accuracy: 0.845\n",
      "Epoch: 661/1000..  Training Loss: 0.200..  Test Loss: 0.752..  Test Accuracy: 0.847\n",
      "Epoch: 662/1000..  Training Loss: 0.152..  Test Loss: 0.757..  Test Accuracy: 0.848\n",
      "Epoch: 663/1000..  Training Loss: 0.231..  Test Loss: 0.747..  Test Accuracy: 0.850\n",
      "Epoch: 664/1000..  Training Loss: 0.136..  Test Loss: 0.749..  Test Accuracy: 0.847\n",
      "Epoch: 665/1000..  Training Loss: 0.192..  Test Loss: 0.757..  Test Accuracy: 0.847\n",
      "Epoch: 666/1000..  Training Loss: 0.194..  Test Loss: 0.770..  Test Accuracy: 0.847\n",
      "Epoch: 667/1000..  Training Loss: 0.218..  Test Loss: 0.757..  Test Accuracy: 0.847\n",
      "Epoch: 668/1000..  Training Loss: 0.235..  Test Loss: 0.755..  Test Accuracy: 0.847\n",
      "Epoch: 669/1000..  Training Loss: 0.250..  Test Loss: 0.779..  Test Accuracy: 0.842\n",
      "Epoch: 670/1000..  Training Loss: 0.258..  Test Loss: 0.764..  Test Accuracy: 0.847\n",
      "Epoch: 671/1000..  Training Loss: 0.285..  Test Loss: 0.771..  Test Accuracy: 0.845\n",
      "Epoch: 672/1000..  Training Loss: 0.293..  Test Loss: 0.771..  Test Accuracy: 0.845\n",
      "Epoch: 673/1000..  Training Loss: 0.137..  Test Loss: 0.766..  Test Accuracy: 0.845\n",
      "Epoch: 674/1000..  Training Loss: 0.158..  Test Loss: 0.741..  Test Accuracy: 0.850\n",
      "Epoch: 675/1000..  Training Loss: 0.159..  Test Loss: 0.769..  Test Accuracy: 0.847\n",
      "Epoch: 676/1000..  Training Loss: 0.160..  Test Loss: 0.785..  Test Accuracy: 0.842\n",
      "Epoch: 677/1000..  Training Loss: 0.113..  Test Loss: 0.757..  Test Accuracy: 0.847\n",
      "Epoch: 678/1000..  Training Loss: 0.226..  Test Loss: 0.766..  Test Accuracy: 0.843\n",
      "Epoch: 679/1000..  Training Loss: 0.186..  Test Loss: 0.754..  Test Accuracy: 0.849\n",
      "Epoch: 680/1000..  Training Loss: 0.155..  Test Loss: 0.769..  Test Accuracy: 0.843\n",
      "Epoch: 681/1000..  Training Loss: 0.138..  Test Loss: 0.775..  Test Accuracy: 0.844\n",
      "Epoch: 682/1000..  Training Loss: 0.154..  Test Loss: 0.797..  Test Accuracy: 0.843\n",
      "Epoch: 683/1000..  Training Loss: 0.206..  Test Loss: 0.794..  Test Accuracy: 0.843\n",
      "Epoch: 684/1000..  Training Loss: 0.127..  Test Loss: 0.749..  Test Accuracy: 0.849\n",
      "Epoch: 685/1000..  Training Loss: 0.150..  Test Loss: 0.761..  Test Accuracy: 0.846\n",
      "Epoch: 686/1000..  Training Loss: 0.178..  Test Loss: 0.773..  Test Accuracy: 0.845\n",
      "Epoch: 687/1000..  Training Loss: 0.222..  Test Loss: 0.781..  Test Accuracy: 0.843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 688/1000..  Training Loss: 0.189..  Test Loss: 0.765..  Test Accuracy: 0.845\n",
      "Epoch: 689/1000..  Training Loss: 0.192..  Test Loss: 0.772..  Test Accuracy: 0.845\n",
      "Epoch: 690/1000..  Training Loss: 0.222..  Test Loss: 0.746..  Test Accuracy: 0.850\n",
      "Epoch: 691/1000..  Training Loss: 0.140..  Test Loss: 0.741..  Test Accuracy: 0.848\n",
      "Epoch: 692/1000..  Training Loss: 0.189..  Test Loss: 0.762..  Test Accuracy: 0.848\n",
      "Epoch: 693/1000..  Training Loss: 0.160..  Test Loss: 0.768..  Test Accuracy: 0.848\n",
      "Epoch: 694/1000..  Training Loss: 0.207..  Test Loss: 0.733..  Test Accuracy: 0.850\n",
      "Epoch: 695/1000..  Training Loss: 0.179..  Test Loss: 0.757..  Test Accuracy: 0.845\n",
      "Epoch: 696/1000..  Training Loss: 0.243..  Test Loss: 0.763..  Test Accuracy: 0.847\n",
      "Epoch: 697/1000..  Training Loss: 0.126..  Test Loss: 0.724..  Test Accuracy: 0.853\n",
      "Epoch: 698/1000..  Training Loss: 0.197..  Test Loss: 0.762..  Test Accuracy: 0.844\n",
      "Epoch: 699/1000..  Training Loss: 0.184..  Test Loss: 0.747..  Test Accuracy: 0.847\n",
      "Epoch: 700/1000..  Training Loss: 0.242..  Test Loss: 0.762..  Test Accuracy: 0.846\n",
      "Epoch: 701/1000..  Training Loss: 0.161..  Test Loss: 0.786..  Test Accuracy: 0.842\n",
      "Epoch: 702/1000..  Training Loss: 0.157..  Test Loss: 0.737..  Test Accuracy: 0.847\n",
      "Epoch: 703/1000..  Training Loss: 0.202..  Test Loss: 0.751..  Test Accuracy: 0.848\n",
      "Epoch: 704/1000..  Training Loss: 0.169..  Test Loss: 0.762..  Test Accuracy: 0.846\n",
      "Epoch: 705/1000..  Training Loss: 0.183..  Test Loss: 0.758..  Test Accuracy: 0.848\n",
      "Epoch: 706/1000..  Training Loss: 0.148..  Test Loss: 0.757..  Test Accuracy: 0.847\n",
      "Epoch: 707/1000..  Training Loss: 0.168..  Test Loss: 0.752..  Test Accuracy: 0.847\n",
      "Epoch: 708/1000..  Training Loss: 0.211..  Test Loss: 0.749..  Test Accuracy: 0.846\n",
      "Epoch: 709/1000..  Training Loss: 0.183..  Test Loss: 0.799..  Test Accuracy: 0.842\n",
      "Epoch: 710/1000..  Training Loss: 0.180..  Test Loss: 0.791..  Test Accuracy: 0.842\n",
      "Epoch: 711/1000..  Training Loss: 0.219..  Test Loss: 0.768..  Test Accuracy: 0.845\n",
      "Epoch: 712/1000..  Training Loss: 0.180..  Test Loss: 0.747..  Test Accuracy: 0.848\n",
      "Epoch: 713/1000..  Training Loss: 0.188..  Test Loss: 0.775..  Test Accuracy: 0.846\n",
      "Epoch: 714/1000..  Training Loss: 0.154..  Test Loss: 0.784..  Test Accuracy: 0.845\n",
      "Epoch: 715/1000..  Training Loss: 0.202..  Test Loss: 0.766..  Test Accuracy: 0.848\n",
      "Epoch: 716/1000..  Training Loss: 0.211..  Test Loss: 0.762..  Test Accuracy: 0.847\n",
      "Epoch: 717/1000..  Training Loss: 0.197..  Test Loss: 0.770..  Test Accuracy: 0.845\n",
      "Epoch: 718/1000..  Training Loss: 0.170..  Test Loss: 0.790..  Test Accuracy: 0.843\n",
      "Epoch: 719/1000..  Training Loss: 0.148..  Test Loss: 0.762..  Test Accuracy: 0.849\n",
      "Epoch: 720/1000..  Training Loss: 0.153..  Test Loss: 0.748..  Test Accuracy: 0.851\n",
      "Epoch: 721/1000..  Training Loss: 0.230..  Test Loss: 0.732..  Test Accuracy: 0.853\n",
      "Epoch: 722/1000..  Training Loss: 0.222..  Test Loss: 0.736..  Test Accuracy: 0.851\n",
      "Epoch: 723/1000..  Training Loss: 0.163..  Test Loss: 0.763..  Test Accuracy: 0.845\n",
      "Epoch: 724/1000..  Training Loss: 0.241..  Test Loss: 0.759..  Test Accuracy: 0.848\n",
      "Epoch: 725/1000..  Training Loss: 0.244..  Test Loss: 0.758..  Test Accuracy: 0.845\n",
      "Epoch: 726/1000..  Training Loss: 0.178..  Test Loss: 0.780..  Test Accuracy: 0.844\n",
      "Epoch: 727/1000..  Training Loss: 0.216..  Test Loss: 0.780..  Test Accuracy: 0.845\n",
      "Epoch: 728/1000..  Training Loss: 0.217..  Test Loss: 0.786..  Test Accuracy: 0.843\n",
      "Epoch: 729/1000..  Training Loss: 0.173..  Test Loss: 0.775..  Test Accuracy: 0.843\n",
      "Epoch: 730/1000..  Training Loss: 0.107..  Test Loss: 0.737..  Test Accuracy: 0.849\n",
      "Epoch: 731/1000..  Training Loss: 0.194..  Test Loss: 0.758..  Test Accuracy: 0.849\n",
      "Epoch: 732/1000..  Training Loss: 0.151..  Test Loss: 0.765..  Test Accuracy: 0.848\n",
      "Epoch: 733/1000..  Training Loss: 0.187..  Test Loss: 0.726..  Test Accuracy: 0.852\n",
      "Epoch: 734/1000..  Training Loss: 0.175..  Test Loss: 0.741..  Test Accuracy: 0.850\n",
      "Epoch: 735/1000..  Training Loss: 0.177..  Test Loss: 0.756..  Test Accuracy: 0.844\n",
      "Epoch: 736/1000..  Training Loss: 0.161..  Test Loss: 0.750..  Test Accuracy: 0.847\n",
      "Epoch: 737/1000..  Training Loss: 0.199..  Test Loss: 0.752..  Test Accuracy: 0.846\n",
      "Epoch: 738/1000..  Training Loss: 0.114..  Test Loss: 0.764..  Test Accuracy: 0.844\n",
      "Epoch: 739/1000..  Training Loss: 0.124..  Test Loss: 0.752..  Test Accuracy: 0.850\n",
      "Epoch: 740/1000..  Training Loss: 0.192..  Test Loss: 0.751..  Test Accuracy: 0.849\n",
      "Epoch: 741/1000..  Training Loss: 0.172..  Test Loss: 0.813..  Test Accuracy: 0.839\n",
      "Epoch: 742/1000..  Training Loss: 0.133..  Test Loss: 0.761..  Test Accuracy: 0.846\n",
      "Epoch: 743/1000..  Training Loss: 0.175..  Test Loss: 0.760..  Test Accuracy: 0.849\n",
      "Epoch: 744/1000..  Training Loss: 0.163..  Test Loss: 0.745..  Test Accuracy: 0.851\n",
      "Epoch: 745/1000..  Training Loss: 0.156..  Test Loss: 0.785..  Test Accuracy: 0.843\n",
      "Epoch: 746/1000..  Training Loss: 0.168..  Test Loss: 0.765..  Test Accuracy: 0.848\n",
      "Epoch: 747/1000..  Training Loss: 0.192..  Test Loss: 0.760..  Test Accuracy: 0.847\n",
      "Epoch: 748/1000..  Training Loss: 0.203..  Test Loss: 0.764..  Test Accuracy: 0.846\n",
      "Epoch: 749/1000..  Training Loss: 0.207..  Test Loss: 0.733..  Test Accuracy: 0.849\n",
      "Epoch: 750/1000..  Training Loss: 0.151..  Test Loss: 0.743..  Test Accuracy: 0.851\n",
      "Epoch: 751/1000..  Training Loss: 0.137..  Test Loss: 0.749..  Test Accuracy: 0.848\n",
      "Epoch: 752/1000..  Training Loss: 0.160..  Test Loss: 0.737..  Test Accuracy: 0.851\n",
      "Epoch: 753/1000..  Training Loss: 0.212..  Test Loss: 0.750..  Test Accuracy: 0.849\n",
      "Epoch: 754/1000..  Training Loss: 0.186..  Test Loss: 0.757..  Test Accuracy: 0.847\n",
      "Epoch: 755/1000..  Training Loss: 0.137..  Test Loss: 0.803..  Test Accuracy: 0.841\n",
      "Epoch: 756/1000..  Training Loss: 0.249..  Test Loss: 0.777..  Test Accuracy: 0.845\n",
      "Epoch: 757/1000..  Training Loss: 0.146..  Test Loss: 0.787..  Test Accuracy: 0.843\n",
      "Epoch: 758/1000..  Training Loss: 0.170..  Test Loss: 0.783..  Test Accuracy: 0.842\n",
      "Epoch: 759/1000..  Training Loss: 0.177..  Test Loss: 0.749..  Test Accuracy: 0.848\n",
      "Epoch: 760/1000..  Training Loss: 0.227..  Test Loss: 0.774..  Test Accuracy: 0.842\n",
      "Epoch: 761/1000..  Training Loss: 0.159..  Test Loss: 0.761..  Test Accuracy: 0.845\n",
      "Epoch: 762/1000..  Training Loss: 0.204..  Test Loss: 0.775..  Test Accuracy: 0.845\n",
      "Epoch: 763/1000..  Training Loss: 0.188..  Test Loss: 0.758..  Test Accuracy: 0.846\n",
      "Epoch: 764/1000..  Training Loss: 0.218..  Test Loss: 0.762..  Test Accuracy: 0.846\n",
      "Epoch: 765/1000..  Training Loss: 0.213..  Test Loss: 0.762..  Test Accuracy: 0.847\n",
      "Epoch: 766/1000..  Training Loss: 0.167..  Test Loss: 0.769..  Test Accuracy: 0.848\n",
      "Epoch: 767/1000..  Training Loss: 0.169..  Test Loss: 0.768..  Test Accuracy: 0.846\n",
      "Epoch: 768/1000..  Training Loss: 0.162..  Test Loss: 0.760..  Test Accuracy: 0.845\n",
      "Epoch: 769/1000..  Training Loss: 0.176..  Test Loss: 0.750..  Test Accuracy: 0.849\n",
      "Epoch: 770/1000..  Training Loss: 0.212..  Test Loss: 0.730..  Test Accuracy: 0.852\n",
      "Epoch: 771/1000..  Training Loss: 0.223..  Test Loss: 0.763..  Test Accuracy: 0.848\n",
      "Epoch: 772/1000..  Training Loss: 0.260..  Test Loss: 0.743..  Test Accuracy: 0.849\n",
      "Epoch: 773/1000..  Training Loss: 0.158..  Test Loss: 0.801..  Test Accuracy: 0.840\n",
      "Epoch: 774/1000..  Training Loss: 0.252..  Test Loss: 0.759..  Test Accuracy: 0.848\n",
      "Epoch: 775/1000..  Training Loss: 0.205..  Test Loss: 0.754..  Test Accuracy: 0.847\n",
      "Epoch: 776/1000..  Training Loss: 0.192..  Test Loss: 0.779..  Test Accuracy: 0.844\n",
      "Epoch: 777/1000..  Training Loss: 0.261..  Test Loss: 0.752..  Test Accuracy: 0.849\n",
      "Epoch: 778/1000..  Training Loss: 0.193..  Test Loss: 0.751..  Test Accuracy: 0.847\n",
      "Epoch: 779/1000..  Training Loss: 0.158..  Test Loss: 0.727..  Test Accuracy: 0.852\n",
      "Epoch: 780/1000..  Training Loss: 0.193..  Test Loss: 0.743..  Test Accuracy: 0.850\n",
      "Epoch: 781/1000..  Training Loss: 0.237..  Test Loss: 0.745..  Test Accuracy: 0.849\n",
      "Epoch: 782/1000..  Training Loss: 0.155..  Test Loss: 0.807..  Test Accuracy: 0.840\n",
      "Epoch: 783/1000..  Training Loss: 0.143..  Test Loss: 0.743..  Test Accuracy: 0.849\n",
      "Epoch: 784/1000..  Training Loss: 0.176..  Test Loss: 0.749..  Test Accuracy: 0.847\n",
      "Epoch: 785/1000..  Training Loss: 0.148..  Test Loss: 0.747..  Test Accuracy: 0.847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 786/1000..  Training Loss: 0.239..  Test Loss: 0.798..  Test Accuracy: 0.840\n",
      "Epoch: 787/1000..  Training Loss: 0.186..  Test Loss: 0.778..  Test Accuracy: 0.843\n",
      "Epoch: 788/1000..  Training Loss: 0.169..  Test Loss: 0.774..  Test Accuracy: 0.844\n",
      "Epoch: 789/1000..  Training Loss: 0.202..  Test Loss: 0.745..  Test Accuracy: 0.848\n",
      "Epoch: 790/1000..  Training Loss: 0.192..  Test Loss: 0.811..  Test Accuracy: 0.840\n",
      "Epoch: 791/1000..  Training Loss: 0.089..  Test Loss: 0.807..  Test Accuracy: 0.842\n",
      "Epoch: 792/1000..  Training Loss: 0.230..  Test Loss: 0.810..  Test Accuracy: 0.841\n",
      "Epoch: 793/1000..  Training Loss: 0.218..  Test Loss: 0.784..  Test Accuracy: 0.843\n",
      "Epoch: 794/1000..  Training Loss: 0.288..  Test Loss: 0.774..  Test Accuracy: 0.847\n",
      "Epoch: 795/1000..  Training Loss: 0.174..  Test Loss: 0.760..  Test Accuracy: 0.848\n",
      "Epoch: 796/1000..  Training Loss: 0.124..  Test Loss: 0.785..  Test Accuracy: 0.844\n",
      "Epoch: 797/1000..  Training Loss: 0.173..  Test Loss: 0.784..  Test Accuracy: 0.845\n",
      "Epoch: 798/1000..  Training Loss: 0.140..  Test Loss: 0.792..  Test Accuracy: 0.844\n",
      "Epoch: 799/1000..  Training Loss: 0.174..  Test Loss: 0.788..  Test Accuracy: 0.842\n",
      "Epoch: 800/1000..  Training Loss: 0.175..  Test Loss: 0.818..  Test Accuracy: 0.839\n",
      "Epoch: 801/1000..  Training Loss: 0.190..  Test Loss: 0.791..  Test Accuracy: 0.845\n",
      "Epoch: 802/1000..  Training Loss: 0.188..  Test Loss: 0.769..  Test Accuracy: 0.847\n",
      "Epoch: 803/1000..  Training Loss: 0.172..  Test Loss: 0.764..  Test Accuracy: 0.847\n",
      "Epoch: 804/1000..  Training Loss: 0.151..  Test Loss: 0.783..  Test Accuracy: 0.843\n",
      "Epoch: 805/1000..  Training Loss: 0.112..  Test Loss: 0.746..  Test Accuracy: 0.849\n",
      "Epoch: 806/1000..  Training Loss: 0.219..  Test Loss: 0.752..  Test Accuracy: 0.850\n",
      "Epoch: 807/1000..  Training Loss: 0.164..  Test Loss: 0.782..  Test Accuracy: 0.842\n",
      "Epoch: 808/1000..  Training Loss: 0.148..  Test Loss: 0.777..  Test Accuracy: 0.846\n",
      "Epoch: 809/1000..  Training Loss: 0.112..  Test Loss: 0.750..  Test Accuracy: 0.849\n",
      "Epoch: 810/1000..  Training Loss: 0.198..  Test Loss: 0.772..  Test Accuracy: 0.842\n",
      "Epoch: 811/1000..  Training Loss: 0.219..  Test Loss: 0.760..  Test Accuracy: 0.848\n",
      "Epoch: 812/1000..  Training Loss: 0.204..  Test Loss: 0.785..  Test Accuracy: 0.841\n",
      "Epoch: 813/1000..  Training Loss: 0.194..  Test Loss: 0.762..  Test Accuracy: 0.845\n",
      "Epoch: 814/1000..  Training Loss: 0.174..  Test Loss: 0.778..  Test Accuracy: 0.843\n",
      "Epoch: 815/1000..  Training Loss: 0.193..  Test Loss: 0.751..  Test Accuracy: 0.847\n",
      "Epoch: 816/1000..  Training Loss: 0.147..  Test Loss: 0.755..  Test Accuracy: 0.847\n",
      "Epoch: 817/1000..  Training Loss: 0.144..  Test Loss: 0.746..  Test Accuracy: 0.850\n",
      "Epoch: 818/1000..  Training Loss: 0.148..  Test Loss: 0.770..  Test Accuracy: 0.846\n",
      "Epoch: 819/1000..  Training Loss: 0.234..  Test Loss: 0.784..  Test Accuracy: 0.846\n",
      "Epoch: 820/1000..  Training Loss: 0.267..  Test Loss: 0.777..  Test Accuracy: 0.844\n",
      "Epoch: 821/1000..  Training Loss: 0.161..  Test Loss: 0.772..  Test Accuracy: 0.846\n",
      "Epoch: 822/1000..  Training Loss: 0.139..  Test Loss: 0.761..  Test Accuracy: 0.846\n",
      "Epoch: 823/1000..  Training Loss: 0.287..  Test Loss: 0.791..  Test Accuracy: 0.842\n",
      "Epoch: 824/1000..  Training Loss: 0.198..  Test Loss: 0.777..  Test Accuracy: 0.842\n",
      "Epoch: 825/1000..  Training Loss: 0.160..  Test Loss: 0.789..  Test Accuracy: 0.844\n",
      "Epoch: 826/1000..  Training Loss: 0.170..  Test Loss: 0.776..  Test Accuracy: 0.845\n",
      "Epoch: 827/1000..  Training Loss: 0.154..  Test Loss: 0.795..  Test Accuracy: 0.843\n",
      "Epoch: 828/1000..  Training Loss: 0.147..  Test Loss: 0.782..  Test Accuracy: 0.844\n",
      "Epoch: 829/1000..  Training Loss: 0.234..  Test Loss: 0.774..  Test Accuracy: 0.845\n",
      "Epoch: 830/1000..  Training Loss: 0.160..  Test Loss: 0.758..  Test Accuracy: 0.847\n",
      "Epoch: 831/1000..  Training Loss: 0.209..  Test Loss: 0.776..  Test Accuracy: 0.844\n",
      "Epoch: 832/1000..  Training Loss: 0.258..  Test Loss: 0.772..  Test Accuracy: 0.844\n",
      "Epoch: 833/1000..  Training Loss: 0.159..  Test Loss: 0.745..  Test Accuracy: 0.849\n",
      "Epoch: 834/1000..  Training Loss: 0.159..  Test Loss: 0.763..  Test Accuracy: 0.846\n",
      "Epoch: 835/1000..  Training Loss: 0.139..  Test Loss: 0.775..  Test Accuracy: 0.843\n",
      "Epoch: 836/1000..  Training Loss: 0.218..  Test Loss: 0.773..  Test Accuracy: 0.846\n",
      "Epoch: 837/1000..  Training Loss: 0.153..  Test Loss: 0.760..  Test Accuracy: 0.845\n",
      "Epoch: 838/1000..  Training Loss: 0.158..  Test Loss: 0.760..  Test Accuracy: 0.844\n",
      "Epoch: 839/1000..  Training Loss: 0.166..  Test Loss: 0.772..  Test Accuracy: 0.845\n",
      "Epoch: 840/1000..  Training Loss: 0.175..  Test Loss: 0.748..  Test Accuracy: 0.848\n",
      "Epoch: 841/1000..  Training Loss: 0.220..  Test Loss: 0.791..  Test Accuracy: 0.843\n",
      "Epoch: 842/1000..  Training Loss: 0.135..  Test Loss: 0.767..  Test Accuracy: 0.845\n",
      "Epoch: 843/1000..  Training Loss: 0.179..  Test Loss: 0.792..  Test Accuracy: 0.844\n",
      "Epoch: 844/1000..  Training Loss: 0.172..  Test Loss: 0.747..  Test Accuracy: 0.849\n",
      "Epoch: 845/1000..  Training Loss: 0.236..  Test Loss: 0.795..  Test Accuracy: 0.840\n",
      "Epoch: 846/1000..  Training Loss: 0.240..  Test Loss: 0.768..  Test Accuracy: 0.846\n",
      "Epoch: 847/1000..  Training Loss: 0.114..  Test Loss: 0.779..  Test Accuracy: 0.844\n",
      "Epoch: 848/1000..  Training Loss: 0.153..  Test Loss: 0.807..  Test Accuracy: 0.840\n",
      "Epoch: 849/1000..  Training Loss: 0.212..  Test Loss: 0.781..  Test Accuracy: 0.844\n",
      "Epoch: 850/1000..  Training Loss: 0.170..  Test Loss: 0.775..  Test Accuracy: 0.847\n",
      "Epoch: 851/1000..  Training Loss: 0.246..  Test Loss: 0.769..  Test Accuracy: 0.844\n",
      "Epoch: 852/1000..  Training Loss: 0.203..  Test Loss: 0.764..  Test Accuracy: 0.848\n",
      "Epoch: 853/1000..  Training Loss: 0.166..  Test Loss: 0.783..  Test Accuracy: 0.843\n",
      "Epoch: 854/1000..  Training Loss: 0.183..  Test Loss: 0.795..  Test Accuracy: 0.843\n",
      "Epoch: 855/1000..  Training Loss: 0.166..  Test Loss: 0.774..  Test Accuracy: 0.844\n",
      "Epoch: 856/1000..  Training Loss: 0.177..  Test Loss: 0.760..  Test Accuracy: 0.846\n",
      "Epoch: 857/1000..  Training Loss: 0.203..  Test Loss: 0.766..  Test Accuracy: 0.845\n",
      "Epoch: 858/1000..  Training Loss: 0.144..  Test Loss: 0.761..  Test Accuracy: 0.847\n",
      "Epoch: 859/1000..  Training Loss: 0.103..  Test Loss: 0.758..  Test Accuracy: 0.847\n",
      "Epoch: 860/1000..  Training Loss: 0.166..  Test Loss: 0.769..  Test Accuracy: 0.845\n",
      "Epoch: 861/1000..  Training Loss: 0.231..  Test Loss: 0.764..  Test Accuracy: 0.846\n",
      "Epoch: 862/1000..  Training Loss: 0.157..  Test Loss: 0.765..  Test Accuracy: 0.848\n",
      "Epoch: 863/1000..  Training Loss: 0.163..  Test Loss: 0.766..  Test Accuracy: 0.847\n",
      "Epoch: 864/1000..  Training Loss: 0.177..  Test Loss: 0.778..  Test Accuracy: 0.845\n",
      "Epoch: 865/1000..  Training Loss: 0.154..  Test Loss: 0.787..  Test Accuracy: 0.842\n",
      "Epoch: 866/1000..  Training Loss: 0.228..  Test Loss: 0.783..  Test Accuracy: 0.844\n",
      "Epoch: 867/1000..  Training Loss: 0.149..  Test Loss: 0.799..  Test Accuracy: 0.842\n",
      "Epoch: 868/1000..  Training Loss: 0.164..  Test Loss: 0.795..  Test Accuracy: 0.840\n",
      "Epoch: 869/1000..  Training Loss: 0.209..  Test Loss: 0.784..  Test Accuracy: 0.842\n",
      "Epoch: 870/1000..  Training Loss: 0.258..  Test Loss: 0.768..  Test Accuracy: 0.846\n",
      "Epoch: 871/1000..  Training Loss: 0.195..  Test Loss: 0.785..  Test Accuracy: 0.845\n",
      "Epoch: 872/1000..  Training Loss: 0.189..  Test Loss: 0.774..  Test Accuracy: 0.847\n",
      "Epoch: 873/1000..  Training Loss: 0.241..  Test Loss: 0.729..  Test Accuracy: 0.853\n",
      "Epoch: 874/1000..  Training Loss: 0.119..  Test Loss: 0.782..  Test Accuracy: 0.845\n",
      "Epoch: 875/1000..  Training Loss: 0.234..  Test Loss: 0.768..  Test Accuracy: 0.845\n",
      "Epoch: 876/1000..  Training Loss: 0.227..  Test Loss: 0.790..  Test Accuracy: 0.844\n",
      "Epoch: 877/1000..  Training Loss: 0.214..  Test Loss: 0.775..  Test Accuracy: 0.846\n",
      "Epoch: 878/1000..  Training Loss: 0.152..  Test Loss: 0.759..  Test Accuracy: 0.850\n",
      "Epoch: 879/1000..  Training Loss: 0.194..  Test Loss: 0.763..  Test Accuracy: 0.847\n",
      "Epoch: 880/1000..  Training Loss: 0.181..  Test Loss: 0.775..  Test Accuracy: 0.847\n",
      "Epoch: 881/1000..  Training Loss: 0.211..  Test Loss: 0.801..  Test Accuracy: 0.842\n",
      "Epoch: 882/1000..  Training Loss: 0.169..  Test Loss: 0.786..  Test Accuracy: 0.844\n",
      "Epoch: 883/1000..  Training Loss: 0.171..  Test Loss: 0.788..  Test Accuracy: 0.843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 884/1000..  Training Loss: 0.113..  Test Loss: 0.769..  Test Accuracy: 0.846\n",
      "Epoch: 885/1000..  Training Loss: 0.255..  Test Loss: 0.805..  Test Accuracy: 0.839\n",
      "Epoch: 886/1000..  Training Loss: 0.169..  Test Loss: 0.799..  Test Accuracy: 0.843\n",
      "Epoch: 887/1000..  Training Loss: 0.268..  Test Loss: 0.776..  Test Accuracy: 0.845\n",
      "Epoch: 888/1000..  Training Loss: 0.191..  Test Loss: 0.809..  Test Accuracy: 0.839\n",
      "Epoch: 889/1000..  Training Loss: 0.199..  Test Loss: 0.772..  Test Accuracy: 0.844\n",
      "Epoch: 890/1000..  Training Loss: 0.150..  Test Loss: 0.768..  Test Accuracy: 0.848\n",
      "Epoch: 891/1000..  Training Loss: 0.123..  Test Loss: 0.760..  Test Accuracy: 0.850\n",
      "Epoch: 892/1000..  Training Loss: 0.188..  Test Loss: 0.760..  Test Accuracy: 0.849\n",
      "Epoch: 893/1000..  Training Loss: 0.134..  Test Loss: 0.785..  Test Accuracy: 0.845\n",
      "Epoch: 894/1000..  Training Loss: 0.126..  Test Loss: 0.789..  Test Accuracy: 0.845\n",
      "Epoch: 895/1000..  Training Loss: 0.222..  Test Loss: 0.803..  Test Accuracy: 0.841\n",
      "Epoch: 896/1000..  Training Loss: 0.132..  Test Loss: 0.775..  Test Accuracy: 0.846\n",
      "Epoch: 897/1000..  Training Loss: 0.168..  Test Loss: 0.762..  Test Accuracy: 0.849\n",
      "Epoch: 898/1000..  Training Loss: 0.097..  Test Loss: 0.769..  Test Accuracy: 0.847\n",
      "Epoch: 899/1000..  Training Loss: 0.266..  Test Loss: 0.800..  Test Accuracy: 0.844\n",
      "Epoch: 900/1000..  Training Loss: 0.118..  Test Loss: 0.809..  Test Accuracy: 0.842\n",
      "Epoch: 901/1000..  Training Loss: 0.204..  Test Loss: 0.767..  Test Accuracy: 0.846\n",
      "Epoch: 902/1000..  Training Loss: 0.141..  Test Loss: 0.740..  Test Accuracy: 0.852\n",
      "Epoch: 903/1000..  Training Loss: 0.175..  Test Loss: 0.764..  Test Accuracy: 0.848\n",
      "Epoch: 904/1000..  Training Loss: 0.180..  Test Loss: 0.760..  Test Accuracy: 0.851\n",
      "Epoch: 905/1000..  Training Loss: 0.178..  Test Loss: 0.749..  Test Accuracy: 0.849\n",
      "Epoch: 906/1000..  Training Loss: 0.200..  Test Loss: 0.768..  Test Accuracy: 0.846\n",
      "Epoch: 907/1000..  Training Loss: 0.146..  Test Loss: 0.754..  Test Accuracy: 0.850\n",
      "Epoch: 908/1000..  Training Loss: 0.269..  Test Loss: 0.770..  Test Accuracy: 0.849\n",
      "Epoch: 909/1000..  Training Loss: 0.159..  Test Loss: 0.759..  Test Accuracy: 0.846\n",
      "Epoch: 910/1000..  Training Loss: 0.151..  Test Loss: 0.775..  Test Accuracy: 0.844\n",
      "Epoch: 911/1000..  Training Loss: 0.173..  Test Loss: 0.795..  Test Accuracy: 0.843\n",
      "Epoch: 912/1000..  Training Loss: 0.177..  Test Loss: 0.772..  Test Accuracy: 0.846\n",
      "Epoch: 913/1000..  Training Loss: 0.177..  Test Loss: 0.765..  Test Accuracy: 0.847\n",
      "Epoch: 914/1000..  Training Loss: 0.174..  Test Loss: 0.761..  Test Accuracy: 0.848\n",
      "Epoch: 915/1000..  Training Loss: 0.186..  Test Loss: 0.765..  Test Accuracy: 0.850\n",
      "Epoch: 916/1000..  Training Loss: 0.168..  Test Loss: 0.762..  Test Accuracy: 0.850\n",
      "Epoch: 917/1000..  Training Loss: 0.149..  Test Loss: 0.760..  Test Accuracy: 0.850\n",
      "Epoch: 918/1000..  Training Loss: 0.223..  Test Loss: 0.770..  Test Accuracy: 0.849\n",
      "Epoch: 919/1000..  Training Loss: 0.159..  Test Loss: 0.763..  Test Accuracy: 0.849\n",
      "Epoch: 920/1000..  Training Loss: 0.181..  Test Loss: 0.779..  Test Accuracy: 0.844\n",
      "Epoch: 921/1000..  Training Loss: 0.234..  Test Loss: 0.756..  Test Accuracy: 0.848\n",
      "Epoch: 922/1000..  Training Loss: 0.163..  Test Loss: 0.769..  Test Accuracy: 0.847\n",
      "Epoch: 923/1000..  Training Loss: 0.154..  Test Loss: 0.760..  Test Accuracy: 0.850\n",
      "Epoch: 924/1000..  Training Loss: 0.189..  Test Loss: 0.776..  Test Accuracy: 0.846\n",
      "Epoch: 925/1000..  Training Loss: 0.162..  Test Loss: 0.777..  Test Accuracy: 0.847\n",
      "Epoch: 926/1000..  Training Loss: 0.178..  Test Loss: 0.785..  Test Accuracy: 0.846\n",
      "Epoch: 927/1000..  Training Loss: 0.195..  Test Loss: 0.809..  Test Accuracy: 0.844\n",
      "Epoch: 928/1000..  Training Loss: 0.158..  Test Loss: 0.795..  Test Accuracy: 0.843\n",
      "Epoch: 929/1000..  Training Loss: 0.166..  Test Loss: 0.776..  Test Accuracy: 0.844\n",
      "Epoch: 930/1000..  Training Loss: 0.116..  Test Loss: 0.761..  Test Accuracy: 0.849\n",
      "Epoch: 931/1000..  Training Loss: 0.261..  Test Loss: 0.757..  Test Accuracy: 0.847\n",
      "Epoch: 932/1000..  Training Loss: 0.196..  Test Loss: 0.772..  Test Accuracy: 0.845\n",
      "Epoch: 933/1000..  Training Loss: 0.183..  Test Loss: 0.767..  Test Accuracy: 0.847\n",
      "Epoch: 934/1000..  Training Loss: 0.209..  Test Loss: 0.775..  Test Accuracy: 0.848\n",
      "Epoch: 935/1000..  Training Loss: 0.160..  Test Loss: 0.773..  Test Accuracy: 0.844\n",
      "Epoch: 936/1000..  Training Loss: 0.200..  Test Loss: 0.767..  Test Accuracy: 0.848\n",
      "Epoch: 937/1000..  Training Loss: 0.183..  Test Loss: 0.801..  Test Accuracy: 0.843\n",
      "Epoch: 938/1000..  Training Loss: 0.211..  Test Loss: 0.802..  Test Accuracy: 0.843\n",
      "Epoch: 939/1000..  Training Loss: 0.206..  Test Loss: 0.804..  Test Accuracy: 0.840\n",
      "Epoch: 940/1000..  Training Loss: 0.214..  Test Loss: 0.761..  Test Accuracy: 0.847\n",
      "Epoch: 941/1000..  Training Loss: 0.199..  Test Loss: 0.774..  Test Accuracy: 0.846\n",
      "Epoch: 942/1000..  Training Loss: 0.221..  Test Loss: 0.742..  Test Accuracy: 0.851\n",
      "Epoch: 943/1000..  Training Loss: 0.165..  Test Loss: 0.744..  Test Accuracy: 0.849\n",
      "Epoch: 944/1000..  Training Loss: 0.163..  Test Loss: 0.754..  Test Accuracy: 0.850\n",
      "Epoch: 945/1000..  Training Loss: 0.194..  Test Loss: 0.760..  Test Accuracy: 0.848\n",
      "Epoch: 946/1000..  Training Loss: 0.138..  Test Loss: 0.752..  Test Accuracy: 0.851\n",
      "Epoch: 947/1000..  Training Loss: 0.169..  Test Loss: 0.743..  Test Accuracy: 0.851\n",
      "Epoch: 948/1000..  Training Loss: 0.164..  Test Loss: 0.751..  Test Accuracy: 0.850\n",
      "Epoch: 949/1000..  Training Loss: 0.174..  Test Loss: 0.761..  Test Accuracy: 0.851\n",
      "Epoch: 950/1000..  Training Loss: 0.180..  Test Loss: 0.758..  Test Accuracy: 0.850\n",
      "Epoch: 951/1000..  Training Loss: 0.290..  Test Loss: 0.782..  Test Accuracy: 0.846\n",
      "Epoch: 952/1000..  Training Loss: 0.139..  Test Loss: 0.785..  Test Accuracy: 0.844\n",
      "Epoch: 953/1000..  Training Loss: 0.170..  Test Loss: 0.746..  Test Accuracy: 0.849\n",
      "Epoch: 954/1000..  Training Loss: 0.297..  Test Loss: 0.761..  Test Accuracy: 0.847\n",
      "Epoch: 955/1000..  Training Loss: 0.203..  Test Loss: 0.769..  Test Accuracy: 0.848\n",
      "Epoch: 956/1000..  Training Loss: 0.123..  Test Loss: 0.778..  Test Accuracy: 0.846\n",
      "Epoch: 957/1000..  Training Loss: 0.144..  Test Loss: 0.746..  Test Accuracy: 0.852\n",
      "Epoch: 958/1000..  Training Loss: 0.119..  Test Loss: 0.761..  Test Accuracy: 0.850\n",
      "Epoch: 959/1000..  Training Loss: 0.222..  Test Loss: 0.773..  Test Accuracy: 0.847\n",
      "Epoch: 960/1000..  Training Loss: 0.242..  Test Loss: 0.771..  Test Accuracy: 0.847\n",
      "Epoch: 961/1000..  Training Loss: 0.163..  Test Loss: 0.748..  Test Accuracy: 0.850\n",
      "Epoch: 962/1000..  Training Loss: 0.312..  Test Loss: 0.749..  Test Accuracy: 0.851\n",
      "Epoch: 963/1000..  Training Loss: 0.165..  Test Loss: 0.763..  Test Accuracy: 0.849\n",
      "Epoch: 964/1000..  Training Loss: 0.245..  Test Loss: 0.738..  Test Accuracy: 0.851\n",
      "Epoch: 965/1000..  Training Loss: 0.152..  Test Loss: 0.738..  Test Accuracy: 0.851\n",
      "Epoch: 966/1000..  Training Loss: 0.158..  Test Loss: 0.766..  Test Accuracy: 0.848\n",
      "Epoch: 967/1000..  Training Loss: 0.151..  Test Loss: 0.769..  Test Accuracy: 0.849\n",
      "Epoch: 968/1000..  Training Loss: 0.238..  Test Loss: 0.753..  Test Accuracy: 0.852\n",
      "Epoch: 969/1000..  Training Loss: 0.231..  Test Loss: 0.752..  Test Accuracy: 0.852\n",
      "Epoch: 970/1000..  Training Loss: 0.160..  Test Loss: 0.755..  Test Accuracy: 0.849\n",
      "Epoch: 971/1000..  Training Loss: 0.116..  Test Loss: 0.775..  Test Accuracy: 0.847\n",
      "Epoch: 972/1000..  Training Loss: 0.157..  Test Loss: 0.776..  Test Accuracy: 0.846\n",
      "Epoch: 973/1000..  Training Loss: 0.154..  Test Loss: 0.747..  Test Accuracy: 0.850\n",
      "Epoch: 974/1000..  Training Loss: 0.185..  Test Loss: 0.766..  Test Accuracy: 0.847\n",
      "Epoch: 975/1000..  Training Loss: 0.131..  Test Loss: 0.765..  Test Accuracy: 0.848\n",
      "Epoch: 976/1000..  Training Loss: 0.212..  Test Loss: 0.780..  Test Accuracy: 0.847\n",
      "Epoch: 977/1000..  Training Loss: 0.197..  Test Loss: 0.751..  Test Accuracy: 0.849\n",
      "Epoch: 978/1000..  Training Loss: 0.185..  Test Loss: 0.759..  Test Accuracy: 0.848\n",
      "Epoch: 979/1000..  Training Loss: 0.121..  Test Loss: 0.771..  Test Accuracy: 0.847\n",
      "Epoch: 980/1000..  Training Loss: 0.210..  Test Loss: 0.746..  Test Accuracy: 0.852\n",
      "Epoch: 981/1000..  Training Loss: 0.199..  Test Loss: 0.741..  Test Accuracy: 0.850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 982/1000..  Training Loss: 0.125..  Test Loss: 0.748..  Test Accuracy: 0.850\n",
      "Epoch: 983/1000..  Training Loss: 0.153..  Test Loss: 0.798..  Test Accuracy: 0.844\n",
      "Epoch: 984/1000..  Training Loss: 0.165..  Test Loss: 0.761..  Test Accuracy: 0.846\n",
      "Epoch: 985/1000..  Training Loss: 0.162..  Test Loss: 0.759..  Test Accuracy: 0.847\n",
      "Epoch: 986/1000..  Training Loss: 0.127..  Test Loss: 0.781..  Test Accuracy: 0.842\n",
      "Epoch: 987/1000..  Training Loss: 0.193..  Test Loss: 0.767..  Test Accuracy: 0.847\n",
      "Epoch: 988/1000..  Training Loss: 0.148..  Test Loss: 0.754..  Test Accuracy: 0.849\n",
      "Epoch: 989/1000..  Training Loss: 0.181..  Test Loss: 0.746..  Test Accuracy: 0.851\n",
      "Epoch: 990/1000..  Training Loss: 0.120..  Test Loss: 0.757..  Test Accuracy: 0.850\n",
      "Epoch: 991/1000..  Training Loss: 0.194..  Test Loss: 0.737..  Test Accuracy: 0.851\n",
      "Epoch: 992/1000..  Training Loss: 0.152..  Test Loss: 0.763..  Test Accuracy: 0.846\n",
      "Epoch: 993/1000..  Training Loss: 0.151..  Test Loss: 0.789..  Test Accuracy: 0.846\n",
      "Epoch: 994/1000..  Training Loss: 0.188..  Test Loss: 0.757..  Test Accuracy: 0.849\n",
      "Epoch: 995/1000..  Training Loss: 0.140..  Test Loss: 0.764..  Test Accuracy: 0.847\n",
      "Epoch: 996/1000..  Training Loss: 0.154..  Test Loss: 0.745..  Test Accuracy: 0.850\n",
      "Epoch: 997/1000..  Training Loss: 0.133..  Test Loss: 0.773..  Test Accuracy: 0.846\n",
      "Epoch: 998/1000..  Training Loss: 0.133..  Test Loss: 0.748..  Test Accuracy: 0.849\n",
      "Epoch: 999/1000..  Training Loss: 0.207..  Test Loss: 0.765..  Test Accuracy: 0.844\n",
      "Epoch: 1000/1000..  Training Loss: 0.138..  Test Loss: 0.768..  Test Accuracy: 0.844\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "transform = transforms.Compose([transforms.GaussianBlur(kernel_size=7)])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    mask_loss = 0\n",
    "\n",
    "    currentdropout = 0.75\n",
    "\n",
    "    i=0\n",
    "\n",
    "    for images,labels in train_loader:\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        drop = nn.Dropout(p=currentdropout)\n",
    "        mask = drop(torch.rand(images.shape).double())\n",
    "\n",
    "        images = images + transform(drop(mask).view(-1, 1, 28, 28)).view(-1, 784)\n",
    "        images = torch.minimum(images, torch.ones(images.shape))\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "\n",
    "        output = gcnn2(train)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        i+=1\n",
    "\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad(): #Turning off gradients to speed up\n",
    "            gcnn2.eval()\n",
    "            for images,labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(-1,1,28,28))\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "                log_ps = gcnn2(test)\n",
    "                test_loss += criterion(log_ps,labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim = 1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "        gcnn2.train()        \n",
    "        train_losses_gcnn2.append(running_loss/len(train_loader))\n",
    "        test_losses_gcnn2.append(test_loss/len(test_loader))\n",
    "        accuracy_graph_gcnn2.append(accuracy/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x202c1314e20>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses_gcnn2, label='Training loss')\n",
    "plt.plot(test_losses_gcnn2, label='Validation loss')\n",
    "plt.plot(accuracy_graph_gcnn2, label='Accuracy')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS_jfWW6EBNW"
   },
   "source": [
    "# Adversarial Mask CNN, Loss 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "hxfzH1K1g7-X"
   },
   "outputs": [],
   "source": [
    "#loss = number of activated neurons in final layer - difference between label and classification\n",
    "\n",
    "adv=Adv2()\n",
    "adv=adv.double()\n",
    "\n",
    "cnn=CNN()\n",
    "cnn=cnn.double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optCNN = torch.optim.Adam(cnn.parameters(), lr=0.0001)\n",
    "\n",
    "optAdv = torch.optim.Adam(adv.parameters(), lr=0.0001)\n",
    "\n",
    "train_losses_adv1, test_losses_adv1, accuracy_graph_adv1 = [], [], []\n",
    "sample_images_adv1=[]\n",
    "sample_masked_adv1=[]\n",
    "sample_mask_adv1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBTFFPhBg-Gl",
    "outputId": "3c5943d6-2f47-40c0-d697-191ce8829ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000..  Training Loss: 0.012..  Mask Loss: 6.022..  Test Loss: 1.159..  Test Accuracy: 0.799\n",
      "Epoch: 2/10000..  Training Loss: 0.006..  Mask Loss: 6.583..  Test Loss: 1.139..  Test Accuracy: 0.801\n",
      "Epoch: 3/10000..  Training Loss: 0.003..  Mask Loss: 7.081..  Test Loss: 1.127..  Test Accuracy: 0.803\n",
      "Epoch: 4/10000..  Training Loss: 0.007..  Mask Loss: 7.250..  Test Loss: 1.120..  Test Accuracy: 0.804\n",
      "Epoch: 5/10000..  Training Loss: 0.003..  Mask Loss: 6.530..  Test Loss: 1.112..  Test Accuracy: 0.806\n",
      "Epoch: 6/10000..  Training Loss: 0.004..  Mask Loss: 6.928..  Test Loss: 1.106..  Test Accuracy: 0.806\n",
      "Epoch: 7/10000..  Training Loss: 0.004..  Mask Loss: 6.938..  Test Loss: 1.095..  Test Accuracy: 0.808\n",
      "Epoch: 8/10000..  Training Loss: 0.002..  Mask Loss: 6.751..  Test Loss: 1.089..  Test Accuracy: 0.810\n",
      "Epoch: 9/10000..  Training Loss: 0.003..  Mask Loss: 6.701..  Test Loss: 1.083..  Test Accuracy: 0.811\n",
      "Epoch: 10/10000..  Training Loss: 0.015..  Mask Loss: 7.063..  Test Loss: 1.080..  Test Accuracy: 0.811\n",
      "Epoch: 11/10000..  Training Loss: 0.002..  Mask Loss: 6.895..  Test Loss: 1.077..  Test Accuracy: 0.812\n",
      "Epoch: 12/10000..  Training Loss: 0.004..  Mask Loss: 7.209..  Test Loss: 1.073..  Test Accuracy: 0.812\n",
      "Epoch: 13/10000..  Training Loss: 0.002..  Mask Loss: 7.075..  Test Loss: 1.069..  Test Accuracy: 0.812\n",
      "Epoch: 14/10000..  Training Loss: 0.003..  Mask Loss: 6.794..  Test Loss: 1.066..  Test Accuracy: 0.813\n",
      "Epoch: 15/10000..  Training Loss: 0.005..  Mask Loss: 7.441..  Test Loss: 1.063..  Test Accuracy: 0.814\n",
      "Epoch: 16/10000..  Training Loss: 0.002..  Mask Loss: 7.458..  Test Loss: 1.062..  Test Accuracy: 0.814\n",
      "Epoch: 17/10000..  Training Loss: 0.001..  Mask Loss: 7.436..  Test Loss: 1.061..  Test Accuracy: 0.814\n",
      "Epoch: 18/10000..  Training Loss: 0.002..  Mask Loss: 7.449..  Test Loss: 1.061..  Test Accuracy: 0.814\n",
      "Epoch: 19/10000..  Training Loss: 0.001..  Mask Loss: 7.145..  Test Loss: 1.059..  Test Accuracy: 0.815\n",
      "Epoch: 20/10000..  Training Loss: 0.002..  Mask Loss: 7.064..  Test Loss: 1.057..  Test Accuracy: 0.815\n",
      "Epoch: 21/10000..  Training Loss: 0.002..  Mask Loss: 7.285..  Test Loss: 1.055..  Test Accuracy: 0.815\n",
      "Epoch: 22/10000..  Training Loss: 0.003..  Mask Loss: 7.040..  Test Loss: 1.055..  Test Accuracy: 0.815\n",
      "Epoch: 23/10000..  Training Loss: 0.001..  Mask Loss: 7.500..  Test Loss: 1.054..  Test Accuracy: 0.815\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-ab2a9b3d496b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    mask_loss = 0\n",
    "\n",
    "    currentdropout = 0.95\n",
    "    \n",
    "    if(epoch>400):\n",
    "      currentdropout=0.75\n",
    "    else:\n",
    "      currentdropout = 0.95 - epoch*(0.15/400)\n",
    "\n",
    "    i=0\n",
    "\n",
    "    for images,labels in train_loader:\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        if(i==0 and epoch%10==0):\n",
    "          sample_images_adv1.append(train.clone().detach().numpy())\n",
    "\n",
    "        optAdv.zero_grad()\n",
    "        optCNN.zero_grad()\n",
    "\n",
    "        mask = adv(train)\n",
    "        finaldrop = nn.Dropout(p=currentdropout)\n",
    "        mask = finaldrop(mask)\n",
    "\n",
    "        images = images + mask\n",
    "        images = torch.minimum(images, torch.ones(images.shape))\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "\n",
    "        if(i==0 and epoch%10==0):\n",
    "          sample_masked_adv1.append(train.clone().detach().numpy())\n",
    "          sample_mask_adv1.append(mask.clone().detach().view(-1, 1, 28, 28).numpy())\n",
    "\n",
    "        output = cnn(train)\n",
    "\n",
    "        lossAdv = -torch.log(criterion(output, labels))\n",
    "        lossCNN = criterion(output, labels)\n",
    "        \n",
    "        # print(lossAdv)\n",
    "        # print(lossCNN)\n",
    "\n",
    "        if(i%3==0):\n",
    "          lossAdv.backward()\n",
    "          optAdv.step()\n",
    "        else:\n",
    "          lossCNN.backward()\n",
    "          optCNN.step()\n",
    "        \n",
    "        mask_loss += lossAdv.item()\n",
    "        running_loss += lossCNN.item()\n",
    "        i+=1\n",
    "\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad(): #Turning off gradients to speed up\n",
    "            cnn.eval()\n",
    "            for images,labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(-1,1,28,28))\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "                log_ps = cnn(test)\n",
    "                test_loss += criterion(log_ps,labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim = 1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        cnn.train()        \n",
    "        train_losses_adv1.append(running_loss/len(train_loader))\n",
    "        test_losses_adv1.append(test_loss/len(test_loader))\n",
    "        accuracy_graph_adv1.append(accuracy/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Mask Loss: {:.3f}.. \".format(mask_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "xsvTKMvUnskW",
    "outputId": "1a850dcd-4f20-4f81-f2e2-c101d3662ed8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses_adv1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-182a3f7ac6b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_losses_adv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_losses_adv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_graph_adv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_losses_adv1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(train_losses_adv1, label='Training loss')\n",
    "plt.plot(test_losses_adv1, label='Validation loss')\n",
    "plt.plot(accuracy_graph_adv1, label='Accuracy')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x202c120e2e0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_graph_gcnn2, label='Adv')\n",
    "plt.plot(accuracy_graph_gcnn, label='Gauss')\n",
    "plt.plot(accuracy_graph_basecnn, label='Base')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RT06dn6EHDV"
   },
   "source": [
    "# Adversarial Mask CNN, Loss 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "nrX-7B8sFJZN",
    "outputId": "ff9ef209-e622-4a66-c9d4-0ac87c9e3a57"
   },
   "outputs": [],
   "source": [
    "#loss = number of activated neurons in final layer - difference between label and classification\n",
    "\n",
    "adv=Adv3()\n",
    "adv=adv.double()\n",
    "\n",
    "cnn=CNN()\n",
    "cnn=cnn.double()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optCNN = torch.optim.Adam(cnn.parameters(), lr=0.0001)\n",
    "\n",
    "optAdv = torch.optim.Adam(adv.parameters(), lr=0.0001)\n",
    "\n",
    "train_losses_adv2, test_losses_adv2, accuracy_graph_adv2 = [], [], []\n",
    "sample_images_adv2=[]\n",
    "sample_masked_adv2=[]\n",
    "sample_mask_adv2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klduniform(p):\n",
    "    maxp=torch.nn.MaxPool2d(6, stride=5)\n",
    "    p=maxp(p.view(-1, 1, 28, 28))\n",
    "    q=torch.ones(p.shape) * torch.mean(p)\n",
    "    kl=p*torch.log(p/q)    \n",
    "    return torch.sum(kl)\n",
    "    \n",
    "def kld(p, q):\n",
    "    maxp=torch.nn.MaxPool2d(6, stride=5)\n",
    "    p=maxp(p.view(-1, 1, 28, 28))\n",
    "    q=maxp(q.view(-1, 1, 28, 28))\n",
    "    kl=p*torch.log(p/q)    \n",
    "    return torch.sum(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UfvRgI7_FJdn",
    "outputId": "257160ea-4606-4ebf-bbd0-d7c617e09990",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5000..  Training Loss: 0.119..  Mask Loss: 0.000..  Test Loss: 0.857..  Test Accuracy: 0.833\n",
      "Epoch: 2/5000..  Training Loss: 0.089..  Mask Loss: 1.849..  Test Loss: 0.868..  Test Accuracy: 0.829\n",
      "Epoch: 3/5000..  Training Loss: 0.081..  Mask Loss: 1.843..  Test Loss: 0.887..  Test Accuracy: 0.827\n",
      "Epoch: 4/5000..  Training Loss: 0.096..  Mask Loss: 1.753..  Test Loss: 0.837..  Test Accuracy: 0.832\n",
      "Epoch: 5/5000..  Training Loss: 0.137..  Mask Loss: 1.701..  Test Loss: 0.860..  Test Accuracy: 0.831\n",
      "Epoch: 6/5000..  Training Loss: 0.101..  Mask Loss: 2.044..  Test Loss: 0.819..  Test Accuracy: 0.836\n",
      "Epoch: 7/5000..  Training Loss: 0.077..  Mask Loss: 1.675..  Test Loss: 0.836..  Test Accuracy: 0.833\n",
      "Epoch: 8/5000..  Training Loss: 0.070..  Mask Loss: 1.849..  Test Loss: 0.827..  Test Accuracy: 0.834\n",
      "Epoch: 9/5000..  Training Loss: 0.054..  Mask Loss: 1.593..  Test Loss: 0.854..  Test Accuracy: 0.829\n",
      "Epoch: 10/5000..  Training Loss: 0.087..  Mask Loss: 1.663..  Test Loss: 0.838..  Test Accuracy: 0.831\n",
      "Epoch: 11/5000..  Training Loss: 0.086..  Mask Loss: 1.708..  Test Loss: 0.828..  Test Accuracy: 0.832\n",
      "Epoch: 12/5000..  Training Loss: 0.100..  Mask Loss: 1.778..  Test Loss: 0.847..  Test Accuracy: 0.828\n",
      "Epoch: 13/5000..  Training Loss: 0.149..  Mask Loss: 1.661..  Test Loss: 0.838..  Test Accuracy: 0.833\n",
      "Epoch: 14/5000..  Training Loss: 0.113..  Mask Loss: 1.831..  Test Loss: 0.819..  Test Accuracy: 0.834\n",
      "Epoch: 15/5000..  Training Loss: 0.079..  Mask Loss: 1.587..  Test Loss: 0.826..  Test Accuracy: 0.832\n",
      "Epoch: 16/5000..  Training Loss: 0.078..  Mask Loss: 1.963..  Test Loss: 0.872..  Test Accuracy: 0.829\n",
      "Epoch: 17/5000..  Training Loss: 0.113..  Mask Loss: 1.809..  Test Loss: 0.852..  Test Accuracy: 0.831\n",
      "Epoch: 18/5000..  Training Loss: 0.089..  Mask Loss: 1.782..  Test Loss: 0.873..  Test Accuracy: 0.827\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-828c0e32df3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mcurrent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mdrop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-34db2c51c143>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[0;32m    163\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                             self.return_indices)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "previous_mask = []\n",
    "transform = transforms.Compose([transforms.GaussianBlur(kernel_size=7)])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    mask_loss = 0\n",
    "\n",
    "    i=0\n",
    "\n",
    "    for images,labels in train_loader:\n",
    "        train = Variable(images.view(-1,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "\n",
    "        optAdv.zero_grad()\n",
    "        optCNN.zero_grad()\n",
    "        \n",
    "        if(i==0 and epoch%10==0):\n",
    "            sample_images_adv2.append(train.clone().detach().numpy())\n",
    "            \n",
    "        current = 0.7\n",
    "        \n",
    "        mask = adv(train)\n",
    "        drop = nn.Dropout(p=current)\n",
    "        \n",
    "        images = images + transform(drop(mask).view(-1, 1, 28, 28)).view(-1, 784)\n",
    "        images = torch.minimum(images, torch.ones(images.shape))\n",
    "        train = Variable(images.view(-1, 1, 28, 28))\n",
    "\n",
    "        if(i==0 and epoch%10==0):\n",
    "            sample_masked_adv2.append(train.clone().detach().numpy())\n",
    "            sample_mask_adv2.append(mask.clone().detach().view(-1, 1, 28, 28).numpy())\n",
    "\n",
    "        output = cnn(train)\n",
    "        \n",
    "        \n",
    "        if(i%3==0 and epoch>0):\n",
    "            lossAdv = - torch.log(criterion(output, labels)) -  klduniform(mask) - kld(mask, previous_mask)\n",
    "            lossAdv.backward()\n",
    "            optAdv.step()\n",
    "            mask_loss += lossAdv.item()\n",
    "          \n",
    "        else:\n",
    "            lossCNN = criterion(output, labels)\n",
    "            lossCNN.backward()\n",
    "            optCNN.step()\n",
    "            running_loss += lossCNN.item()\n",
    "          \n",
    "        i+=1\n",
    "        previous_mask = mask.clone().detach()\n",
    "\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad(): #Turning off gradients to speed up\n",
    "            cnn.eval()\n",
    "            for images,labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(-1,1,28,28))\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "                log_ps = cnn(test)\n",
    "                test_loss += criterion(log_ps,labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim = 1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        cnn.train()        \n",
    "        train_losses_adv2.append(running_loss/len(train_loader))\n",
    "        test_losses_adv2.append(test_loss/len(test_loader))\n",
    "        accuracy_graph_adv2.append(accuracy/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Mask Loss: {:.3f}.. \".format(mask_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "Q9MJaKRSXtaH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x202c12361f0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses_adv2, label='Training loss')\n",
    "plt.plot(test_losses_adv2, label='Validation loss')\n",
    "plt.plot(accuracy_graph_adv2, label='Accuracy')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "577r3NvoXu9e"
   },
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "XPdtoneIL3J0",
    "outputId": "e89f41e1-b92b-4862-c80d-ab43cbf26b9c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_images_gcnn2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-79a563bfa895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0maxarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_images_gcnn2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0maxarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_masked_gcnn2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_images_gcnn2' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display image next to mask\n",
    "\n",
    "epoch = 1000\n",
    "image = 5\n",
    "\n",
    "f, axarr = plt.subplots(2)\n",
    "\n",
    "axarr[0].imshow(sample_images_gcnn[epoch][image][0])\n",
    "axarr[1].imshow(sample_masked_gcnn[epoch][image][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "T8tOh1p5L6tK",
    "outputId": "9af3e6c0-b8a1-425c-ea7c-7cf87f4c42b1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_images_adv1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-fdc9ed6ee065>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0maxarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_images_adv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0maxarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_masked_adv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0maxarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_mask_adv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_images_adv1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 10\n",
    "image = 0\n",
    "\n",
    "f, axarr = plt.subplots(1,3)\n",
    "\n",
    "axarr[0].imshow(sample_images_adv1[epoch][image][0])\n",
    "axarr[1].imshow(sample_masked_adv1[epoch][image][0])\n",
    "axarr[2].imshow(sample_mask_adv1[epoch][image][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "D3IqnF7iL7L3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x202cac7a700>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = 482\n",
    "image = 0\n",
    "\n",
    "# transform = transforms.Compose([transforms.GaussianBlur(kernel_size=5)])\n",
    "# blur = transform(torch.from_numpy(sample_mask_adv2[epoch][image][0]).view(1, 28, 28)).view(28, 28).numpy()\n",
    "\n",
    "f, axarr = plt.subplots(1,3)\n",
    "\n",
    "axarr[0].imshow(sample_images_adv2[epoch][image][0])\n",
    "axarr[1].imshow(sample_masked_adv2[epoch][image][0])\n",
    "axarr[2].imshow(np.clip(sample_mask_adv2[epoch][image][0], 0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "id": "Dtcp28bLL7yD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 1.        , 0.71428571, 0.        , 1.        ,\n",
       "        0.71428571, 0.        , 1.        , 0.71428571, 0.        ,\n",
       "        1.        , 0.71428571, 1.        , 0.        , 0.71428571,\n",
       "        0.73539753, 0.71428571, 1.        , 0.71428571, 0.        ,\n",
       "        0.        , 1.        , 0.71428571],\n",
       "       [0.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.71428571, 1.        , 0.        , 0.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.        , 1.        , 1.        ,\n",
       "        0.71428571, 0.        , 0.71428571, 0.        , 1.        ,\n",
       "        0.71428571, 0.        , 0.71428571],\n",
       "       [0.71428571, 0.        , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.        , 1.        , 1.        ,\n",
       "        0.71428571, 0.        , 0.71428571, 0.        , 0.        ,\n",
       "        0.71428571, 0.        , 0.71428571, 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.71428571, 0.71428571, 0.        ,\n",
       "        0.71428571, 0.71428571, 1.        ],\n",
       "       [0.        , 0.71428571, 0.        , 0.71428571, 0.        ,\n",
       "        0.71428571, 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 1.        , 0.29803922,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.75703533,\n",
       "        0.71428571, 0.71428571, 0.        , 0.71428571, 0.        ,\n",
       "        0.        , 0.71428571, 0.71428571],\n",
       "       [0.        , 0.71428571, 0.71428571, 0.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.        , 1.        ,\n",
       "        0.71428571, 0.55294118, 0.98823529, 0.98823529, 1.        ,\n",
       "        0.71428571, 0.        , 0.71428571, 0.71428571, 0.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 1.        ],\n",
       "       [0.        , 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.        , 0.71428571, 0.71428571, 0.71428571, 1.        ,\n",
       "        0.21568627, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.        , 0.71428571,\n",
       "        0.71428571, 0.        , 0.85273887, 0.71644454, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571],\n",
       "       [0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.        , 0.71428571, 0.        , 0.71428571,\n",
       "        0.70980392, 1.        , 1.        , 0.39607843, 0.03137255,\n",
       "        0.71428571, 0.        , 0.        , 0.        , 0.71428571,\n",
       "        0.71428571, 0.        , 1.        , 0.        , 0.71428571,\n",
       "        0.71428571, 0.        , 0.        ],\n",
       "       [1.        , 1.        , 0.71428571, 0.        , 1.        ,\n",
       "        1.        , 1.        , 0.71428571, 0.96903066, 0.80947398,\n",
       "        1.        , 0.92156863, 1.        , 1.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.        , 0.71428571, 0.71428571, 1.        ,\n",
       "        0.71428571, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.71428571, 1.        ,\n",
       "        0.        , 1.        , 0.        , 0.71428571, 0.14901961,\n",
       "        1.        , 1.        , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.        , 0.71428571,\n",
       "        0.        , 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.        , 0.71428571, 0.        ],\n",
       "       [0.        , 0.86944895, 1.        , 0.83543827, 0.71428571,\n",
       "        1.        , 0.71428571, 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.        , 0.71428571, 0.        ,\n",
       "        0.        , 0.        , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 1.        ],\n",
       "       [0.71428571, 0.71428571, 0.71428571, 1.        , 0.        ,\n",
       "        1.        , 0.71428571, 0.71428571, 0.        , 1.        ,\n",
       "        0.98823529, 1.        , 0.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.        , 0.71428571, 0.        ,\n",
       "        0.        , 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.        , 0.71428571, 1.        ],\n",
       "       [1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "        0.98823529, 1.        , 0.        , 0.71428571, 0.        ,\n",
       "        0.71428571, 0.        , 0.71428571, 0.        , 0.71428571,\n",
       "        1.        , 0.71428571, 0.71428571, 0.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571],\n",
       "       [0.        , 0.        , 0.71428571, 0.        , 0.71428571,\n",
       "        0.        , 0.71428571, 0.71428571, 0.71428571, 1.        ,\n",
       "        1.        , 0.68235294, 0.71428571, 0.71428571, 0.        ,\n",
       "        0.        , 1.        , 1.        , 0.40784314, 0.        ,\n",
       "        1.        , 0.71428571, 0.        , 0.        , 0.71428571,\n",
       "        0.        , 0.71428571, 0.71428571],\n",
       "       [1.        , 0.71428571, 0.71428571, 0.71428571, 0.        ,\n",
       "        1.        , 1.        , 1.        , 0.71428571, 0.64313725,\n",
       "        1.        , 0.70588235, 0.71428571, 0.45098039, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99215686, 0.99215686,\n",
       "        0.65490196, 0.14509804, 0.        , 0.        , 0.71428571,\n",
       "        0.71428571, 0.        , 0.71428571],\n",
       "       [0.71428571, 1.        , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.        , 0.        , 0.71428571, 0.        , 0.19215686,\n",
       "        0.98823529, 0.70588235, 0.74957983, 0.8627451 , 1.        ,\n",
       "        0.98823529, 0.42745098, 1.        , 1.        , 1.        ,\n",
       "        0.98823529, 0.73333333, 0.73389356, 0.        , 0.        ,\n",
       "        0.71428571, 0.71428571, 1.        ],\n",
       "       [0.93545834, 0.78583343, 0.        , 0.71428571, 0.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.90644258,\n",
       "        1.        , 1.        , 1.        , 0.98823529, 1.        ,\n",
       "        0.37647059, 0.71428571, 0.        , 0.71428571, 0.78879552,\n",
       "        1.        , 1.        , 1.        , 0.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571],\n",
       "       [0.71428571, 0.        , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.        , 0.71428571, 0.71428571, 0.0627451 ,\n",
       "        1.        , 1.        , 0.83137255, 1.        , 0.89859944,\n",
       "        0.        , 0.71428571, 0.        , 0.71428571, 0.        ,\n",
       "        1.        , 0.98823529, 0.65490196, 1.        , 0.71428571,\n",
       "        0.71428571, 0.        , 0.71428571],\n",
       "       [0.71428571, 0.71428571, 0.71428571, 0.        , 0.71428571,\n",
       "        1.        , 1.        , 0.        , 0.71428571, 0.71428571,\n",
       "        1.        , 1.        , 0.98823529, 0.98823529, 1.        ,\n",
       "        1.        , 0.        , 0.71428571, 0.71428571, 0.71428571,\n",
       "        1.        , 1.        , 0.65490196, 0.71428571, 0.        ,\n",
       "        0.71428571, 0.        , 0.71428571],\n",
       "       [0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.        ,\n",
       "        1.        , 0.        , 1.        , 0.71428571, 0.        ,\n",
       "        0.57254902, 1.        , 1.        , 0.98823529, 0.56078431,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.        , 0.        ,\n",
       "        1.        , 1.        , 0.29803922, 0.71428571, 1.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.71428571, 0.        , 0.        , 0.71428571, 0.        ,\n",
       "        0.71428571, 0.71428571, 1.        , 0.71428571, 0.71428571,\n",
       "        0.76134454, 1.        , 0.98823529, 0.98823529, 1.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 1.        ,\n",
       "        0.9372549 , 1.        , 0.03529412, 0.71428571, 0.        ,\n",
       "        1.        , 0.71428571, 0.71428571],\n",
       "       [0.71428571, 0.        , 0.        , 0.71428571, 0.71428571,\n",
       "        0.71752426, 0.71428571, 0.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.24313725, 0.91764706, 1.        , 0.92941176,\n",
       "        0.62352941, 1.        , 0.38039216, 1.        , 1.        ,\n",
       "        0.89803922, 1.        , 1.        , 0.71428571, 0.        ,\n",
       "        0.71428571, 0.71428571, 0.        ],\n",
       "       [0.71428571, 0.71428571, 0.71428571, 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.78879552, 0.65882353, 1.        ,\n",
       "        0.98823529, 1.        , 1.        , 0.98823529, 0.98823529,\n",
       "        1.        , 0.71428571, 1.        , 0.        , 0.        ,\n",
       "        0.71428571, 1.        , 1.        ],\n",
       "       [0.71428571, 0.71428571, 0.71428571, 0.        , 1.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.        , 0.        ,\n",
       "        0.        , 0.71428571, 0.71428571, 0.73389356, 0.96134454,\n",
       "        1.        , 0.51764706, 1.        , 0.92156863, 1.        ,\n",
       "        0.86330532, 0.        , 0.        , 1.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571],\n",
       "       [0.71428571, 0.        , 0.        , 0.71428571, 1.        ,\n",
       "        1.        , 0.71428571, 0.71428571, 0.71428571, 0.        ,\n",
       "        1.        , 0.81845873, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.71428571, 0.        , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.        ],\n",
       "       [0.77038217, 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.71428571, 0.71428571, 1.        , 0.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.        , 0.71428571,\n",
       "        0.        , 0.71428571, 1.        , 0.        , 0.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571],\n",
       "       [0.71428571, 1.        , 1.        , 0.        , 0.71428571,\n",
       "        0.        , 0.        , 0.71428571, 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.71428571, 0.71428571, 0.        ,\n",
       "        0.        , 0.71428571, 1.        , 0.71428571, 0.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.88354126],\n",
       "       [0.71428571, 1.        , 0.        , 1.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 1.        , 0.71428571, 0.        ,\n",
       "        0.        , 0.71428571, 0.        , 0.        , 0.71428571,\n",
       "        0.71428571, 0.        , 1.        , 0.71428571, 1.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.        , 1.        ],\n",
       "       [0.71428571, 0.71428571, 1.        , 0.71428571, 0.71428571,\n",
       "        1.        , 0.        , 0.71428571, 0.74692705, 0.        ,\n",
       "        0.71428571, 1.        , 0.        , 0.        , 0.71428571,\n",
       "        1.        , 0.71428571, 0.71428571, 0.        , 0.71428571,\n",
       "        0.        , 1.        , 1.        , 0.71428571, 0.71428571,\n",
       "        1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_masked_adv2[epoch][image][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.8962e-01,  5.2245e-02, -1.0626e-01,  6.8432e-01,  6.9485e-01,\n",
       "           5.8065e-01,  6.4448e-01,  8.8485e-01,  7.1800e-01,  3.8096e-01,\n",
       "           5.7106e-01,  7.3791e-01,  1.9029e-01,  3.2319e-01,  8.6475e-01,\n",
       "           8.7977e-01,  4.8084e-01,  3.8043e-01,  1.7568e-01,  5.6528e-01,\n",
       "           8.6474e-01,  5.3652e-01, -2.2389e-02,  1.4896e-01,  5.8102e-01,\n",
       "           7.0135e-01,  7.4971e-03, -1.1618e-01],\n",
       "         [ 2.2806e-01,  4.1010e-01,  4.9684e-02,  4.6069e-01,  2.2283e-01,\n",
       "           1.4983e-01,  1.6723e-01,  8.0011e-01,  9.2075e-01,  6.9052e-01,\n",
       "           3.7219e-01,  7.7890e-01,  7.3578e-01,  8.0363e-01,  9.2549e-01,\n",
       "           6.4868e-01, -2.9933e-02, -3.0974e-02,  3.3752e-01,  4.0230e-01,\n",
       "           6.2164e-01,  3.1229e-01, -1.2613e-02,  2.5969e-01,  4.2025e-01,\n",
       "           6.0486e-01,  3.6202e-01,  5.0456e-01],\n",
       "         [ 1.2448e-01,  3.5685e-01, -1.8863e-01, -9.1104e-02, -1.5623e-01,\n",
       "           3.5350e-01,  6.6370e-03,  6.2988e-01,  9.6035e-01,  9.1075e-01,\n",
       "           6.8084e-01,  9.0770e-01,  9.7801e-01,  9.9070e-01,  8.6692e-01,\n",
       "           4.1713e-01,  2.9242e-01, -1.0480e-01, -1.8200e-02,  4.1343e-01,\n",
       "           3.5962e-01,  5.1751e-01,  5.2679e-01,  8.9311e-02,  3.7924e-01,\n",
       "           4.0555e-01,  7.3963e-01,  8.8402e-01],\n",
       "         [ 5.3720e-01,  1.8732e-01, -8.9432e-02,  2.0616e-01, -9.8396e-02,\n",
       "           5.1919e-01,  1.4213e-01,  3.4261e-01,  8.0675e-01,  9.6703e-01,\n",
       "           9.4927e-01,  9.3122e-01,  8.3918e-01,  9.5574e-01,  9.1388e-01,\n",
       "           5.2160e-01,  6.3718e-02, -1.5229e-01, -2.5507e-02,  2.7495e-01,\n",
       "           4.6914e-01,  2.2342e-01,  4.1112e-01, -1.0767e-02,  8.5926e-02,\n",
       "           4.4295e-01,  8.2995e-01,  8.2267e-01],\n",
       "         [ 8.1939e-01,  4.6090e-01,  9.5077e-02,  3.8411e-01,  1.9345e-01,\n",
       "           5.9888e-01,  2.0242e-01,  4.7369e-01,  6.2626e-01,  7.9938e-01,\n",
       "           9.5088e-01,  7.6544e-01,  2.9052e-01,  7.4666e-01,  6.1414e-01,\n",
       "           1.6478e-01,  1.6275e-01,  3.9822e-01,  5.2466e-01,  5.2347e-01,\n",
       "           3.2810e-01,  3.1196e-01, -2.7035e-02,  5.1696e-01,  5.5127e-01,\n",
       "           5.0838e-02,  4.7707e-01,  3.6301e-01],\n",
       "         [ 5.4271e-01,  1.1348e-01,  4.6604e-01,  3.9883e-01,  7.0829e-01,\n",
       "           7.8032e-01,  1.8633e-01,  2.2193e-01,  6.0523e-01,  3.3643e-01,\n",
       "           7.0722e-01,  7.8691e-01,  3.3977e-01,  4.8606e-01,  1.6098e-01,\n",
       "           5.9492e-01,  6.5041e-01,  9.5065e-02, -2.1211e-02,  1.3849e-01,\n",
       "          -4.7380e-02,  8.1472e-02,  3.3424e-02,  7.1016e-01,  6.0906e-01,\n",
       "           1.0562e-01,  1.3018e-01,  3.9837e-01],\n",
       "         [ 5.1418e-01,  8.6401e-02,  6.0081e-01,  8.2693e-01,  9.2849e-01,\n",
       "           7.6664e-01,  4.5913e-01,  4.9557e-01,  6.7443e-01,  3.5768e-02,\n",
       "           1.4982e-01,  5.9185e-01,  6.2438e-01,  3.0938e-01,  4.7638e-01,\n",
       "           7.8457e-01,  9.1512e-01,  6.2490e-01,  1.7013e-01,  4.3798e-01,\n",
       "           5.4596e-01,  6.5873e-01,  5.6147e-01,  4.5232e-01, -9.2056e-02,\n",
       "           2.2785e-01,  3.3602e-02,  1.5576e-01],\n",
       "         [ 4.2347e-01, -1.5899e-01,  2.2819e-01,  7.5592e-01,  8.3481e-01,\n",
       "           4.8754e-01,  7.6812e-01,  8.6265e-01,  6.6530e-01,  2.2854e-02,\n",
       "          -2.0016e-01, -1.8166e-01,  4.0976e-01,  2.6452e-01,  2.1847e-01,\n",
       "           3.7264e-01,  6.9727e-01,  7.4590e-01,  6.4474e-01,  2.2940e-01,\n",
       "           2.5805e-01,  5.2049e-01,  1.0156e-01, -2.8348e-01, -4.6440e-01,\n",
       "          -3.2956e-01, -4.4883e-02,  4.5830e-01],\n",
       "         [ 5.0476e-01,  1.1944e-01,  4.1954e-01,  4.6265e-01,  6.8806e-01,\n",
       "           7.0000e-01,  8.2665e-01,  7.3192e-01,  4.7395e-01,  3.6422e-01,\n",
       "          -1.6695e-01, -3.7608e-01,  1.1814e-02,  5.9061e-01,  7.4415e-01,\n",
       "           5.4239e-01,  1.1140e-01,  1.7681e-01,  7.4605e-01,  6.6263e-01,\n",
       "           5.5796e-01,  1.9025e-01,  4.6364e-01,  1.6217e-01, -1.2312e-02,\n",
       "          -3.9860e-01, -8.4582e-02,  5.6189e-01],\n",
       "         [ 5.3052e-01,  3.8899e-02,  2.4479e-01,  4.7169e-01,  4.4254e-01,\n",
       "           7.2401e-01,  4.5099e-01,  3.6268e-01,  6.1542e-01,  3.9687e-01,\n",
       "           4.1297e-01, -1.9052e-02,  4.0548e-01,  4.2864e-01,  5.8119e-01,\n",
       "           1.8341e-01,  4.6379e-02,  5.8541e-01,  6.8878e-01,  4.6066e-01,\n",
       "           6.1980e-01,  1.4927e-01,  5.7021e-01,  8.0276e-01,  6.5924e-01,\n",
       "           1.1731e-01,  4.5124e-01,  7.5230e-01],\n",
       "         [ 3.8323e-01, -7.9639e-03,  3.1244e-01,  2.9581e-01,  7.1100e-01,\n",
       "           7.9282e-01,  3.0706e-01,  5.2332e-01,  7.3587e-01,  8.0426e-01,\n",
       "           6.7893e-01,  1.2603e-01,  4.8362e-01, -1.4265e-01,  6.8886e-02,\n",
       "           2.3103e-01,  6.0191e-01,  6.7475e-01,  4.2368e-01,  6.4662e-01,\n",
       "           7.6838e-01,  2.4595e-01,  1.1627e-01,  5.8689e-01,  7.4486e-01,\n",
       "           5.1643e-01,  2.3240e-01,  2.7944e-01],\n",
       "         [ 1.3869e-01,  1.0754e-02,  1.2726e-01,  6.3660e-01,  9.3370e-01,\n",
       "           8.9563e-01,  5.1506e-01,  1.8008e-01,  2.3736e-01,  6.8916e-01,\n",
       "           6.9409e-01,  2.3762e-01,  4.5233e-01,  1.7010e-02,  4.2640e-01,\n",
       "           6.8653e-01,  7.2198e-01,  2.7008e-01,  5.5741e-01,  4.5470e-01,\n",
       "           6.4893e-01,  5.7349e-01,  4.0938e-01,  6.0362e-02,  1.5905e-01,\n",
       "           6.1127e-02,  4.7792e-02,  3.2033e-02],\n",
       "         [ 6.8064e-01,  5.1313e-01,  4.9436e-01,  7.5814e-01,  7.1678e-01,\n",
       "           6.0427e-01,  1.1762e-01,  9.3803e-02,  5.2283e-01,  4.4969e-01,\n",
       "           8.0440e-01,  6.9138e-01,  3.0359e-01,  3.5168e-01,  2.4767e-01,\n",
       "           4.5235e-01,  6.2592e-01,  5.0213e-02,  5.4326e-01,  8.8504e-02,\n",
       "          -5.3094e-02, -1.9549e-01,  8.0100e-02,  5.8233e-01,  5.8749e-01,\n",
       "           5.8168e-02, -9.0133e-02,  3.7423e-01],\n",
       "         [ 4.7321e-01,  2.0898e-01,  3.4940e-01,  6.2283e-01, -4.1432e-02,\n",
       "          -3.5742e-02,  3.1953e-01,  2.8564e-01,  7.4754e-01,  6.6748e-01,\n",
       "           7.5260e-01,  7.5275e-01,  5.3626e-02, -1.0113e-01,  2.0095e-01,\n",
       "           7.2580e-01,  7.3833e-01,  1.1398e-01,  4.7091e-01,  3.0154e-01,\n",
       "           9.7314e-02, -1.4680e-01, -1.0241e-01,  5.9278e-01,  7.5984e-01,\n",
       "           6.7302e-01,  4.3183e-01,  5.8538e-01],\n",
       "         [ 1.5657e-01,  4.5908e-01,  2.5088e-01,  3.9456e-01, -1.2104e-01,\n",
       "          -1.9855e-01,  1.8685e-01,  5.8711e-01,  7.7426e-01,  2.7717e-01,\n",
       "           1.6908e-01,  4.2114e-01, -5.4600e-02, -6.5159e-03,  5.0724e-01,\n",
       "           8.6871e-01,  9.3360e-01,  6.4288e-01,  1.6589e-01,  1.7860e-01,\n",
       "           5.9884e-01,  4.3294e-01,  5.3376e-02,  8.9008e-03,  1.0873e-01,\n",
       "           4.6798e-01,  2.5358e-01,  1.5058e-01],\n",
       "         [ 6.6650e-01,  7.1202e-01,  6.5299e-02, -4.9824e-02,  2.3442e-01,\n",
       "           1.4266e-01,  3.0772e-01,  1.9827e-01,  6.8364e-01,  6.1829e-01,\n",
       "           5.2032e-01, -6.4386e-02, -4.2380e-02,  3.5401e-01,  2.5799e-01,\n",
       "           5.7820e-01,  7.1294e-01,  6.6055e-01,  4.0899e-01,  3.1695e-01,\n",
       "           6.4695e-01,  2.2483e-01,  3.6027e-01,  1.0356e-01,  2.4979e-02,\n",
       "           1.9915e-02,  5.7390e-01,  7.5305e-01],\n",
       "         [ 6.1095e-01,  8.4731e-01,  7.7538e-01,  5.1329e-01, -8.1256e-03,\n",
       "           3.0491e-01, -6.1728e-02, -1.9969e-01,  3.8500e-01,  1.3513e-01,\n",
       "           4.9252e-01,  2.5260e-01,  3.6899e-01,  3.3666e-01,  3.3321e-01,\n",
       "          -1.5672e-01, -2.2591e-01, -1.3969e-01, -1.0944e-01,  6.2233e-01,\n",
       "           9.1140e-01,  6.5056e-01,  3.1548e-01,  6.4159e-01,  5.8862e-01,\n",
       "           5.8177e-02,  4.9298e-01,  8.4533e-01],\n",
       "         [ 1.8239e-01,  7.6214e-01,  9.4665e-01,  7.5396e-01,  1.8124e-01,\n",
       "           2.3582e-01,  1.6424e-01,  2.0637e-01,  5.9572e-01,  1.4946e-01,\n",
       "           2.8545e-01,  4.0564e-01,  7.5052e-02,  3.2614e-01,  5.7403e-02,\n",
       "          -1.2397e-01,  3.3200e-02,  4.8122e-01,  3.7826e-01,  6.2174e-01,\n",
       "           7.8750e-01,  7.1594e-01,  5.2021e-02,  4.8847e-01,  6.3643e-01,\n",
       "           8.4726e-02,  1.8347e-01,  5.2899e-01],\n",
       "         [ 1.8721e-01,  7.4076e-01,  8.1010e-01,  7.1114e-01,  6.6680e-01,\n",
       "           6.3797e-01,  5.9140e-02, -1.0910e-01,  7.0590e-01,  8.1294e-01,\n",
       "           6.4858e-01,  3.0859e-02, -2.2777e-01,  5.4360e-02,  8.1721e-03,\n",
       "           4.4898e-01,  7.3625e-01,  7.9772e-01,  6.8794e-01,  6.3426e-02,\n",
       "          -5.1441e-04,  3.8752e-01, -1.5520e-01, -5.4742e-02,  4.0102e-01,\n",
       "           1.6275e-01,  2.3908e-01,  1.6614e-01],\n",
       "         [ 1.0842e-01,  7.1242e-01,  7.7302e-01,  6.3007e-01,  4.9664e-01,\n",
       "           8.3047e-01,  5.4639e-01, -1.2842e-01,  4.8894e-01,  7.7670e-01,\n",
       "           6.0270e-01, -5.9206e-02,  3.9222e-02,  4.4676e-01,  4.9214e-01,\n",
       "           8.4079e-01,  8.5422e-01,  4.6770e-01,  4.8314e-01, -2.1273e-01,\n",
       "          -4.2556e-01, -1.3437e-01,  2.8334e-01,  3.8642e-01,  1.2759e-01,\n",
       "           3.0741e-01,  1.7126e-01,  3.8702e-01],\n",
       "         [ 2.5697e-01,  6.6276e-01,  3.1102e-01,  9.3415e-02,  5.2027e-01,\n",
       "           7.2332e-01,  4.9302e-01, -2.7854e-01, -1.3517e-01,  2.0527e-01,\n",
       "           1.8392e-01, -1.4249e-02,  4.2056e-01,  3.3675e-01,  7.6432e-01,\n",
       "           9.7907e-01,  9.2191e-01,  5.4811e-01,  7.8692e-02, -3.0572e-01,\n",
       "          -4.1739e-01, -2.8251e-01,  5.5745e-02,  7.2033e-01,  6.1202e-01,\n",
       "           1.1476e-01,  1.1269e-01,  5.9084e-01],\n",
       "         [ 5.5945e-01,  6.5707e-01,  5.9420e-01,  1.3449e-02, -2.0638e-02,\n",
       "          -7.9722e-02, -1.5666e-01, -2.5488e-01,  3.4673e-01,  7.0640e-01,\n",
       "           4.3520e-01, -1.0420e-01,  4.9645e-01,  3.0375e-01,  7.6177e-01,\n",
       "           8.3652e-01,  6.6140e-01,  2.2055e-01,  1.9966e-01,  2.9026e-01,\n",
       "          -9.4190e-02,  2.3813e-01,  6.4615e-01,  8.2118e-01,  8.8683e-01,\n",
       "           7.4042e-01,  6.4133e-01,  7.5405e-01],\n",
       "         [-4.2052e-02,  6.1576e-03,  4.5753e-01,  6.6489e-02, -7.5330e-02,\n",
       "          -9.9408e-02, -1.7618e-01, -1.5572e-01, -9.8767e-03,  5.2385e-01,\n",
       "           2.3373e-01, -6.3306e-02,  5.8462e-01,  3.7898e-01,  5.3861e-01,\n",
       "           2.5896e-01,  2.4792e-01,  6.0526e-01,  6.9266e-01,  4.7305e-01,\n",
       "           5.4546e-01,  4.2107e-01,  7.2304e-01,  5.2701e-01,  7.5114e-01,\n",
       "           8.3738e-01,  4.1562e-01,  3.2174e-01],\n",
       "         [ 6.7092e-01,  4.8684e-01,  5.2936e-02, -5.6203e-02,  4.9684e-01,\n",
       "           5.7286e-01,  6.5799e-01,  4.3739e-01, -9.2215e-02,  1.1744e-01,\n",
       "           6.4311e-01,  7.4026e-01,  9.0549e-01,  7.9615e-01,  4.7074e-01,\n",
       "           8.3734e-02,  4.3866e-01,  6.9946e-01,  6.3282e-01,  5.6187e-01,\n",
       "           5.7821e-01,  2.4955e-01,  6.8518e-01,  6.9871e-01,  3.7724e-01,\n",
       "           7.5751e-01,  6.4034e-01,  3.6427e-01],\n",
       "         [ 7.6327e-01,  5.0274e-01,  8.0808e-02,  8.2987e-02,  6.3924e-01,\n",
       "           4.5559e-01,  6.8674e-01,  3.2277e-01,  4.5363e-01,  3.3502e-01,\n",
       "           7.9398e-01,  8.3779e-01,  9.2694e-01,  9.2498e-01,  5.5109e-01,\n",
       "          -4.9110e-02, -2.7612e-02, -9.8637e-04, -6.4725e-02, -2.0858e-01,\n",
       "           1.0445e-02, -4.0831e-02,  3.2818e-01,  7.1025e-01,  3.2580e-01,\n",
       "           5.0284e-01,  5.7828e-01,  6.9988e-01],\n",
       "         [ 5.1902e-01,  6.9161e-01,  6.5536e-01,  7.6312e-01,  9.0089e-01,\n",
       "           8.0388e-01,  6.4025e-01,  3.6631e-01,  7.4624e-01,  6.7637e-01,\n",
       "           7.3689e-01,  3.7800e-01,  6.6928e-01,  6.7204e-01,  3.4384e-01,\n",
       "           6.0295e-01,  5.5468e-01,  1.9533e-01,  3.8420e-01, -5.3664e-02,\n",
       "           2.6997e-01, -1.0912e-01,  1.6736e-01,  6.2985e-01,  6.2329e-01,\n",
       "           3.6093e-01,  6.9617e-01,  7.9173e-01],\n",
       "         [ 3.2798e-01,  6.1074e-01,  3.4671e-01,  6.6413e-01,  8.4614e-01,\n",
       "           5.7724e-01,  1.7566e-01,  6.5099e-01,  6.6312e-01,  1.8988e-01,\n",
       "           4.8434e-01,  2.9056e-01,  4.9308e-01,  4.5295e-01,  6.8902e-01,\n",
       "           7.8688e-01,  7.8914e-01,  7.9766e-01,  7.2119e-01,  1.9452e-03,\n",
       "           8.7406e-02,  1.7351e-01,  4.6391e-01,  1.5019e-01,  5.7082e-01,\n",
       "           6.6087e-01,  7.3388e-01,  3.4021e-01],\n",
       "         [ 6.5617e-01,  6.7784e-01,  1.7850e-01,  2.3298e-01,  6.1370e-01,\n",
       "           2.9192e-02, -3.5017e-02,  6.7220e-01,  4.0087e-01, -6.9110e-03,\n",
       "           2.7809e-01,  1.0349e-01,  3.3734e-01,  6.2876e-01,  7.9181e-01,\n",
       "           4.7215e-01,  7.7083e-01,  9.2753e-01,  7.4652e-01, -1.2109e-01,\n",
       "          -1.8109e-01,  4.9398e-01,  6.7108e-01,  5.8734e-02,  1.5975e-01,\n",
       "           2.9995e-01,  6.4814e-01,  2.7244e-01]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.GaussianBlur(kernel_size=3)])\n",
    "transform(torch.from_numpy(sample_mask_adv2[epoch][image][0]).view(1, 28, 28)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x202cb225e80>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.ceil(train[0][0].numpy()+0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x202cb033b80>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a= np.random.rand(28,28)\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST AdvCnn v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
